{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":0,"renderable":0},{"_id":"source/alipay.png","path":"alipay.png","modified":0,"renderable":0},{"_id":"source/wechatpay.png","path":"wechatpay.png","modified":0,"renderable":0},{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":0,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/apple-touch-icon-next.png","path":"images/apple-touch-icon-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/avatar.png","path":"images/avatar.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-32x32-next.png","path":"images/favicon-32x32-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/favicon-16x16-next.png","path":"images/favicon-16x16-next.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/logo.svg","path":"images/logo.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/gzh.png","path":"images/gzh.png","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":0,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":0,"renderable":1},{"_id":"themes/next/source/404/images/bird.png","path":"404/images/bird.png","modified":0,"renderable":1},{"_id":"themes/next/source/404/images/san.png","path":"404/images/san.png","modified":0,"renderable":1},{"_id":"themes/next/source/404/images/yun1.png","path":"404/images/yun1.png","modified":0,"renderable":1},{"_id":"themes/next/source/404/images/yun0.png","path":"404/images/yun0.png","modified":0,"renderable":1},{"_id":"themes/next/source/404/images/yun2.png","path":"404/images/yun2.png","modified":0,"renderable":1},{"_id":"themes/next/source/404/css/404.css","path":"404/css/404.css","modified":0,"renderable":1},{"_id":"themes/next/source/404/css/index.css","path":"404/css/index.css","modified":0,"renderable":1},{"_id":"themes/next/source/404/css/public.css","path":"404/css/public.css","modified":0,"renderable":1},{"_id":"themes/next/source/about/css/style.css","path":"about/css/style.css","modified":0,"renderable":1},{"_id":"themes/next/source/about/images/arrow.png","path":"about/images/arrow.png","modified":0,"renderable":1},{"_id":"themes/next/source/about/images/avatar.jpg","path":"about/images/avatar.jpg","modified":0,"renderable":1},{"_id":"themes/next/source/about/images/bg-down-arrow.png","path":"about/images/bg-down-arrow.png","modified":0,"renderable":1},{"_id":"themes/next/source/about/images/avatar@2x.jpg","path":"about/images/avatar@2x.jpg","modified":0,"renderable":1},{"_id":"themes/next/source/about/images/bg-tile.png","path":"about/images/bg-tile.png","modified":0,"renderable":1},{"_id":"themes/next/source/about/images/bio-icon-2.png","path":"about/images/bio-icon-2.png","modified":0,"renderable":1},{"_id":"themes/next/source/about/images/bio-icon-1.png","path":"about/images/bio-icon-1.png","modified":0,"renderable":1},{"_id":"themes/next/source/about/images/bio-icon-3.png","path":"about/images/bio-icon-3.png","modified":0,"renderable":1},{"_id":"themes/next/source/about/images/bio-text-2.png","path":"about/images/bio-text-2.png","modified":0,"renderable":1},{"_id":"themes/next/source/about/images/bio-text-1.png","path":"about/images/bio-text-1.png","modified":0,"renderable":1},{"_id":"themes/next/source/about/images/bio-text-3.png","path":"about/images/bio-text-3.png","modified":0,"renderable":1},{"_id":"themes/next/source/about/images/home-bg.jpg","path":"about/images/home-bg.jpg","modified":0,"renderable":1},{"_id":"themes/next/source/about/js/global.js","path":"about/js/global.js","modified":0,"renderable":1},{"_id":"themes/next/source/about/js/jquery.stellar.min.js","path":"about/js/jquery.stellar.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/about/js/waypoints.min.js","path":"about/js/waypoints.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/about/js/js.js","path":"about/js/js.js","modified":0,"renderable":1},{"_id":"themes/next/source/about/js/password.js","path":"about/js/password.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/exturl.js","path":"js/src/exturl.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/js.cookie.js","path":"js/src/js.cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/love.js","path":"js/src/love.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scroll-cookie.js","path":"js/src/scroll-cookie.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","path":"lib/canvas-nest/canvas-nest.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","path":"lib/canvas-ribbon/canvas-ribbon.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","path":"lib/needsharebutton/font-embedded.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","path":"lib/needsharebutton/needsharebutton.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","path":"lib/needsharebutton/needsharebutton.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","path":"lib/pace/pace-theme-barber-shop.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","path":"lib/pace/pace-theme-big-counter.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","path":"lib/pace/pace-theme-center-atom.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","path":"lib/pace/pace-theme-bounce.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","path":"lib/pace/pace-theme-center-radar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","path":"lib/pace/pace-theme-center-circle.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","path":"lib/pace/pace-theme-center-simple.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","path":"lib/pace/pace-theme-fill-left.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","path":"lib/pace/pace-theme-corner-indicator.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","path":"lib/pace/pace-theme-flash.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","path":"lib/pace/pace-theme-mac-osx.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","path":"lib/pace/pace-theme-loading-bar.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace.min.js","path":"lib/pace/pace.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","path":"lib/pace/pace-theme-minimal.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","path":"lib/three/canvas_lines.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","path":"lib/three/canvas_sphere.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three-waves.min.js","path":"lib/three/three-waves.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":0,"renderable":1},{"_id":"themes/next/source/404/js/jquery-1.7.2.min.js","path":"404/js/jquery-1.7.2.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/about/js/jquery-1.9.1.min.js","path":"about/js/jquery-1.9.1.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":0,"renderable":1},{"_id":"source/images/2021/07/26/f69f0940-edea-11eb-9787-e1cba314367a.png","path":"images/2021/07/26/f69f0940-edea-11eb-9787-e1cba314367a.png","modified":0,"renderable":0},{"_id":"themes/next/source/about/images/works/91zaojia.jpg","path":"about/images/works/91zaojia.jpg","modified":0,"renderable":1},{"_id":"themes/next/source/about/images/works/cv.jpg","path":"about/images/works/cv.jpg","modified":0,"renderable":1},{"_id":"themes/next/source/about/images/works/ys.jpg","path":"about/images/works/ys.jpg","modified":0,"renderable":1},{"_id":"themes/next/source/about/images/works/dp.jpeg","path":"about/images/works/dp.jpeg","modified":0,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.css","path":"lib/Han/dist/han.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.css","path":"lib/Han/dist/han.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.min.js","path":"lib/Han/dist/han.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/han.js","path":"lib/Han/dist/han.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","path":"lib/Han/dist/font/han-space.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","path":"lib/Han/dist/font/han-space.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","path":"lib/Han/dist/font/han.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","path":"lib/Han/dist/font/han.woff","modified":0,"renderable":1},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","path":"lib/Han/dist/font/han.woff2","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":0,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/three/three.min.js","path":"lib/three/three.min.js","modified":0,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":0,"renderable":1},{"_id":"themes/next/source/images/b.jpg","path":"images/b.jpg","modified":0,"renderable":1}],"Cache":[{"_id":"source/404.html","hash":"8c45a71b935272fc24041153f9577fd8fd207e83","modified":1544647507854},{"_id":"source/CNAME","hash":"1b6e54a9b846deab320f0fa7c759d80708966e46","modified":1627295163239},{"_id":"source/alipay.png","hash":"80ef654693530ddf38a89b3f6815f6fe0ddb9767","modified":1544213608124},{"_id":"source/wechatpay.png","hash":"5a07fbce5516b94f8f84ab753b643059942d81b6","modified":1544213676808},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1544212560216},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1544212560217},{"_id":"themes/next/.gitattributes","hash":"44bd4729c74ccb88110804f41746fec07bf487d4","modified":1544212560218},{"_id":"themes/next/.gitignore","hash":"0b5c2ffd41f66eb1849d6426ba8cf9649eeed329","modified":1544212560222},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1544212560223},{"_id":"themes/next/.javascript_ignore","hash":"8a224b381155f10e6eb132a4d815c5b52962a9d1","modified":1544212560224},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1544212560224},{"_id":"themes/next/.travis.yml","hash":"d60d4a5375fea23d53b2156b764a99b2e56fa660","modified":1544212560226},{"_id":"themes/next/.stylintrc","hash":"b28e24704a5d8de08346c45286574c8e76cc109f","modified":1544212560225},{"_id":"themes/next/LICENSE","hash":"f293bcfcdc06c0b77ba13570bb8af55eb5c059fd","modified":1544212560227},{"_id":"themes/next/README.cn.md","hash":"2c766b3369ed477bce134a5450dab45bef161504","modified":1544212560227},{"_id":"themes/next/README.md","hash":"8ce60ce578963eb4e1eb5e33e1efc2fc4779af9c","modified":1544212560228},{"_id":"themes/next/_config.yml","hash":"e53a5881d480a105f257a14f6e5f41d2c0267f1c","modified":1544646382365},{"_id":"themes/next/bower.json","hash":"0674f11d3d514e087a176da0e1d85c2286aa5fba","modified":1544212560230},{"_id":"themes/next/gulpfile.coffee","hash":"031bffc483e417b20e90eceb6cf358e7596d2e69","modified":1544212560231},{"_id":"themes/next/package.json","hash":"036d3a1346203d2f1a3958024df7f74e7ac07bfe","modified":1544212560317},{"_id":"themes/next/.git/FETCH_HEAD","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1677648900450},{"_id":"source/about/index.html","hash":"d1b03b0115d365b3e742e044ac8e16be225b7d2b","modified":1583172431865},{"_id":"source/_posts/KDD-CUP99数据集预处理.md","hash":"93320613f7bce1769d4e9e22316fc7b775030daa","modified":1627293482514},{"_id":"source/_posts/LOL-换肤快捷工具.md","hash":"95601458ef749f68f159aa4f09936ef011eae8ad","modified":1627293482515},{"_id":"source/_posts/Nvidia-Jetson-nano-介绍.md","hash":"21c841f6e10ae28aa4006e9fbdd2108b76f3b51f","modified":1627293482515},{"_id":"source/_posts/Nvidia-Jetson-nano-配置.md","hash":"3fc5b58197c6257758783fbebfd627fd491a603c","modified":1627293665508},{"_id":"source/_posts/P图-无缝克隆.md","hash":"a148ac17a5f1265ab641e67c47f334c570f35508","modified":1627293482569},{"_id":"source/_posts/WordPress页面，分页函数调用，主题函数调用，模板函数调用.md","hash":"ed89835b8b88d305a15f74f607f514e13118158a","modified":1627293482569},{"_id":"source/_posts/The-size-of-tensor-a-(5)-must-match-the-size-of-tensor-b-(3)-at-non-singleton-dimension-3.md","hash":"d3438e9cd327303777af59f373402958913a2179","modified":1627293482569},{"_id":"source/_posts/fastai-入门视觉.md","hash":"5015685390849f864a7cdaa26703fbc236412ea7","modified":1627293482514},{"_id":"source/_posts/fastai-安装.md","hash":"7d28b341f2cf1a5c29001d40a9fb064f95ae400d","modified":1627293482513},{"_id":"source/_posts/instagan-pytorch1.1实现.md","hash":"d11794ee5d78b84bd4226065b0978c2cdcf35ebe","modified":1627293482514},{"_id":"source/_posts/php中添加html中的css，js，图片，视频等外部文件方法.md","hash":"02e2e1ab93b2473b4b80ad2773fe8abc5f9543be","modified":1627293482516},{"_id":"source/_posts/pytorch RuntimeError-expected-backend-CPU-and-dtype-Double-but-got-backend-CPU-and-dtype-Float.md","hash":"912b4f7f621bcf802696a9349f13a02a0c5570b7","modified":1627292831132},{"_id":"source/_posts/pytorch搭建网络测试时报错RuntimeError-expected-backend-CPU-and-dtype-Double-but-got-backend-CPU-and-dtype-Float.md","hash":"ddf2279df2da8eafed88acc45217b31390c4635f","modified":1627293482516},{"_id":"source/_posts/一些系统的工具.md","hash":"6005354506040e2279b4252f84f592889c96c57f","modified":1627293482584},{"_id":"source/_posts/pytorch维度报错.md","hash":"38f1bb06c4144642226728bfd7be82fe7d25c4c2","modified":1627293482568},{"_id":"source/_posts/为什么我要写博客！.md","hash":"15153f1ec66ff46f26145d913d8dda06d31f82d1","modified":1627293482582},{"_id":"source/_posts/回顾-AlexNet.md","hash":"69890e9aec27929254dcd5c54daf3a0aed6b486d","modified":1627293482575},{"_id":"source/_posts/回顾-BEGAN.md","hash":"bacc5e321cbda9f659da51e52d20556db635059b","modified":1627293482575},{"_id":"source/_posts/回顾-CNN.md","hash":"904909b0f1bc2bd0643314fa3785646f88c1223b","modified":1627293482576},{"_id":"source/_posts/回顾-DCGAN.md","hash":"7e88754131c102539b498e1133aeeaea715c2480","modified":1627293482577},{"_id":"source/_posts/回顾-DiscoGAN.md","hash":"22db63672a022ec853b5170604b548c2718221b9","modified":1627293482577},{"_id":"source/_posts/回顾-GAN.md","hash":"7c58b0c2c441c5934f8af2f612689dd36f8b44f0","modified":1627293482578},{"_id":"source/_posts/回顾-VAEGAN.md","hash":"90e7bd1a90f2fb84563831f032465b1bcff89ddc","modified":1627293482579},{"_id":"source/_posts/回顾-Resnet.md","hash":"cd962b147020ac28edb3ea1986fffe7d0889744f","modified":1627293482578},{"_id":"source/_posts/回顾-VGG.md","hash":"5454dae03c6dd3563dfd42bd074b991b816d3d93","modified":1627293482580},{"_id":"source/_posts/回顾-WGAN.md","hash":"20a7087c83bdc026094592ad232296cbc743ced7","modified":1627293482580},{"_id":"source/_posts/回顾-pix2pix.md","hash":"9ce92a4d91c6931a72cfe71da4c0ce68342c1745","modified":1627293482578},{"_id":"source/_posts/在Pytorch中正确设计dateset并加载数据集.md","hash":"f4764d9bf5781f2977c6ead20e65e67bdf454973","modified":1627293482584},{"_id":"source/_posts/基于神经网络的入侵检测提取异常行为特征—绪论.md","hash":"59c5fe8711a49955bcf6f9d90733d1c5665dfa20","modified":1627293482580},{"_id":"source/_posts/如何使用思维导图.md","hash":"c1a467fce1dd83ec0be52ebb710cbbde11a8608b","modified":1627293855989},{"_id":"source/_posts/将数据归一化到任意区间范围的方法.md","hash":"de49a9c17d8dfad587e650d6bd7c79d8c1919e35","modified":1627293482580},{"_id":"source/_posts/小玩具-VIP视频解析界面.md","hash":"c2508d6485c457f18f720bdcaa1ad40b42b4c08f","modified":1627293482583},{"_id":"source/_posts/教程1-OpenCV代码转换为Web-API.md","hash":"5986e4bb027de1c98ff015c431be8ad254258964","modified":1627293539348},{"_id":"source/_posts/教程2-斑点检测-Blob检测.md","hash":"79e122795ebe0d1edc3d0bb87daf6ffd635e9c47","modified":1627293482581},{"_id":"source/_posts/数据链路层.md","hash":"5e50d29641e7669aab604ea2f3aa1301a7837a80","modified":1627293482582},{"_id":"source/_posts/最小二乘推导.md","hash":"55ae1d72746320b5330f565ea55570d5c88bab6e","modified":1627293482584},{"_id":"source/_posts/构建简单社交推荐系统——绪论.md","hash":"311d2d0265f52933269f9ee351c1ea9ea901febb","modified":1627293482575},{"_id":"source/_posts/漂亮又简洁的hexo编辑器hexoEditor.md","hash":"7332b9b4d2c93fcfa5dc1a50351353aeee9e5c77","modified":1627293482581},{"_id":"source/_posts/模型评估与选择.md","hash":"cbd17841b38c6917ea93aa6e1086f3e3a28716b1","modified":1627293482581},{"_id":"source/_posts/物理层.md","hash":"4f6012544bd7adad40f2ec76f6bbf6b663964fcb","modified":1627293482583},{"_id":"source/_posts/破解MathType-方法.md","hash":"c9043add7543e825c1196ed43b6ad7ed0d8de035","modified":1627293482582},{"_id":"source/_posts/第一节：开班典礼.md","hash":"298195f75352fcc5e14fb31df472b58dd72cc609","modified":1627293482575},{"_id":"source/_posts/第七节：函数基础和函数参数.md","hash":"5c539c7014a555a10beaa0426796cedc81280aeb","modified":1627293482570},{"_id":"source/_posts/第一部分-GitKraken破解及教程.md","hash":"dcc60a52430a290546463b05b6e77b4759f2e636","modified":1627293482575},{"_id":"source/_posts/第三节：序列类型的方法.md","hash":"455d2ecd32e5bec558cc52a31b0dd248ba9d4cc5","modified":1627293482571},{"_id":"source/_posts/第九节：类.md","hash":"2bc642b81189d39191338c21ef39197b2e21f2dc","modified":1627293482570},{"_id":"source/_posts/第二节：数值类型和序列类型.md","hash":"7493425ce89f89d0dd381cef6b2e95804d36455a","modified":1627293482569},{"_id":"source/_posts/第二部分-GitKraken破解及教程.md","hash":"effa484a32899570310c6100773440f936025305","modified":1627293482569},{"_id":"source/_posts/第八节：函数作用域和匿名函数.md","hash":"e1c255a0d2632c151114b889361e7ad4f615eb39","modified":1627293482569},{"_id":"source/_posts/第五节：散列类型，运算符.md","hash":"a9644abfae75d7da70cd71c3e0e7fa8eccafba31","modified":1627293482575},{"_id":"source/_posts/第六节：控制流程.md","hash":"d8a7453b7667d1a2352559ac5eb19b013b04ce77","modified":1627293482570},{"_id":"source/_posts/第十一节：描述符，装饰器，定制属性访问，__new__方法.md","hash":"7fa2ff78edd90c5226df51d2614a3e4f0edf3525","modified":1627293482574},{"_id":"source/_posts/第十二节：文件IO，私有属性和方法.md","hash":"fb9df63d89719f04e3041ea11aa4da39e22796a6","modified":1627293482571},{"_id":"source/_posts/第十三节：异常.md","hash":"f5d0c72548622fb4918aefc0e7e4cfd3a4fa145a","modified":1627293482572},{"_id":"source/_posts/第十五节：正则表达式.md","hash":"806bf3ab4a35113098ba0276479d41253be30948","modified":1627293482574},{"_id":"source/_posts/第十四节：推导表达式，迭代器，生成器，模块，包.md","hash":"c8500f1c8e62230f21f9abf56b54cc8ea4f7d72e","modified":1627293482573},{"_id":"source/_posts/第十节：多继承与魔法方法.md","hash":"2ac15f20cbca12f245ab6e94bc481b080657440b","modified":1627293482571},{"_id":"source/_posts/第四节：格式化输出，字符串.md","hash":"eae804a6d9434aa52a276603a8c460ed939da842","modified":1627293482574},{"_id":"source/_posts/解决wordpress下载插件 安装失败 无法创建目录问题.md","hash":"e1a703cc285de45f7db2823a7b1240feafb1c1cd","modified":1627292852236},{"_id":"source/_posts/解决向github提交代码不用输入帐号密码.md","hash":"57811aaf3d4395dac41a3249af5bceddda6c34ba","modified":1627293482581},{"_id":"source/_posts/计算机网络体系结构.md","hash":"7b9230380c0ae255ab330bb4f70dcbdf745e547c","modified":1627293482580},{"_id":"source/_posts/阈值分割.md","hash":"245e6a7db97a26d10128f8c9a299eadb813cd857","modified":1627293482584},{"_id":"source/categories/index.md","hash":"108d69d9b70c1b66531b8de5e89d809f9fad26a6","modified":1544304062891},{"_id":"source/tags/index.md","hash":"13f466609e0528dfebb1f9ba5a01a70c6f1cbfca","modified":1544304099091},{"_id":"themes/next/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1544212560189},{"_id":"themes/next/.git/config","hash":"8e94cc015a498d35202e9fd57e44b3c51e1e5634","modified":1544212560200},{"_id":"themes/next/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1544212532352},{"_id":"themes/next/.git/index","hash":"c891dcf8982bf144b66000bb1c08604bfcb01c6b","modified":1544212560565},{"_id":"themes/next/.git/packed-refs","hash":"69237944e31c16fe545d1f47b0b1e5b1d99660da","modified":1544212560176},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"3b5eafd32abb718e56ccf8d1cee0607ad8ce611d","modified":1544212560219},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"50d48c47162817a3810a9d9ad51104e83947419a","modified":1544212560220},{"_id":"themes/next/.github/PULL_REQUEST_TEMPLATE.md","hash":"902f627155a65099e0a37842ff396a58d0dc306f","modified":1544212560221},{"_id":"themes/next/.github/browserstack_logo.png","hash":"a6c43887f64a7f48a2814e3714eaa1215e542037","modified":1544212560222},{"_id":"themes/next/languages/de.yml","hash":"057e7df11ddeb1c8c15a5d7c5ff29430d725ec6b","modified":1544212560233},{"_id":"themes/next/languages/default.yml","hash":"44ef3f26917f467459326c2c8be2f73e4d947f35","modified":1544212560234},{"_id":"themes/next/languages/en.yml","hash":"7e680d9bb8f3a3a9d1ba1c9d312b3d257183dded","modified":1544212560234},{"_id":"themes/next/languages/fr-FR.yml","hash":"7e4eb7011b8feee641cfb11c6e73180b0ded1c0f","modified":1544212560235},{"_id":"themes/next/languages/ja.yml","hash":"3c76e16fd19b262864475faa6854b718bc08c4d8","modified":1544212560238},{"_id":"themes/next/languages/id.yml","hash":"b5de1ea66dd9ef54cac9a1440eaa4e3f5fc011f5","modified":1544212560236},{"_id":"themes/next/languages/it.yml","hash":"aa595f2bda029f73ef7bfa104b4c55c3f4e9fb4c","modified":1544212560237},{"_id":"themes/next/languages/ko.yml","hash":"ea5b46056e73ebcee121d5551627af35cbffc900","modified":1544212560239},{"_id":"themes/next/languages/nl-NL.yml","hash":"edca4f3598857dbc3cbf19ed412213329b6edd47","modified":1544212560239},{"_id":"themes/next/languages/pt-BR.yml","hash":"b1694ae766ed90277bcc4daca4b1cfa19cdcb72b","modified":1544212560240},{"_id":"themes/next/languages/pt.yml","hash":"44b61f2d085b827b507909a0b8f8ce31c6ef5d04","modified":1544212560241},{"_id":"themes/next/languages/ru.yml","hash":"98ec6f0b7183282e11cffc7ff586ceb82400dd75","modified":1544212560242},{"_id":"themes/next/languages/vi.yml","hash":"fd08d3c8d2c62965a98ac420fdaf95e54c25d97c","modified":1544212560243},{"_id":"themes/next/languages/zh-Hans.yml","hash":"1b5a4694e203456621d65d72c4b6f1bc228705a3","modified":1544266169064},{"_id":"themes/next/languages/zh-hk.yml","hash":"9396f41ae76e4fef99b257c93c7354e661f6e0fa","modified":1544212560244},{"_id":"themes/next/languages/zh-tw.yml","hash":"50b71abb3ecc0686f9739e179e2f829cd074ecd9","modified":1544212560245},{"_id":"themes/next/layout/_layout.swig","hash":"c52d582394926849c4e7ad849d90ebbb3445994e","modified":1544303923371},{"_id":"themes/next/layout/archive.swig","hash":"f0a8225feafd971419837cdb4bcfec98a4a59b2f","modified":1544212560311},{"_id":"themes/next/layout/category.swig","hash":"4472255f4a3e3dd6d79201523a9526dcabdfbf18","modified":1544212560312},{"_id":"themes/next/layout/index.swig","hash":"783611349c941848a0e26ee2f1dc44dd14879bd1","modified":1544212560313},{"_id":"themes/next/layout/post.swig","hash":"b3589a8e46288a10d20e41c7a5985d2493725aec","modified":1544212560315},{"_id":"themes/next/layout/page.swig","hash":"969caaee05bdea725e99016eb63d810893a73e99","modified":1544212560314},{"_id":"themes/next/layout/schedule.swig","hash":"d86f8de4e118f8c4d778b285c140474084a271db","modified":1544212560315},{"_id":"themes/next/layout/tag.swig","hash":"7e0a7d7d832883eddb1297483ad22c184e4368de","modified":1544212560316},{"_id":"themes/next/scripts/merge-configs.js","hash":"81e86717ecfb775986b945d17f0a4ba27532ef07","modified":1544212560318},{"_id":"themes/next/scripts/merge.js","hash":"9130dabe6a674c54b535f322b17d75fe6081472f","modified":1544212560320},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1544212560561},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1544212560562},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1544212560563},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1544212560428},{"_id":"source/about/.idea/about.iml","hash":"48dc199a103922efac02e6f577f4a3e7a7d73dda","modified":1583161905158},{"_id":"source/about/.idea/misc.xml","hash":"ef2a41adc601ede5409c589e7fc7f9abdb551d93","modified":1583161905166},{"_id":"source/about/.idea/modules.xml","hash":"50cc8e0b02ad6440366e991d7eafb93070f0dfcc","modified":1583161905170},{"_id":"source/about/.idea/workspace.xml","hash":"494ebe6b0da6cc1e0a4fc5c913a0182c6371537d","modified":1583170540497},{"_id":"themes/next/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1544212532354},{"_id":"themes/next/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1544212532354},{"_id":"themes/next/.git/hooks/fsmonitor-watchman.sample","hash":"f7c0aa40cb0d620ff0bca3efe3521ec79e5d7156","modified":1544212532355},{"_id":"themes/next/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1544212532357},{"_id":"themes/next/.git/hooks/pre-commit.sample","hash":"33729ad4ce51acda35094e581e4088f3167a0af8","modified":1544212532358},{"_id":"themes/next/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1544212532359},{"_id":"themes/next/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1544212532356},{"_id":"themes/next/.git/hooks/pre-rebase.sample","hash":"288efdc0027db4cfd8b7c47c4aeddba09b6ded12","modified":1544212532360},{"_id":"themes/next/.git/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1544212532360},{"_id":"themes/next/.git/hooks/prepare-commit-msg.sample","hash":"2584806ba147152ae005cb675aa4f01d5d068456","modified":1544212532361},{"_id":"themes/next/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1544212532362},{"_id":"themes/next/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1544212532363},{"_id":"themes/next/.git/logs/HEAD","hash":"aebac4269a724a4380d0e690540d326ee5a4826b","modified":1544212560193},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1544212560247},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1544212560247},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"31322a7f57936cf2dc62e824af5490da5354cf02","modified":1544212560250},{"_id":"themes/next/layout/_macro/reward.swig","hash":"56e8d8556cf474c56ae1bef9cb7bbd26554adb07","modified":1544212560253},{"_id":"themes/next/layout/_macro/post-copyright.swig","hash":"665a928604f99d2ba7dc4a4a9150178229568cc6","modified":1544212560251},{"_id":"themes/next/layout/_macro/post.swig","hash":"5067cea517ed0cd9b5e620aa382fede980954920","modified":1544266068016},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"6a54c3c85ff6b19d275827a327abbf4bd99b2ebf","modified":1544212560253},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"39852700e4084ecccffa6d4669168e5cc0514c9e","modified":1544212560254},{"_id":"themes/next/layout/_partials/comments.swig","hash":"4a6f5b1792b2e5262b7fdab9a716b3108e2f09c7","modified":1544212560255},{"_id":"themes/next/layout/_partials/footer.swig","hash":"b73852ad15aec8080e833a5c8c83ecea1e47d7bf","modified":1638337097592},{"_id":"themes/next/layout/_partials/head.swig","hash":"6b94fe8f3279daea5623c49ef4bb35917ba57510","modified":1544212560257},{"_id":"themes/next/layout/_partials/header.swig","hash":"ed042be6252848058c90109236ec988e392d91d4","modified":1544212560260},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1544212560261},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"1efd925d34a5d4ba2dc0838d9c86ba911e705fc9","modified":1544212560261},{"_id":"themes/next/layout/_partials/search.swig","hash":"9dbd378e94abfcb3f864a5b8dbbf18d212ca2ee0","modified":1544212560262},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1544212560271},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1544212560272},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"a266f96ad06ee87bdeae6e105a4b53cd587bbd04","modified":1544212560278},{"_id":"themes/next/layout/_third-party/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1544212560299},{"_id":"themes/next/layout/_third-party/exturl.swig","hash":"7c04a42319d728be356746363aff8ea247791d24","modified":1544212560300},{"_id":"themes/next/layout/_third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1544212560301},{"_id":"themes/next/layout/_third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1544212560303},{"_id":"themes/next/layout/_third-party/needsharebutton.swig","hash":"5fe0447cc88a5a63b530cf0426f93c4634811876","modified":1544212560302},{"_id":"themes/next/layout/_third-party/rating.swig","hash":"fc93b1a7e6aed0dddb1f3910142b48d8ab61174e","modified":1544212560302},{"_id":"themes/next/layout/_third-party/scroll-cookie.swig","hash":"1ddb2336a1a19b47af3017047012c01ec5f54529","modified":1544212560304},{"_id":"themes/next/scripts/tags/button.js","hash":"d023f10a00077f47082b0517e2ad666e6e994f60","modified":1544212560321},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1544212560322},{"_id":"themes/next/scripts/tags/exturl.js","hash":"8d7e60f60779bde050d20fd76f6fdc36fc85e06d","modified":1544212560323},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1544212560325},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1544212560324},{"_id":"themes/next/scripts/tags/lazy-image.js","hash":"eeeabede68cf263de9e6593ecf682f620da16f0a","modified":1544212560326},{"_id":"themes/next/scripts/tags/note.js","hash":"64de4e9d01cf3b491ffc7d53afdf148ee5ad9779","modified":1544212560327},{"_id":"themes/next/scripts/tags/label.js","hash":"2f8f41a7316372f0d1ed6b51190dc4acd3e16fff","modified":1544212560325},{"_id":"themes/next/scripts/tags/tabs.js","hash":"5786545d51c38e8ca38d1bfc7dd9e946fc70a316","modified":1544212560328},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1544212560427},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1544212560429},{"_id":"themes/next/source/images/apple-touch-icon-next.png","hash":"a284ef46b872db3b6880ad89d55e97df895ec119","modified":1544634188102},{"_id":"themes/next/source/images/avatar.png","hash":"b959e8832dd83722d2a61011094fe6fd70a12fa9","modified":1544259409644},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1544212560432},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1544212560432},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1544212560433},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1544212560434},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1544212560436},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1544212560435},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1544212560436},{"_id":"themes/next/source/images/favicon-32x32-next.png","hash":"320f5ae20a358a9668e7f3be2f1deb064f059ee7","modified":1544633974116},{"_id":"themes/next/source/images/favicon-16x16-next.png","hash":"62c24ee5d99e9e853e678041b290fb90907072b7","modified":1544633990949},{"_id":"themes/next/source/images/loading.gif","hash":"2afcf30698ef6b8a5553dff86c511bf50f1d2465","modified":1544634080140},{"_id":"themes/next/source/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1544212560440},{"_id":"themes/next/source/images/gzh.png","hash":"c3ca32276aa19b043c99be34ed8d101aba8a1604","modified":1544264337729},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1544212560441},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1544212560441},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1544212560442},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1544212560443},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1544212560275},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1544212560276},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1544212560397},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1544212560398},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1544212560400},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1544212560423},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1544212560426},{"_id":"themes/next/.git/objects/62/0b1e829eb8b6fd72426f3009866b79d8ee2e7b","hash":"f4b4e5001d6fa2046e1fb648056389ef28c8a7f5","modified":1677647980719},{"_id":"themes/next/.git/objects/33/8ae65b0b4ebd06f628c13cba624158baebbddc","hash":"5f83ad6ee2c97827b036ff1064e99c6952972154","modified":1677647980769},{"_id":"themes/next/.git/objects/9c/8cea69bf0d4f91c07779d71b01814b27bbb6a1","hash":"89ab85747b40158a89befb98886d47b4157e3704","modified":1677647980766},{"_id":"themes/next/.git/objects/66/ca1aa9e02618f354d401107cc5bf0d209be4a2","hash":"7b2ed3fa0ec4af6d4b0ea2b7e78dabd9a42d85dd","modified":1677647980767},{"_id":"themes/next/.git/objects/c9/091cb3a1443bc6b79f41617f80a7c3b61cc931","hash":"346b8b052b87ce5fdd70dbe7171289b3c927df31","modified":1677647980768},{"_id":"themes/next/.git/objects/d6/0ac946d7b9c5ec7bf8a97f0b52cc2b7b848207","hash":"da1f2f115796cb4bce46f20a197b4280cdd436bb","modified":1677647980763},{"_id":"themes/next/.git/refs/heads/master","hash":"7999da428ebb87e5a2b27315d8d5123c1ccdfaa5","modified":1544212560193},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1544212560259},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1544212560259},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"957701729b85fb0c5bfcf2fb99c19d54582f91ed","modified":1544212560264},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1544212560264},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1544212560265},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1544212560267},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1544212560267},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"048fd5e98149469f8c28c21ba3561a7a67952c9b","modified":1544212560269},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1544212560268},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1544212560273},{"_id":"themes/next/layout/_scripts/schemes/gemini.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1544212560275},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1544212560277},{"_id":"themes/next/layout/_third-party/analytics/analytics-with-widget.swig","hash":"98df9d72e37dd071e882f2d5623c9d817815b139","modified":1544212560280},{"_id":"themes/next/layout/_third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1544212560281},{"_id":"themes/next/layout/_third-party/analytics/baidu-analytics.swig","hash":"deda6a814ed48debc694c4e0c466f06c127163d0","modified":1544212560282},{"_id":"themes/next/layout/_third-party/analytics/facebook-sdk.swig","hash":"a234c5cd1f75ca5731e814d0dbb92fdcf9240d1b","modified":1544212560284},{"_id":"themes/next/layout/_third-party/analytics/firestore.swig","hash":"1cd01c6e92ab1913d48e556a92bb4f28b6dc4996","modified":1544212560285},{"_id":"themes/next/layout/_third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1544212560284},{"_id":"themes/next/layout/_third-party/analytics/busuanzi-counter.swig","hash":"18e7bef8923d83ea42df6c97405e515a876cede4","modified":1544212560283},{"_id":"themes/next/layout/_third-party/analytics/google-analytics.swig","hash":"5d9943d74cc2e0a91badcf4f755c6de77eab193a","modified":1544212560286},{"_id":"themes/next/layout/_third-party/analytics/index.swig","hash":"5e9bb24c750b49513d9a65799e832f07410002ac","modified":1544212560287},{"_id":"themes/next/layout/_third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1544212560289},{"_id":"themes/next/layout/_third-party/analytics/lean-analytics.swig","hash":"fc65b9c98a0a8ab43a5e7aabff6c5f03838e09c8","modified":1544212560288},{"_id":"themes/next/layout/_third-party/analytics/vkontakte-api.swig","hash":"c3971fd154d781088e1cc665035f8561a4098f4c","modified":1544212560290},{"_id":"themes/next/layout/_third-party/analytics/tencent-mta.swig","hash":"0ddc94ed4ba0c19627765fdf1abc4d8efbe53d5a","modified":1544212560289},{"_id":"themes/next/layout/_third-party/comments/changyan.swig","hash":"0e3378f7c39b2b0f69638290873ede6b6b6825c0","modified":1544212560292},{"_id":"themes/next/layout/_third-party/comments/disqus.swig","hash":"c316758546dc9ba6c60cb4d852c17ca6bb6d6724","modified":1544212560293},{"_id":"themes/next/layout/_third-party/comments/gitment.swig","hash":"10160daceaa6f1ecf632323d422ebe2caae49ddf","modified":1544212560294},{"_id":"themes/next/layout/_third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1544212560295},{"_id":"themes/next/layout/_third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1544212560293},{"_id":"themes/next/layout/_third-party/comments/livere.swig","hash":"8a2e393d2e49f7bf560766d8a07cd461bf3fce4f","modified":1544212560297},{"_id":"themes/next/layout/_third-party/comments/index.swig","hash":"aa0629277d751c55c6d973e7691bf84af9b17a60","modified":1544212560296},{"_id":"themes/next/layout/_third-party/comments/valine.swig","hash":"fcabbb241f894c9a6309c44e126cf3e8fea81fd4","modified":1544212560298},{"_id":"themes/next/layout/_third-party/comments/youyan.swig","hash":"8b6650f77fe0a824c8075b2659e0403e0c78a705","modified":1544212560298},{"_id":"themes/next/layout/_third-party/search/index.swig","hash":"c747fb5c6b1f500e8f0c583e44195878b66e4e29","modified":1544212560308},{"_id":"themes/next/layout/_third-party/search/localsearch.swig","hash":"385c066af96bee30be2459dbec8aae1f15d382f5","modified":1544212560309},{"_id":"themes/next/layout/_third-party/search/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1544212560309},{"_id":"themes/next/.git/objects/a2/02b7efed7817b2a729d64f453994c720d3332b","hash":"2437ede73ad98f191710572f57418bfb0c5142c2","modified":1677647980762},{"_id":"themes/next/layout/_third-party/seo/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1544212560310},{"_id":"themes/next/.git/objects/f9/d899a74fb83511858e1766d2fd1a845d9ec1f5","hash":"5a80bab3f9379b267dbac7e14ab312826b8f152a","modified":1677647980770},{"_id":"themes/next/source/404/images/bird.png","hash":"9e0798b01e54ec033a47795c7b7610bd6e1ee77d","modified":1522857600000},{"_id":"themes/next/source/404/images/san.png","hash":"659aaca45f96838f66b0fc6f062f588c6cb62824","modified":1522857600000},{"_id":"themes/next/source/404/images/yun1.png","hash":"a776001b9a61b0bdbd650b8346321b5004200fad","modified":1522857600000},{"_id":"themes/next/source/404/images/yun0.png","hash":"b21498b2f11a62d422da7a1ab2a24c26af4c5224","modified":1522857600000},{"_id":"themes/next/source/404/images/yun2.png","hash":"76018d55773ba8f07dbb440ffcfed412f0ac46b9","modified":1522857600000},{"_id":"themes/next/source/404/css/404.css","hash":"cf777b454bb6a64d92a7b40038725819cc7febfd","modified":1522857600000},{"_id":"themes/next/source/404/css/index.css","hash":"3d200770e05af204fcddfa133a40bd9e84b34f9f","modified":1522857600000},{"_id":"themes/next/source/404/css/public.css","hash":"651fe117ad21ff0d72584e8b00774e720026e0b1","modified":1522857600000},{"_id":"themes/next/source/about/css/style.css","hash":"d5f9427fca9a5423508cd71d512f6e05f05f8e37","modified":1583161499116},{"_id":"themes/next/source/about/images/arrow.png","hash":"cd3367b5cf1df79efdd5dc1c9a3ef50f950afbef","modified":1583161499088},{"_id":"themes/next/source/about/images/avatar.jpg","hash":"8205b8dd816bf7204da74f9c23f7ed33852ed4e4","modified":1583161499088},{"_id":"themes/next/source/about/images/bg-down-arrow.png","hash":"b462a8aad67812717f17c1568319e63498e1b295","modified":1583161499088},{"_id":"themes/next/source/about/images/avatar@2x.jpg","hash":"d913589bef5002af126b3a296130009ddd65b72e","modified":1583161499088},{"_id":"themes/next/source/about/images/bg-tile.png","hash":"515fc732f0c5dd23e199716e531cde634136766f","modified":1583161499088},{"_id":"themes/next/source/about/images/bio-icon-2.png","hash":"b72c201dbd81e528290ab54dbfca36ad795d485a","modified":1583161499088},{"_id":"themes/next/source/about/images/bio-icon-1.png","hash":"2b48878b4089cc8ba998ad660b7f5f56eb254223","modified":1583161499088},{"_id":"themes/next/.git/objects/fa/97eb73d5e4dee0f61dc04676321802f13de754","hash":"feac9de689be7f8687f6b1122430b6eb0848ba8b","modified":1677647980765},{"_id":"themes/next/source/about/images/bio-icon-3.png","hash":"e8c575d2ad3989a363d12230ca8c7808c152ea05","modified":1583161499088},{"_id":"themes/next/source/about/images/bio-text-2.png","hash":"050d81de2bcb50a099698521a028a2b0e9a0de0a","modified":1583161499088},{"_id":"themes/next/source/about/images/bio-text-1.png","hash":"84d6016e4726c6ba2f59c740954d23c74fa4ba03","modified":1583161499088},{"_id":"themes/next/source/about/images/bio-text-3.png","hash":"f993f58a62b77b44829fe6aa43b2c62dec0a3ba1","modified":1583161499088},{"_id":"themes/next/source/about/images/home-bg.jpg","hash":"ffd86fb9edb1151e3db8e7e3f50b434e44de9fb2","modified":1583161499088},{"_id":"themes/next/source/about/js/global.js","hash":"302297db83d450452ac0d7c9e154d5e87555b23c","modified":1583161499104},{"_id":"themes/next/source/about/js/jquery.stellar.min.js","hash":"96d41d4ee128138ee29cd4e8e4ad20da54b39929","modified":1583161499108},{"_id":"themes/next/source/about/js/waypoints.min.js","hash":"bedeb001dfb0b40f52c1b234bd7ceebe6a0a0928","modified":1583161499100},{"_id":"themes/next/source/about/js/js.js","hash":"c8033416ec46c129ed1b9cee03a2bde121a55d86","modified":1583161499100},{"_id":"themes/next/source/about/js/password.js","hash":"963ad9f5f8e693a10b394bef60f9e768bcd1ee8d","modified":1583171823740},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"e4d2f755ed73b20c4173b2a60294c795511503d7","modified":1544259721310},{"_id":"themes/next/source/css/_mixins/Gemini.styl","hash":"2aa5b7166a85a8aa34b17792ae4f58a5a96df6cc","modified":1544212560397},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"9ab65361ba0a12a986edd103e56492644c2db0b8","modified":1544212560399},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"82f9055955920ed88a2ab6a20ab02169abb2c634","modified":1544212560399},{"_id":"themes/next/source/css/_variables/Gemini.styl","hash":"99fbb4686ea9a3e03a4726ed7cf4d8f529034452","modified":1544212560422},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"be087dcc060e8179f7e7f60ab4feb65817bd3d9f","modified":1544212560423},{"_id":"themes/next/source/css/_variables/base.styl","hash":"29c261fa6b4046322559074d75239c6b272fb8a3","modified":1544212560425},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"f29165e36489a87ba32d17dddfd2720d84e3f3ec","modified":1544212560424},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1544212560445},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1544212560446},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1544212560446},{"_id":"themes/next/source/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1544212560447},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1544212560448},{"_id":"themes/next/source/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1544212560449},{"_id":"themes/next/source/js/src/love.js","hash":"9e8e79d69ad8338761272f86fe5cad0ad5e503cc","modified":1544296110337},{"_id":"themes/next/source/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1544212560450},{"_id":"themes/next/source/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1544212560451},{"_id":"themes/next/source/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1544212560453},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1544212560453},{"_id":"themes/next/source/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1544212560454},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1544212560467},{"_id":"themes/next/source/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1544212560472},{"_id":"themes/next/source/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1544212560473},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"9be892a4e14e0da18ff9cb962c9ef71f163b1b22","modified":1544212560475},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"672d3b5767e0eacd83bb41b188c913f2cf754793","modified":1544212560476},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1544212560491},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1544212560492},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1544212560493},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1544212560493},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1544212560520},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1544212560523},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1544212560524},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1544212560524},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1544212560526},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1544212560525},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1544212560527},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"a2aaaf12378db56bd10596ba3daae30950eac051","modified":1544212560497},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1544212560498},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1544212560499},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1544212560499},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1544212560500},{"_id":"themes/next/source/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1544212560528},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1544212560530},{"_id":"themes/next/source/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1544212560529},{"_id":"themes/next/source/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1544212560532},{"_id":"themes/next/source/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1544212560533},{"_id":"themes/next/source/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1544212560534},{"_id":"themes/next/source/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1544212560533},{"_id":"themes/next/source/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1544212560536},{"_id":"themes/next/source/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1544212560535},{"_id":"themes/next/source/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1544212560536},{"_id":"themes/next/source/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1544212560538},{"_id":"themes/next/source/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1544212560537},{"_id":"themes/next/source/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1544212560539},{"_id":"themes/next/source/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1544212560541},{"_id":"themes/next/source/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1544212560540},{"_id":"themes/next/source/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1544212560542},{"_id":"themes/next/source/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1544212560541},{"_id":"themes/next/source/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1544212560544},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1544212560554},{"_id":"themes/next/source/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1544212560545},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1544212560555},{"_id":"themes/next/source/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1544212560545},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1544212560558},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1544212560560},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1544212560559},{"_id":"themes/next/source/404/js/jquery-1.7.2.min.js","hash":"08b92c5a9ed01f31b13318be2ba7abd3db252760","modified":1523116800000},{"_id":"themes/next/source/about/js/jquery-1.9.1.min.js","hash":"b5926d5e80b94d7eee4e9f1c18b91427d47f2530","modified":1583161499120},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1544212560522},{"_id":"source/images/2021/07/26/f69f0940-edea-11eb-9787-e1cba314367a.png","hash":"b959e8832dd83722d2a61011094fe6fd70a12fa9","modified":1627287898069},{"_id":"themes/next/.git/logs/refs/heads/master","hash":"aebac4269a724a4380d0e690540d326ee5a4826b","modified":1544212560195},{"_id":"themes/next/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1544212560186},{"_id":"themes/next/.git/refs/remotes/origin/master","hash":"fde0697e3e19aa7426f55fa0e66db96fd65052be","modified":1677647980819},{"_id":"themes/next/layout/_third-party/search/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1544212560306},{"_id":"themes/next/layout/_third-party/search/algolia-search/dom.swig","hash":"ba698f49dd3a868c95b240d802f5b1b24ff287e4","modified":1544212560307},{"_id":"themes/next/source/about/images/works/91zaojia.jpg","hash":"9a6024e9528299dbe102298484764831d05434e2","modified":1583161499088},{"_id":"themes/next/source/about/images/works/cv.jpg","hash":"96695ec47c52e7750d15746e434dacbea61a1a7d","modified":1583165599964},{"_id":"themes/next/source/about/images/works/ys.jpg","hash":"c82f9126e35900640aa581034298012f55b8afd4","modified":1583165073791},{"_id":"themes/next/source/about/images/works/dp.jpeg","hash":"a6e64ac1f08b8c77fa2f564b2180dd8ac9ec7e77","modified":1583164977657},{"_id":"themes/next/source/css/_common/components/back-to-top-sidebar.styl","hash":"4719ce717962663c5c33ef97b1119a0b3a4ecdc3","modified":1544212560331},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"31050fc7a25784805b4843550151c93bfa55c9c8","modified":1544212560332},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"7e509c7c28c59f905b847304dd3d14d94b6f3b8e","modified":1544212560333},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1544212560333},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"a6bb5256be6195e76addbda12f4ed7c662d65e7a","modified":1544212560334},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"c5d48863f332ff8ce7c88dec2c893f709d7331d3","modified":1544212560349},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1544212560371},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1544212560388},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"f7c44b0ee46cf2cf82a4c9455ba8d8b55299976f","modified":1544212560390},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"9c25c75311e1bd4d68df031d3f2ae6d141a90766","modified":1544212560391},{"_id":"themes/next/source/css/_common/scaffolding/mobile.styl","hash":"47a46583a1f3731157a3f53f80ed1ed5e2753e8e","modified":1544212560392},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1544212560393},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"a280a583b7615e939aaddbf778f5c108ef8a2a6c","modified":1544212560393},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1544212560394},{"_id":"themes/next/source/css/_schemes/Gemini/index.styl","hash":"18c3336ee3d09bd2da6a876e1336539f03d5a973","modified":1544212560402},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1544212560404},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1544212560403},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1544212560405},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1544212560406},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"3b25edfa187d1bbbd0d38b50dd013cef54758abf","modified":1544212560407},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1544212560407},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1544212560408},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1544212560411},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1544212560412},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"4aac01962520d60b03b23022ab601ad4bd19c08c","modified":1544212560413},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1544212560414},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1544212560415},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"c4ed249798296f60bda02351fe6404fb3ef2126f","modified":1544212560417},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"5b93958239d3d2bf9aeaede44eced2434d784462","modified":1544212560418},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"215de948be49bcf14f06d500cef9f7035e406a43","modified":1544212560419},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"9d16fa3c14ed76b71229f022b63a02fd0f580958","modified":1544212560420},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1544212560419},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"69ecd6c97e7cdfd822ac8102b45ad0ede85050db","modified":1544212560421},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1544212560452},{"_id":"themes/next/source/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1544212560462},{"_id":"themes/next/source/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1544212560465},{"_id":"themes/next/source/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1544212560466},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1544212560477},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1544212560479},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1544212560478},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1544212560478},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1544212560481},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1544212560480},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"82f33ad0842aa9c154d029e0dada2497d4eb1d57","modified":1544212560487},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"d71602cbca33b9ecdb7ab291b7f86a49530f3601","modified":1544212560489},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"ae6318aeb62ad4ce7a7e9a4cdacd93ffb004f0fb","modified":1544212560490},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1544212560495},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1544212560496},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1544212560501},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1544212560503},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1544212560504},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1544212560551},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1544212560552},{"_id":"themes/next/source/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1544212560464},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1544212560519},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1544212560518},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1544212560557},{"_id":"themes/next/.git/logs/refs/remotes/origin/HEAD","hash":"aebac4269a724a4380d0e690540d326ee5a4826b","modified":1544212560186},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"7905a7f625702b45645d8be1268cb8af3f698c70","modified":1544212560335},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1544212560337},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"8a2421cb9005352905fae9d41a847ae56957247e","modified":1544212560339},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1544212560338},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1544212560340},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1544212560340},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1544212560342},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"25dc25f61a232f03ca72472b7852f882448ec185","modified":1544212560343},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1544212560344},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"f5aa2ba3bfffc15475e7e72a55b5c9d18609fdf5","modified":1544212560345},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1544212560346},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1544212560347},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1544212560348},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1544212560348},{"_id":"themes/next/source/css/_common/components/post/post-button.styl","hash":"e72a89e0f421444453e149ba32c77a64bd8e44e8","modified":1544212560350},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"0f7f522cc6bfb3401d5afd62b0fcdf48bb2d604b","modified":1544212560351},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1544212560353},{"_id":"themes/next/source/css/_common/components/post/post-copyright.styl","hash":"f54367c0feda6986c030cc4d15a0ca6ceea14bcb","modified":1544212560352},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1544212560355},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"535b3b4f8cb1eec2558e094320e7dfb01f94c0e7","modified":1544212560354},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"aea21141015ca8c409d8b33e3e34ec505f464e93","modified":1544212560355},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"a5d8617a24d7cb6c5ad91ea621183ca2c0917331","modified":1544212560356},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"36332c8a91f089f545f3c3e8ea90d08aa4d6e60c","modified":1544212560357},{"_id":"themes/next/source/css/_common/components/post/post-rtl.styl","hash":"017074ef58166e2d69c53bb7590a0e7a8947a1ed","modified":1544212560358},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1544212560359},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"d5a4e4fc17f1f7e7c3a61b52d8e2e9677e139de7","modified":1544212560360},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1544212560360},{"_id":"themes/next/source/css/_common/components/post/post-widgets.styl","hash":"e4055a0d2cd2b0ad9dc55928e2f3e7bd4e499da3","modified":1544212560361},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"262debfd4442fa03d9919ceb88b948339df03fb0","modified":1544212560362},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1544212560364},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"0a6c0efffdf18bddbc1d1238feaed282b09cd0fe","modified":1544212560363},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-dimmer.styl","hash":"efa5e5022e205b52786ce495d4879f5e7b8f84b2","modified":1544212560366},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"89dd4f8b1f1cce3ad46cf2256038472712387d02","modified":1544212560365},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1544212560368},{"_id":"themes/next/.git/logs/refs/remotes/origin/master","hash":"e68d457f7eaa529bd49c0f997c9e02199bc8e0d8","modified":1677647980819},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1544212560367},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"f7784aba0c1cd20d824c918c120012d57a5eaa2a","modified":1544212560369},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"12937cae17c96c74d5c58db6cb29de3b2dfa14a2","modified":1544212560368},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"50305b6ad7d09d2ffa4854e39f41ec1f4fe984fd","modified":1544212560370},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1544212560371},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"fd42777b9125fd8969dc39d4f15473e2b91b4142","modified":1544212560380},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1544212560381},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"d4e6d8d7b34dc69994593c208f875ae8f7e8a3ae","modified":1544212560382},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1544212560383},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1544212560385},{"_id":"themes/next/source/css/_common/components/third-party/gitment.styl","hash":"34935b40237c074be5f5e8818c14ccfd802b7439","modified":1544212560383},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"d89c4b562b528e4746696b2ad8935764d133bdae","modified":1544212560385},{"_id":"themes/next/source/css/_common/components/third-party/han.styl","hash":"cce6772e2cdb4db85d35486ae4c6c59367fbdd40","modified":1544212560384},{"_id":"themes/next/source/css/_common/components/third-party/needsharebutton.styl","hash":"a5e3e6b4b4b814a9fe40b34d784fed67d6d977fa","modified":1544212560386},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"1ccfbd4d0f5754b2dc2719a91245c95f547a7652","modified":1544212560387},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1544212560373},{"_id":"themes/next/source/css/_common/components/tags/exturl.styl","hash":"1b3cc9f4e5a7f6e05b4100e9990b37b20d4a2005","modified":1544212560374},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"37e951e734a252fe8a81f452b963df2ba90bfe90","modified":1544212560374},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1544212560375},{"_id":"themes/next/source/css/_common/components/tags/label.styl","hash":"4a457d265d62f287c63d48764ce45d9bcfc9ec5a","modified":1544212560376},{"_id":"themes/next/source/css/_common/components/tags/note-modern.styl","hash":"ee7528900578ef4753effe05b346381c40de5499","modified":1544212560377},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"32c9156bea5bac9e9ad0b4c08ffbca8b3d9aac4b","modified":1544212560378},{"_id":"themes/next/source/css/_common/components/tags/tabs.styl","hash":"4ab5deed8c3b0c338212380f678f8382672e1bcb","modified":1544212560378},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"ead0d0f2321dc71505788c7f689f92257cf14947","modified":1544212560379},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1544212560409},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1544212560410},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"817587e46df49e819858c8ecbafa08b53d5ff040","modified":1544212560416},{"_id":"themes/next/source/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1544212560458},{"_id":"themes/next/source/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1544212560459},{"_id":"themes/next/source/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1544212560460},{"_id":"themes/next/source/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1544212560461},{"_id":"themes/next/source/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1544212560461},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1544212560482},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"ee948b4489aedeb548a77c9e45d8c7c5732fd62d","modified":1544212560484},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"6394c48092085788a8c0ef72670b0652006231a1","modified":1544212560483},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"b88b589f5f1aa1b3d87cc7eef34c281ff749b1ae","modified":1544212560486},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"51139a4c79573d372a347ef01a493222a1eaf10a","modified":1544212560485},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"d22b1629cb23a6181bebb70d0cf653ffe4b835c8","modified":1544212560487},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1544212560507},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1544212560509},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1544212560516},{"_id":"themes/next/.git/objects/pack/pack-08078752a6bc127bb8528289eb98002154112900.idx","hash":"cf9438eb39dacfe6100d63742c4c33d2e9736d63","modified":1544212560118},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1544212560471},{"_id":"themes/next/source/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1544212560549},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1544212560514},{"_id":"themes/next/source/images/b.jpg","hash":"ff23147ec592d70e86548fda89b606baba77c00f","modified":1544216707621},{"_id":"themes/next/.git/objects/pack/pack-08078752a6bc127bb8528289eb98002154112900.pack","hash":"9450dff4ff0670a73844a663605a3a5e5f379bc1","modified":1544212560123},{"_id":"public/404.html","hash":"a179379d9b2fa3242dd6c03419f65c7e43976952","modified":1677649203905},{"_id":"public/about/index.html","hash":"48933201a92333f36313a870046c958c98f27f6a","modified":1677649203993},{"_id":"public/search.xml","hash":"44af6b531b84438cab0515207d99bcd6f3e7c274","modified":1677649203994},{"_id":"public/categories/index.html","hash":"a50215b4f2cea2e6c202567e489e8cf2ba25cbbb","modified":1677649204045},{"_id":"public/2020/03/09/P图-无缝克隆/index.html","hash":"c9efd45402dfd9afbbf669311db3492cc6bb27dc","modified":1677649204045},{"_id":"public/tags/index.html","hash":"01f960bcd088add0233dd8d6d0d6e21c89744599","modified":1677649204045},{"_id":"public/2020/03/09/阈值分割/index.html","hash":"c7aa5da45e48b14696fe278b9e85f80dc4ecd45d","modified":1677649204045},{"_id":"public/2020/03/09/教程2-斑点检测-Blob检测/index.html","hash":"25805216f7114ee48f07f35491d6a41c9a62ef22","modified":1677649204045},{"_id":"public/2020/03/02/第二部分-GitKraken破解及教程/index.html","hash":"d0356a2389049accdcc9390df4669e07a11385b8","modified":1677649204045},{"_id":"public/2020/03/08/教程1-OpenCV代码转换为Web-API/index.html","hash":"f901c376ae8f12e901e43b128c51a1bd414c8bb0","modified":1677649204045},{"_id":"public/2020/03/01/第一部分-GitKraken破解及教程/index.html","hash":"5301593c3f2bc539b0d49493095572c162c62cd9","modified":1677649204045},{"_id":"public/2019/06/10/Nvidia-Jetson-nano-介绍/index.html","hash":"43210c778bd003b9c5cedb5eb6da7767d12f4d95","modified":1677649204045},{"_id":"public/2019/05/15/pytorch维度报错/index.html","hash":"95d4091d29f089c3db4e14b9787dc2ec211d563d","modified":1677649204045},{"_id":"public/2019/06/10/Nvidia-Jetson-nano-配置/index.html","hash":"66e36333e5febacfbf90c23f07a0e0723caa715c","modified":1677649204045},{"_id":"public/2019/05/07/在Pytorch中正确设计dateset并加载数据集/index.html","hash":"146264e8f228196390f7aaaa9d77591a253aa653","modified":1677649204045},{"_id":"public/2019/05/04/解决向github提交代码不用输入帐号密码/index.html","hash":"820a09212a06086951324a0641a52082bf69cb10","modified":1677649204045},{"_id":"public/2019/05/04/KDD-CUP99数据集预处理/index.html","hash":"9ea0afffc6ade753f8e6a84164d9905b563779ac","modified":1677649204045},{"_id":"public/2019/03/27/一些系统的工具/index.html","hash":"14e787a8e063d4913b1b8de60851e4737ed7549f","modified":1677649204045},{"_id":"public/2019/02/21/instagan-pytorch1.1实现/index.html","hash":"4ce8c52a296f1bd70b150c1ab174ac4e0ad55ed3","modified":1677649204045},{"_id":"public/2019/01/25/pytorch搭建网络测试时报错RuntimeError-expected-backend-CPU-and-dtype-Double-but-got-backend-CPU-and-dtype-Float/index.html","hash":"c38d9b2aa34a037f7ebd56ee6283d2f520c9a778","modified":1677649204045},{"_id":"public/2019/01/25/pytorch RuntimeError-expected-backend-CPU-and-dtype-Double-but-got-backend-CPU-and-dtype-Float/index.html","hash":"1e3462d3f05100962404b59bc833590594a3c4fd","modified":1677649204046},{"_id":"public/2019/01/02/LOL-换肤快捷工具/index.html","hash":"c4f8d1a86bcdf79280e7d4b9a386458d4b94ac1f","modified":1677649204046},{"_id":"public/2019/01/15/将数据归一化到任意区间范围的方法/index.html","hash":"110238b13a056216e447db1d496512eb6d22e9a3","modified":1677649204046},{"_id":"public/2018/12/28/回顾-DiscoGAN/index.html","hash":"291a65d216f41c2806b16d7e371d5bea14a426c3","modified":1677649204046},{"_id":"public/2018/12/27/回顾-WGAN/index.html","hash":"48edb9de19a876815ea69f0238eed35360ce0299","modified":1677649204046},{"_id":"public/2018/12/26/回顾-BEGAN/index.html","hash":"9dc13b261c9da9d8b5eb2cf73a23d784a0673888","modified":1677649204046},{"_id":"public/2018/12/25/The-size-of-tensor-a-(5)-must-match-the-size-of-tensor-b-(3)-at-non-singleton-dimension-3/index.html","hash":"f717fec1dc791de42466c338001e21aab160eb4b","modified":1677649204046},{"_id":"public/2018/12/25/回顾-pix2pix/index.html","hash":"5635009172b47bf4523cd92161f18513d9d3a37a","modified":1677649204046},{"_id":"public/2018/12/24/回顾-DCGAN/index.html","hash":"7b1874721ee987b7d8043133710c2e11c4983218","modified":1677649204046},{"_id":"public/2018/12/24/回顾-VAEGAN/index.html","hash":"41642ba69984eec5ba4b65ffecb0ea7167dfd9f1","modified":1677649204046},{"_id":"public/2018/12/21/回顾-GAN/index.html","hash":"d57808f467ad1fa68b1f40ff53061f371152afab","modified":1677649204046},{"_id":"public/2018/12/24/破解MathType-方法/index.html","hash":"9a9aee1b90226b854ecb4ba4816dac74b8ff7a72","modified":1677649204046},{"_id":"public/2018/12/20/回顾-Resnet/index.html","hash":"b489cf023199707a868d961fc9a4a83fb9be33dd","modified":1677649204046},{"_id":"public/2018/12/19/回顾-VGG/index.html","hash":"2b702f46157ea7dc4f3b46e2427471d4d92eeaf4","modified":1677649204046},{"_id":"public/2018/12/18/回顾-AlexNet/index.html","hash":"dc3fd63b1ea0d7ec197878ba7982cbd18040d521","modified":1677649204046},{"_id":"public/2018/12/17/回顾-CNN/index.html","hash":"5d6ca98dcaf669992bd228424f7e721a3a646ad2","modified":1677649204046},{"_id":"public/2018/12/15/fastai-入门视觉/index.html","hash":"a78486c95162893a8f645370f10fd051d769942f","modified":1677649204046},{"_id":"public/2018/12/15/fastai-安装/index.html","hash":"784c7b6e577103060be093fedc09979101e405b9","modified":1677649204046},{"_id":"public/2018/12/14/小玩具-VIP视频解析界面/index.html","hash":"f8a6be049701c72dade6f01c2f138af8a9536344","modified":1677649204046},{"_id":"public/2018/11/05/漂亮又简洁的hexo编辑器hexoEditor/index.html","hash":"a11510335e3e91f9bd0d0b1589d7d3c645be3672","modified":1677649204046},{"_id":"public/2018/05/30/第十五节：正则表达式/index.html","hash":"e7984a9ed76077fb43c0eb25f788c68d7087e2b0","modified":1677649204046},{"_id":"public/2018/05/28/第十四节：推导表达式，迭代器，生成器，模块，包/index.html","hash":"d925b32c59c0b96031d81704d6a427afcf6b6e5a","modified":1677649204046},{"_id":"public/2018/05/28/第十三节：异常/index.html","hash":"e64520be465e7e9ca05c2c076e4ea82cb39fe95c","modified":1677649204046},{"_id":"public/2018/05/23/第十二节：文件IO，私有属性和方法/index.html","hash":"73249235d63af4b1fc6fdbaef110f1ff30ed4528","modified":1677649204046},{"_id":"public/2018/05/21/第十一节：描述符，装饰器，定制属性访问，__new__方法/index.html","hash":"bce26d7bab29ff143f6d6f022bd2507c1976c6ad","modified":1677649204046},{"_id":"public/2018/05/18/第十节：多继承与魔法方法/index.html","hash":"d38b1c0fd42325df241d4e6c72525b5dee921662","modified":1677649204046},{"_id":"public/2018/05/12/第九节：类/index.html","hash":"2e025796ccd1f5d848535156e80047dcdf76adc4","modified":1677649204046},{"_id":"public/2018/05/09/模型评估与选择/index.html","hash":"ed0d49a17469400c6fe1369a87f30fb47dbf0e11","modified":1677649204046},{"_id":"public/2018/05/08/第八节：函数作用域和匿名函数/index.html","hash":"f699d4bc04cea92284fbb6048313904b19c8a751","modified":1677649204046},{"_id":"public/2018/05/09/最小二乘推导/index.html","hash":"684f04fa2b67d625481b8712a27557399205a8e7","modified":1677649204046},{"_id":"public/2018/05/08/第七节：函数基础和函数参数/index.html","hash":"a874f5256309d9921987816a4d2944f1583fe750","modified":1677649204046},{"_id":"public/2018/05/08/第六节：控制流程/index.html","hash":"f1b18d299f154b4932d34b17354950a176fa084d","modified":1677649204046},{"_id":"public/2018/05/08/第五节：散列类型，运算符/index.html","hash":"a66684a77d5f60434ca32b8ac866b00f7cea8ef4","modified":1677649204046},{"_id":"public/2018/05/08/第四节：格式化输出，字符串/index.html","hash":"5fabc6070374e5f01defa9cb3979511fda6cf2c2","modified":1677649204046},{"_id":"public/2018/05/08/第二节：数值类型和序列类型/index.html","hash":"0692cf5f5149809f312dddbd1c7cf0e043959b46","modified":1677649204046},{"_id":"public/2018/05/08/第三节：序列类型的方法/index.html","hash":"2dad604d25d145d7767327ca77465b91041a471c","modified":1677649204046},{"_id":"public/2018/05/08/第一节：开班典礼/index.html","hash":"9ec83f8a56fa26028df58029e28a35fc323f458d","modified":1677649204046},{"_id":"public/2018/04/17/构建简单社交推荐系统——绪论/index.html","hash":"5b26a58840bb2414b0e2e9c3fa23993b9cc0f079","modified":1677649204046},{"_id":"public/2018/04/17/基于神经网络的入侵检测提取异常行为特征—绪论/index.html","hash":"8925bb89620b23347779f39c06d6cd6b499674c4","modified":1677649204047},{"_id":"public/2018/04/11/如何使用思维导图/index.html","hash":"afe0c39c7cd031ccaf384c7e04ad7a87b528e096","modified":1677649204047},{"_id":"public/2018/04/09/计算机网络体系结构/index.html","hash":"bbb2b5bb883e312bfdcf5d59f5cf5d3f116ca651","modified":1677649204047},{"_id":"public/2018/04/09/WordPress页面，分页函数调用，主题函数调用，模板函数调用/index.html","hash":"930ba389fc32a944ad6ddabf887c903d842ec145","modified":1677649204047},{"_id":"public/2018/04/08/php中添加html中的css，js，图片，视频等外部文件方法/index.html","hash":"728f9354d19ebbd88538e5b0fe4d72e9627f45cd","modified":1677649204047},{"_id":"public/2018/04/05/物理层/index.html","hash":"51866b056da607a7c4e8c02f682995efe9518e4f","modified":1677649204047},{"_id":"public/2018/04/05/数据链路层/index.html","hash":"0c968b69f6e8b695dcdc5d08c6bdbe1e26786e5b","modified":1677649204047},{"_id":"public/index.html","hash":"189d2812da8d92edb9647403cb9bfc331765fed3","modified":1677649204047},{"_id":"public/2018/04/05/解决wordpress下载插件 安装失败 无法创建目录问题/index.html","hash":"fb1e5dc9a19decc93c52d42d4e7777ea2dd328b6","modified":1677649204047},{"_id":"public/2018/04/05/为什么我要写博客！/index.html","hash":"f3457e305e93b9c46d428d02f4b93bfbf2652316","modified":1677649204047},{"_id":"public/page/2/index.html","hash":"73294268f60ac34d3d9e0c392dba836ce0d6773c","modified":1677649204047},{"_id":"public/page/3/index.html","hash":"9aeac1b2b90454aa3e48626dc716aa9bc8dc4ee4","modified":1677649204047},{"_id":"public/page/4/index.html","hash":"dc3a880eb71184e23e3d5a723133c6b887f06d39","modified":1677649204047},{"_id":"public/page/6/index.html","hash":"441f6540a5800046fb5e7e2e7634986c741a4f38","modified":1677649204047},{"_id":"public/page/5/index.html","hash":"fe9ef2bf146b7fac041a3c6fb83687bad5bc35d1","modified":1677649204047},{"_id":"public/page/7/index.html","hash":"951fd709b2b22d1db961ea009def84a59ea2377d","modified":1677649204047},{"_id":"public/archives/index.html","hash":"c8b6e6f8432e38dea1ffa23fded79bb5af534386","modified":1677649204047},{"_id":"public/archives/page/3/index.html","hash":"37467de7def94782d80d1b9cd9137dd5381b06f1","modified":1677649204047},{"_id":"public/archives/page/2/index.html","hash":"24745daa3e165d35a1521d1aca0d59496562c363","modified":1677649204047},{"_id":"public/archives/page/4/index.html","hash":"630038f454c083c81b0caacced0a17f54d674e75","modified":1677649204047},{"_id":"public/archives/page/5/index.html","hash":"a5a8bc9aabaec85879bfe6dddb5106f531c5d9ad","modified":1677649204047},{"_id":"public/archives/page/6/index.html","hash":"e81167c74471e3d025bd5d7b8f9ed1b4f7597e55","modified":1677649204047},{"_id":"public/archives/page/7/index.html","hash":"3ed1b682a7226388adc7d0f9519a034865990944","modified":1677649204047},{"_id":"public/archives/2018/index.html","hash":"c9c2fec0b369909ffae9dd1727e9403ab7229c3c","modified":1677649204047},{"_id":"public/archives/2018/page/2/index.html","hash":"b8cc205fd6f2162e0bfacf4107b1043550af90f3","modified":1677649204047},{"_id":"public/archives/2018/page/4/index.html","hash":"b8dbdb00a256e8f4b74eba6d3819dab90719c835","modified":1677649204048},{"_id":"public/archives/2018/page/3/index.html","hash":"3ce84d1eb40160c264e0e33405630a1776c75169","modified":1677649204048},{"_id":"public/archives/2018/page/5/index.html","hash":"47f06ab02ce42b58a119363826b584e33ae1e72a","modified":1677649204048},{"_id":"public/archives/2018/04/index.html","hash":"431540b5beecf656a883d528c5eedfc92499b7af","modified":1677649204048},{"_id":"public/archives/2018/05/index.html","hash":"dc5fd24a817db88050ad5f3684086b2426caed67","modified":1677649204048},{"_id":"public/archives/2018/05/page/2/index.html","hash":"612d29cc5f267e653cfbdc9243202be2570d62a1","modified":1677649204048},{"_id":"public/archives/2018/11/index.html","hash":"34eff311d7b39866b86f9ba0c656cba5598b5d84","modified":1677649204048},{"_id":"public/archives/2018/12/index.html","hash":"1701a8bf4e561a54d438b966f8f43300fa31d020","modified":1677649204048},{"_id":"public/archives/2019/index.html","hash":"b52e617d56bfc750075a0f73d81de3fa438abf8b","modified":1677649204048},{"_id":"public/archives/2018/12/page/2/index.html","hash":"6ddd2e3c45404afd622a63e7574d632c1353c629","modified":1677649204048},{"_id":"public/archives/2019/01/index.html","hash":"3c69427bea2d313968ca13b05393f0b671a60269","modified":1677649204048},{"_id":"public/archives/2019/page/2/index.html","hash":"c84cb620a33291449a0d9e0379b1fbd524869cde","modified":1677649204048},{"_id":"public/archives/2019/02/index.html","hash":"2d8911c5bc078d9481e30a34dbe09380c98be51b","modified":1677649204048},{"_id":"public/archives/2019/06/index.html","hash":"70c0f483870ec71b20428e235197999c9d6ea374","modified":1677649204048},{"_id":"public/archives/2019/05/index.html","hash":"2341b928c0f5aaac6840f9fb02312dc9dc876ed1","modified":1677649204048},{"_id":"public/archives/2019/03/index.html","hash":"01462b52f3681de07f78392a9ef983da03b16cf0","modified":1677649204048},{"_id":"public/archives/2020/index.html","hash":"4f4484ea28063499767fec69bf68fa99aea0d734","modified":1677649204048},{"_id":"public/archives/2020/03/index.html","hash":"10351041d5515cec83fecb011b817168ae0db933","modified":1677649204048},{"_id":"public/categories/工具/index.html","hash":"db8119c920167f6b0481866291317f42d30c9441","modified":1677649204048},{"_id":"public/categories/网站/index.html","hash":"010d71b7c4c6af638e9266efd1c368e0b613c847","modified":1677649204048},{"_id":"public/categories/框架/index.html","hash":"fac8740dbb6eba7f0ffc19d3c045554e792337b4","modified":1677649204048},{"_id":"public/categories/框架/page/2/index.html","hash":"697b77952d6b96817ba216b603f143880d1cec02","modified":1677649204048},{"_id":"public/categories/工具/日常工具/index.html","hash":"1da0a102d90833c55370f527cbf2b3868e19524a","modified":1677649204048},{"_id":"public/categories/工具/嵌入式/index.html","hash":"a5a7c4091ab771001b8076b6debbdf3644e4194d","modified":1677649204048},{"_id":"public/categories/网站/wordpress/index.html","hash":"16f54c5356b1d39b7792302da8bd9accf166ea29","modified":1677649204048},{"_id":"public/categories/框架/opencv/index.html","hash":"306fa71d9e676aefd92be6df9133c77cfe36159b","modified":1677649204048},{"_id":"public/categories/工具/日常工具/系统软件/index.html","hash":"adb4e0d013840ac97277a211b1601dfadff76498","modified":1677649204049},{"_id":"public/categories/框架/pytorch/index.html","hash":"47c860b1cf352b5572102085d6ae012b05e48a7d","modified":1677649204049},{"_id":"public/categories/工具/日常工具/LOL/index.html","hash":"daa96198f8823dbbf5686abcd30b6b9c70c9141c","modified":1677649204049},{"_id":"public/categories/框架/pytorch/page/2/index.html","hash":"dcf6314ba78953c4f4d74acc2a025fa9ac35be89","modified":1677649204049},{"_id":"public/categories/工具/嵌入式/nvidia/index.html","hash":"14412b918a7cde9066489e9ffa749409679e6283","modified":1677649204049},{"_id":"public/categories/感悟/index.html","hash":"7c66d6210cc7879e11f9961d88eefaf7b6c28428","modified":1677649204049},{"_id":"public/categories/学习/index.html","hash":"7feee57dcd295e3dd474a56bafb49a12abcab220","modified":1677649204049},{"_id":"public/categories/工具/日常工具/思维导图/index.html","hash":"f3a200b47eb160b5adef995884d74ba664644dc9","modified":1677649204049},{"_id":"public/categories/学习/page/2/index.html","hash":"9520c8da62c7f9da4d2717fa78b4bb3df1ad2da0","modified":1677649204049},{"_id":"public/categories/学习/page/3/index.html","hash":"d9d1b9c2b85859123eaca673e71b5db3a6800174","modified":1677649204049},{"_id":"public/categories/界面/index.html","hash":"d4e49f39307914824cf10d74261cc18b243b83f8","modified":1677649204049},{"_id":"public/categories/网站/hexo/index.html","hash":"06f434fb91435aa20352c698d47a54e30e837c71","modified":1677649204049},{"_id":"public/categories/框架/pytorch/AlexNet/index.html","hash":"af44640c1b9256542e9a42fe5562851bd86ecc5c","modified":1677649204049},{"_id":"public/categories/框架/pytorch/CNN/index.html","hash":"be77c9813ec7eb0b9ff2187848751e0261f514f8","modified":1677649204049},{"_id":"public/categories/工具/日常工具/GItKraken/index.html","hash":"d66c81f0f75b4fd87095324dc180d57a33b09258","modified":1677649204049},{"_id":"public/categories/框架/pytorch/fastai/index.html","hash":"5bf4c2e30cf417f9fe6d7fdf60887c18f9aff8e7","modified":1677649204049},{"_id":"public/categories/框架/pytorch/GAN/index.html","hash":"6772a37ea9e102024ea3efbab717a5b4f6aa5c57","modified":1677649204049},{"_id":"public/categories/工具/日常工具/github/index.html","hash":"7364933350377b5d013e9fd083e7d37bf1c1bad4","modified":1677649204049},{"_id":"public/categories/框架/pytorch/Resnet/index.html","hash":"82558d07ba3a9fa1d1ea6e4c955c57b310707ee3","modified":1677649204049},{"_id":"public/categories/框架/pytorch/VGG/index.html","hash":"336a5927c95312b90401b91034336d52b3dcdf74","modified":1677649204049},{"_id":"public/categories/框架/pytorch/数据加载/index.html","hash":"fdca76328988a56c2c4915866a8e8435533e604f","modified":1677649204049},{"_id":"public/categories/学习/算法/index.html","hash":"746d25ae8fafc1ad5f49323264678714120fd14f","modified":1677649204049},{"_id":"public/categories/界面/pyqt/index.html","hash":"278d7bd98aaf8e454a81addfc6e177d68d4fe330","modified":1677649204049},{"_id":"public/categories/学习/计算机网络/index.html","hash":"f8639ac9299684789ecfc7a082b54513af379c22","modified":1677649204049},{"_id":"public/categories/学习/教学/index.html","hash":"3e4436975cbd10748669ecabb244f9f633bc8bb2","modified":1677649204049},{"_id":"public/categories/学习/算法/数据处理/index.html","hash":"2c7a7997506b7d328d0eb462c14a5a6e887f35a6","modified":1677649204049},{"_id":"public/categories/学习/教学/page/2/index.html","hash":"1eadebfeb339f1df105c93a842ac41eb3fd5002f","modified":1677649204049},{"_id":"public/categories/学习/计算机网络/数据链路层/index.html","hash":"672b4946f97c160e28d4453196352e5786654b04","modified":1677649204049},{"_id":"public/categories/学习/计算机网络/物理层/index.html","hash":"8df8da09ac3e60c5c21f18803c0d2044aa2c6eca","modified":1677649204049},{"_id":"public/tags/kdd99/index.html","hash":"23d257acd8057020bdb701d4e123afe7f53f66b9","modified":1677649204049},{"_id":"public/categories/学习/计算机网络/网络体系/index.html","hash":"4f19b80e1da6123c41ba01c9ca199928be42cbba","modified":1677649204049},{"_id":"public/tags/LOL/index.html","hash":"263588b385ff6be8c6895b29dca73d20c0107439","modified":1677649204049},{"_id":"public/tags/jetson-nano/index.html","hash":"5f4710c1fff9636c18dfbeb4e0055e9b206652cb","modified":1677649204050},{"_id":"public/tags/wordpress/index.html","hash":"eaccadfb9884fa36b6e6ea54f3285a2c42a63c11","modified":1677649204050},{"_id":"public/tags/cv/index.html","hash":"36c355b2ced68be8f0ac0b23a80f66126708f1ed","modified":1677649204050},{"_id":"public/tags/爬坑/index.html","hash":"603cde66f588c9e7ce8d79468985a8ea093866c4","modified":1677649204050},{"_id":"public/tags/fastai/index.html","hash":"27b9b760a90444d102c063a5c38b7ce66cb1da1d","modified":1677649204050},{"_id":"public/tags/instaGAN/index.html","hash":"26213a6909cf2b6fed4b12d3b56f9a7c98c753ea","modified":1677649204050},{"_id":"public/tags/系统软件/index.html","hash":"d5e4ba80b10a84fbed4feebd80abb351c830ca14","modified":1677649204050},{"_id":"public/tags/AlexNet/index.html","hash":"5abaa6cb1a676de0d107679a1e14f74525cdd186","modified":1677649204050},{"_id":"public/tags/心理/index.html","hash":"f67953983dfe044bc222b9b91bb45cecf36fddb3","modified":1677649204050},{"_id":"public/tags/CNN/index.html","hash":"0c861b1ca9ffdee69a35482f3cf661335f61e389","modified":1677649204050},{"_id":"public/tags/BEGAN/index.html","hash":"43c0ab58fd8a2d203ab87cc623581f8e8d628a51","modified":1677649204050},{"_id":"public/tags/DiscoGAN/index.html","hash":"7a031996fccb7114670eb0322e6baab215617d47","modified":1677649204050},{"_id":"public/tags/DCGAN/index.html","hash":"6d4980761ee13a9ab3ac45c0cbc7e4b76ac63559","modified":1677649204050},{"_id":"public/tags/GAN/index.html","hash":"53749d89dbb0b4320ce0911835752fd195299823","modified":1677649204050},{"_id":"public/tags/VAEGAN/index.html","hash":"10a127894743c6818c654c501d958465564d6b57","modified":1677649204050},{"_id":"public/tags/Resnet/index.html","hash":"cd0171b8ecdcf572f2802a7007aa01fc3917cdb3","modified":1677649204050},{"_id":"public/tags/VGG/index.html","hash":"b5ce0cee074685e58a05f95acf897d4d1fc3ac3a","modified":1677649204050},{"_id":"public/tags/WGAN/index.html","hash":"d1d6ca990e3ab19a399668be389fdb967a41accc","modified":1677649204050},{"_id":"public/tags/pix2pix/index.html","hash":"0aa95c1cbd08f7aef40f8089bb6e6e94513c25a4","modified":1677649204050},{"_id":"public/tags/加载数据集/index.html","hash":"682cd13c0f37704c6c340d301db807540b39be95","modified":1677649204050},{"_id":"public/tags/思维导图/index.html","hash":"c5615f5c7e6b5b9caeddacf8de7da0e6af830f98","modified":1677649204050},{"_id":"public/tags/归一化/index.html","hash":"72d60fba4825d665899563dc11417f766d1d02bf","modified":1677649204050},{"_id":"public/tags/pyqt5/index.html","hash":"704ff5fc4d53563925bfdb82f8db5bde9a8de888","modified":1677649204050},{"_id":"public/tags/网络/index.html","hash":"2f61920785c831d1c475d1c5b57e7e80cb9f62dd","modified":1677649204050},{"_id":"public/tags/推导/index.html","hash":"6cff397268ad4bd3c8880d7d68f59ab08547cd43","modified":1677649204050},{"_id":"public/tags/hexo/index.html","hash":"93c1e2a7346acd171046fb59463328dc93fea53f","modified":1677649204050},{"_id":"public/tags/计算机网络/index.html","hash":"50ae0df490c92956e03f9ba507528630bf731195","modified":1677649204050},{"_id":"public/tags/破解MathType/index.html","hash":"a25e9702dcb72319ded2fed9790a57a5597c5488","modified":1677649204050},{"_id":"public/tags/课后解答/index.html","hash":"53fa16602ddff83476e7a3710cae4c65ce7b1c09","modified":1677649204050},{"_id":"public/tags/GItKraken/index.html","hash":"0a51f6d30142580d40bcfe1f586a97117362c4d4","modified":1677649204051},{"_id":"public/tags/课后解答/page/2/index.html","hash":"5f2e2d75a01423f60eb5fbfcc0edad24f737b76c","modified":1677649204051},{"_id":"public/tags/github/index.html","hash":"ba1d7248f4b4c23e9a35a5a0f269aa6a7a2e1053","modified":1677649204051},{"_id":"public/CNAME","hash":"1b6e54a9b846deab320f0fa7c759d80708966e46","modified":1677649204051},{"_id":"public/alipay.png","hash":"80ef654693530ddf38a89b3f6815f6fe0ddb9767","modified":1677649204051},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1677649204051},{"_id":"public/wechatpay.png","hash":"5a07fbce5516b94f8f84ab753b643059942d81b6","modified":1677649204051},{"_id":"public/images/apple-touch-icon-next.png","hash":"a284ef46b872db3b6880ad89d55e97df895ec119","modified":1677649204051},{"_id":"public/images/algolia_logo.svg","hash":"ec119560b382b2624e00144ae01c137186e91621","modified":1677649204051},{"_id":"public/images/avatar.png","hash":"b959e8832dd83722d2a61011094fe6fd70a12fa9","modified":1677649204051},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1677649204051},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1677649204051},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1677649204051},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1677649204051},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1677649204051},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1677649204051},{"_id":"public/images/favicon-32x32-next.png","hash":"320f5ae20a358a9668e7f3be2f1deb064f059ee7","modified":1677649204051},{"_id":"public/images/loading.gif","hash":"2afcf30698ef6b8a5553dff86c511bf50f1d2465","modified":1677649204051},{"_id":"public/images/favicon-16x16-next.png","hash":"62c24ee5d99e9e853e678041b290fb90907072b7","modified":1677649204051},{"_id":"public/images/logo.svg","hash":"d29cacbae1bdc4bbccb542107ee0524fe55ad6de","modified":1677649204051},{"_id":"public/images/gzh.png","hash":"c3ca32276aa19b043c99be34ed8d101aba8a1604","modified":1677649204051},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1677649204051},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1677649204051},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1677649204051},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1677649204051},{"_id":"public/404/images/bird.png","hash":"9e0798b01e54ec033a47795c7b7610bd6e1ee77d","modified":1677649204051},{"_id":"public/404/images/san.png","hash":"659aaca45f96838f66b0fc6f062f588c6cb62824","modified":1677649204051},{"_id":"public/404/images/yun1.png","hash":"a776001b9a61b0bdbd650b8346321b5004200fad","modified":1677649204051},{"_id":"public/404/images/yun0.png","hash":"b21498b2f11a62d422da7a1ab2a24c26af4c5224","modified":1677649204051},{"_id":"public/404/images/yun2.png","hash":"76018d55773ba8f07dbb440ffcfed412f0ac46b9","modified":1677649204051},{"_id":"public/about/images/arrow.png","hash":"cd3367b5cf1df79efdd5dc1c9a3ef50f950afbef","modified":1677649204051},{"_id":"public/about/images/bg-down-arrow.png","hash":"b462a8aad67812717f17c1568319e63498e1b295","modified":1677649204051},{"_id":"public/about/images/avatar.jpg","hash":"8205b8dd816bf7204da74f9c23f7ed33852ed4e4","modified":1677649204051},{"_id":"public/about/images/avatar@2x.jpg","hash":"d913589bef5002af126b3a296130009ddd65b72e","modified":1677649204051},{"_id":"public/about/images/bg-tile.png","hash":"515fc732f0c5dd23e199716e531cde634136766f","modified":1677649204051},{"_id":"public/about/images/bio-icon-2.png","hash":"b72c201dbd81e528290ab54dbfca36ad795d485a","modified":1677649204051},{"_id":"public/about/images/bio-icon-1.png","hash":"2b48878b4089cc8ba998ad660b7f5f56eb254223","modified":1677649204051},{"_id":"public/about/images/bio-icon-3.png","hash":"e8c575d2ad3989a363d12230ca8c7808c152ea05","modified":1677649204051},{"_id":"public/about/images/bio-text-2.png","hash":"050d81de2bcb50a099698521a028a2b0e9a0de0a","modified":1677649204051},{"_id":"public/about/images/bio-text-1.png","hash":"84d6016e4726c6ba2f59c740954d23c74fa4ba03","modified":1677649204051},{"_id":"public/about/images/bio-text-3.png","hash":"f993f58a62b77b44829fe6aa43b2c62dec0a3ba1","modified":1677649204051},{"_id":"public/about/images/home-bg.jpg","hash":"ffd86fb9edb1151e3db8e7e3f50b434e44de9fb2","modified":1677649204051},{"_id":"public/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1677649204051},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1677649204051},{"_id":"public/images/2021/07/26/f69f0940-edea-11eb-9787-e1cba314367a.png","hash":"b959e8832dd83722d2a61011094fe6fd70a12fa9","modified":1677649204052},{"_id":"public/about/images/works/91zaojia.jpg","hash":"9a6024e9528299dbe102298484764831d05434e2","modified":1677649204052},{"_id":"public/about/images/works/cv.jpg","hash":"96695ec47c52e7750d15746e434dacbea61a1a7d","modified":1677649204052},{"_id":"public/about/images/works/ys.jpg","hash":"c82f9126e35900640aa581034298012f55b8afd4","modified":1677649204052},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1677649204052},{"_id":"public/about/images/works/dp.jpeg","hash":"a6e64ac1f08b8c77fa2f564b2180dd8ac9ec7e77","modified":1677649204052},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1677649204052},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1677649204052},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1677649204052},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1677649205361},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1677649205363},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1677649205366},{"_id":"public/lib/Han/dist/font/han-space.woff","hash":"7a635062b10bf5662ae1d218ba0980171005d060","modified":1677649205366},{"_id":"public/lib/Han/dist/font/han-space.otf","hash":"07436f011b44051f61b8329c99de4bec64e86f4b","modified":1677649205366},{"_id":"public/lib/Han/dist/font/han.woff","hash":"f38ff9b2eecaa17b50b66aa2dae87e9e7436d195","modified":1677649205366},{"_id":"public/lib/Han/dist/font/han.woff2","hash":"623af3ed5423371ac136a4fe0e8cc7bb7396037a","modified":1677649205366},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1677649205366},{"_id":"public/lib/Han/dist/font/han.otf","hash":"f1f6bb8f461f5672e000380195d3d2358a28494c","modified":1677649205366},{"_id":"public/live2dw/assets/moc/z16.256/texture_00.png","hash":"19f22619c246067d519aa1e6e477497cc4342414","modified":1677649205366},{"_id":"public/live2dw/assets/exp/f00.exp.json","hash":"84073a497ddb6e56c6cfc244a0fb217ba473abf9","modified":1677649205366},{"_id":"public/live2dw/assets/moc/z16.512/texture_00.png","hash":"251b9f944fb1575c01a62b8a9d7522fe76954b3b","modified":1677649205366},{"_id":"public/live2dw/assets/mtn/idle.mtn","hash":"f6b879d9f1d096509a7edbc971b8fdd9697932e9","modified":1677649205366},{"_id":"public/live2dw/assets/z16.model.json","hash":"e69f3d2ecc9bf51b3972ad9df8f6aaa31956910c","modified":1677649205366},{"_id":"public/live2dw/lib/L2Dwidget.min.js","hash":"5f1a807437cc723bcadc3791d37add5ceed566a2","modified":1677649205366},{"_id":"public/live2dw/assets/z16.physics.json","hash":"67f13f60030d7e4c7f824c001ab5254ce4b9bafd","modified":1677649205366},{"_id":"public/404/css/404.css","hash":"00d433d95ed867f368c033b1dba1629e72727d3b","modified":1677649205377},{"_id":"public/about/js/global.js","hash":"302297db83d450452ac0d7c9e154d5e87555b23c","modified":1677649205377},{"_id":"public/404/css/public.css","hash":"1ccd94e3cbb447853f46d9279faaa1c2ed94833a","modified":1677649205381},{"_id":"public/about/js/js.js","hash":"c8033416ec46c129ed1b9cee03a2bde121a55d86","modified":1677649205381},{"_id":"public/about/js/password.js","hash":"963ad9f5f8e693a10b394bef60f9e768bcd1ee8d","modified":1677649205382},{"_id":"public/about/js/waypoints.min.js","hash":"bedeb001dfb0b40f52c1b234bd7ceebe6a0a0928","modified":1677649205382},{"_id":"public/js/src/algolia-search.js","hash":"b172f697ed339a24b1e80261075232978d164c35","modified":1677649205382},{"_id":"public/js/src/bootstrap.js","hash":"034bc8113e0966fe2096ba5b56061bbf10ef0512","modified":1677649205382},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1677649205382},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1677649205382},{"_id":"public/js/src/js.cookie.js","hash":"9b37973a90fd50e71ea91682265715e45ae82c75","modified":1677649205382},{"_id":"public/js/src/love.js","hash":"9e8e79d69ad8338761272f86fe5cad0ad5e503cc","modified":1677649205382},{"_id":"public/js/src/exturl.js","hash":"e42e2aaab7bf4c19a0c8e779140e079c6aa5c0b1","modified":1677649205382},{"_id":"public/js/src/motion.js","hash":"754b294394f102c8fd9423a1789ddb1201677898","modified":1677649205382},{"_id":"public/js/src/post-details.js","hash":"a13f45f7aa8291cf7244ec5ba93907d119c5dbdd","modified":1677649205382},{"_id":"public/js/src/scroll-cookie.js","hash":"09dc828cbf5f31158ff6250d2bf7c3cde6365c67","modified":1677649205382},{"_id":"public/js/src/utils.js","hash":"9b1325801d27213083d1487a12b1a62b539ab6f8","modified":1677649205382},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1677649205382},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1677649205382},{"_id":"public/lib/canvas-ribbon/canvas-ribbon.js","hash":"ff5915eb2596e890a2fc6697c864f861a1995ec0","modified":1677649205382},{"_id":"public/lib/canvas-nest/canvas-nest.min.js","hash":"0387e75e23b1db108a755073fe52a0d03eb391a7","modified":1677649205382},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1677649205382},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1677649205382},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1677649205382},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1677649205382},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1677649205382},{"_id":"public/lib/needsharebutton/needsharebutton.css","hash":"3ef0020a1815ca6151ea4886cd0d37421ae3695c","modified":1677649205382},{"_id":"public/lib/pace/pace-theme-big-counter.min.css","hash":"5b561dc328af4c4d512e20a76fe964d113a32ba8","modified":1677649205382},{"_id":"public/lib/pace/pace-theme-bounce.min.css","hash":"f6bdb9a785b7979dd8ec5c60e278af955ef1e585","modified":1677649205382},{"_id":"public/lib/pace/pace-theme-barber-shop.min.css","hash":"ee0d51446cb4ffe1bb96bd7bc8c8e046dddfcf46","modified":1677649205382},{"_id":"public/lib/pace/pace-theme-center-circle.min.css","hash":"a4066769c78affbfbc5e30a600e2c7862cd532e0","modified":1677649205382},{"_id":"public/lib/pace/pace-theme-center-atom.min.css","hash":"dcf79c24fe5350fb73d8038573a104e73639e9d3","modified":1677649205382},{"_id":"public/lib/pace/pace-theme-center-radar.min.css","hash":"ab7cba998bf4c03b13df342bf43647fa4f419783","modified":1677649205382},{"_id":"public/lib/pace/pace-theme-center-simple.min.css","hash":"67f44c947548bd4d77e7590d3f59e236cbf9e98a","modified":1677649205382},{"_id":"public/lib/pace/pace-theme-fill-left.min.css","hash":"0bec1e235a4a2cccda3f993b205424e1441a44ae","modified":1677649205382},{"_id":"public/lib/pace/pace-theme-corner-indicator.min.css","hash":"b3c64c973f31884e3d8145989476707333406b9a","modified":1677649205383},{"_id":"public/lib/pace/pace-theme-flash.min.css","hash":"13ace22c40312d7bbd8d9c1e50eff897a7a497d8","modified":1677649205383},{"_id":"public/lib/pace/pace-theme-mac-osx.min.css","hash":"9f2e7b51b084da407863826b25265b31150b3821","modified":1677649205383},{"_id":"public/lib/pace/pace-theme-loading-bar.min.css","hash":"7ee28875dfc1230d76c537f6605766e8d4011e9f","modified":1677649205383},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1677649205383},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1677649205383},{"_id":"public/lib/pace/pace.min.js","hash":"9944dfb7814b911090e96446cea4d36e2b487234","modified":1677649205383},{"_id":"public/js/src/schemes/pisces.js","hash":"8050a5b2683d1d77238c5762b6bd89c543daed6e","modified":1677649205383},{"_id":"public/lib/pace/pace-theme-minimal.min.css","hash":"9cd783cceb8a191f3c8b5d81f7a430ecc3e489d3","modified":1677649205383},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1677649205383},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1677649205383},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1677649205383},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1677649205383},{"_id":"public/lib/fastclick/README.html","hash":"da3c74d484c73cc7df565e8abbfa4d6a5a18d4da","modified":1677649205383},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"a6358170d346af13b1452ac157b60505bec7015c","modified":1677649205383},{"_id":"public/lib/jquery_lazyload/README.html","hash":"bde24335f6bc09d8801c0dcd7274f71b466552bd","modified":1677649205383},{"_id":"public/css/main.css","hash":"622c9e5aab2975bb14f56bb841f17529b8c5c0af","modified":1677649205383},{"_id":"public/about/js/jquery.stellar.min.js","hash":"96d41d4ee128138ee29cd4e8e4ad20da54b39929","modified":1677649205383},{"_id":"public/about/css/style.css","hash":"d5f9427fca9a5423508cd71d512f6e05f05f8e37","modified":1677649205383},{"_id":"public/404/css/index.css","hash":"1e49f5c820eeb5b343be731506d3ac259a002b7f","modified":1677649205383},{"_id":"public/lib/needsharebutton/needsharebutton.js","hash":"9885fd9bea5e7ebafc5b1de9d17be5e106248d96","modified":1677649205383},{"_id":"public/lib/needsharebutton/font-embedded.css","hash":"c39d37278c1e178838732af21bd26cd0baeddfe0","modified":1677649205383},{"_id":"public/lib/three/canvas_sphere.min.js","hash":"d8ea241a53c135a650f7335d2b6982b899fd58a9","modified":1677649205383},{"_id":"public/lib/three/three-waves.min.js","hash":"d968cba6b3a50b3626a02d67b544f349d83b147c","modified":1677649205383},{"_id":"public/lib/three/canvas_lines.min.js","hash":"dce4a3b65f8bf958f973690caa7ec4952f353b0c","modified":1677649205383},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1677649205383},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1677649205383},{"_id":"public/404/js/jquery-1.7.2.min.js","hash":"abcd2ba13348f178b17141b445bc99f1917d47af","modified":1677649205383},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1677649205383},{"_id":"public/lib/Han/dist/han.css","hash":"bd40da3fba8735df5850956814e312bd7b3193d7","modified":1677649205383},{"_id":"public/lib/Han/dist/han.min.css","hash":"a0c9e32549a8b8cf327ab9227b037f323cdb60ee","modified":1677649205383},{"_id":"public/about/js/jquery-1.9.1.min.js","hash":"b5926d5e80b94d7eee4e9f1c18b91427d47f2530","modified":1677649205383},{"_id":"public/lib/Han/dist/han.min.js","hash":"f559c68a25065a14f47da954a7617d87263e409d","modified":1677649205383},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1677649205383},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1677649205383},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"512c7d79033e3028a9be61b540cf1a6870c896f8","modified":1677649205383},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"0140952c64e3f2b74ef64e050f2fe86eab6624c8","modified":1677649205384},{"_id":"public/lib/Han/dist/han.js","hash":"e345397e0585c9fed1449e614ec13e0224acf2ab","modified":1677649205384},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1677649205384},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"d6f48cba7d076fb6f2fd6ba993a75b9dc1ecbf0c","modified":1677649205384},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"28b782240b3e76db824e12c02754a9731a167527","modified":1677649205384},{"_id":"public/live2dw/assets/moc/z16.moc","hash":"6b0241e80e94664d694b43ad05333960de2550c1","modified":1677649205384},{"_id":"public/live2dw/lib/L2Dwidget.min.js.map","hash":"3290fe2df45f065b51a1cd7b24ec325cbf9bb5ce","modified":1677649205384},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1677649205392},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1677649205392},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1677649205392},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1677649205392},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1677649205392},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1677649205392},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1677649205392},{"_id":"public/lib/three/three.min.js","hash":"73f4cdc17e51a72b9bf5b9291f65386d615c483b","modified":1677649205392},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"13b1eab65a983c7a73bc7997c479d66943f7c6cb","modified":1677649205392},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"d980c2ce873dc43af460d4d572d441304499f400","modified":1677649205392},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"048707bc52ac4b6563aaa383bfe8660a0ddc908c","modified":1677649205392},{"_id":"public/live2dw/assets/moc/z16.1024/texture_00.png","hash":"c4f7c067d7d37601490554438ab801fce1feb92d","modified":1677649205392},{"_id":"public/live2dw/lib/L2Dwidget.0.min.js","hash":"35bb5b588b6de25c9be2dd51d3fd331feafac02d","modified":1677649205392},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"98a8aa5cf7d62c2eff5f07ede8d844b874ef06ed","modified":1677649205432},{"_id":"public/live2dw/lib/L2Dwidget.0.min.js.map","hash":"35e71cc2a130199efb167b9a06939576602f0d75","modified":1677649205460},{"_id":"public/images/b.jpg","hash":"ff23147ec592d70e86548fda89b606baba77c00f","modified":1677649205493}],"Category":[{"name":"工具","_id":"clep90m150008igtaub81ddvy"},{"name":"网站","_id":"clep90m1e000iigtaj9ghkgwx"},{"name":"框架","_id":"clep90m1j000nigtafn4plil3"},{"name":"日常工具","parent":"clep90m150008igtaub81ddvy","_id":"clep90m1n000sigtag4kz3d20"},{"name":"嵌入式","parent":"clep90m150008igtaub81ddvy","_id":"clep90m1q000yigtahlxusmqb"},{"name":"wordpress","parent":"clep90m1e000iigtaj9ghkgwx","_id":"clep90m20001jigtaa1h4m1g5"},{"name":"opencv","parent":"clep90m1j000nigtafn4plil3","_id":"clep90m270020igtat5u8vg6u"},{"name":"系统软件","parent":"clep90m1n000sigtag4kz3d20","_id":"clep90m2b0026igtacmdf5qil"},{"name":"LOL","parent":"clep90m1n000sigtag4kz3d20","_id":"clep90m2e002digtagz16kxel"},{"name":"pytorch","parent":"clep90m1j000nigtafn4plil3","_id":"clep90m2i002nigta9xayotb1"},{"name":"nvidia","parent":"clep90m1q000yigtahlxusmqb","_id":"clep90m2q0031igtakowaynnn"},{"name":"感悟","_id":"clep90m2t0038igtaovf882gd"},{"name":"思维导图","parent":"clep90m1n000sigtag4kz3d20","_id":"clep90m3m005oigta05clydu6"},{"name":"学习","_id":"clep90m3q005sigta7m2hemoe"},{"name":"界面","_id":"clep90m3q005wigtaojzizpgr"},{"name":"hexo","parent":"clep90m1e000iigtaj9ghkgwx","_id":"clep90m3v0069igtaiq414pp5"},{"name":"AlexNet","parent":"clep90m2i002nigta9xayotb1","_id":"clep90m3x006higtaxgvv9u8n"},{"name":"CNN","parent":"clep90m2i002nigta9xayotb1","_id":"clep90m430074igtaq71f3pvq"},{"name":"GItKraken","parent":"clep90m1n000sigtag4kz3d20","_id":"clep90m45007aigtac9lboyiu"},{"name":"GAN","parent":"clep90m2i002nigta9xayotb1","_id":"clep90m48007oigtah4t2tyg6"},{"name":"fastai","parent":"clep90m2i002nigta9xayotb1","_id":"clep90m4d0083igta2vp33y72"},{"name":"github","parent":"clep90m1n000sigtag4kz3d20","_id":"clep90m4h008higta7juxddcc"},{"name":"Resnet","parent":"clep90m2i002nigta9xayotb1","_id":"clep90m4j008sigtaot7qmgs9"},{"name":"VGG","parent":"clep90m2i002nigta9xayotb1","_id":"clep90m4k008vigtavgx1nfxj"},{"name":"数据加载","parent":"clep90m2i002nigta9xayotb1","_id":"clep90m4m0097igtapw63gtng"},{"name":"算法","parent":"clep90m3q005sigta7m2hemoe","_id":"clep90m4n009aigta3dxbhtgk"},{"name":"pyqt","parent":"clep90m3q005wigtaojzizpgr","_id":"clep90m4n009eigtaoe1uh27q"},{"name":"计算机网络","parent":"clep90m3q005sigta7m2hemoe","_id":"clep90m4o009higtadu1ctbj0"},{"name":"教学","parent":"clep90m3q005sigta7m2hemoe","_id":"clep90m4r009tigta3ayjozzj"},{"name":"数据处理","parent":"clep90m4n009aigta3dxbhtgk","_id":"clep90m5100b5igta9j7vqb4f"},{"name":"数据链路层","parent":"clep90m4o009higtadu1ctbj0","_id":"clep90m5200b8igtazq6a4zud"},{"name":"物理层","parent":"clep90m4o009higtadu1ctbj0","_id":"clep90m5200baigtaf0k8itra"},{"name":"网络体系","parent":"clep90m4o009higtadu1ctbj0","_id":"clep90m5300bdigtad6g9b4lv"}],"Data":[],"Page":[{"layout":"false","_content":"<html>\n    <head>\n        <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n        <link href=\"/404/css/public.css\" rel=\"stylesheet\" type=\"text/css\" />\n        <link href=\"/404/css/index.css\" rel=\"stylesheet\" type=\"text/css\" />\n        <link href=\"/404/css/404.css\" rel=\"stylesheet\" type=\"text/css\" />\n        <script src=\"/404/js/jquery-1.7.2.min.js\"></script>\n        <script type=\"text/javascript\">\n            $(function() {\n                var h = $(window).height();\n                $('body').height(h);\n                $('.mianBox').height(h);\n                centerWindow(\".tipInfo\");\n            });\n\n            //2.将盒子方法放入这个方，方便法统一调用\n            function centerWindow(a) {\n                center(a);\n                //自适应窗口\n                $(window).bind('scroll resize',\n                        function() {\n                            center(a);\n                        });\n            }\n\n            //1.居中方法，传入需要剧中的标签\n            function center(a) {\n                var wWidth = $(window).width();\n                var wHeight = $(window).height();\n                var boxWidth = $(a).width();\n                var boxHeight = $(a).height();\n                var scrollTop = $(window).scrollTop();\n                var scrollLeft = $(window).scrollLeft();\n                var top = scrollTop + (wHeight - boxHeight) / 2;\n                var left = scrollLeft + (wWidth - boxWidth) / 2;\n                $(a).css({\n                    \"top\": top,\n                    \"left\": left\n                });\n            }\n        </script>\n    </head>\n    <body>\n        <div class=\"mianBox\">\n            <img src=\"/404/images/yun0.png\" alt=\"\" class=\"yun yun0\" />\n            <img src=\"/404/images/yun1.png\" alt=\"\" class=\"yun yun1\" />\n            <img src=\"/404/images/yun2.png\" alt=\"\" class=\"yun yun2\" />\n            <img src=\"/404/images/bird.png\" alt=\"\" class=\"bird\" />\n            <img src=\"/404/images/san.png\" alt=\"\" class=\"san\" />\n            <div class=\"tipInfo\">\n                <div class=\"in\">\n                    <div class=\"textThis\">\n                        <h2>页面错误</h2>\n                        <p><span>页面自动<a id=\"href\" href=\"http://sindre97.github.io\">跳转</a></span><span>等待<b id=\"wait\">5</b>秒</span></p>\n                        <script type=\"text/javascript\">                            (function() {\n                                var wait = document.getElementById('wait'), href = document.getElementById('href').href;\n                                var interval = setInterval(function() {\n                                    var time = --wait.innerHTML;\n                                    if (time <= 0) {\n                                        location.href = href;\n                                        clearInterval(interval);\n                                    }\n                                    ;\n                                }, 1000);\n                            })();\n                        </script>\n                    </div>\n                </div>\n            </div>\n        </div>\n    </body>\n</html>","source":"404.html","raw":"---\nlayout: false\n---\n<html>\n    <head>\n        <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\" />\n        <link href=\"/404/css/public.css\" rel=\"stylesheet\" type=\"text/css\" />\n        <link href=\"/404/css/index.css\" rel=\"stylesheet\" type=\"text/css\" />\n        <link href=\"/404/css/404.css\" rel=\"stylesheet\" type=\"text/css\" />\n        <script src=\"/404/js/jquery-1.7.2.min.js\"></script>\n        <script type=\"text/javascript\">\n            $(function() {\n                var h = $(window).height();\n                $('body').height(h);\n                $('.mianBox').height(h);\n                centerWindow(\".tipInfo\");\n            });\n\n            //2.将盒子方法放入这个方，方便法统一调用\n            function centerWindow(a) {\n                center(a);\n                //自适应窗口\n                $(window).bind('scroll resize',\n                        function() {\n                            center(a);\n                        });\n            }\n\n            //1.居中方法，传入需要剧中的标签\n            function center(a) {\n                var wWidth = $(window).width();\n                var wHeight = $(window).height();\n                var boxWidth = $(a).width();\n                var boxHeight = $(a).height();\n                var scrollTop = $(window).scrollTop();\n                var scrollLeft = $(window).scrollLeft();\n                var top = scrollTop + (wHeight - boxHeight) / 2;\n                var left = scrollLeft + (wWidth - boxWidth) / 2;\n                $(a).css({\n                    \"top\": top,\n                    \"left\": left\n                });\n            }\n        </script>\n    </head>\n    <body>\n        <div class=\"mianBox\">\n            <img src=\"/404/images/yun0.png\" alt=\"\" class=\"yun yun0\" />\n            <img src=\"/404/images/yun1.png\" alt=\"\" class=\"yun yun1\" />\n            <img src=\"/404/images/yun2.png\" alt=\"\" class=\"yun yun2\" />\n            <img src=\"/404/images/bird.png\" alt=\"\" class=\"bird\" />\n            <img src=\"/404/images/san.png\" alt=\"\" class=\"san\" />\n            <div class=\"tipInfo\">\n                <div class=\"in\">\n                    <div class=\"textThis\">\n                        <h2>页面错误</h2>\n                        <p><span>页面自动<a id=\"href\" href=\"http://sindre97.github.io\">跳转</a></span><span>等待<b id=\"wait\">5</b>秒</span></p>\n                        <script type=\"text/javascript\">                            (function() {\n                                var wait = document.getElementById('wait'), href = document.getElementById('href').href;\n                                var interval = setInterval(function() {\n                                    var time = --wait.innerHTML;\n                                    if (time <= 0) {\n                                        location.href = href;\n                                        clearInterval(interval);\n                                    }\n                                    ;\n                                }, 1000);\n                            })();\n                        </script>\n                    </div>\n                </div>\n            </div>\n        </div>\n    </body>\n</html>","date":"2023-03-01T05:17:39.660Z","updated":"2018-12-12T20:45:07.854Z","path":"404.html","title":"","comments":1,"_id":"clep90lwp0000igta3o64zm8p","content":"<html>\n    <head><meta name=\"generator\" content=\"Hexo 3.8.0\">\n        <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n        <link href=\"/404/css/public.css\" rel=\"stylesheet\" type=\"text/css\">\n        <link href=\"/404/css/index.css\" rel=\"stylesheet\" type=\"text/css\">\n        <link href=\"/404/css/404.css\" rel=\"stylesheet\" type=\"text/css\">\n        <script src=\"/404/js/jquery-1.7.2.min.js\"></script>\n        <script type=\"text/javascript\">\n            $(function() {\n                var h = $(window).height();\n                $('body').height(h);\n                $('.mianBox').height(h);\n                centerWindow(\".tipInfo\");\n            });\n\n            //2.将盒子方法放入这个方，方便法统一调用\n            function centerWindow(a) {\n                center(a);\n                //自适应窗口\n                $(window).bind('scroll resize',\n                        function() {\n                            center(a);\n                        });\n            }\n\n            //1.居中方法，传入需要剧中的标签\n            function center(a) {\n                var wWidth = $(window).width();\n                var wHeight = $(window).height();\n                var boxWidth = $(a).width();\n                var boxHeight = $(a).height();\n                var scrollTop = $(window).scrollTop();\n                var scrollLeft = $(window).scrollLeft();\n                var top = scrollTop + (wHeight - boxHeight) / 2;\n                var left = scrollLeft + (wWidth - boxWidth) / 2;\n                $(a).css({\n                    \"top\": top,\n                    \"left\": left\n                });\n            }\n        </script>\n    </head>\n    <body>\n        <div class=\"mianBox\">\n            <img src=\"/404/images/yun0.png\" alt class=\"yun yun0\">\n            <img src=\"/404/images/yun1.png\" alt class=\"yun yun1\">\n            <img src=\"/404/images/yun2.png\" alt class=\"yun yun2\">\n            <img src=\"/404/images/bird.png\" alt class=\"bird\">\n            <img src=\"/404/images/san.png\" alt class=\"san\">\n            <div class=\"tipInfo\">\n                <div class=\"in\">\n                    <div class=\"textThis\">\n                        <h2>页面错误</h2>\n                        <p><span>页面自动<a id=\"href\" href=\"http://sindre97.github.io\" target=\"_blank\" rel=\"noopener\">跳转</a></span><span>等待<b id=\"wait\">5</b>秒</span></p>\n                        <script type=\"text/javascript\">                            (function() {\n                                var wait = document.getElementById('wait'), href = document.getElementById('href').href;\n                                var interval = setInterval(function() {\n                                    var time = --wait.innerHTML;\n                                    if (time <= 0) {\n                                        location.href = href;\n                                        clearInterval(interval);\n                                    }\n                                    ;\n                                }, 1000);\n                            })();\n                        </script>\n                    </div>\n                </div>\n            </div>\n        </div>\n    <script src=\"/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05\"></script><script>L2Dwidget.init({\"pluginRootPath\":\"live2dw/\",\"pluginJsPath\":\"lib/\",\"pluginModelPath\":\"assets/\",\"tagMode\":false,\"debug\":false,\"model\":{\"jsonPath\":\"/live2dw/assets/z16.model.json\"},\"display\":{\"position\":\"left\",\"width\":75,\"height\":150},\"mobile\":{\"show\":true},\"log\":false});</script></body>\n</html>","site":{"data":{}},"excerpt":"","more":"<html>\n    <head><meta name=\"generator\" content=\"Hexo 3.8.0\">\n        <meta http-equiv=\"Content-Type\" content=\"text/html; charset=utf-8\">\n        <link href=\"/404/css/public.css\" rel=\"stylesheet\" type=\"text/css\">\n        <link href=\"/404/css/index.css\" rel=\"stylesheet\" type=\"text/css\">\n        <link href=\"/404/css/404.css\" rel=\"stylesheet\" type=\"text/css\">\n        <script src=\"/404/js/jquery-1.7.2.min.js\"></script>\n        <script type=\"text/javascript\">\n            $(function() {\n                var h = $(window).height();\n                $('body').height(h);\n                $('.mianBox').height(h);\n                centerWindow(\".tipInfo\");\n            });\n\n            //2.将盒子方法放入这个方，方便法统一调用\n            function centerWindow(a) {\n                center(a);\n                //自适应窗口\n                $(window).bind('scroll resize',\n                        function() {\n                            center(a);\n                        });\n            }\n\n            //1.居中方法，传入需要剧中的标签\n            function center(a) {\n                var wWidth = $(window).width();\n                var wHeight = $(window).height();\n                var boxWidth = $(a).width();\n                var boxHeight = $(a).height();\n                var scrollTop = $(window).scrollTop();\n                var scrollLeft = $(window).scrollLeft();\n                var top = scrollTop + (wHeight - boxHeight) / 2;\n                var left = scrollLeft + (wWidth - boxWidth) / 2;\n                $(a).css({\n                    \"top\": top,\n                    \"left\": left\n                });\n            }\n        </script>\n    </head>\n    <body>\n        <div class=\"mianBox\">\n            <img src=\"/404/images/yun0.png\" alt class=\"yun yun0\">\n            <img src=\"/404/images/yun1.png\" alt class=\"yun yun1\">\n            <img src=\"/404/images/yun2.png\" alt class=\"yun yun2\">\n            <img src=\"/404/images/bird.png\" alt class=\"bird\">\n            <img src=\"/404/images/san.png\" alt class=\"san\">\n            <div class=\"tipInfo\">\n                <div class=\"in\">\n                    <div class=\"textThis\">\n                        <h2>页面错误</h2>\n                        <p><span>页面自动<a id=\"href\" href=\"http://sindre97.github.io\" target=\"_blank\" rel=\"noopener\">跳转</a></span><span>等待<b id=\"wait\">5</b>秒</span></p>\n                        <script type=\"text/javascript\">                            (function() {\n                                var wait = document.getElementById('wait'), href = document.getElementById('href').href;\n                                var interval = setInterval(function() {\n                                    var time = --wait.innerHTML;\n                                    if (time <= 0) {\n                                        location.href = href;\n                                        clearInterval(interval);\n                                    }\n                                    ;\n                                }, 1000);\n                            })();\n                        </script>\n                    </div>\n                </div>\n            </div>\n        </div>\n    <script src=\"/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05\"></script><script>L2Dwidget.init({\"pluginRootPath\":\"live2dw/\",\"pluginJsPath\":\"lib/\",\"pluginModelPath\":\"assets/\",\"tagMode\":false,\"debug\":false,\"model\":{\"jsonPath\":\"/live2dw/assets/z16.model.json\"},\"display\":{\"position\":\"left\",\"width\":75,\"height\":150},\"mobile\":{\"show\":true},\"log\":false});</script></body>\n</html>"},{"layout":"false","_content":"\n<!DOCTYPE html>\n<html>\n<head><meta name=\"generator\" content=\"Hexo 3.8.0\">\n\t<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n\t<meta name=\"viewport\" content=\"width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0\">\t\n\t<title>关于</title>\n\t<link rel=\"stylesheet\" href=\"/about/css/style.css\" type=\"text/css\" media=\"all\" >\n\n</head>\n\n<body class=\"loading-process\" onload=\"checkpassword()\">\n<div class=\"loading\">\n\t<div class=\"loading-circle\"></div>\n\t<div class=\"loading-avatar\"><img src=\"/about/images/avatar@2x.jpg\" alt width=\"100\" height=\"100\"></div>\n\t<div class=\"loading-info\">正在努力加载中...</div>\n</div>\n<div class=\"home-bg\">\n\t<img src=\"/about/images/home-bg.jpg\" alt width=\"1000\" height=\"667\">\n</div>\n<div class=\"section-wrap section-fristpage\" data-slide=\"1\">\n\t<div class=\"section\">\n\t\t<div class=\"section-content\">\n\t\t\t<p class=\"fade fade1\">感谢您的光临</p>\n\t\t\t<p class=\"fade fade2\">本模块正在建设中！</p>\n\t\t\t<p class=\"fade fade3\">想了解更多，往下滚动哦 ^_^</p>\n\n\t\t</div>\n\n\t\t<a class=\"button2 scroll-tip fade fade4\" data-slide=\"3\" title >向下滚动</a>\n\t</div>\n</div>\n<div id=\"/about\" data-slide=\"2\" data-stellar-background-ratio=\"0.3\" class=\"section-wrap section-/about\">\n\t<div class=\"section\">\n\t\t<div class=\"/about-content clearfix section-content\">\n\t\t\t<div class=\"introli\">\n\t\t\t  <span class=\"left_icon\"><img class=\"bio-text bio-icon-1\" src=\"/about/images/bio-icon-1.png\" data-stellar-ratio=\"0.7\"></span>\n\t\t\t  <span class=\"right_content \">从局部到全局的方式去除图像中的雨水条纹 </span>\n\t\t\t</div>\n\t\t\t<div class=\"introli\">\n\t\t\t  <span class=\"left_icon\"><img class=\"bio-text bio-icon-2\" src=\"/about/images/bio-icon-2.png\" data-stellar-ratio=\"0.7\"></span>\n\t\t\t  <span class=\"right_content\"><img class=\"bio-text bio-text-2\" src=\"/about/images/bio-text-2.png\" data-stellar-ratio=\"0.7\"></span>\n\t\t\t</div>\n\t\t\t<div class=\"introli\">\n\t\t\t  <span class=\"left_icon\"><img class=\"bio-text bio-icon-3\" src=\"/about/images/bio-icon-3.png \" data-stellar-ratio=\"0.7\"></span>\n\t\t\t  <span class=\"right_content\"><img class=\"bio-text bio-text-3\" src=\"/about/images/bio-text-3.png \" data-stellar-ratio=\"0.7\"></span>\n\t\t\t</div>\n\n\t\t</div>\n\n\t</div>\n\t<a class=\"button2 dark-button2 scroll-tip\" style=\"background-position:0 -60px;\" data-slide=\"3\" title></a>\n</div>\n<div id=\"works\" class=\"section-wrap section-works\" data-slide=\"3\">\n\t<div class=\"section\">\n\t\t<div class=\"works-content section-content\">\n\t\t\t<h1>作品</h1>\n\t\t\t<div class=\"works-list clearfix\">\n\t\t\t\t<div class=\"works-item first fade fade1\">\n\t\t\t\t\t<a href=\"#\" target=\"_blank\">\n\t\t\t\t\t\t<img src=\"/about/images/works/dp.jpeg\" alt width=\"300\" height=\"180\">\n\t\t\t\t\t\t<div class=\"work-info\">\n\t\t\t\t\t\t\t<h2>基于GAN的流数据生成方法</h2>\n\t\t\t\t\t\t\t<p><strong>工作详情：</strong>利用生成对抗网络的良好图像生成技术,增强入侵系统的知识库丰富度,提高入侵检测系统的可进化性及检测准确性<br>\n\t\t\t\t\t\t\t<strong>工作时间：</strong>2018年12月</p>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"works-item fade fade2\">\n\t\t\t\t\t<a href=\"#/\" target=\"_blank\">\n\t\t\t\t\t\t<img src=\"/about/images/works/dp.jpeg\" alt width=\"300\" height=\"180\">\n\t\t\t\t\t\t<div class=\"work-info\">\n\t\t\t\t\t\t\t<h2>从局部到全局的方式去除图像中的雨水条纹</h2>\n\t\t\t\t\t\t\t<p><strong>工作详情：</strong>结合时间先验和人工监督方式,通过SPANet从局部到全局的方式去除条纹<br>\n\t\t\t\t\t\t\t<strong>工作时间：</strong>2018年10月</p>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"works-item fade fade3\">\n\t\t\t\t\t<a href=\"#/\" target=\"_blank\">\n\t\t\t\t\t\t<img src=\"/about/images/works/cv.jpg\" alt width=\"300\" height=\"180\">\n\t\t\t\t\t\t<div class=\"work-info\">\n\t\t\t\t\t\t\t<h2>基于opencv的表情识别</h2>\n\t\t\t\t\t\t\t<p><strong>工作详情：</strong>使用ORI提取五官,通过特征降维,使用自训练级联器识别<br>\n\t\t\t\t\t\t\t<strong>工作时间：</strong>2018年6月</p>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"works-item first fade fade4\">\n\t\t\t\t\t<a href=\"#\" target=\"_blank\">\n\t\t\t\t\t\t<img src=\"/about/images/works/ys.jpg\" alt width=\"300\" height=\"180\">\n\t\t\t\t\t\t<div class=\"work-info\">\n\t\t\t\t\t\t\t<h2>考试报名系统及验证码识别</h2>\n\t\t\t\t\t\t\t<p><strong>工作详情：</strong>使用网络爬虫进行自动化读取,对验证码进行ocr识别<br>\n\t\t\t\t\t\t\t<strong>工作时间：</strong>2017年1月</p>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"works-item fade fade5\">\n\t\t\t\t\t<a>\n\t\t\t\t\t\t<img src=\"/about/images/works/ys.jpg\" alt width=\"300\" height=\"180\">\n\t\t\t\t\t\t<div class=\"work-info\">\n\t\t\t\t\t\t\t<h2>抖音小视频识别并换衣</h2>\n\t\t\t\t\t\t\t<p><strong>工作详情：</strong>自动化刷粉及对主角进行颜值评判,并进行换衣<br>\n\t\t\t\t\t\t\t<strong>工作时间：</strong>2017年3月</p>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"works-item fade fade6\">\n\t\t\t\t\t<a>\n\t\t\t\t\t\t<img src=\"/about/images/works/ys.jpg\" alt width=\"300\" height=\"180\">\n\t\t\t\t\t\t<div class=\"work-info\">\n\t\t\t\t\t\t\t<h2>Nvidia jetson nano系统界面优化</h2>\n\t\t\t\t\t\t\t<p><strong>工作详情：</strong>让初学者更容易接受定制界面<br>\n\t\t\t\t\t\t\t<strong>工作时间：</strong>2019年3月</p>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t</div>\n\t\t\t<a class=\"more-link\" href=\"page/product\">查看更多<br></a>\n\n\t\t</div>\n\t\t<a class=\"button2 scroll-tip fade fade4\" data-slide=\"4\" title>向下滚动</a>\n\t</div>\n</div>\n<div id=\"skill\" class=\"section-wrap section-skill\" data-slide=\"4\">\n\t<div class=\"section\">\n\t\t<div class=\"skill-content section-content\">\n\t\t\t<h1>相关技能:</h1>\n\t\t\t<ul>\n\t\t\t\t<li class=\"fade fade1\">1、熟练运用python,C++;</li>\n\t\t\t\t<li class=\"fade fade2\">2、熟悉Pytorh,Tensorflow,Fastai,torchCV的使用;</li>\n\t\t\t\t<li class=\"fade fade3\">3、熟悉C++,python交互编程及深度模型的线上部署;</li>\n\t\t\t\t<li class=\"fade fade4\">4、能较好的利用PyQt,Qt,Flask进行设计与部署;</li>\n\t\t\t\t<li class=\"fade fade5\">5、熟练opencv3,opencv4,DNN;</li>\n\t\t\t\t<li class=\"fade fade6\">6、熟悉常见的机器学习算法,如SVM,CART,LR,GBDT,RF等经典算法;</li>\n\t\t\t\t<li class=\"fade fade7\">7、熟悉常见的深度学习算法,如CNN,GANs,YOLO,CRNN,MTCNN,openpose等框架;</li>\n\t\t\t\t<li class=\"fade fade8\">8、熟悉图像特征提取技术,如Canny,HOG,SIFT,LBP等;</li>\n\t\t\t\t<li class=\"fade fade9\">9、熟悉常见的自然语言框架使用,如Hanlp,StanfordCoreNLP,NLTK;</li>\n\t\t\t\t<li class=\"fade fade10\">10、了解网站设计,App设计,爬虫框架,渗透技术,线程优化等;</li>\n\t\t\t\t<li class=\"fade fade11\">11、了解nvidia jetson系列的使用;</li>\n\t\t\t\t<li class=\"fade fade12\">12、了解SLAM,光流算法;</li>\n\t\t\t</ul>\n\t\t</div>\n\t</div>\n\t<a class=\"button2 scroll-tip fade fade4\" data-slide=\"5\" title>向下滚动</a>\n</div>\n<div id=\"contact\" class=\"section-wrap section-contact\" data-slide=\"5\">\n\t<div class=\"section\">\n\t\t<div class=\"contact-content clearfix section-content\">\n\t\t\t<h1>联系本人</h1>\n\t\t\t<div class=\"left\">\n\t\t\t\t<div class=\"contact-ways fade fade1\">\n\t\t\t\t\t<h2>社交网络</h2>\n\t\t\t\t\t<ul>\n\t\t\t\t\t\t<li>邮箱：sindre1997@sina.com</li>\n\t\t\t\t\t\t<li>Q Q ：550549443</li>\n\t\t\t\t\t\t<li>Github：https://github.com/sindre97</li>\n\t\t\t\t\t</ul>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"contact-info fade fade2\">\n\t\t\t\t\t<p>希望邮箱联系！</p>\n\t\t\t\t</div>\n\t\t\t</div>\n<!--\t\t<div class=\"right fade fade3\">\n\t\t\t\t<h2>意见与建议</h2>\n\t\t\t\t<p>如果你有任何建议或想法</p>\n\t\t\t\t<ul>\n\t\t\t\t\t<li></li>\n\t\t\t\t\t<li></li>\n\t\t\t\t\t<li>。</li>\n\t\t\t\t\t<li></li>\n\t\t\t\t</ul>\n\t\t\t\t<p><strong>适用浏览器</strong>：360、FireFox、Chrome、Safari、Opera、傲游、搜狗、世界之窗. 不支持IE8及以下浏览器。</p>\n\t\t\t\t\n\t\t\t</div>\n-->\t\t\t\n\t\t</div>\n\t</div>\n\t<a class=\"button2 button2-2-top scroll-tip\" id=\"gototops\" data-slide=\"1\" href=\"#top\" style=\"background-position: -60px 0;width:80px;height:80px;\" title></a>\n</div>\n\n<div class=\"overlay\"></div>\n<div class=\"state-indicator\"></div>\n\n<script type=\"text/javascript\" src=\"/about/js/jquery-1.9.1.min.js\"></script>\n<script src=\"/about/js/global.js\"></script>\n<script src=\"/about/js/waypoints.min.js\"></script>\n<script src=\"/about/js/js.js\"></script>\n<script src=\"/about/js/jquery.stellar.min.js\"></script>\n<script src=\"/about/js/password.js\"></script>\n<div style=\"text-align:center;\">\n<p>来源:<a href=\"http://www.yx1024.top/\" target=\"_blank\">落叶无痕</a></p>\n</div>\n<script src=\"/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05\"></script>\n<script>L2Dwidget.init({\"pluginRootPath\":\"live2dw/\",\"pluginJsPath\":\"lib/\",\"pluginModelPath\":\"assets/\",\"tagMode\":false,\"debug\":false,\"model\":{\"jsonPath\":\"/live2dw/assets/z16.model.json\"},\"display\":{\"position\":\"left\",\"width\":75,\"height\":150},\"mobile\":{\"show\":true},\"log\":false});</script>\n</body>\n</html>\n","source":"about/index.html","raw":"---\nlayout: false\n---\n\n<!DOCTYPE html>\n<html>\n<head><meta name=\"generator\" content=\"Hexo 3.8.0\">\n\t<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n\t<meta name=\"viewport\" content=\"width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0\">\t\n\t<title>关于</title>\n\t<link rel=\"stylesheet\" href=\"/about/css/style.css\" type=\"text/css\" media=\"all\" >\n\n</head>\n\n<body class=\"loading-process\" onload=\"checkpassword()\">\n<div class=\"loading\">\n\t<div class=\"loading-circle\"></div>\n\t<div class=\"loading-avatar\"><img src=\"/about/images/avatar@2x.jpg\" alt width=\"100\" height=\"100\"></div>\n\t<div class=\"loading-info\">正在努力加载中...</div>\n</div>\n<div class=\"home-bg\">\n\t<img src=\"/about/images/home-bg.jpg\" alt width=\"1000\" height=\"667\">\n</div>\n<div class=\"section-wrap section-fristpage\" data-slide=\"1\">\n\t<div class=\"section\">\n\t\t<div class=\"section-content\">\n\t\t\t<p class=\"fade fade1\">感谢您的光临</p>\n\t\t\t<p class=\"fade fade2\">本模块正在建设中！</p>\n\t\t\t<p class=\"fade fade3\">想了解更多，往下滚动哦 ^_^</p>\n\n\t\t</div>\n\n\t\t<a class=\"button2 scroll-tip fade fade4\" data-slide=\"3\" title >向下滚动</a>\n\t</div>\n</div>\n<div id=\"/about\" data-slide=\"2\" data-stellar-background-ratio=\"0.3\" class=\"section-wrap section-/about\">\n\t<div class=\"section\">\n\t\t<div class=\"/about-content clearfix section-content\">\n\t\t\t<div class=\"introli\">\n\t\t\t  <span class=\"left_icon\"><img class=\"bio-text bio-icon-1\" src=\"/about/images/bio-icon-1.png\" data-stellar-ratio=\"0.7\"></span>\n\t\t\t  <span class=\"right_content \">从局部到全局的方式去除图像中的雨水条纹 </span>\n\t\t\t</div>\n\t\t\t<div class=\"introli\">\n\t\t\t  <span class=\"left_icon\"><img class=\"bio-text bio-icon-2\" src=\"/about/images/bio-icon-2.png\" data-stellar-ratio=\"0.7\"></span>\n\t\t\t  <span class=\"right_content\"><img class=\"bio-text bio-text-2\" src=\"/about/images/bio-text-2.png\" data-stellar-ratio=\"0.7\"></span>\n\t\t\t</div>\n\t\t\t<div class=\"introli\">\n\t\t\t  <span class=\"left_icon\"><img class=\"bio-text bio-icon-3\" src=\"/about/images/bio-icon-3.png \" data-stellar-ratio=\"0.7\"></span>\n\t\t\t  <span class=\"right_content\"><img class=\"bio-text bio-text-3\" src=\"/about/images/bio-text-3.png \" data-stellar-ratio=\"0.7\"></span>\n\t\t\t</div>\n\n\t\t</div>\n\n\t</div>\n\t<a class=\"button2 dark-button2 scroll-tip\" style=\"background-position:0 -60px;\" data-slide=\"3\" title></a>\n</div>\n<div id=\"works\" class=\"section-wrap section-works\" data-slide=\"3\">\n\t<div class=\"section\">\n\t\t<div class=\"works-content section-content\">\n\t\t\t<h1>作品</h1>\n\t\t\t<div class=\"works-list clearfix\">\n\t\t\t\t<div class=\"works-item first fade fade1\">\n\t\t\t\t\t<a href=\"#\" target=\"_blank\">\n\t\t\t\t\t\t<img src=\"/about/images/works/dp.jpeg\" alt width=\"300\" height=\"180\">\n\t\t\t\t\t\t<div class=\"work-info\">\n\t\t\t\t\t\t\t<h2>基于GAN的流数据生成方法</h2>\n\t\t\t\t\t\t\t<p><strong>工作详情：</strong>利用生成对抗网络的良好图像生成技术,增强入侵系统的知识库丰富度,提高入侵检测系统的可进化性及检测准确性<br>\n\t\t\t\t\t\t\t<strong>工作时间：</strong>2018年12月</p>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"works-item fade fade2\">\n\t\t\t\t\t<a href=\"#/\" target=\"_blank\">\n\t\t\t\t\t\t<img src=\"/about/images/works/dp.jpeg\" alt width=\"300\" height=\"180\">\n\t\t\t\t\t\t<div class=\"work-info\">\n\t\t\t\t\t\t\t<h2>从局部到全局的方式去除图像中的雨水条纹</h2>\n\t\t\t\t\t\t\t<p><strong>工作详情：</strong>结合时间先验和人工监督方式,通过SPANet从局部到全局的方式去除条纹<br>\n\t\t\t\t\t\t\t<strong>工作时间：</strong>2018年10月</p>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"works-item fade fade3\">\n\t\t\t\t\t<a href=\"#/\" target=\"_blank\">\n\t\t\t\t\t\t<img src=\"/about/images/works/cv.jpg\" alt width=\"300\" height=\"180\">\n\t\t\t\t\t\t<div class=\"work-info\">\n\t\t\t\t\t\t\t<h2>基于opencv的表情识别</h2>\n\t\t\t\t\t\t\t<p><strong>工作详情：</strong>使用ORI提取五官,通过特征降维,使用自训练级联器识别<br>\n\t\t\t\t\t\t\t<strong>工作时间：</strong>2018年6月</p>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"works-item first fade fade4\">\n\t\t\t\t\t<a href=\"#\" target=\"_blank\">\n\t\t\t\t\t\t<img src=\"/about/images/works/ys.jpg\" alt width=\"300\" height=\"180\">\n\t\t\t\t\t\t<div class=\"work-info\">\n\t\t\t\t\t\t\t<h2>考试报名系统及验证码识别</h2>\n\t\t\t\t\t\t\t<p><strong>工作详情：</strong>使用网络爬虫进行自动化读取,对验证码进行ocr识别<br>\n\t\t\t\t\t\t\t<strong>工作时间：</strong>2017年1月</p>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"works-item fade fade5\">\n\t\t\t\t\t<a>\n\t\t\t\t\t\t<img src=\"/about/images/works/ys.jpg\" alt width=\"300\" height=\"180\">\n\t\t\t\t\t\t<div class=\"work-info\">\n\t\t\t\t\t\t\t<h2>抖音小视频识别并换衣</h2>\n\t\t\t\t\t\t\t<p><strong>工作详情：</strong>自动化刷粉及对主角进行颜值评判,并进行换衣<br>\n\t\t\t\t\t\t\t<strong>工作时间：</strong>2017年3月</p>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"works-item fade fade6\">\n\t\t\t\t\t<a>\n\t\t\t\t\t\t<img src=\"/about/images/works/ys.jpg\" alt width=\"300\" height=\"180\">\n\t\t\t\t\t\t<div class=\"work-info\">\n\t\t\t\t\t\t\t<h2>Nvidia jetson nano系统界面优化</h2>\n\t\t\t\t\t\t\t<p><strong>工作详情：</strong>让初学者更容易接受定制界面<br>\n\t\t\t\t\t\t\t<strong>工作时间：</strong>2019年3月</p>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t</div>\n\t\t\t<a class=\"more-link\" href=\"page/product\">查看更多<br></a>\n\n\t\t</div>\n\t\t<a class=\"button2 scroll-tip fade fade4\" data-slide=\"4\" title>向下滚动</a>\n\t</div>\n</div>\n<div id=\"skill\" class=\"section-wrap section-skill\" data-slide=\"4\">\n\t<div class=\"section\">\n\t\t<div class=\"skill-content section-content\">\n\t\t\t<h1>相关技能:</h1>\n\t\t\t<ul>\n\t\t\t\t<li class=\"fade fade1\">1、熟练运用python,C++;</li>\n\t\t\t\t<li class=\"fade fade2\">2、熟悉Pytorh,Tensorflow,Fastai,torchCV的使用;</li>\n\t\t\t\t<li class=\"fade fade3\">3、熟悉C++,python交互编程及深度模型的线上部署;</li>\n\t\t\t\t<li class=\"fade fade4\">4、能较好的利用PyQt,Qt,Flask进行设计与部署;</li>\n\t\t\t\t<li class=\"fade fade5\">5、熟练opencv3,opencv4,DNN;</li>\n\t\t\t\t<li class=\"fade fade6\">6、熟悉常见的机器学习算法,如SVM,CART,LR,GBDT,RF等经典算法;</li>\n\t\t\t\t<li class=\"fade fade7\">7、熟悉常见的深度学习算法,如CNN,GANs,YOLO,CRNN,MTCNN,openpose等框架;</li>\n\t\t\t\t<li class=\"fade fade8\">8、熟悉图像特征提取技术,如Canny,HOG,SIFT,LBP等;</li>\n\t\t\t\t<li class=\"fade fade9\">9、熟悉常见的自然语言框架使用,如Hanlp,StanfordCoreNLP,NLTK;</li>\n\t\t\t\t<li class=\"fade fade10\">10、了解网站设计,App设计,爬虫框架,渗透技术,线程优化等;</li>\n\t\t\t\t<li class=\"fade fade11\">11、了解nvidia jetson系列的使用;</li>\n\t\t\t\t<li class=\"fade fade12\">12、了解SLAM,光流算法;</li>\n\t\t\t</ul>\n\t\t</div>\n\t</div>\n\t<a class=\"button2 scroll-tip fade fade4\" data-slide=\"5\" title>向下滚动</a>\n</div>\n<div id=\"contact\" class=\"section-wrap section-contact\" data-slide=\"5\">\n\t<div class=\"section\">\n\t\t<div class=\"contact-content clearfix section-content\">\n\t\t\t<h1>联系本人</h1>\n\t\t\t<div class=\"left\">\n\t\t\t\t<div class=\"contact-ways fade fade1\">\n\t\t\t\t\t<h2>社交网络</h2>\n\t\t\t\t\t<ul>\n\t\t\t\t\t\t<li>邮箱：sindre1997@sina.com</li>\n\t\t\t\t\t\t<li>Q Q ：550549443</li>\n\t\t\t\t\t\t<li>Github：https://github.com/sindre97</li>\n\t\t\t\t\t</ul>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"contact-info fade fade2\">\n\t\t\t\t\t<p>希望邮箱联系！</p>\n\t\t\t\t</div>\n\t\t\t</div>\n<!--\t\t<div class=\"right fade fade3\">\n\t\t\t\t<h2>意见与建议</h2>\n\t\t\t\t<p>如果你有任何建议或想法</p>\n\t\t\t\t<ul>\n\t\t\t\t\t<li></li>\n\t\t\t\t\t<li></li>\n\t\t\t\t\t<li>。</li>\n\t\t\t\t\t<li></li>\n\t\t\t\t</ul>\n\t\t\t\t<p><strong>适用浏览器</strong>：360、FireFox、Chrome、Safari、Opera、傲游、搜狗、世界之窗. 不支持IE8及以下浏览器。</p>\n\t\t\t\t\n\t\t\t</div>\n-->\t\t\t\n\t\t</div>\n\t</div>\n\t<a class=\"button2 button2-2-top scroll-tip\" id=\"gototops\" data-slide=\"1\" href=\"#top\" style=\"background-position: -60px 0;width:80px;height:80px;\" title></a>\n</div>\n\n<div class=\"overlay\"></div>\n<div class=\"state-indicator\"></div>\n\n<script type=\"text/javascript\" src=\"/about/js/jquery-1.9.1.min.js\"></script>\n<script src=\"/about/js/global.js\"></script>\n<script src=\"/about/js/waypoints.min.js\"></script>\n<script src=\"/about/js/js.js\"></script>\n<script src=\"/about/js/jquery.stellar.min.js\"></script>\n<script src=\"/about/js/password.js\"></script>\n<div style=\"text-align:center;\">\n<p>来源:<a href=\"http://www.yx1024.top/\" target=\"_blank\">落叶无痕</a></p>\n</div>\n<script src=\"/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05\"></script>\n<script>L2Dwidget.init({\"pluginRootPath\":\"live2dw/\",\"pluginJsPath\":\"lib/\",\"pluginModelPath\":\"assets/\",\"tagMode\":false,\"debug\":false,\"model\":{\"jsonPath\":\"/live2dw/assets/z16.model.json\"},\"display\":{\"position\":\"left\",\"width\":75,\"height\":150},\"mobile\":{\"show\":true},\"log\":false});</script>\n</body>\n</html>\n","date":"2023-03-01T05:17:39.662Z","updated":"2020-03-02T18:07:11.865Z","path":"about/index.html","title":"","comments":1,"_id":"clep90m0t0001igtawcmk4d51","content":"\n<!DOCTYPE html>\n<html>\n<head><meta name=\"generator\" content=\"Hexo 3.8.0\">\n\t<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n\t<meta name=\"viewport\" content=\"width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0\">\t\n\t<title>关于</title>\n\t<link rel=\"stylesheet\" href=\"/about/css/style.css\" type=\"text/css\" media=\"all\">\n\n</head>\n\n<body class=\"loading-process\" onload=\"checkpassword()\">\n<div class=\"loading\">\n\t<div class=\"loading-circle\"></div>\n\t<div class=\"loading-avatar\"><img src=\"/about/images/avatar@2x.jpg\" alt width=\"100\" height=\"100\"></div>\n\t<div class=\"loading-info\">正在努力加载中...</div>\n</div>\n<div class=\"home-bg\">\n\t<img src=\"/about/images/home-bg.jpg\" alt width=\"1000\" height=\"667\">\n</div>\n<div class=\"section-wrap section-fristpage\" data-slide=\"1\">\n\t<div class=\"section\">\n\t\t<div class=\"section-content\">\n\t\t\t<p class=\"fade fade1\">感谢您的光临</p>\n\t\t\t<p class=\"fade fade2\">本模块正在建设中！</p>\n\t\t\t<p class=\"fade fade3\">想了解更多，往下滚动哦 ^_^</p>\n\n\t\t</div>\n\n\t\t<a class=\"button2 scroll-tip fade fade4\" data-slide=\"3\" title>向下滚动</a>\n\t</div>\n</div>\n<div id=\"/about\" data-slide=\"2\" data-stellar-background-ratio=\"0.3\" class=\"section-wrap section-/about\">\n\t<div class=\"section\">\n\t\t<div class=\"/about-content clearfix section-content\">\n\t\t\t<div class=\"introli\">\n\t\t\t  <span class=\"left_icon\"><img class=\"bio-text bio-icon-1\" src=\"/about/images/bio-icon-1.png\" data-stellar-ratio=\"0.7\"></span>\n\t\t\t  <span class=\"right_content \">从局部到全局的方式去除图像中的雨水条纹 </span>\n\t\t\t</div>\n\t\t\t<div class=\"introli\">\n\t\t\t  <span class=\"left_icon\"><img class=\"bio-text bio-icon-2\" src=\"/about/images/bio-icon-2.png\" data-stellar-ratio=\"0.7\"></span>\n\t\t\t  <span class=\"right_content\"><img class=\"bio-text bio-text-2\" src=\"/about/images/bio-text-2.png\" data-stellar-ratio=\"0.7\"></span>\n\t\t\t</div>\n\t\t\t<div class=\"introli\">\n\t\t\t  <span class=\"left_icon\"><img class=\"bio-text bio-icon-3\" src=\"/about/images/bio-icon-3.png \" data-stellar-ratio=\"0.7\"></span>\n\t\t\t  <span class=\"right_content\"><img class=\"bio-text bio-text-3\" src=\"/about/images/bio-text-3.png \" data-stellar-ratio=\"0.7\"></span>\n\t\t\t</div>\n\n\t\t</div>\n\n\t</div>\n\t<a class=\"button2 dark-button2 scroll-tip\" style=\"background-position:0 -60px;\" data-slide=\"3\" title></a>\n</div>\n<div id=\"works\" class=\"section-wrap section-works\" data-slide=\"3\">\n\t<div class=\"section\">\n\t\t<div class=\"works-content section-content\">\n\t\t\t<h1>作品</h1>\n\t\t\t<div class=\"works-list clearfix\">\n\t\t\t\t<div class=\"works-item first fade fade1\">\n\t\t\t\t\t<a href=\"#\" target=\"_blank\">\n\t\t\t\t\t\t<img src=\"/about/images/works/dp.jpeg\" alt width=\"300\" height=\"180\">\n\t\t\t\t\t\t<div class=\"work-info\">\n\t\t\t\t\t\t\t<h2>基于GAN的流数据生成方法</h2>\n\t\t\t\t\t\t\t<p><strong>工作详情：</strong>利用生成对抗网络的良好图像生成技术,增强入侵系统的知识库丰富度,提高入侵检测系统的可进化性及检测准确性<br>\n\t\t\t\t\t\t\t<strong>工作时间：</strong>2018年12月</p>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"works-item fade fade2\">\n\t\t\t\t\t<a href=\"#/\" target=\"_blank\">\n\t\t\t\t\t\t<img src=\"/about/images/works/dp.jpeg\" alt width=\"300\" height=\"180\">\n\t\t\t\t\t\t<div class=\"work-info\">\n\t\t\t\t\t\t\t<h2>从局部到全局的方式去除图像中的雨水条纹</h2>\n\t\t\t\t\t\t\t<p><strong>工作详情：</strong>结合时间先验和人工监督方式,通过SPANet从局部到全局的方式去除条纹<br>\n\t\t\t\t\t\t\t<strong>工作时间：</strong>2018年10月</p>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"works-item fade fade3\">\n\t\t\t\t\t<a href=\"#/\" target=\"_blank\">\n\t\t\t\t\t\t<img src=\"/about/images/works/cv.jpg\" alt width=\"300\" height=\"180\">\n\t\t\t\t\t\t<div class=\"work-info\">\n\t\t\t\t\t\t\t<h2>基于opencv的表情识别</h2>\n\t\t\t\t\t\t\t<p><strong>工作详情：</strong>使用ORI提取五官,通过特征降维,使用自训练级联器识别<br>\n\t\t\t\t\t\t\t<strong>工作时间：</strong>2018年6月</p>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"works-item first fade fade4\">\n\t\t\t\t\t<a href=\"#\" target=\"_blank\">\n\t\t\t\t\t\t<img src=\"/about/images/works/ys.jpg\" alt width=\"300\" height=\"180\">\n\t\t\t\t\t\t<div class=\"work-info\">\n\t\t\t\t\t\t\t<h2>考试报名系统及验证码识别</h2>\n\t\t\t\t\t\t\t<p><strong>工作详情：</strong>使用网络爬虫进行自动化读取,对验证码进行ocr识别<br>\n\t\t\t\t\t\t\t<strong>工作时间：</strong>2017年1月</p>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"works-item fade fade5\">\n\t\t\t\t\t<a>\n\t\t\t\t\t\t<img src=\"/about/images/works/ys.jpg\" alt width=\"300\" height=\"180\">\n\t\t\t\t\t\t<div class=\"work-info\">\n\t\t\t\t\t\t\t<h2>抖音小视频识别并换衣</h2>\n\t\t\t\t\t\t\t<p><strong>工作详情：</strong>自动化刷粉及对主角进行颜值评判,并进行换衣<br>\n\t\t\t\t\t\t\t<strong>工作时间：</strong>2017年3月</p>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"works-item fade fade6\">\n\t\t\t\t\t<a>\n\t\t\t\t\t\t<img src=\"/about/images/works/ys.jpg\" alt width=\"300\" height=\"180\">\n\t\t\t\t\t\t<div class=\"work-info\">\n\t\t\t\t\t\t\t<h2>Nvidia jetson nano系统界面优化</h2>\n\t\t\t\t\t\t\t<p><strong>工作详情：</strong>让初学者更容易接受定制界面<br>\n\t\t\t\t\t\t\t<strong>工作时间：</strong>2019年3月</p>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t</div>\n\t\t\t<a class=\"more-link\" href=\"page/product\">查看更多<br></a>\n\n\t\t</div>\n\t\t<a class=\"button2 scroll-tip fade fade4\" data-slide=\"4\" title>向下滚动</a>\n\t</div>\n</div>\n<div id=\"skill\" class=\"section-wrap section-skill\" data-slide=\"4\">\n\t<div class=\"section\">\n\t\t<div class=\"skill-content section-content\">\n\t\t\t<h1>相关技能:</h1>\n\t\t\t<ul>\n\t\t\t\t<li class=\"fade fade1\">1、熟练运用python,C++;</li>\n\t\t\t\t<li class=\"fade fade2\">2、熟悉Pytorh,Tensorflow,Fastai,torchCV的使用;</li>\n\t\t\t\t<li class=\"fade fade3\">3、熟悉C++,python交互编程及深度模型的线上部署;</li>\n\t\t\t\t<li class=\"fade fade4\">4、能较好的利用PyQt,Qt,Flask进行设计与部署;</li>\n\t\t\t\t<li class=\"fade fade5\">5、熟练opencv3,opencv4,DNN;</li>\n\t\t\t\t<li class=\"fade fade6\">6、熟悉常见的机器学习算法,如SVM,CART,LR,GBDT,RF等经典算法;</li>\n\t\t\t\t<li class=\"fade fade7\">7、熟悉常见的深度学习算法,如CNN,GANs,YOLO,CRNN,MTCNN,openpose等框架;</li>\n\t\t\t\t<li class=\"fade fade8\">8、熟悉图像特征提取技术,如Canny,HOG,SIFT,LBP等;</li>\n\t\t\t\t<li class=\"fade fade9\">9、熟悉常见的自然语言框架使用,如Hanlp,StanfordCoreNLP,NLTK;</li>\n\t\t\t\t<li class=\"fade fade10\">10、了解网站设计,App设计,爬虫框架,渗透技术,线程优化等;</li>\n\t\t\t\t<li class=\"fade fade11\">11、了解nvidia jetson系列的使用;</li>\n\t\t\t\t<li class=\"fade fade12\">12、了解SLAM,光流算法;</li>\n\t\t\t</ul>\n\t\t</div>\n\t</div>\n\t<a class=\"button2 scroll-tip fade fade4\" data-slide=\"5\" title>向下滚动</a>\n</div>\n<div id=\"contact\" class=\"section-wrap section-contact\" data-slide=\"5\">\n\t<div class=\"section\">\n\t\t<div class=\"contact-content clearfix section-content\">\n\t\t\t<h1>联系本人</h1>\n\t\t\t<div class=\"left\">\n\t\t\t\t<div class=\"contact-ways fade fade1\">\n\t\t\t\t\t<h2>社交网络</h2>\n\t\t\t\t\t<ul>\n\t\t\t\t\t\t<li>邮箱：sindre1997@sina.com</li>\n\t\t\t\t\t\t<li>Q Q ：550549443</li>\n\t\t\t\t\t\t<li>Github：https://github.com/sindre97</li>\n\t\t\t\t\t</ul>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"contact-info fade fade2\">\n\t\t\t\t\t<p>希望邮箱联系！</p>\n\t\t\t\t</div>\n\t\t\t</div>\n<!--\t\t<div class=\"right fade fade3\">\n\t\t\t\t<h2>意见与建议</h2>\n\t\t\t\t<p>如果你有任何建议或想法</p>\n\t\t\t\t<ul>\n\t\t\t\t\t<li></li>\n\t\t\t\t\t<li></li>\n\t\t\t\t\t<li>。</li>\n\t\t\t\t\t<li></li>\n\t\t\t\t</ul>\n\t\t\t\t<p><strong>适用浏览器</strong>：360、FireFox、Chrome、Safari、Opera、傲游、搜狗、世界之窗. 不支持IE8及以下浏览器。</p>\n\t\t\t\t\n\t\t\t</div>\n-->\t\t\t\n\t\t</div>\n\t</div>\n\t<a class=\"button2 button2-2-top scroll-tip\" id=\"gototops\" data-slide=\"1\" href=\"#top\" style=\"background-position: -60px 0;width:80px;height:80px;\" title></a>\n</div>\n\n<div class=\"overlay\"></div>\n<div class=\"state-indicator\"></div>\n\n<script type=\"text/javascript\" src=\"/about/js/jquery-1.9.1.min.js\"></script>\n<script src=\"/about/js/global.js\"></script>\n<script src=\"/about/js/waypoints.min.js\"></script>\n<script src=\"/about/js/js.js\"></script>\n<script src=\"/about/js/jquery.stellar.min.js\"></script>\n<script src=\"/about/js/password.js\"></script>\n<div style=\"text-align:center;\">\n<p>来源:<a href=\"http://www.yx1024.top/\" target=\"_blank\">落叶无痕</a></p>\n</div>\n<script src=\"/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05\"></script>\n<script>L2Dwidget.init({\"pluginRootPath\":\"live2dw/\",\"pluginJsPath\":\"lib/\",\"pluginModelPath\":\"assets/\",\"tagMode\":false,\"debug\":false,\"model\":{\"jsonPath\":\"/live2dw/assets/z16.model.json\"},\"display\":{\"position\":\"left\",\"width\":75,\"height\":150},\"mobile\":{\"show\":true},\"log\":false});</script>\n<script src=\"/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05\"></script><script>L2Dwidget.init({\"pluginRootPath\":\"live2dw/\",\"pluginJsPath\":\"lib/\",\"pluginModelPath\":\"assets/\",\"tagMode\":false,\"debug\":false,\"model\":{\"jsonPath\":\"/live2dw/assets/z16.model.json\"},\"display\":{\"position\":\"left\",\"width\":75,\"height\":150},\"mobile\":{\"show\":true},\"log\":false});</script></body>\n</html>\n","site":{"data":{}},"excerpt":"","more":"\n<!DOCTYPE html>\n<html>\n<head><meta name=\"generator\" content=\"Hexo 3.8.0\">\n\t<meta http-equiv=\"Content-Type\" content=\"text/html; charset=UTF-8\">\n\t<meta name=\"viewport\" content=\"width=device-width,initial-scale=1.0,maximum-scale=1.0,user-scalable=0\">\t\n\t<title>关于</title>\n\t<link rel=\"stylesheet\" href=\"/about/css/style.css\" type=\"text/css\" media=\"all\">\n\n</head>\n\n<body class=\"loading-process\" onload=\"checkpassword()\">\n<div class=\"loading\">\n\t<div class=\"loading-circle\"></div>\n\t<div class=\"loading-avatar\"><img src=\"/about/images/avatar@2x.jpg\" alt width=\"100\" height=\"100\"></div>\n\t<div class=\"loading-info\">正在努力加载中...</div>\n</div>\n<div class=\"home-bg\">\n\t<img src=\"/about/images/home-bg.jpg\" alt width=\"1000\" height=\"667\">\n</div>\n<div class=\"section-wrap section-fristpage\" data-slide=\"1\">\n\t<div class=\"section\">\n\t\t<div class=\"section-content\">\n\t\t\t<p class=\"fade fade1\">感谢您的光临</p>\n\t\t\t<p class=\"fade fade2\">本模块正在建设中！</p>\n\t\t\t<p class=\"fade fade3\">想了解更多，往下滚动哦 ^_^</p>\n\n\t\t</div>\n\n\t\t<a class=\"button2 scroll-tip fade fade4\" data-slide=\"3\" title>向下滚动</a>\n\t</div>\n</div>\n<div id=\"/about\" data-slide=\"2\" data-stellar-background-ratio=\"0.3\" class=\"section-wrap section-/about\">\n\t<div class=\"section\">\n\t\t<div class=\"/about-content clearfix section-content\">\n\t\t\t<div class=\"introli\">\n\t\t\t  <span class=\"left_icon\"><img class=\"bio-text bio-icon-1\" src=\"/about/images/bio-icon-1.png\" data-stellar-ratio=\"0.7\"></span>\n\t\t\t  <span class=\"right_content \">从局部到全局的方式去除图像中的雨水条纹 </span>\n\t\t\t</div>\n\t\t\t<div class=\"introli\">\n\t\t\t  <span class=\"left_icon\"><img class=\"bio-text bio-icon-2\" src=\"/about/images/bio-icon-2.png\" data-stellar-ratio=\"0.7\"></span>\n\t\t\t  <span class=\"right_content\"><img class=\"bio-text bio-text-2\" src=\"/about/images/bio-text-2.png\" data-stellar-ratio=\"0.7\"></span>\n\t\t\t</div>\n\t\t\t<div class=\"introli\">\n\t\t\t  <span class=\"left_icon\"><img class=\"bio-text bio-icon-3\" src=\"/about/images/bio-icon-3.png \" data-stellar-ratio=\"0.7\"></span>\n\t\t\t  <span class=\"right_content\"><img class=\"bio-text bio-text-3\" src=\"/about/images/bio-text-3.png \" data-stellar-ratio=\"0.7\"></span>\n\t\t\t</div>\n\n\t\t</div>\n\n\t</div>\n\t<a class=\"button2 dark-button2 scroll-tip\" style=\"background-position:0 -60px;\" data-slide=\"3\" title></a>\n</div>\n<div id=\"works\" class=\"section-wrap section-works\" data-slide=\"3\">\n\t<div class=\"section\">\n\t\t<div class=\"works-content section-content\">\n\t\t\t<h1>作品</h1>\n\t\t\t<div class=\"works-list clearfix\">\n\t\t\t\t<div class=\"works-item first fade fade1\">\n\t\t\t\t\t<a href=\"#\" target=\"_blank\">\n\t\t\t\t\t\t<img src=\"/about/images/works/dp.jpeg\" alt width=\"300\" height=\"180\">\n\t\t\t\t\t\t<div class=\"work-info\">\n\t\t\t\t\t\t\t<h2>基于GAN的流数据生成方法</h2>\n\t\t\t\t\t\t\t<p><strong>工作详情：</strong>利用生成对抗网络的良好图像生成技术,增强入侵系统的知识库丰富度,提高入侵检测系统的可进化性及检测准确性<br>\n\t\t\t\t\t\t\t<strong>工作时间：</strong>2018年12月</p>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"works-item fade fade2\">\n\t\t\t\t\t<a href=\"#/\" target=\"_blank\">\n\t\t\t\t\t\t<img src=\"/about/images/works/dp.jpeg\" alt width=\"300\" height=\"180\">\n\t\t\t\t\t\t<div class=\"work-info\">\n\t\t\t\t\t\t\t<h2>从局部到全局的方式去除图像中的雨水条纹</h2>\n\t\t\t\t\t\t\t<p><strong>工作详情：</strong>结合时间先验和人工监督方式,通过SPANet从局部到全局的方式去除条纹<br>\n\t\t\t\t\t\t\t<strong>工作时间：</strong>2018年10月</p>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"works-item fade fade3\">\n\t\t\t\t\t<a href=\"#/\" target=\"_blank\">\n\t\t\t\t\t\t<img src=\"/about/images/works/cv.jpg\" alt width=\"300\" height=\"180\">\n\t\t\t\t\t\t<div class=\"work-info\">\n\t\t\t\t\t\t\t<h2>基于opencv的表情识别</h2>\n\t\t\t\t\t\t\t<p><strong>工作详情：</strong>使用ORI提取五官,通过特征降维,使用自训练级联器识别<br>\n\t\t\t\t\t\t\t<strong>工作时间：</strong>2018年6月</p>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"works-item first fade fade4\">\n\t\t\t\t\t<a href=\"#\" target=\"_blank\">\n\t\t\t\t\t\t<img src=\"/about/images/works/ys.jpg\" alt width=\"300\" height=\"180\">\n\t\t\t\t\t\t<div class=\"work-info\">\n\t\t\t\t\t\t\t<h2>考试报名系统及验证码识别</h2>\n\t\t\t\t\t\t\t<p><strong>工作详情：</strong>使用网络爬虫进行自动化读取,对验证码进行ocr识别<br>\n\t\t\t\t\t\t\t<strong>工作时间：</strong>2017年1月</p>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"works-item fade fade5\">\n\t\t\t\t\t<a>\n\t\t\t\t\t\t<img src=\"/about/images/works/ys.jpg\" alt width=\"300\" height=\"180\">\n\t\t\t\t\t\t<div class=\"work-info\">\n\t\t\t\t\t\t\t<h2>抖音小视频识别并换衣</h2>\n\t\t\t\t\t\t\t<p><strong>工作详情：</strong>自动化刷粉及对主角进行颜值评判,并进行换衣<br>\n\t\t\t\t\t\t\t<strong>工作时间：</strong>2017年3月</p>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"works-item fade fade6\">\n\t\t\t\t\t<a>\n\t\t\t\t\t\t<img src=\"/about/images/works/ys.jpg\" alt width=\"300\" height=\"180\">\n\t\t\t\t\t\t<div class=\"work-info\">\n\t\t\t\t\t\t\t<h2>Nvidia jetson nano系统界面优化</h2>\n\t\t\t\t\t\t\t<p><strong>工作详情：</strong>让初学者更容易接受定制界面<br>\n\t\t\t\t\t\t\t<strong>工作时间：</strong>2019年3月</p>\n\t\t\t\t\t\t</div>\n\t\t\t\t\t</a>\n\t\t\t\t</div>\n\t\t\t</div>\n\t\t\t<a class=\"more-link\" href=\"page/product\">查看更多<br></a>\n\n\t\t</div>\n\t\t<a class=\"button2 scroll-tip fade fade4\" data-slide=\"4\" title>向下滚动</a>\n\t</div>\n</div>\n<div id=\"skill\" class=\"section-wrap section-skill\" data-slide=\"4\">\n\t<div class=\"section\">\n\t\t<div class=\"skill-content section-content\">\n\t\t\t<h1>相关技能:</h1>\n\t\t\t<ul>\n\t\t\t\t<li class=\"fade fade1\">1、熟练运用python,C++;</li>\n\t\t\t\t<li class=\"fade fade2\">2、熟悉Pytorh,Tensorflow,Fastai,torchCV的使用;</li>\n\t\t\t\t<li class=\"fade fade3\">3、熟悉C++,python交互编程及深度模型的线上部署;</li>\n\t\t\t\t<li class=\"fade fade4\">4、能较好的利用PyQt,Qt,Flask进行设计与部署;</li>\n\t\t\t\t<li class=\"fade fade5\">5、熟练opencv3,opencv4,DNN;</li>\n\t\t\t\t<li class=\"fade fade6\">6、熟悉常见的机器学习算法,如SVM,CART,LR,GBDT,RF等经典算法;</li>\n\t\t\t\t<li class=\"fade fade7\">7、熟悉常见的深度学习算法,如CNN,GANs,YOLO,CRNN,MTCNN,openpose等框架;</li>\n\t\t\t\t<li class=\"fade fade8\">8、熟悉图像特征提取技术,如Canny,HOG,SIFT,LBP等;</li>\n\t\t\t\t<li class=\"fade fade9\">9、熟悉常见的自然语言框架使用,如Hanlp,StanfordCoreNLP,NLTK;</li>\n\t\t\t\t<li class=\"fade fade10\">10、了解网站设计,App设计,爬虫框架,渗透技术,线程优化等;</li>\n\t\t\t\t<li class=\"fade fade11\">11、了解nvidia jetson系列的使用;</li>\n\t\t\t\t<li class=\"fade fade12\">12、了解SLAM,光流算法;</li>\n\t\t\t</ul>\n\t\t</div>\n\t</div>\n\t<a class=\"button2 scroll-tip fade fade4\" data-slide=\"5\" title>向下滚动</a>\n</div>\n<div id=\"contact\" class=\"section-wrap section-contact\" data-slide=\"5\">\n\t<div class=\"section\">\n\t\t<div class=\"contact-content clearfix section-content\">\n\t\t\t<h1>联系本人</h1>\n\t\t\t<div class=\"left\">\n\t\t\t\t<div class=\"contact-ways fade fade1\">\n\t\t\t\t\t<h2>社交网络</h2>\n\t\t\t\t\t<ul>\n\t\t\t\t\t\t<li>邮箱：sindre1997@sina.com</li>\n\t\t\t\t\t\t<li>Q Q ：550549443</li>\n\t\t\t\t\t\t<li>Github：https://github.com/sindre97</li>\n\t\t\t\t\t</ul>\n\t\t\t\t</div>\n\t\t\t\t<div class=\"contact-info fade fade2\">\n\t\t\t\t\t<p>希望邮箱联系！</p>\n\t\t\t\t</div>\n\t\t\t</div>\n<!--\t\t<div class=\"right fade fade3\">\n\t\t\t\t<h2>意见与建议</h2>\n\t\t\t\t<p>如果你有任何建议或想法</p>\n\t\t\t\t<ul>\n\t\t\t\t\t<li></li>\n\t\t\t\t\t<li></li>\n\t\t\t\t\t<li>。</li>\n\t\t\t\t\t<li></li>\n\t\t\t\t</ul>\n\t\t\t\t<p><strong>适用浏览器</strong>：360、FireFox、Chrome、Safari、Opera、傲游、搜狗、世界之窗. 不支持IE8及以下浏览器。</p>\n\t\t\t\t\n\t\t\t</div>\n-->\t\t\t\n\t\t</div>\n\t</div>\n\t<a class=\"button2 button2-2-top scroll-tip\" id=\"gototops\" data-slide=\"1\" href=\"#top\" style=\"background-position: -60px 0;width:80px;height:80px;\" title></a>\n</div>\n\n<div class=\"overlay\"></div>\n<div class=\"state-indicator\"></div>\n\n<script type=\"text/javascript\" src=\"/about/js/jquery-1.9.1.min.js\"></script>\n<script src=\"/about/js/global.js\"></script>\n<script src=\"/about/js/waypoints.min.js\"></script>\n<script src=\"/about/js/js.js\"></script>\n<script src=\"/about/js/jquery.stellar.min.js\"></script>\n<script src=\"/about/js/password.js\"></script>\n<div style=\"text-align:center;\">\n<p>来源:<a href=\"http://www.yx1024.top/\" target=\"_blank\">落叶无痕</a></p>\n</div>\n<script src=\"/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05\"></script>\n<script>L2Dwidget.init({\"pluginRootPath\":\"live2dw/\",\"pluginJsPath\":\"lib/\",\"pluginModelPath\":\"assets/\",\"tagMode\":false,\"debug\":false,\"model\":{\"jsonPath\":\"/live2dw/assets/z16.model.json\"},\"display\":{\"position\":\"left\",\"width\":75,\"height\":150},\"mobile\":{\"show\":true},\"log\":false});</script>\n<script src=\"/live2dw/lib/L2Dwidget.min.js?094cbace49a39548bed64abff5988b05\"></script><script>L2Dwidget.init({\"pluginRootPath\":\"live2dw/\",\"pluginJsPath\":\"lib/\",\"pluginModelPath\":\"assets/\",\"tagMode\":false,\"debug\":false,\"model\":{\"jsonPath\":\"/live2dw/assets/z16.model.json\"},\"display\":{\"position\":\"left\",\"width\":75,\"height\":150},\"mobile\":{\"show\":true},\"log\":false});</script></body>\n</html>\n"},{"title":"分类","type":"categories","layout":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: 分类\ntype: \"categories\"\nlayout: \"categories\"\n---","date":"2023-03-01T05:17:39.664Z","updated":"2018-12-08T21:21:02.891Z","path":"categories/index.html","comments":1,"_id":"clep90m0y0003igtam366vfu4","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"标签","layout":"tags","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: 标签\nlayout: \"tags\"\ntype: \"tags\"\n---","date":"2023-03-01T05:17:39.705Z","updated":"2018-12-08T21:21:39.091Z","path":"tags/index.html","comments":1,"_id":"clep90m130006igtad8hsg1s0","content":"","site":{"data":{}},"excerpt":"","more":""}],"Post":[{"title":"KDD CUP99数据集预处理","date":"2019-05-04T09:30:17.000Z","catagories":["框架","数据处理","kdd99"],"_content":"-----\n***       KDD CUP99数据集预处理  ***\n\n-----\n \n\n1、数据集下载：http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html\n\n2、KDDCup99网络入侵检测数据集介绍：\n\nhttps://blog.csdn.net/com_stu_zhang/article/details/6987632\n\nhttps://www.cnblogs.com/gongyanc/p/6703532.html\n\n3、Weka进阶——基于KDD99数据集的入侵检测分析：\n\nhttps://blog.csdn.net/jbfsdzpp/article/details/44099849\n\n4、符号型特征数值化\n\n采用one-hot方法进行数值化：https://blog.csdn.net/qq_28617019/article/details/79717184\n\n \n\n5、KDD CUP99数据集预处理\n\n（1）字符型特征转换为数值型特征（即符号型特征数值化）\nPython3对KDD CUP99数据集预处理代码实现（仅实现字符型特征转为数值型特征）\n# kdd99数据集预处理\n 将kdd99符号型数据转化为数值型数据\n\n```python\n# coding:utf-8\n\nimport numpy as np\nimport pandas as pd\nimport csv\nimport time\n\nglobal label_list  # label_list为全局变量\n\nlist_big=[] #储存大数据\n# 定义kdd99数据预处理函数\ndef preHandel_data ():\n\tsource_file = 'kddcup.data_10_percent_corrected'\n\thandled_file = 'kddcup.data_10_percent_corrected.csv'\n\tdata_file = open (handled_file, 'w', newline='')  # python3.x中添加newline=''这一参数使写入的文件没有多余的空行\n\twith open (source_file, 'r') as data_source:\n\t\tcsv_reader = csv.reader (data_source)\n\t\tcsv_writer = csv.writer (data_file)\n\t\tcount = 0  # 记录数据的行数，初始化为0\n\t\tfor row in csv_reader:\n\t\t\ttemp_line = np.array (row)  # 将每行数据存入temp_line数组里\n\t\t\tlist_big.append (int(temp_line [4]))\n\t\t\tlist_big.append (int(temp_line [5]))\n\t\t\ttemp_line [1] = handleProtocol (row)  # 将源文件行中3种协议类型转换成数字标识\n\t\t\ttemp_line [2] = handleService (row)  # 将源文件行中70种网络服务类型转换成数字标识\n\t\t\ttemp_line [3] = handleFlag (row)  # 将源文件行中11种网络连接状态转换成数字标识\n\t\t\ttemp_line [4] = handlenorm (int(row[4]))\n\t\t\ttemp_line [5] = handlenorm (int(row[5]))\n\t\t\ttemp_line [41] = handleLabel (row)  # 将源文件行中23种攻击类型转换成数字标识\n\t\t\tcsv_writer.writerow (temp_line)\n\t\t\tcount += 1\n\t\t\t# 输出每行数据中所修改后的状态\n\t\t\t#print (count, 'status:', temp_line [1], temp_line [2], temp_line [3], temp_line [41])\n\t\tdata_file.close ()\n\n\n# 将相应的非数字类型转换为数字标识即符号型数据转化为数值型数据\ndef find_index (x, y):\n\treturn [i for i in range (len (y)) if y [i] == x]\n\n\n# 定义将源文件行中3种协议类型转换成数字标识的函数\ndef handleProtocol (input):\n\tprotocol_list = ['tcp', 'udp', 'icmp']\n\tif input [1] in protocol_list:\n\t\treturn find_index (input [1], protocol_list) [0]\n\n\n# 定义将源文件行中70种网络服务类型转换成数字标识的函数\ndef handleService (input):\n\tservice_list = ['aol', 'auth', 'bgp', 'courier', 'csnet_ns', 'ctf', 'daytime', 'discard', 'domain', 'domain_u',\n\t\t\t\t\t'echo', 'eco_i', 'ecr_i', 'efs', 'exec', 'finger', 'ftp', 'ftp_data', 'gopher', 'harvest',\n\t\t\t\t\t'hostnames',\n\t\t\t\t\t'http', 'http_2784', 'http_443', 'http_8001', 'imap4', 'IRC', 'iso_tsap', 'klogin', 'kshell',\n\t\t\t\t\t'ldap',\n\t\t\t\t\t'link', 'login', 'mtp', 'name', 'netbios_dgm', 'netbios_ns', 'netbios_ssn', 'netstat', 'nnsp',\n\t\t\t\t\t'nntp',\n\t\t\t\t\t'ntp_u', 'other', 'pm_dump', 'pop_2', 'pop_3', 'printer', 'private', 'red_i', 'remote_job', 'rje',\n\t\t\t\t\t'shell',\n\t\t\t\t\t'smtp', 'sql_net', 'ssh', 'sunrpc', 'supdup', 'systat', 'telnet', 'tftp_u', 'tim_i', 'time',\n\t\t\t\t\t'urh_i', 'urp_i',\n\t\t\t\t\t'uucp', 'uucp_path', 'vmnet', 'whois', 'X11', 'Z39_50']\n\tif input [2] in service_list:\n\t\treturn find_index (input [2], service_list) [0]\n\n\n# 定义将源文件行中11种网络连接状态转换成数字标识的函数\ndef handleFlag (input):\n\tflag_list = ['OTH', 'REJ', 'RSTO', 'RSTOS0', 'RSTR', 'S0', 'S1', 'S2', 'S3', 'SF', 'SH']\n\tif input [3] in flag_list:\n\t\treturn find_index (input [3], flag_list) [0]\n\n\n# 定义将源文件行中攻击类型转换成数字标识的函数(训练集中共出现了22个攻击类型，而剩下的17种只在测试集中出现)\ndef handleLabel (input):\n\t# label_list=['normal.', 'buffer_overflow.', 'loadmodule.', 'perl.', 'neptune.', 'smurf.',\n\t# 'guess_passwd.', 'pod.', 'teardrop.', 'portsweep.', 'ipsweep.', 'land.', 'ftp_write.',\n\t# 'back.', 'imap.', 'satan.', 'phf.', 'nmap.', 'multihop.', 'warezmaster.', 'warezclient.',\n\t# 'spy.', 'rootkit.']\n\tglobal label_list  # 在函数内部使用全局变量并修改它\n\tif input [41] in label_list:\n\t\treturn find_index (input [41], label_list) [0]\n\telse:\n\t\tlabel_list.append (input [41])\n\t\treturn find_index (input [41], label_list) [0]\n\n\n\n#定义将源文件行中从源主机到目标主机的数据的字节数归一化到（0,255)\ndef handlenorm(input):\n\tmax_data=max(list_big)\n\tmin_data=min(list_big)\n\tresults=255/max_data*(input-min_data)\n\t\n\treturn  results\n\n\nif __name__ == '__main__':\n\tstart_time = time.clock ()\n\tglobal label_list  # 声明一个全局变量的列表并初始化为空\n\tlabel_list = []\n\tpreHandel_data ()\n\tend_time = time.clock ()\n\tprint (\"Running time:\", (end_time - start_time))  # 输出程序运行时间\n    \n```\n      该代码仅对10%的训练集（kddcup.data_10_percent_corrected）进行处理\n\n\n\n引用：\nhttps://blog.csdn.net/asialee_bird/article/details/80491256\n\n\n6、KDD CUP99数据集按行转换成图片\n# 将其转换为图片  \n```python\nimport csv\n\nimport numpy as np\n\ndata =np.random.random((4,4,3))\ndata=[]\ndef Toimage():\n\tsource_file = 'kddcup.data_10_percent_corrected.csv'\n\twith open (source_file, 'r') as data_source:\n\t\tcsv_reader = csv.reader (data_source)\n\t\tcount = 0  记录数据的行数，初始化为0\n\t\tfor row in csv_reader:\n\n\t\t\tnew_row=[float(x) for x in row]\n\t\t\timage_data=np.array(new_row)\n\n\t\t\tdata = np.array (image_data).reshape (6, 7)\n\t\t\timageio.imwrite ('image/{}.jpg'.format(count), data)\n\t\t\tcount+=1\n\n\n'''\n\n#Toimage()\n#print(np.array(data))\n#\n# new_list = [i for i in range(9)]\n# data=np.array(data).reshape(4,4,3)\n# print(data)\n\nfrom multiprocessing import Process\nfrom multiprocessing import Manager\nimport cv2\n\ndef Toimage ():\n\tsource_file = 'kddcup.data_10_percent_corrected.csv'\n\twith open (source_file, 'r') as data_source:\n\t\tcsv_reader = csv.reader (data_source)\n\t\tcount = 0  # 记录数据的行数，初始化为0\n\t\tfor row in csv_reader:\n\t\t\tnew_row = [float (x) for x in row]\n\t\t\timage_data = np.array (new_row)\n\t\t\tdata = np.array (image_data).reshape (6, 7)\n\t\t\tcv2.imwrite ('image/{}.jpg'.format (count), data)\n\t\t\tcv2.waitKey ()\n\t\t\tcv2.destroyAllWindows ()\n\t\t\tcount += 1\n\n\n\nif __name__ == '__main__':  # 进程间默认不能共用内存\n\tmanager = Manager ()\n\tdic = manager.dict ()  # 这是一个特殊的字典\n\t\n\n\tp = Process (target=Toimage, args=(dic))\n\tp.start ()\n\tp.join ()\n\t\n\t\n\tprint ('end')\n```\n","source":"_posts/KDD-CUP99数据集预处理.md","raw":"---\ntitle: KDD CUP99数据集预处理\ndate: 2019-05-04 17:30:17\ntags:\n    - kdd99\ncatagories:\n    - 框架\n    - 数据处理\n    - kdd99\n---\n-----\n***       KDD CUP99数据集预处理  ***\n\n-----\n \n\n1、数据集下载：http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html\n\n2、KDDCup99网络入侵检测数据集介绍：\n\nhttps://blog.csdn.net/com_stu_zhang/article/details/6987632\n\nhttps://www.cnblogs.com/gongyanc/p/6703532.html\n\n3、Weka进阶——基于KDD99数据集的入侵检测分析：\n\nhttps://blog.csdn.net/jbfsdzpp/article/details/44099849\n\n4、符号型特征数值化\n\n采用one-hot方法进行数值化：https://blog.csdn.net/qq_28617019/article/details/79717184\n\n \n\n5、KDD CUP99数据集预处理\n\n（1）字符型特征转换为数值型特征（即符号型特征数值化）\nPython3对KDD CUP99数据集预处理代码实现（仅实现字符型特征转为数值型特征）\n# kdd99数据集预处理\n 将kdd99符号型数据转化为数值型数据\n\n```python\n# coding:utf-8\n\nimport numpy as np\nimport pandas as pd\nimport csv\nimport time\n\nglobal label_list  # label_list为全局变量\n\nlist_big=[] #储存大数据\n# 定义kdd99数据预处理函数\ndef preHandel_data ():\n\tsource_file = 'kddcup.data_10_percent_corrected'\n\thandled_file = 'kddcup.data_10_percent_corrected.csv'\n\tdata_file = open (handled_file, 'w', newline='')  # python3.x中添加newline=''这一参数使写入的文件没有多余的空行\n\twith open (source_file, 'r') as data_source:\n\t\tcsv_reader = csv.reader (data_source)\n\t\tcsv_writer = csv.writer (data_file)\n\t\tcount = 0  # 记录数据的行数，初始化为0\n\t\tfor row in csv_reader:\n\t\t\ttemp_line = np.array (row)  # 将每行数据存入temp_line数组里\n\t\t\tlist_big.append (int(temp_line [4]))\n\t\t\tlist_big.append (int(temp_line [5]))\n\t\t\ttemp_line [1] = handleProtocol (row)  # 将源文件行中3种协议类型转换成数字标识\n\t\t\ttemp_line [2] = handleService (row)  # 将源文件行中70种网络服务类型转换成数字标识\n\t\t\ttemp_line [3] = handleFlag (row)  # 将源文件行中11种网络连接状态转换成数字标识\n\t\t\ttemp_line [4] = handlenorm (int(row[4]))\n\t\t\ttemp_line [5] = handlenorm (int(row[5]))\n\t\t\ttemp_line [41] = handleLabel (row)  # 将源文件行中23种攻击类型转换成数字标识\n\t\t\tcsv_writer.writerow (temp_line)\n\t\t\tcount += 1\n\t\t\t# 输出每行数据中所修改后的状态\n\t\t\t#print (count, 'status:', temp_line [1], temp_line [2], temp_line [3], temp_line [41])\n\t\tdata_file.close ()\n\n\n# 将相应的非数字类型转换为数字标识即符号型数据转化为数值型数据\ndef find_index (x, y):\n\treturn [i for i in range (len (y)) if y [i] == x]\n\n\n# 定义将源文件行中3种协议类型转换成数字标识的函数\ndef handleProtocol (input):\n\tprotocol_list = ['tcp', 'udp', 'icmp']\n\tif input [1] in protocol_list:\n\t\treturn find_index (input [1], protocol_list) [0]\n\n\n# 定义将源文件行中70种网络服务类型转换成数字标识的函数\ndef handleService (input):\n\tservice_list = ['aol', 'auth', 'bgp', 'courier', 'csnet_ns', 'ctf', 'daytime', 'discard', 'domain', 'domain_u',\n\t\t\t\t\t'echo', 'eco_i', 'ecr_i', 'efs', 'exec', 'finger', 'ftp', 'ftp_data', 'gopher', 'harvest',\n\t\t\t\t\t'hostnames',\n\t\t\t\t\t'http', 'http_2784', 'http_443', 'http_8001', 'imap4', 'IRC', 'iso_tsap', 'klogin', 'kshell',\n\t\t\t\t\t'ldap',\n\t\t\t\t\t'link', 'login', 'mtp', 'name', 'netbios_dgm', 'netbios_ns', 'netbios_ssn', 'netstat', 'nnsp',\n\t\t\t\t\t'nntp',\n\t\t\t\t\t'ntp_u', 'other', 'pm_dump', 'pop_2', 'pop_3', 'printer', 'private', 'red_i', 'remote_job', 'rje',\n\t\t\t\t\t'shell',\n\t\t\t\t\t'smtp', 'sql_net', 'ssh', 'sunrpc', 'supdup', 'systat', 'telnet', 'tftp_u', 'tim_i', 'time',\n\t\t\t\t\t'urh_i', 'urp_i',\n\t\t\t\t\t'uucp', 'uucp_path', 'vmnet', 'whois', 'X11', 'Z39_50']\n\tif input [2] in service_list:\n\t\treturn find_index (input [2], service_list) [0]\n\n\n# 定义将源文件行中11种网络连接状态转换成数字标识的函数\ndef handleFlag (input):\n\tflag_list = ['OTH', 'REJ', 'RSTO', 'RSTOS0', 'RSTR', 'S0', 'S1', 'S2', 'S3', 'SF', 'SH']\n\tif input [3] in flag_list:\n\t\treturn find_index (input [3], flag_list) [0]\n\n\n# 定义将源文件行中攻击类型转换成数字标识的函数(训练集中共出现了22个攻击类型，而剩下的17种只在测试集中出现)\ndef handleLabel (input):\n\t# label_list=['normal.', 'buffer_overflow.', 'loadmodule.', 'perl.', 'neptune.', 'smurf.',\n\t# 'guess_passwd.', 'pod.', 'teardrop.', 'portsweep.', 'ipsweep.', 'land.', 'ftp_write.',\n\t# 'back.', 'imap.', 'satan.', 'phf.', 'nmap.', 'multihop.', 'warezmaster.', 'warezclient.',\n\t# 'spy.', 'rootkit.']\n\tglobal label_list  # 在函数内部使用全局变量并修改它\n\tif input [41] in label_list:\n\t\treturn find_index (input [41], label_list) [0]\n\telse:\n\t\tlabel_list.append (input [41])\n\t\treturn find_index (input [41], label_list) [0]\n\n\n\n#定义将源文件行中从源主机到目标主机的数据的字节数归一化到（0,255)\ndef handlenorm(input):\n\tmax_data=max(list_big)\n\tmin_data=min(list_big)\n\tresults=255/max_data*(input-min_data)\n\t\n\treturn  results\n\n\nif __name__ == '__main__':\n\tstart_time = time.clock ()\n\tglobal label_list  # 声明一个全局变量的列表并初始化为空\n\tlabel_list = []\n\tpreHandel_data ()\n\tend_time = time.clock ()\n\tprint (\"Running time:\", (end_time - start_time))  # 输出程序运行时间\n    \n```\n      该代码仅对10%的训练集（kddcup.data_10_percent_corrected）进行处理\n\n\n\n引用：\nhttps://blog.csdn.net/asialee_bird/article/details/80491256\n\n\n6、KDD CUP99数据集按行转换成图片\n# 将其转换为图片  \n```python\nimport csv\n\nimport numpy as np\n\ndata =np.random.random((4,4,3))\ndata=[]\ndef Toimage():\n\tsource_file = 'kddcup.data_10_percent_corrected.csv'\n\twith open (source_file, 'r') as data_source:\n\t\tcsv_reader = csv.reader (data_source)\n\t\tcount = 0  记录数据的行数，初始化为0\n\t\tfor row in csv_reader:\n\n\t\t\tnew_row=[float(x) for x in row]\n\t\t\timage_data=np.array(new_row)\n\n\t\t\tdata = np.array (image_data).reshape (6, 7)\n\t\t\timageio.imwrite ('image/{}.jpg'.format(count), data)\n\t\t\tcount+=1\n\n\n'''\n\n#Toimage()\n#print(np.array(data))\n#\n# new_list = [i for i in range(9)]\n# data=np.array(data).reshape(4,4,3)\n# print(data)\n\nfrom multiprocessing import Process\nfrom multiprocessing import Manager\nimport cv2\n\ndef Toimage ():\n\tsource_file = 'kddcup.data_10_percent_corrected.csv'\n\twith open (source_file, 'r') as data_source:\n\t\tcsv_reader = csv.reader (data_source)\n\t\tcount = 0  # 记录数据的行数，初始化为0\n\t\tfor row in csv_reader:\n\t\t\tnew_row = [float (x) for x in row]\n\t\t\timage_data = np.array (new_row)\n\t\t\tdata = np.array (image_data).reshape (6, 7)\n\t\t\tcv2.imwrite ('image/{}.jpg'.format (count), data)\n\t\t\tcv2.waitKey ()\n\t\t\tcv2.destroyAllWindows ()\n\t\t\tcount += 1\n\n\n\nif __name__ == '__main__':  # 进程间默认不能共用内存\n\tmanager = Manager ()\n\tdic = manager.dict ()  # 这是一个特殊的字典\n\t\n\n\tp = Process (target=Toimage, args=(dic))\n\tp.start ()\n\tp.join ()\n\t\n\t\n\tprint ('end')\n```\n","slug":"KDD-CUP99数据集预处理","published":1,"updated":"2021-07-26T09:58:02.514Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m0u0002igtaquofoseq","content":"<hr>\n<p><strong><em>       KDD CUP99数据集预处理  </em></strong></p>\n<hr>\n<p>1、数据集下载：<a href=\"http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html\" target=\"_blank\" rel=\"noopener\">http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html</a></p>\n<p>2、KDDCup99网络入侵检测数据集介绍：</p>\n<p><a href=\"https://blog.csdn.net/com_stu_zhang/article/details/6987632\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/com_stu_zhang/article/details/6987632</a></p>\n<p><a href=\"https://www.cnblogs.com/gongyanc/p/6703532.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/gongyanc/p/6703532.html</a></p>\n<p>3、Weka进阶——基于KDD99数据集的入侵检测分析：</p>\n<p><a href=\"https://blog.csdn.net/jbfsdzpp/article/details/44099849\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/jbfsdzpp/article/details/44099849</a></p>\n<p>4、符号型特征数值化</p>\n<p>采用one-hot方法进行数值化：<a href=\"https://blog.csdn.net/qq_28617019/article/details/79717184\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_28617019/article/details/79717184</a></p>\n<p>5、KDD CUP99数据集预处理</p>\n<p>（1）字符型特征转换为数值型特征（即符号型特征数值化）<br>Python3对KDD CUP99数据集预处理代码实现（仅实现字符型特征转为数值型特征）</p>\n<h1 id=\"kdd99数据集预处理\"><a href=\"#kdd99数据集预处理\" class=\"headerlink\" title=\"kdd99数据集预处理\"></a>kdd99数据集预处理</h1><p> 将kdd99符号型数据转化为数值型数据</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># coding:utf-8</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> csv</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">global</span> label_list  <span class=\"comment\"># label_list为全局变量</span></span><br><span class=\"line\"></span><br><span class=\"line\">list_big=[] <span class=\"comment\">#储存大数据</span></span><br><span class=\"line\"><span class=\"comment\"># 定义kdd99数据预处理函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">preHandel_data</span> <span class=\"params\">()</span>:</span></span><br><span class=\"line\">\tsource_file = <span class=\"string\">'kddcup.data_10_percent_corrected'</span></span><br><span class=\"line\">\thandled_file = <span class=\"string\">'kddcup.data_10_percent_corrected.csv'</span></span><br><span class=\"line\">\tdata_file = open (handled_file, <span class=\"string\">'w'</span>, newline=<span class=\"string\">''</span>)  <span class=\"comment\"># python3.x中添加newline=''这一参数使写入的文件没有多余的空行</span></span><br><span class=\"line\">\t<span class=\"keyword\">with</span> open (source_file, <span class=\"string\">'r'</span>) <span class=\"keyword\">as</span> data_source:</span><br><span class=\"line\">\t\tcsv_reader = csv.reader (data_source)</span><br><span class=\"line\">\t\tcsv_writer = csv.writer (data_file)</span><br><span class=\"line\">\t\tcount = <span class=\"number\">0</span>  <span class=\"comment\"># 记录数据的行数，初始化为0</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> row <span class=\"keyword\">in</span> csv_reader:</span><br><span class=\"line\">\t\t\ttemp_line = np.array (row)  <span class=\"comment\"># 将每行数据存入temp_line数组里</span></span><br><span class=\"line\">\t\t\tlist_big.append (int(temp_line [<span class=\"number\">4</span>]))</span><br><span class=\"line\">\t\t\tlist_big.append (int(temp_line [<span class=\"number\">5</span>]))</span><br><span class=\"line\">\t\t\ttemp_line [<span class=\"number\">1</span>] = handleProtocol (row)  <span class=\"comment\"># 将源文件行中3种协议类型转换成数字标识</span></span><br><span class=\"line\">\t\t\ttemp_line [<span class=\"number\">2</span>] = handleService (row)  <span class=\"comment\"># 将源文件行中70种网络服务类型转换成数字标识</span></span><br><span class=\"line\">\t\t\ttemp_line [<span class=\"number\">3</span>] = handleFlag (row)  <span class=\"comment\"># 将源文件行中11种网络连接状态转换成数字标识</span></span><br><span class=\"line\">\t\t\ttemp_line [<span class=\"number\">4</span>] = handlenorm (int(row[<span class=\"number\">4</span>]))</span><br><span class=\"line\">\t\t\ttemp_line [<span class=\"number\">5</span>] = handlenorm (int(row[<span class=\"number\">5</span>]))</span><br><span class=\"line\">\t\t\ttemp_line [<span class=\"number\">41</span>] = handleLabel (row)  <span class=\"comment\"># 将源文件行中23种攻击类型转换成数字标识</span></span><br><span class=\"line\">\t\t\tcsv_writer.writerow (temp_line)</span><br><span class=\"line\">\t\t\tcount += <span class=\"number\">1</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\"># 输出每行数据中所修改后的状态</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\">#print (count, 'status:', temp_line [1], temp_line [2], temp_line [3], temp_line [41])</span></span><br><span class=\"line\">\t\tdata_file.close ()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 将相应的非数字类型转换为数字标识即符号型数据转化为数值型数据</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">find_index</span> <span class=\"params\">(x, y)</span>:</span></span><br><span class=\"line\">\t<span class=\"keyword\">return</span> [i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range (len (y)) <span class=\"keyword\">if</span> y [i] == x]</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义将源文件行中3种协议类型转换成数字标识的函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">handleProtocol</span> <span class=\"params\">(input)</span>:</span></span><br><span class=\"line\">\tprotocol_list = [<span class=\"string\">'tcp'</span>, <span class=\"string\">'udp'</span>, <span class=\"string\">'icmp'</span>]</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> input [<span class=\"number\">1</span>] <span class=\"keyword\">in</span> protocol_list:</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> find_index (input [<span class=\"number\">1</span>], protocol_list) [<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义将源文件行中70种网络服务类型转换成数字标识的函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">handleService</span> <span class=\"params\">(input)</span>:</span></span><br><span class=\"line\">\tservice_list = [<span class=\"string\">'aol'</span>, <span class=\"string\">'auth'</span>, <span class=\"string\">'bgp'</span>, <span class=\"string\">'courier'</span>, <span class=\"string\">'csnet_ns'</span>, <span class=\"string\">'ctf'</span>, <span class=\"string\">'daytime'</span>, <span class=\"string\">'discard'</span>, <span class=\"string\">'domain'</span>, <span class=\"string\">'domain_u'</span>,</span><br><span class=\"line\">\t\t\t\t\t<span class=\"string\">'echo'</span>, <span class=\"string\">'eco_i'</span>, <span class=\"string\">'ecr_i'</span>, <span class=\"string\">'efs'</span>, <span class=\"string\">'exec'</span>, <span class=\"string\">'finger'</span>, <span class=\"string\">'ftp'</span>, <span class=\"string\">'ftp_data'</span>, <span class=\"string\">'gopher'</span>, <span class=\"string\">'harvest'</span>,</span><br><span class=\"line\">\t\t\t\t\t<span class=\"string\">'hostnames'</span>,</span><br><span class=\"line\">\t\t\t\t\t<span class=\"string\">'http'</span>, <span class=\"string\">'http_2784'</span>, <span class=\"string\">'http_443'</span>, <span class=\"string\">'http_8001'</span>, <span class=\"string\">'imap4'</span>, <span class=\"string\">'IRC'</span>, <span class=\"string\">'iso_tsap'</span>, <span class=\"string\">'klogin'</span>, <span class=\"string\">'kshell'</span>,</span><br><span class=\"line\">\t\t\t\t\t<span class=\"string\">'ldap'</span>,</span><br><span class=\"line\">\t\t\t\t\t<span class=\"string\">'link'</span>, <span class=\"string\">'login'</span>, <span class=\"string\">'mtp'</span>, <span class=\"string\">'name'</span>, <span class=\"string\">'netbios_dgm'</span>, <span class=\"string\">'netbios_ns'</span>, <span class=\"string\">'netbios_ssn'</span>, <span class=\"string\">'netstat'</span>, <span class=\"string\">'nnsp'</span>,</span><br><span class=\"line\">\t\t\t\t\t<span class=\"string\">'nntp'</span>,</span><br><span class=\"line\">\t\t\t\t\t<span class=\"string\">'ntp_u'</span>, <span class=\"string\">'other'</span>, <span class=\"string\">'pm_dump'</span>, <span class=\"string\">'pop_2'</span>, <span class=\"string\">'pop_3'</span>, <span class=\"string\">'printer'</span>, <span class=\"string\">'private'</span>, <span class=\"string\">'red_i'</span>, <span class=\"string\">'remote_job'</span>, <span class=\"string\">'rje'</span>,</span><br><span class=\"line\">\t\t\t\t\t<span class=\"string\">'shell'</span>,</span><br><span class=\"line\">\t\t\t\t\t<span class=\"string\">'smtp'</span>, <span class=\"string\">'sql_net'</span>, <span class=\"string\">'ssh'</span>, <span class=\"string\">'sunrpc'</span>, <span class=\"string\">'supdup'</span>, <span class=\"string\">'systat'</span>, <span class=\"string\">'telnet'</span>, <span class=\"string\">'tftp_u'</span>, <span class=\"string\">'tim_i'</span>, <span class=\"string\">'time'</span>,</span><br><span class=\"line\">\t\t\t\t\t<span class=\"string\">'urh_i'</span>, <span class=\"string\">'urp_i'</span>,</span><br><span class=\"line\">\t\t\t\t\t<span class=\"string\">'uucp'</span>, <span class=\"string\">'uucp_path'</span>, <span class=\"string\">'vmnet'</span>, <span class=\"string\">'whois'</span>, <span class=\"string\">'X11'</span>, <span class=\"string\">'Z39_50'</span>]</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> input [<span class=\"number\">2</span>] <span class=\"keyword\">in</span> service_list:</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> find_index (input [<span class=\"number\">2</span>], service_list) [<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义将源文件行中11种网络连接状态转换成数字标识的函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">handleFlag</span> <span class=\"params\">(input)</span>:</span></span><br><span class=\"line\">\tflag_list = [<span class=\"string\">'OTH'</span>, <span class=\"string\">'REJ'</span>, <span class=\"string\">'RSTO'</span>, <span class=\"string\">'RSTOS0'</span>, <span class=\"string\">'RSTR'</span>, <span class=\"string\">'S0'</span>, <span class=\"string\">'S1'</span>, <span class=\"string\">'S2'</span>, <span class=\"string\">'S3'</span>, <span class=\"string\">'SF'</span>, <span class=\"string\">'SH'</span>]</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> input [<span class=\"number\">3</span>] <span class=\"keyword\">in</span> flag_list:</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> find_index (input [<span class=\"number\">3</span>], flag_list) [<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义将源文件行中攻击类型转换成数字标识的函数(训练集中共出现了22个攻击类型，而剩下的17种只在测试集中出现)</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">handleLabel</span> <span class=\"params\">(input)</span>:</span></span><br><span class=\"line\">\t<span class=\"comment\"># label_list=['normal.', 'buffer_overflow.', 'loadmodule.', 'perl.', 'neptune.', 'smurf.',</span></span><br><span class=\"line\">\t<span class=\"comment\"># 'guess_passwd.', 'pod.', 'teardrop.', 'portsweep.', 'ipsweep.', 'land.', 'ftp_write.',</span></span><br><span class=\"line\">\t<span class=\"comment\"># 'back.', 'imap.', 'satan.', 'phf.', 'nmap.', 'multihop.', 'warezmaster.', 'warezclient.',</span></span><br><span class=\"line\">\t<span class=\"comment\"># 'spy.', 'rootkit.']</span></span><br><span class=\"line\">\t<span class=\"keyword\">global</span> label_list  <span class=\"comment\"># 在函数内部使用全局变量并修改它</span></span><br><span class=\"line\">\t<span class=\"keyword\">if</span> input [<span class=\"number\">41</span>] <span class=\"keyword\">in</span> label_list:</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> find_index (input [<span class=\"number\">41</span>], label_list) [<span class=\"number\">0</span>]</span><br><span class=\"line\">\t<span class=\"keyword\">else</span>:</span><br><span class=\"line\">\t\tlabel_list.append (input [<span class=\"number\">41</span>])</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> find_index (input [<span class=\"number\">41</span>], label_list) [<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#定义将源文件行中从源主机到目标主机的数据的字节数归一化到（0,255)</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">handlenorm</span><span class=\"params\">(input)</span>:</span></span><br><span class=\"line\">\tmax_data=max(list_big)</span><br><span class=\"line\">\tmin_data=min(list_big)</span><br><span class=\"line\">\tresults=<span class=\"number\">255</span>/max_data*(input-min_data)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"keyword\">return</span>  results</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">\tstart_time = time.clock ()</span><br><span class=\"line\">\t<span class=\"keyword\">global</span> label_list  <span class=\"comment\"># 声明一个全局变量的列表并初始化为空</span></span><br><span class=\"line\">\tlabel_list = []</span><br><span class=\"line\">\tpreHandel_data ()</span><br><span class=\"line\">\tend_time = time.clock ()</span><br><span class=\"line\">\t<span class=\"keyword\">print</span> (<span class=\"string\">\"Running time:\"</span>, (end_time - start_time))  <span class=\"comment\"># 输出程序运行时间</span></span><br></pre></td></tr></table></figure>\n<pre><code>该代码仅对10%的训练集（kddcup.data_10_percent_corrected）进行处理\n</code></pre><p>引用：<br><a href=\"https://blog.csdn.net/asialee_bird/article/details/80491256\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/asialee_bird/article/details/80491256</a></p>\n<p>6、KDD CUP99数据集按行转换成图片</p>\n<h1 id=\"将其转换为图片\"><a href=\"#将其转换为图片\" class=\"headerlink\" title=\"将其转换为图片\"></a>将其转换为图片</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> csv</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\">data =np.random.random((<span class=\"number\">4</span>,<span class=\"number\">4</span>,<span class=\"number\">3</span>))</span><br><span class=\"line\">data=[]</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">Toimage</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">\tsource_file = <span class=\"string\">'kddcup.data_10_percent_corrected.csv'</span></span><br><span class=\"line\">\t<span class=\"keyword\">with</span> open (source_file, <span class=\"string\">'r'</span>) <span class=\"keyword\">as</span> data_source:</span><br><span class=\"line\">\t\tcsv_reader = csv.reader (data_source)</span><br><span class=\"line\">\t\tcount = <span class=\"number\">0</span>  记录数据的行数，初始化为<span class=\"number\">0</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> row <span class=\"keyword\">in</span> csv_reader:</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\tnew_row=[float(x) <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> row]</span><br><span class=\"line\">\t\t\timage_data=np.array(new_row)</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\tdata = np.array (image_data).reshape (<span class=\"number\">6</span>, <span class=\"number\">7</span>)</span><br><span class=\"line\">\t\t\timageio.imwrite (<span class=\"string\">'image/&#123;&#125;.jpg'</span>.format(count), data)</span><br><span class=\"line\">\t\t\tcount+=<span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">#Toimage()</span></span><br><span class=\"line\"><span class=\"string\">#print(np.array(data))</span></span><br><span class=\"line\"><span class=\"string\">#</span></span><br><span class=\"line\"><span class=\"string\"># new_list = [i for i in range(9)]</span></span><br><span class=\"line\"><span class=\"string\"># data=np.array(data).reshape(4,4,3)</span></span><br><span class=\"line\"><span class=\"string\"># print(data)</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">from multiprocessing import Process</span></span><br><span class=\"line\"><span class=\"string\">from multiprocessing import Manager</span></span><br><span class=\"line\"><span class=\"string\">import cv2</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">def Toimage ():</span></span><br><span class=\"line\"><span class=\"string\">\tsource_file = 'kddcup.data_10_percent_corrected.csv'</span></span><br><span class=\"line\"><span class=\"string\">\twith open (source_file, 'r') as data_source:</span></span><br><span class=\"line\"><span class=\"string\">\t\tcsv_reader = csv.reader (data_source)</span></span><br><span class=\"line\"><span class=\"string\">\t\tcount = 0  # 记录数据的行数，初始化为0</span></span><br><span class=\"line\"><span class=\"string\">\t\tfor row in csv_reader:</span></span><br><span class=\"line\"><span class=\"string\">\t\t\tnew_row = [float (x) for x in row]</span></span><br><span class=\"line\"><span class=\"string\">\t\t\timage_data = np.array (new_row)</span></span><br><span class=\"line\"><span class=\"string\">\t\t\tdata = np.array (image_data).reshape (6, 7)</span></span><br><span class=\"line\"><span class=\"string\">\t\t\tcv2.imwrite ('image/&#123;&#125;.jpg'.format (count), data)</span></span><br><span class=\"line\"><span class=\"string\">\t\t\tcv2.waitKey ()</span></span><br><span class=\"line\"><span class=\"string\">\t\t\tcv2.destroyAllWindows ()</span></span><br><span class=\"line\"><span class=\"string\">\t\t\tcount += 1</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">if __name__ == '__main__':  # 进程间默认不能共用内存</span></span><br><span class=\"line\"><span class=\"string\">\tmanager = Manager ()</span></span><br><span class=\"line\"><span class=\"string\">\tdic = manager.dict ()  # 这是一个特殊的字典</span></span><br><span class=\"line\"><span class=\"string\">\t</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">\tp = Process (target=Toimage, args=(dic))</span></span><br><span class=\"line\"><span class=\"string\">\tp.start ()</span></span><br><span class=\"line\"><span class=\"string\">\tp.join ()</span></span><br><span class=\"line\"><span class=\"string\">\t</span></span><br><span class=\"line\"><span class=\"string\">\t</span></span><br><span class=\"line\"><span class=\"string\">\tprint ('end')</span></span><br></pre></td></tr></table></figure>\n","site":{"data":{}},"excerpt":"","more":"<hr>\n<p><strong><em>       KDD CUP99数据集预处理  </em></strong></p>\n<hr>\n<p>1、数据集下载：<a href=\"http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html\" target=\"_blank\" rel=\"noopener\">http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html</a></p>\n<p>2、KDDCup99网络入侵检测数据集介绍：</p>\n<p><a href=\"https://blog.csdn.net/com_stu_zhang/article/details/6987632\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/com_stu_zhang/article/details/6987632</a></p>\n<p><a href=\"https://www.cnblogs.com/gongyanc/p/6703532.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/gongyanc/p/6703532.html</a></p>\n<p>3、Weka进阶——基于KDD99数据集的入侵检测分析：</p>\n<p><a href=\"https://blog.csdn.net/jbfsdzpp/article/details/44099849\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/jbfsdzpp/article/details/44099849</a></p>\n<p>4、符号型特征数值化</p>\n<p>采用one-hot方法进行数值化：<a href=\"https://blog.csdn.net/qq_28617019/article/details/79717184\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_28617019/article/details/79717184</a></p>\n<p>5、KDD CUP99数据集预处理</p>\n<p>（1）字符型特征转换为数值型特征（即符号型特征数值化）<br>Python3对KDD CUP99数据集预处理代码实现（仅实现字符型特征转为数值型特征）</p>\n<h1 id=\"kdd99数据集预处理\"><a href=\"#kdd99数据集预处理\" class=\"headerlink\" title=\"kdd99数据集预处理\"></a>kdd99数据集预处理</h1><p> 将kdd99符号型数据转化为数值型数据</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># coding:utf-8</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> pandas <span class=\"keyword\">as</span> pd</span><br><span class=\"line\"><span class=\"keyword\">import</span> csv</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">global</span> label_list  <span class=\"comment\"># label_list为全局变量</span></span><br><span class=\"line\"></span><br><span class=\"line\">list_big=[] <span class=\"comment\">#储存大数据</span></span><br><span class=\"line\"><span class=\"comment\"># 定义kdd99数据预处理函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">preHandel_data</span> <span class=\"params\">()</span>:</span></span><br><span class=\"line\">\tsource_file = <span class=\"string\">'kddcup.data_10_percent_corrected'</span></span><br><span class=\"line\">\thandled_file = <span class=\"string\">'kddcup.data_10_percent_corrected.csv'</span></span><br><span class=\"line\">\tdata_file = open (handled_file, <span class=\"string\">'w'</span>, newline=<span class=\"string\">''</span>)  <span class=\"comment\"># python3.x中添加newline=''这一参数使写入的文件没有多余的空行</span></span><br><span class=\"line\">\t<span class=\"keyword\">with</span> open (source_file, <span class=\"string\">'r'</span>) <span class=\"keyword\">as</span> data_source:</span><br><span class=\"line\">\t\tcsv_reader = csv.reader (data_source)</span><br><span class=\"line\">\t\tcsv_writer = csv.writer (data_file)</span><br><span class=\"line\">\t\tcount = <span class=\"number\">0</span>  <span class=\"comment\"># 记录数据的行数，初始化为0</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> row <span class=\"keyword\">in</span> csv_reader:</span><br><span class=\"line\">\t\t\ttemp_line = np.array (row)  <span class=\"comment\"># 将每行数据存入temp_line数组里</span></span><br><span class=\"line\">\t\t\tlist_big.append (int(temp_line [<span class=\"number\">4</span>]))</span><br><span class=\"line\">\t\t\tlist_big.append (int(temp_line [<span class=\"number\">5</span>]))</span><br><span class=\"line\">\t\t\ttemp_line [<span class=\"number\">1</span>] = handleProtocol (row)  <span class=\"comment\"># 将源文件行中3种协议类型转换成数字标识</span></span><br><span class=\"line\">\t\t\ttemp_line [<span class=\"number\">2</span>] = handleService (row)  <span class=\"comment\"># 将源文件行中70种网络服务类型转换成数字标识</span></span><br><span class=\"line\">\t\t\ttemp_line [<span class=\"number\">3</span>] = handleFlag (row)  <span class=\"comment\"># 将源文件行中11种网络连接状态转换成数字标识</span></span><br><span class=\"line\">\t\t\ttemp_line [<span class=\"number\">4</span>] = handlenorm (int(row[<span class=\"number\">4</span>]))</span><br><span class=\"line\">\t\t\ttemp_line [<span class=\"number\">5</span>] = handlenorm (int(row[<span class=\"number\">5</span>]))</span><br><span class=\"line\">\t\t\ttemp_line [<span class=\"number\">41</span>] = handleLabel (row)  <span class=\"comment\"># 将源文件行中23种攻击类型转换成数字标识</span></span><br><span class=\"line\">\t\t\tcsv_writer.writerow (temp_line)</span><br><span class=\"line\">\t\t\tcount += <span class=\"number\">1</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\"># 输出每行数据中所修改后的状态</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\">#print (count, 'status:', temp_line [1], temp_line [2], temp_line [3], temp_line [41])</span></span><br><span class=\"line\">\t\tdata_file.close ()</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 将相应的非数字类型转换为数字标识即符号型数据转化为数值型数据</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">find_index</span> <span class=\"params\">(x, y)</span>:</span></span><br><span class=\"line\">\t<span class=\"keyword\">return</span> [i <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range (len (y)) <span class=\"keyword\">if</span> y [i] == x]</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义将源文件行中3种协议类型转换成数字标识的函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">handleProtocol</span> <span class=\"params\">(input)</span>:</span></span><br><span class=\"line\">\tprotocol_list = [<span class=\"string\">'tcp'</span>, <span class=\"string\">'udp'</span>, <span class=\"string\">'icmp'</span>]</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> input [<span class=\"number\">1</span>] <span class=\"keyword\">in</span> protocol_list:</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> find_index (input [<span class=\"number\">1</span>], protocol_list) [<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义将源文件行中70种网络服务类型转换成数字标识的函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">handleService</span> <span class=\"params\">(input)</span>:</span></span><br><span class=\"line\">\tservice_list = [<span class=\"string\">'aol'</span>, <span class=\"string\">'auth'</span>, <span class=\"string\">'bgp'</span>, <span class=\"string\">'courier'</span>, <span class=\"string\">'csnet_ns'</span>, <span class=\"string\">'ctf'</span>, <span class=\"string\">'daytime'</span>, <span class=\"string\">'discard'</span>, <span class=\"string\">'domain'</span>, <span class=\"string\">'domain_u'</span>,</span><br><span class=\"line\">\t\t\t\t\t<span class=\"string\">'echo'</span>, <span class=\"string\">'eco_i'</span>, <span class=\"string\">'ecr_i'</span>, <span class=\"string\">'efs'</span>, <span class=\"string\">'exec'</span>, <span class=\"string\">'finger'</span>, <span class=\"string\">'ftp'</span>, <span class=\"string\">'ftp_data'</span>, <span class=\"string\">'gopher'</span>, <span class=\"string\">'harvest'</span>,</span><br><span class=\"line\">\t\t\t\t\t<span class=\"string\">'hostnames'</span>,</span><br><span class=\"line\">\t\t\t\t\t<span class=\"string\">'http'</span>, <span class=\"string\">'http_2784'</span>, <span class=\"string\">'http_443'</span>, <span class=\"string\">'http_8001'</span>, <span class=\"string\">'imap4'</span>, <span class=\"string\">'IRC'</span>, <span class=\"string\">'iso_tsap'</span>, <span class=\"string\">'klogin'</span>, <span class=\"string\">'kshell'</span>,</span><br><span class=\"line\">\t\t\t\t\t<span class=\"string\">'ldap'</span>,</span><br><span class=\"line\">\t\t\t\t\t<span class=\"string\">'link'</span>, <span class=\"string\">'login'</span>, <span class=\"string\">'mtp'</span>, <span class=\"string\">'name'</span>, <span class=\"string\">'netbios_dgm'</span>, <span class=\"string\">'netbios_ns'</span>, <span class=\"string\">'netbios_ssn'</span>, <span class=\"string\">'netstat'</span>, <span class=\"string\">'nnsp'</span>,</span><br><span class=\"line\">\t\t\t\t\t<span class=\"string\">'nntp'</span>,</span><br><span class=\"line\">\t\t\t\t\t<span class=\"string\">'ntp_u'</span>, <span class=\"string\">'other'</span>, <span class=\"string\">'pm_dump'</span>, <span class=\"string\">'pop_2'</span>, <span class=\"string\">'pop_3'</span>, <span class=\"string\">'printer'</span>, <span class=\"string\">'private'</span>, <span class=\"string\">'red_i'</span>, <span class=\"string\">'remote_job'</span>, <span class=\"string\">'rje'</span>,</span><br><span class=\"line\">\t\t\t\t\t<span class=\"string\">'shell'</span>,</span><br><span class=\"line\">\t\t\t\t\t<span class=\"string\">'smtp'</span>, <span class=\"string\">'sql_net'</span>, <span class=\"string\">'ssh'</span>, <span class=\"string\">'sunrpc'</span>, <span class=\"string\">'supdup'</span>, <span class=\"string\">'systat'</span>, <span class=\"string\">'telnet'</span>, <span class=\"string\">'tftp_u'</span>, <span class=\"string\">'tim_i'</span>, <span class=\"string\">'time'</span>,</span><br><span class=\"line\">\t\t\t\t\t<span class=\"string\">'urh_i'</span>, <span class=\"string\">'urp_i'</span>,</span><br><span class=\"line\">\t\t\t\t\t<span class=\"string\">'uucp'</span>, <span class=\"string\">'uucp_path'</span>, <span class=\"string\">'vmnet'</span>, <span class=\"string\">'whois'</span>, <span class=\"string\">'X11'</span>, <span class=\"string\">'Z39_50'</span>]</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> input [<span class=\"number\">2</span>] <span class=\"keyword\">in</span> service_list:</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> find_index (input [<span class=\"number\">2</span>], service_list) [<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义将源文件行中11种网络连接状态转换成数字标识的函数</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">handleFlag</span> <span class=\"params\">(input)</span>:</span></span><br><span class=\"line\">\tflag_list = [<span class=\"string\">'OTH'</span>, <span class=\"string\">'REJ'</span>, <span class=\"string\">'RSTO'</span>, <span class=\"string\">'RSTOS0'</span>, <span class=\"string\">'RSTR'</span>, <span class=\"string\">'S0'</span>, <span class=\"string\">'S1'</span>, <span class=\"string\">'S2'</span>, <span class=\"string\">'S3'</span>, <span class=\"string\">'SF'</span>, <span class=\"string\">'SH'</span>]</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> input [<span class=\"number\">3</span>] <span class=\"keyword\">in</span> flag_list:</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> find_index (input [<span class=\"number\">3</span>], flag_list) [<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 定义将源文件行中攻击类型转换成数字标识的函数(训练集中共出现了22个攻击类型，而剩下的17种只在测试集中出现)</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">handleLabel</span> <span class=\"params\">(input)</span>:</span></span><br><span class=\"line\">\t<span class=\"comment\"># label_list=['normal.', 'buffer_overflow.', 'loadmodule.', 'perl.', 'neptune.', 'smurf.',</span></span><br><span class=\"line\">\t<span class=\"comment\"># 'guess_passwd.', 'pod.', 'teardrop.', 'portsweep.', 'ipsweep.', 'land.', 'ftp_write.',</span></span><br><span class=\"line\">\t<span class=\"comment\"># 'back.', 'imap.', 'satan.', 'phf.', 'nmap.', 'multihop.', 'warezmaster.', 'warezclient.',</span></span><br><span class=\"line\">\t<span class=\"comment\"># 'spy.', 'rootkit.']</span></span><br><span class=\"line\">\t<span class=\"keyword\">global</span> label_list  <span class=\"comment\"># 在函数内部使用全局变量并修改它</span></span><br><span class=\"line\">\t<span class=\"keyword\">if</span> input [<span class=\"number\">41</span>] <span class=\"keyword\">in</span> label_list:</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> find_index (input [<span class=\"number\">41</span>], label_list) [<span class=\"number\">0</span>]</span><br><span class=\"line\">\t<span class=\"keyword\">else</span>:</span><br><span class=\"line\">\t\tlabel_list.append (input [<span class=\"number\">41</span>])</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> find_index (input [<span class=\"number\">41</span>], label_list) [<span class=\"number\">0</span>]</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#定义将源文件行中从源主机到目标主机的数据的字节数归一化到（0,255)</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">handlenorm</span><span class=\"params\">(input)</span>:</span></span><br><span class=\"line\">\tmax_data=max(list_big)</span><br><span class=\"line\">\tmin_data=min(list_big)</span><br><span class=\"line\">\tresults=<span class=\"number\">255</span>/max_data*(input-min_data)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"keyword\">return</span>  results</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">\tstart_time = time.clock ()</span><br><span class=\"line\">\t<span class=\"keyword\">global</span> label_list  <span class=\"comment\"># 声明一个全局变量的列表并初始化为空</span></span><br><span class=\"line\">\tlabel_list = []</span><br><span class=\"line\">\tpreHandel_data ()</span><br><span class=\"line\">\tend_time = time.clock ()</span><br><span class=\"line\">\t<span class=\"keyword\">print</span> (<span class=\"string\">\"Running time:\"</span>, (end_time - start_time))  <span class=\"comment\"># 输出程序运行时间</span></span><br></pre></td></tr></table></figure>\n<pre><code>该代码仅对10%的训练集（kddcup.data_10_percent_corrected）进行处理\n</code></pre><p>引用：<br><a href=\"https://blog.csdn.net/asialee_bird/article/details/80491256\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/asialee_bird/article/details/80491256</a></p>\n<p>6、KDD CUP99数据集按行转换成图片</p>\n<h1 id=\"将其转换为图片\"><a href=\"#将其转换为图片\" class=\"headerlink\" title=\"将其转换为图片\"></a>将其转换为图片</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> csv</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\">data =np.random.random((<span class=\"number\">4</span>,<span class=\"number\">4</span>,<span class=\"number\">3</span>))</span><br><span class=\"line\">data=[]</span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">Toimage</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">\tsource_file = <span class=\"string\">'kddcup.data_10_percent_corrected.csv'</span></span><br><span class=\"line\">\t<span class=\"keyword\">with</span> open (source_file, <span class=\"string\">'r'</span>) <span class=\"keyword\">as</span> data_source:</span><br><span class=\"line\">\t\tcsv_reader = csv.reader (data_source)</span><br><span class=\"line\">\t\tcount = <span class=\"number\">0</span>  记录数据的行数，初始化为<span class=\"number\">0</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> row <span class=\"keyword\">in</span> csv_reader:</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\tnew_row=[float(x) <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> row]</span><br><span class=\"line\">\t\t\timage_data=np.array(new_row)</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\tdata = np.array (image_data).reshape (<span class=\"number\">6</span>, <span class=\"number\">7</span>)</span><br><span class=\"line\">\t\t\timageio.imwrite (<span class=\"string\">'image/&#123;&#125;.jpg'</span>.format(count), data)</span><br><span class=\"line\">\t\t\tcount+=<span class=\"number\">1</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">#Toimage()</span></span><br><span class=\"line\"><span class=\"string\">#print(np.array(data))</span></span><br><span class=\"line\"><span class=\"string\">#</span></span><br><span class=\"line\"><span class=\"string\"># new_list = [i for i in range(9)]</span></span><br><span class=\"line\"><span class=\"string\"># data=np.array(data).reshape(4,4,3)</span></span><br><span class=\"line\"><span class=\"string\"># print(data)</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">from multiprocessing import Process</span></span><br><span class=\"line\"><span class=\"string\">from multiprocessing import Manager</span></span><br><span class=\"line\"><span class=\"string\">import cv2</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">def Toimage ():</span></span><br><span class=\"line\"><span class=\"string\">\tsource_file = 'kddcup.data_10_percent_corrected.csv'</span></span><br><span class=\"line\"><span class=\"string\">\twith open (source_file, 'r') as data_source:</span></span><br><span class=\"line\"><span class=\"string\">\t\tcsv_reader = csv.reader (data_source)</span></span><br><span class=\"line\"><span class=\"string\">\t\tcount = 0  # 记录数据的行数，初始化为0</span></span><br><span class=\"line\"><span class=\"string\">\t\tfor row in csv_reader:</span></span><br><span class=\"line\"><span class=\"string\">\t\t\tnew_row = [float (x) for x in row]</span></span><br><span class=\"line\"><span class=\"string\">\t\t\timage_data = np.array (new_row)</span></span><br><span class=\"line\"><span class=\"string\">\t\t\tdata = np.array (image_data).reshape (6, 7)</span></span><br><span class=\"line\"><span class=\"string\">\t\t\tcv2.imwrite ('image/&#123;&#125;.jpg'.format (count), data)</span></span><br><span class=\"line\"><span class=\"string\">\t\t\tcv2.waitKey ()</span></span><br><span class=\"line\"><span class=\"string\">\t\t\tcv2.destroyAllWindows ()</span></span><br><span class=\"line\"><span class=\"string\">\t\t\tcount += 1</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">if __name__ == '__main__':  # 进程间默认不能共用内存</span></span><br><span class=\"line\"><span class=\"string\">\tmanager = Manager ()</span></span><br><span class=\"line\"><span class=\"string\">\tdic = manager.dict ()  # 这是一个特殊的字典</span></span><br><span class=\"line\"><span class=\"string\">\t</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">\tp = Process (target=Toimage, args=(dic))</span></span><br><span class=\"line\"><span class=\"string\">\tp.start ()</span></span><br><span class=\"line\"><span class=\"string\">\tp.join ()</span></span><br><span class=\"line\"><span class=\"string\">\t</span></span><br><span class=\"line\"><span class=\"string\">\t</span></span><br><span class=\"line\"><span class=\"string\">\tprint ('end')</span></span><br></pre></td></tr></table></figure>\n"},{"title":"LOL-换肤快捷工具","date":"2019-01-01T18:46:01.000Z","_content":"# 第一步:\n打开链接:\n* 百度云:https://pan.yangxin.com/s/13YsHOdSH82qGBO4XRh2TFA\n** 选择Setup_sindre.exe 下载** \n\n\n** 如需改进(新手别点):\n源码文件:https://pan.yangxin.com/s/15er7GhOfnFoOse7YmK4vzQ**\n\n\n# 第二步:\n下载安装(纯净,无二次添加):\n![](https://blog.mviai.com/images/lol/1.png)\n\n# 第三步:\n就可以用了\n![](https://blog.mviai.com/images/lol/2.png)\n\n\n# lolsk 使用:\n打开如图:\n![](https://blog.mviai.com/images/lol/3.png)\n\n登入游戏:(默认每个英雄都有皮肤)\n![](https://blog.mviai.com/images/lol/4.png)\n\n<font color=red>\n**  切忌不能关掉,不然进去就失效,窗口缩小即可 **\n**  切忌不能关掉,不然进去就失效,窗口缩小即可 **\n**  切忌不能关掉,不然进去就失效,窗口缩小即可 **\n**  切忌不能关掉,不然进去就失效,窗口缩小即可 **\n\n\n如果要自定义皮肤:\n选好 按右下角蓝色按钮激活\n![](https://blog.mviai.com/images/lol/5.png)\n</font>\n","source":"_posts/LOL-换肤快捷工具.md","raw":"---\ntitle: LOL-换肤快捷工具\ndate: 2019-01-02 02:46:01\ntags:\n    - LOL\ncategories:\n    - 工具\n    - 日常工具\n    - LOL\n---\n# 第一步:\n打开链接:\n* 百度云:https://pan.yangxin.com/s/13YsHOdSH82qGBO4XRh2TFA\n** 选择Setup_sindre.exe 下载** \n\n\n** 如需改进(新手别点):\n源码文件:https://pan.yangxin.com/s/15er7GhOfnFoOse7YmK4vzQ**\n\n\n# 第二步:\n下载安装(纯净,无二次添加):\n![](https://blog.mviai.com/images/lol/1.png)\n\n# 第三步:\n就可以用了\n![](https://blog.mviai.com/images/lol/2.png)\n\n\n# lolsk 使用:\n打开如图:\n![](https://blog.mviai.com/images/lol/3.png)\n\n登入游戏:(默认每个英雄都有皮肤)\n![](https://blog.mviai.com/images/lol/4.png)\n\n<font color=red>\n**  切忌不能关掉,不然进去就失效,窗口缩小即可 **\n**  切忌不能关掉,不然进去就失效,窗口缩小即可 **\n**  切忌不能关掉,不然进去就失效,窗口缩小即可 **\n**  切忌不能关掉,不然进去就失效,窗口缩小即可 **\n\n\n如果要自定义皮肤:\n选好 按右下角蓝色按钮激活\n![](https://blog.mviai.com/images/lol/5.png)\n</font>\n","slug":"LOL-换肤快捷工具","published":1,"updated":"2021-07-26T09:58:02.515Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m0z0004igtavxljvzfz","content":"<h1 id=\"第一步\"><a href=\"#第一步\" class=\"headerlink\" title=\"第一步:\"></a>第一步:</h1><p>打开链接:</p>\n<ul>\n<li>百度云:<a href=\"https://pan.yangxin.com/s/13YsHOdSH82qGBO4XRh2TFA\" target=\"_blank\" rel=\"noopener\">https://pan.yangxin.com/s/13YsHOdSH82qGBO4XRh2TFA</a><br><strong> 选择Setup_sindre.exe 下载</strong> </li>\n</ul>\n<p><strong> 如需改进(新手别点):<br>源码文件:<a href=\"https://pan.yangxin.com/s/15er7GhOfnFoOse7YmK4vzQ\" target=\"_blank\" rel=\"noopener\">https://pan.yangxin.com/s/15er7GhOfnFoOse7YmK4vzQ</a></strong></p>\n<h1 id=\"第二步\"><a href=\"#第二步\" class=\"headerlink\" title=\"第二步:\"></a>第二步:</h1><p>下载安装(纯净,无二次添加):<br><img src=\"https://blog.mviai.com/images/lol/1.png\" alt></p>\n<h1 id=\"第三步\"><a href=\"#第三步\" class=\"headerlink\" title=\"第三步:\"></a>第三步:</h1><p>就可以用了<br><img src=\"https://blog.mviai.com/images/lol/2.png\" alt></p>\n<h1 id=\"lolsk-使用\"><a href=\"#lolsk-使用\" class=\"headerlink\" title=\"lolsk 使用:\"></a>lolsk 使用:</h1><p>打开如图:<br><img src=\"https://blog.mviai.com/images/lol/3.png\" alt></p>\n<p>登入游戏:(默认每个英雄都有皮肤)<br><img src=\"https://blog.mviai.com/images/lol/4.png\" alt></p>\n<font color=\"red\"><br><strong>  切忌不能关掉,不然进去就失效,窗口缩小即可 </strong><br><strong>  切忌不能关掉,不然进去就失效,窗口缩小即可 </strong><br><strong>  切忌不能关掉,不然进去就失效,窗口缩小即可 </strong><br><strong>  切忌不能关掉,不然进去就失效,窗口缩小即可 </strong><br><br><br>如果要自定义皮肤:<br>选好 按右下角蓝色按钮激活<br><img src=\"https://blog.mviai.com/images/lol/5.png\" alt><br></font>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"第一步\"><a href=\"#第一步\" class=\"headerlink\" title=\"第一步:\"></a>第一步:</h1><p>打开链接:</p>\n<ul>\n<li>百度云:<a href=\"https://pan.yangxin.com/s/13YsHOdSH82qGBO4XRh2TFA\" target=\"_blank\" rel=\"noopener\">https://pan.yangxin.com/s/13YsHOdSH82qGBO4XRh2TFA</a><br><strong> 选择Setup_sindre.exe 下载</strong> </li>\n</ul>\n<p><strong> 如需改进(新手别点):<br>源码文件:<a href=\"https://pan.yangxin.com/s/15er7GhOfnFoOse7YmK4vzQ\" target=\"_blank\" rel=\"noopener\">https://pan.yangxin.com/s/15er7GhOfnFoOse7YmK4vzQ</a></strong></p>\n<h1 id=\"第二步\"><a href=\"#第二步\" class=\"headerlink\" title=\"第二步:\"></a>第二步:</h1><p>下载安装(纯净,无二次添加):<br><img src=\"https://blog.mviai.com/images/lol/1.png\" alt></p>\n<h1 id=\"第三步\"><a href=\"#第三步\" class=\"headerlink\" title=\"第三步:\"></a>第三步:</h1><p>就可以用了<br><img src=\"https://blog.mviai.com/images/lol/2.png\" alt></p>\n<h1 id=\"lolsk-使用\"><a href=\"#lolsk-使用\" class=\"headerlink\" title=\"lolsk 使用:\"></a>lolsk 使用:</h1><p>打开如图:<br><img src=\"https://blog.mviai.com/images/lol/3.png\" alt></p>\n<p>登入游戏:(默认每个英雄都有皮肤)<br><img src=\"https://blog.mviai.com/images/lol/4.png\" alt></p>\n<font color=\"red\"><br><strong>  切忌不能关掉,不然进去就失效,窗口缩小即可 </strong><br><strong>  切忌不能关掉,不然进去就失效,窗口缩小即可 </strong><br><strong>  切忌不能关掉,不然进去就失效,窗口缩小即可 </strong><br><strong>  切忌不能关掉,不然进去就失效,窗口缩小即可 </strong><br><br><br>如果要自定义皮肤:<br>选好 按右下角蓝色按钮激活<br><img src=\"https://blog.mviai.com/images/lol/5.png\" alt><br></font>\n"},{"title":"Jetson nano 介绍","toc":false,"date":"2019-06-10T02:52:43.000Z","_content":"\n1、官网介绍\nhttps://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-nano/\n\n![](https://blog.mviai.com/images/n1/1.webp)\n\n\n良心价，只要99美元。\n各模型跑分。\n\n\n![](https://blog.mviai.com/images/n1/2.webp)\n\n\n2、相关参数\n\n![](https://blog.mviai.com/images/n1/3.webp)\n\n\n\n跟x1对比功耗超低；\n\n![](https://blog.mviai.com/images/n1/4.webp)\n3、软件支持\n相关内容可以到官网下载\nhttps://developer.nvidia.com/embedded/downloads\n\n![](https://blog.mviai.com/images/n1/5.webp)\n\n\n有些资源估计的科学下载才行。\n国内微雪作为销售商，已经整理了资料更方便下载，百度云盘下载快很多。\nhttp://www.waveshare.net/wiki/Jetson_Nano_Developer_Kit\n\n\n![](https://blog.mviai.com/images/n1/7.webp)\n\n\n系统是Ubuntu定制版，有5g多。\n5、开箱图片\n\n![](https://blog.mviai.com/images/n1/8.webp)\n\n\n![](https://blog.mviai.com/images/n1/9.webp)\n\n\n\n做工精良，良心机。\n\n6、配件及软件准备\nJetson nano包装只有板子。\n6.1.电源\n小米充电器，5V 2A，电源线；要保证2A。有5V 2Adc口电源线亦可，但是需要设置跳线屏蔽usb供电口。\n\n![](https://blog.mviai.com/images/n1/pz.png)\n![](https://blog.mviai.com/images/n1/pz.gif)\n6.2 TF卡\n要刷系统到TF卡，最小要求16G。\nsd卡插在如图：\n![](https://blog.mviai.com/images/n1/sd.png)\n6.3 格式化软件\nhttps://www.sdcard.org/downloads/formatter/\n6.4 烧录软件\nNvidia官方推荐使用Etcher\n![](https://blog.mviai.com/images/n1/10.webp)\n\n\n支持各种平台。\n6.5 显示配件\n键盘鼠标、hdmi接口显示器等；\n7、烧录系统\n通过微雪的百度云分享下载完成后，用sdformater格式化sd卡，然后用ether烧录系统镜像。\n![](https://blog.mviai.com/images/n1/11.webp)\n![](https://blog.mviai.com/images/n1/12.webp)\n![](https://blog.mviai.com/images/n1/13.webp)\n烧录要12分钟，12g的系统镜像。\n\n\n8、启动系统\n\n\n![](https://blog.mviai.com/images/n1/14.webp)\n\n\n\n![](https://blog.mviai.com/images/n1/15.webp)\n\n\n\n\n\n\n设置完初始信息即可进入系统，跟Ubuntu操作体验一样。\n\n9、启动系统查看工作状态，温度\n```\nsudo tegrastats\nroot@jetson-desktop:~# sudo tegrastats\nRAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [1%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/125\nRAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [1%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35.5C thermal@28.5C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/125\nRAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [0%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35.5C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/111\nRAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [2%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35.5C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/104\nRAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [3%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27C PMIC@100C GPU@29C AO@34.5C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/99\nRAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [0%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@28C PMIC@100C GPU@29C AO@35C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/104\nRAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [2%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@24.5C CPU@28C PMIC@100C GPU@28.5C AO@35C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/101\nRAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [0%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35.5C thermal@28.5C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/104\nRAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [1%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@24.5C CPU@27.5C PMIC@100C GPU@28.5C AO@35C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/101\nRAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [1%@102,1%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35.5C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/104\nRAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [4%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/105\nRAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [1%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@24.5C CPU@27C PMIC@100C GPU@28.5C AO@35C thermal@28C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/104\n\n```\n开箱介绍完成。\n\n参考：https://www.jianshu.com/p/c9a7635f315c\n","source":"_posts/Nvidia-Jetson-nano-介绍.md","raw":"---\ntitle: Jetson nano 介绍\ntags:\n  - jetson nano\ncategories:\n  - 工具\n  - 嵌入式\n  - nvidia\ntoc: false\ndate: 2019-06-10 10:52:43\n---\n\n1、官网介绍\nhttps://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-nano/\n\n![](https://blog.mviai.com/images/n1/1.webp)\n\n\n良心价，只要99美元。\n各模型跑分。\n\n\n![](https://blog.mviai.com/images/n1/2.webp)\n\n\n2、相关参数\n\n![](https://blog.mviai.com/images/n1/3.webp)\n\n\n\n跟x1对比功耗超低；\n\n![](https://blog.mviai.com/images/n1/4.webp)\n3、软件支持\n相关内容可以到官网下载\nhttps://developer.nvidia.com/embedded/downloads\n\n![](https://blog.mviai.com/images/n1/5.webp)\n\n\n有些资源估计的科学下载才行。\n国内微雪作为销售商，已经整理了资料更方便下载，百度云盘下载快很多。\nhttp://www.waveshare.net/wiki/Jetson_Nano_Developer_Kit\n\n\n![](https://blog.mviai.com/images/n1/7.webp)\n\n\n系统是Ubuntu定制版，有5g多。\n5、开箱图片\n\n![](https://blog.mviai.com/images/n1/8.webp)\n\n\n![](https://blog.mviai.com/images/n1/9.webp)\n\n\n\n做工精良，良心机。\n\n6、配件及软件准备\nJetson nano包装只有板子。\n6.1.电源\n小米充电器，5V 2A，电源线；要保证2A。有5V 2Adc口电源线亦可，但是需要设置跳线屏蔽usb供电口。\n\n![](https://blog.mviai.com/images/n1/pz.png)\n![](https://blog.mviai.com/images/n1/pz.gif)\n6.2 TF卡\n要刷系统到TF卡，最小要求16G。\nsd卡插在如图：\n![](https://blog.mviai.com/images/n1/sd.png)\n6.3 格式化软件\nhttps://www.sdcard.org/downloads/formatter/\n6.4 烧录软件\nNvidia官方推荐使用Etcher\n![](https://blog.mviai.com/images/n1/10.webp)\n\n\n支持各种平台。\n6.5 显示配件\n键盘鼠标、hdmi接口显示器等；\n7、烧录系统\n通过微雪的百度云分享下载完成后，用sdformater格式化sd卡，然后用ether烧录系统镜像。\n![](https://blog.mviai.com/images/n1/11.webp)\n![](https://blog.mviai.com/images/n1/12.webp)\n![](https://blog.mviai.com/images/n1/13.webp)\n烧录要12分钟，12g的系统镜像。\n\n\n8、启动系统\n\n\n![](https://blog.mviai.com/images/n1/14.webp)\n\n\n\n![](https://blog.mviai.com/images/n1/15.webp)\n\n\n\n\n\n\n设置完初始信息即可进入系统，跟Ubuntu操作体验一样。\n\n9、启动系统查看工作状态，温度\n```\nsudo tegrastats\nroot@jetson-desktop:~# sudo tegrastats\nRAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [1%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/125\nRAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [1%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35.5C thermal@28.5C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/125\nRAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [0%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35.5C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/111\nRAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [2%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35.5C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/104\nRAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [3%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27C PMIC@100C GPU@29C AO@34.5C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/99\nRAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [0%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@28C PMIC@100C GPU@29C AO@35C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/104\nRAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [2%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@24.5C CPU@28C PMIC@100C GPU@28.5C AO@35C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/101\nRAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [0%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35.5C thermal@28.5C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/104\nRAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [1%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@24.5C CPU@27.5C PMIC@100C GPU@28.5C AO@35C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/101\nRAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [1%@102,1%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35.5C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/104\nRAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [4%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/105\nRAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [1%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@24.5C CPU@27C PMIC@100C GPU@28.5C AO@35C thermal@28C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/104\n\n```\n开箱介绍完成。\n\n参考：https://www.jianshu.com/p/c9a7635f315c\n","slug":"Nvidia-Jetson-nano-介绍","published":1,"updated":"2021-07-26T09:58:02.515Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m140007igtaefhtnl48","content":"<p>1、官网介绍<br><a href=\"https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-nano/\" target=\"_blank\" rel=\"noopener\">https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-nano/</a></p>\n<p><img src=\"https://blog.mviai.com/images/n1/1.webp\" alt></p>\n<p>良心价，只要99美元。<br>各模型跑分。</p>\n<p><img src=\"https://blog.mviai.com/images/n1/2.webp\" alt></p>\n<p>2、相关参数</p>\n<p><img src=\"https://blog.mviai.com/images/n1/3.webp\" alt></p>\n<p>跟x1对比功耗超低；</p>\n<p><img src=\"https://blog.mviai.com/images/n1/4.webp\" alt><br>3、软件支持<br>相关内容可以到官网下载<br><a href=\"https://developer.nvidia.com/embedded/downloads\" target=\"_blank\" rel=\"noopener\">https://developer.nvidia.com/embedded/downloads</a></p>\n<p><img src=\"https://blog.mviai.com/images/n1/5.webp\" alt></p>\n<p>有些资源估计的科学下载才行。<br>国内微雪作为销售商，已经整理了资料更方便下载，百度云盘下载快很多。<br><a href=\"http://www.waveshare.net/wiki/Jetson_Nano_Developer_Kit\" target=\"_blank\" rel=\"noopener\">http://www.waveshare.net/wiki/Jetson_Nano_Developer_Kit</a></p>\n<p><img src=\"https://blog.mviai.com/images/n1/7.webp\" alt></p>\n<p>系统是Ubuntu定制版，有5g多。<br>5、开箱图片</p>\n<p><img src=\"https://blog.mviai.com/images/n1/8.webp\" alt></p>\n<p><img src=\"https://blog.mviai.com/images/n1/9.webp\" alt></p>\n<p>做工精良，良心机。</p>\n<p>6、配件及软件准备<br>Jetson nano包装只有板子。<br>6.1.电源<br>小米充电器，5V 2A，电源线；要保证2A。有5V 2Adc口电源线亦可，但是需要设置跳线屏蔽usb供电口。</p>\n<p><img src=\"https://blog.mviai.com/images/n1/pz.png\" alt><br><img src=\"https://blog.mviai.com/images/n1/pz.gif\" alt><br>6.2 TF卡<br>要刷系统到TF卡，最小要求16G。<br>sd卡插在如图：<br><img src=\"https://blog.mviai.com/images/n1/sd.png\" alt><br>6.3 格式化软件<br><a href=\"https://www.sdcard.org/downloads/formatter/\" target=\"_blank\" rel=\"noopener\">https://www.sdcard.org/downloads/formatter/</a><br>6.4 烧录软件<br>Nvidia官方推荐使用Etcher<br><img src=\"https://blog.mviai.com/images/n1/10.webp\" alt></p>\n<p>支持各种平台。<br>6.5 显示配件<br>键盘鼠标、hdmi接口显示器等；<br>7、烧录系统<br>通过微雪的百度云分享下载完成后，用sdformater格式化sd卡，然后用ether烧录系统镜像。<br><img src=\"https://blog.mviai.com/images/n1/11.webp\" alt><br><img src=\"https://blog.mviai.com/images/n1/12.webp\" alt><br><img src=\"https://blog.mviai.com/images/n1/13.webp\" alt><br>烧录要12分钟，12g的系统镜像。</p>\n<p>8、启动系统</p>\n<p><img src=\"https://blog.mviai.com/images/n1/14.webp\" alt></p>\n<p><img src=\"https://blog.mviai.com/images/n1/15.webp\" alt></p>\n<p>设置完初始信息即可进入系统，跟Ubuntu操作体验一样。</p>\n<p>9、启动系统查看工作状态，温度<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo tegrastats</span><br><span class=\"line\">root@jetson-desktop:~# sudo tegrastats</span><br><span class=\"line\">RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [1%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/125</span><br><span class=\"line\">RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [1%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35.5C thermal@28.5C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/125</span><br><span class=\"line\">RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [0%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35.5C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/111</span><br><span class=\"line\">RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [2%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35.5C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/104</span><br><span class=\"line\">RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [3%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27C PMIC@100C GPU@29C AO@34.5C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/99</span><br><span class=\"line\">RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [0%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@28C PMIC@100C GPU@29C AO@35C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/104</span><br><span class=\"line\">RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [2%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@24.5C CPU@28C PMIC@100C GPU@28.5C AO@35C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/101</span><br><span class=\"line\">RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [0%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35.5C thermal@28.5C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/104</span><br><span class=\"line\">RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [1%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@24.5C CPU@27.5C PMIC@100C GPU@28.5C AO@35C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/101</span><br><span class=\"line\">RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [1%@102,1%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35.5C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/104</span><br><span class=\"line\">RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [4%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/105</span><br><span class=\"line\">RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [1%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@24.5C CPU@27C PMIC@100C GPU@28.5C AO@35C thermal@28C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/104</span><br></pre></td></tr></table></figure></p>\n<p>开箱介绍完成。</p>\n<p>参考：<a href=\"https://www.jianshu.com/p/c9a7635f315c\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/c9a7635f315c</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>1、官网介绍<br><a href=\"https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-nano/\" target=\"_blank\" rel=\"noopener\">https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-nano/</a></p>\n<p><img src=\"https://blog.mviai.com/images/n1/1.webp\" alt></p>\n<p>良心价，只要99美元。<br>各模型跑分。</p>\n<p><img src=\"https://blog.mviai.com/images/n1/2.webp\" alt></p>\n<p>2、相关参数</p>\n<p><img src=\"https://blog.mviai.com/images/n1/3.webp\" alt></p>\n<p>跟x1对比功耗超低；</p>\n<p><img src=\"https://blog.mviai.com/images/n1/4.webp\" alt><br>3、软件支持<br>相关内容可以到官网下载<br><a href=\"https://developer.nvidia.com/embedded/downloads\" target=\"_blank\" rel=\"noopener\">https://developer.nvidia.com/embedded/downloads</a></p>\n<p><img src=\"https://blog.mviai.com/images/n1/5.webp\" alt></p>\n<p>有些资源估计的科学下载才行。<br>国内微雪作为销售商，已经整理了资料更方便下载，百度云盘下载快很多。<br><a href=\"http://www.waveshare.net/wiki/Jetson_Nano_Developer_Kit\" target=\"_blank\" rel=\"noopener\">http://www.waveshare.net/wiki/Jetson_Nano_Developer_Kit</a></p>\n<p><img src=\"https://blog.mviai.com/images/n1/7.webp\" alt></p>\n<p>系统是Ubuntu定制版，有5g多。<br>5、开箱图片</p>\n<p><img src=\"https://blog.mviai.com/images/n1/8.webp\" alt></p>\n<p><img src=\"https://blog.mviai.com/images/n1/9.webp\" alt></p>\n<p>做工精良，良心机。</p>\n<p>6、配件及软件准备<br>Jetson nano包装只有板子。<br>6.1.电源<br>小米充电器，5V 2A，电源线；要保证2A。有5V 2Adc口电源线亦可，但是需要设置跳线屏蔽usb供电口。</p>\n<p><img src=\"https://blog.mviai.com/images/n1/pz.png\" alt><br><img src=\"https://blog.mviai.com/images/n1/pz.gif\" alt><br>6.2 TF卡<br>要刷系统到TF卡，最小要求16G。<br>sd卡插在如图：<br><img src=\"https://blog.mviai.com/images/n1/sd.png\" alt><br>6.3 格式化软件<br><a href=\"https://www.sdcard.org/downloads/formatter/\" target=\"_blank\" rel=\"noopener\">https://www.sdcard.org/downloads/formatter/</a><br>6.4 烧录软件<br>Nvidia官方推荐使用Etcher<br><img src=\"https://blog.mviai.com/images/n1/10.webp\" alt></p>\n<p>支持各种平台。<br>6.5 显示配件<br>键盘鼠标、hdmi接口显示器等；<br>7、烧录系统<br>通过微雪的百度云分享下载完成后，用sdformater格式化sd卡，然后用ether烧录系统镜像。<br><img src=\"https://blog.mviai.com/images/n1/11.webp\" alt><br><img src=\"https://blog.mviai.com/images/n1/12.webp\" alt><br><img src=\"https://blog.mviai.com/images/n1/13.webp\" alt><br>烧录要12分钟，12g的系统镜像。</p>\n<p>8、启动系统</p>\n<p><img src=\"https://blog.mviai.com/images/n1/14.webp\" alt></p>\n<p><img src=\"https://blog.mviai.com/images/n1/15.webp\" alt></p>\n<p>设置完初始信息即可进入系统，跟Ubuntu操作体验一样。</p>\n<p>9、启动系统查看工作状态，温度<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo tegrastats</span><br><span class=\"line\">root@jetson-desktop:~# sudo tegrastats</span><br><span class=\"line\">RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [1%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/125</span><br><span class=\"line\">RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [1%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35.5C thermal@28.5C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/125</span><br><span class=\"line\">RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [0%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35.5C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/111</span><br><span class=\"line\">RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [2%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35.5C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/104</span><br><span class=\"line\">RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [3%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27C PMIC@100C GPU@29C AO@34.5C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/99</span><br><span class=\"line\">RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [0%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@28C PMIC@100C GPU@29C AO@35C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/104</span><br><span class=\"line\">RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [2%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@24.5C CPU@28C PMIC@100C GPU@28.5C AO@35C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/101</span><br><span class=\"line\">RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [0%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35.5C thermal@28.5C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/104</span><br><span class=\"line\">RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [1%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@24.5C CPU@27.5C PMIC@100C GPU@28.5C AO@35C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/101</span><br><span class=\"line\">RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [1%@102,1%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35.5C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/104</span><br><span class=\"line\">RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [4%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/105</span><br><span class=\"line\">RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [1%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@24.5C CPU@27C PMIC@100C GPU@28.5C AO@35C thermal@28C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/104</span><br></pre></td></tr></table></figure></p>\n<p>开箱介绍完成。</p>\n<p>参考：<a href=\"https://www.jianshu.com/p/c9a7635f315c\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/c9a7635f315c</a></p>\n"},{"title":"WordPress页面，分页函数调用，主题函数调用，模板函数调用","url":"137.html","id":"137","date":"2018-04-08T18:30:26.000Z","_content":"\n*   WordPress页面，分页函数调用，主题函数调用，模板函数调用\n    --------------------------------\n    \n\n*   [1描述](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.8F.8F.E8.BF.B0)\n*   [2与WP_Query的互动](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E4.B8.8EWP_Query.E7.9A.84.E4.BA.92.E5.8A.A8)\n*   [3用法](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E7.94.A8.E6.B3.95)\n*   [4方法和属性](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.96.B9.E6.B3.95.E5.92.8C.E5.B1.9E.E6.80.A7)\n    *   [4.1属性](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E5.B1.9E.E6.80.A7)\n    *   [4.2方法](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.96.B9.E6.B3.95)\n*   [5参数](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E5.8F.82.E6.95.B0)\n    *   [5.1作者](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E4.BD.9C.E8.80.85)\n    *   [5.2分类目录](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E5.88.86.E7.B1.BB.E7.9B.AE.E5.BD.95)\n    *   [5.3标签](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.A0.87.E7.AD.BE)\n    *   [5.4自定义分类法](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E8.87.AA.E5.AE.9A.E4.B9.89.E5.88.86.E7.B1.BB.E6.B3.95)\n    *   [5.5搜索](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.90.9C.E7.B4.A2)\n    *   [5.6文章＆页面](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.96.87.E7.AB.A0_.26_.E9.A1.B5.E9.9D.A2)\n    *   [5.7文章类型](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.96.87.E7.AB.A0.E7.B1.BB.E5.9E.8B)\n    *   [5.8文章状态](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.96.87.E7.AB.A0.E7.8A.B6.E6.80.81)\n    *   [5.9分页](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E5.88.86.E9.A1.B5)\n    *   [5.10排序](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.8E.92.E5.BA.8F)\n    *   [5.11置顶文章](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E7.BD.AE.E9.A1.B6.E6.96.87.E7.AB.A0)\n    *   [5.12时间](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.97.B6.E9.97.B4)\n    *   [5.13自定义字段](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E8.87.AA.E5.AE.9A.E4.B9.89.E5.AD.97.E6.AE.B5)\n    *   [5.14权限](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.9D.83.E9.99.90)\n    *   [5.15缓存](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E7.BC.93.E5.AD.98)\n    *   [5.16返回字段](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E8.BF.94.E5.9B.9E.E5.AD.97.E6.AE.B5)\n\n[官网法典](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.96.87.E7.AB.A0_.26_.E9.A1.B5.E9.9D.A2)\n","source":"_posts/WordPress页面，分页函数调用，主题函数调用，模板函数调用.md","raw":"---\ntitle: WordPress页面，分页函数调用，主题函数调用，模板函数调用\ntags:\n  - wordpress\nurl: 137.html\nid: 137\ncategories:\n  - 网站\n  - wordpress\ndate: 2018-04-09 02:30:26\n\n---\n\n*   WordPress页面，分页函数调用，主题函数调用，模板函数调用\n    --------------------------------\n    \n\n*   [1描述](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.8F.8F.E8.BF.B0)\n*   [2与WP_Query的互动](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E4.B8.8EWP_Query.E7.9A.84.E4.BA.92.E5.8A.A8)\n*   [3用法](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E7.94.A8.E6.B3.95)\n*   [4方法和属性](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.96.B9.E6.B3.95.E5.92.8C.E5.B1.9E.E6.80.A7)\n    *   [4.1属性](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E5.B1.9E.E6.80.A7)\n    *   [4.2方法](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.96.B9.E6.B3.95)\n*   [5参数](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E5.8F.82.E6.95.B0)\n    *   [5.1作者](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E4.BD.9C.E8.80.85)\n    *   [5.2分类目录](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E5.88.86.E7.B1.BB.E7.9B.AE.E5.BD.95)\n    *   [5.3标签](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.A0.87.E7.AD.BE)\n    *   [5.4自定义分类法](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E8.87.AA.E5.AE.9A.E4.B9.89.E5.88.86.E7.B1.BB.E6.B3.95)\n    *   [5.5搜索](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.90.9C.E7.B4.A2)\n    *   [5.6文章＆页面](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.96.87.E7.AB.A0_.26_.E9.A1.B5.E9.9D.A2)\n    *   [5.7文章类型](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.96.87.E7.AB.A0.E7.B1.BB.E5.9E.8B)\n    *   [5.8文章状态](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.96.87.E7.AB.A0.E7.8A.B6.E6.80.81)\n    *   [5.9分页](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E5.88.86.E9.A1.B5)\n    *   [5.10排序](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.8E.92.E5.BA.8F)\n    *   [5.11置顶文章](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E7.BD.AE.E9.A1.B6.E6.96.87.E7.AB.A0)\n    *   [5.12时间](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.97.B6.E9.97.B4)\n    *   [5.13自定义字段](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E8.87.AA.E5.AE.9A.E4.B9.89.E5.AD.97.E6.AE.B5)\n    *   [5.14权限](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.9D.83.E9.99.90)\n    *   [5.15缓存](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E7.BC.93.E5.AD.98)\n    *   [5.16返回字段](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E8.BF.94.E5.9B.9E.E5.AD.97.E6.AE.B5)\n\n[官网法典](https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.96.87.E7.AB.A0_.26_.E9.A1.B5.E9.9D.A2)\n","slug":"WordPress页面，分页函数调用，主题函数调用，模板函数调用","published":1,"updated":"2021-07-26T09:58:02.569Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m160009igtaekqftsha","content":"<ul>\n<li><h2 id=\"WordPress页面，分页函数调用，主题函数调用，模板函数调用\"><a href=\"#WordPress页面，分页函数调用，主题函数调用，模板函数调用\" class=\"headerlink\" title=\"WordPress页面，分页函数调用，主题函数调用，模板函数调用\"></a>WordPress页面，分页函数调用，主题函数调用，模板函数调用</h2></li>\n</ul>\n<ul>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.8F.8F.E8.BF.B0\" target=\"_blank\" rel=\"noopener\">1描述</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E4.B8.8EWP_Query.E7.9A.84.E4.BA.92.E5.8A.A8\" target=\"_blank\" rel=\"noopener\">2与WP_Query的互动</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E7.94.A8.E6.B3.95\" target=\"_blank\" rel=\"noopener\">3用法</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.96.B9.E6.B3.95.E5.92.8C.E5.B1.9E.E6.80.A7\" target=\"_blank\" rel=\"noopener\">4方法和属性</a><ul>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E5.B1.9E.E6.80.A7\" target=\"_blank\" rel=\"noopener\">4.1属性</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.96.B9.E6.B3.95\" target=\"_blank\" rel=\"noopener\">4.2方法</a></li>\n</ul>\n</li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E5.8F.82.E6.95.B0\" target=\"_blank\" rel=\"noopener\">5参数</a><ul>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E4.BD.9C.E8.80.85\" target=\"_blank\" rel=\"noopener\">5.1作者</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E5.88.86.E7.B1.BB.E7.9B.AE.E5.BD.95\" target=\"_blank\" rel=\"noopener\">5.2分类目录</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.A0.87.E7.AD.BE\" target=\"_blank\" rel=\"noopener\">5.3标签</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E8.87.AA.E5.AE.9A.E4.B9.89.E5.88.86.E7.B1.BB.E6.B3.95\" target=\"_blank\" rel=\"noopener\">5.4自定义分类法</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.90.9C.E7.B4.A2\" target=\"_blank\" rel=\"noopener\">5.5搜索</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.96.87.E7.AB.A0_.26_.E9.A1.B5.E9.9D.A2\" target=\"_blank\" rel=\"noopener\">5.6文章＆页面</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.96.87.E7.AB.A0.E7.B1.BB.E5.9E.8B\" target=\"_blank\" rel=\"noopener\">5.7文章类型</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.96.87.E7.AB.A0.E7.8A.B6.E6.80.81\" target=\"_blank\" rel=\"noopener\">5.8文章状态</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E5.88.86.E9.A1.B5\" target=\"_blank\" rel=\"noopener\">5.9分页</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.8E.92.E5.BA.8F\" target=\"_blank\" rel=\"noopener\">5.10排序</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E7.BD.AE.E9.A1.B6.E6.96.87.E7.AB.A0\" target=\"_blank\" rel=\"noopener\">5.11置顶文章</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.97.B6.E9.97.B4\" target=\"_blank\" rel=\"noopener\">5.12时间</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E8.87.AA.E5.AE.9A.E4.B9.89.E5.AD.97.E6.AE.B5\" target=\"_blank\" rel=\"noopener\">5.13自定义字段</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.9D.83.E9.99.90\" target=\"_blank\" rel=\"noopener\">5.14权限</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E7.BC.93.E5.AD.98\" target=\"_blank\" rel=\"noopener\">5.15缓存</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E8.BF.94.E5.9B.9E.E5.AD.97.E6.AE.B5\" target=\"_blank\" rel=\"noopener\">5.16返回字段</a></li>\n</ul>\n</li>\n</ul>\n<p><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.96.87.E7.AB.A0_.26_.E9.A1.B5.E9.9D.A2\" target=\"_blank\" rel=\"noopener\">官网法典</a></p>\n","site":{"data":{}},"excerpt":"","more":"<ul>\n<li><h2 id=\"WordPress页面，分页函数调用，主题函数调用，模板函数调用\"><a href=\"#WordPress页面，分页函数调用，主题函数调用，模板函数调用\" class=\"headerlink\" title=\"WordPress页面，分页函数调用，主题函数调用，模板函数调用\"></a>WordPress页面，分页函数调用，主题函数调用，模板函数调用</h2></li>\n</ul>\n<ul>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.8F.8F.E8.BF.B0\" target=\"_blank\" rel=\"noopener\">1描述</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E4.B8.8EWP_Query.E7.9A.84.E4.BA.92.E5.8A.A8\" target=\"_blank\" rel=\"noopener\">2与WP_Query的互动</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E7.94.A8.E6.B3.95\" target=\"_blank\" rel=\"noopener\">3用法</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.96.B9.E6.B3.95.E5.92.8C.E5.B1.9E.E6.80.A7\" target=\"_blank\" rel=\"noopener\">4方法和属性</a><ul>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E5.B1.9E.E6.80.A7\" target=\"_blank\" rel=\"noopener\">4.1属性</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.96.B9.E6.B3.95\" target=\"_blank\" rel=\"noopener\">4.2方法</a></li>\n</ul>\n</li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E5.8F.82.E6.95.B0\" target=\"_blank\" rel=\"noopener\">5参数</a><ul>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E4.BD.9C.E8.80.85\" target=\"_blank\" rel=\"noopener\">5.1作者</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E5.88.86.E7.B1.BB.E7.9B.AE.E5.BD.95\" target=\"_blank\" rel=\"noopener\">5.2分类目录</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.A0.87.E7.AD.BE\" target=\"_blank\" rel=\"noopener\">5.3标签</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E8.87.AA.E5.AE.9A.E4.B9.89.E5.88.86.E7.B1.BB.E6.B3.95\" target=\"_blank\" rel=\"noopener\">5.4自定义分类法</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.90.9C.E7.B4.A2\" target=\"_blank\" rel=\"noopener\">5.5搜索</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.96.87.E7.AB.A0_.26_.E9.A1.B5.E9.9D.A2\" target=\"_blank\" rel=\"noopener\">5.6文章＆页面</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.96.87.E7.AB.A0.E7.B1.BB.E5.9E.8B\" target=\"_blank\" rel=\"noopener\">5.7文章类型</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.96.87.E7.AB.A0.E7.8A.B6.E6.80.81\" target=\"_blank\" rel=\"noopener\">5.8文章状态</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E5.88.86.E9.A1.B5\" target=\"_blank\" rel=\"noopener\">5.9分页</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.8E.92.E5.BA.8F\" target=\"_blank\" rel=\"noopener\">5.10排序</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E7.BD.AE.E9.A1.B6.E6.96.87.E7.AB.A0\" target=\"_blank\" rel=\"noopener\">5.11置顶文章</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.97.B6.E9.97.B4\" target=\"_blank\" rel=\"noopener\">5.12时间</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E8.87.AA.E5.AE.9A.E4.B9.89.E5.AD.97.E6.AE.B5\" target=\"_blank\" rel=\"noopener\">5.13自定义字段</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.9D.83.E9.99.90\" target=\"_blank\" rel=\"noopener\">5.14权限</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E7.BC.93.E5.AD.98\" target=\"_blank\" rel=\"noopener\">5.15缓存</a></li>\n<li><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E8.BF.94.E5.9B.9E.E5.AD.97.E6.AE.B5\" target=\"_blank\" rel=\"noopener\">5.16返回字段</a></li>\n</ul>\n</li>\n</ul>\n<p><a href=\"https://codex.wordpress.org/zh-cn:Class_Reference/WP_Query#.E6.96.87.E7.AB.A0_.26_.E9.A1.B5.E9.9D.A2\" target=\"_blank\" rel=\"noopener\">官网法典</a></p>\n"},{"title":"P图(无缝克隆)","toc":false,"date":"2020-03-08T17:58:44.000Z","_content":"\n# 无缝克隆是什么\n两张图片合在一起,一般有以下三种方式\n-\t新手方式\n-\t![image.png](https://blog.mviai.com/images/Fs9r1gVdpyhIPnBve931nF2gPvbb)\n-\tPhotoshop(遮罩)\n-\t![image.png](https://blog.mviai.com/images/FnwLXFbvhoNJfYZOpkMRLqslvIzb)\n-\topencv方式\n-\t![image.png]https://blog.mviai.com/images/FprK2rkiGOSWO25lKuShhVluN77_)\n\n\n# 原理\nOpenCV中的无缝克隆是SIGGRAPH 2003有影响力的论文的实现，该论文名为Patrick Poez，Michel Gangnet和Andrew Blake，名称为[“ Poisson Image Editing”](http://www.irisa.fr/vista/Papers/2003_siggraph_perez.pdf)。\n\n现在我们知道，如果使用精心创建的遮罩将源图像（飞机）的强度（RGB值）与目标图像（天空）混合，我们将获得如图3所示的结果。本文的中心思想是使用图像梯度而不是图像强度可以产生更真实的结果。无缝克隆后，蒙版区域中结果图像的强度与蒙版区域中源区域的强度不同。相反，结果图像在遮罩区域中的梯度与源区域在遮罩区域中的梯度大约相同。另外，在被遮蔽区域的边界处的结果图像的强度与目的地图像（天空）的强度相同。\n\n作者表明，这是通过求解泊松方程来完成的，因此可以解决论文的标题-泊松图像编辑。该论文的理论和实现细节实际上非常酷.\n\n\n\n# 主要函数\n```python\noutput = cv2.seamlessClone(src, dst, mask, center, flags)\n```\n\n```c++\nseamlessClone(Mat src, Mat dst, Mat mask, Point center, Mat output, int flags)\n\n```\n\nsrc\t        将被复制到目标图像的源图像。在我们的示例中是飞机。\ndst\t        源映像将被克隆到的目标映像。在我们的示例中，它是天空图像。\nmask\t要克隆的对象周围的粗糙蒙版。这应该是源图像的大小。如果您很懒，请将其设置为全白图像！\ncenter \t源图像中心在目标图像中的位置。\nflags\t当前起作用的两个标志是NORMAL_CLONE和MIXED_CLONE。正常克隆和无缝克隆。\noutput\t输出结果图像。\n\n\n# 基础版\n```python\n# 基本\n\n# 导入相关的包\nimport cv2\nimport numpy as np \n\n# 读入图片\nsrc = cv2.imread(\"images/airplane.jpg\")\ndst = cv2.imread(\"images/sky.jpg\")\n\n\n#在飞机周围创建一个粗糙的mask。\nsrc_mask = np.zeros(src.shape, src.dtype)\n#将遮罩定义为封闭的多边形\npoly = np.array([ [4,80], [30,54], [151,63], [254,37], [298,90], [272,134], [43,122] ], np.int32)\n#函数cv :: fillPoly填充由多个多边形轮廓所界定的区域。该函数可以填充。复杂区域，例如，带有孔的区域，具有自相交的轮廓（它们的某些部分）等等\ncv2.fillPoly(src_mask, [poly], (255, 255, 255))\n\n# 飞机中心的位置\ncenter = (800,100)\n\n# 完成克隆\noutput = cv2.seamlessClone(src, dst, src_mask, center, cv2.NORMAL_CLONE)\n\n# 保存结果\ncv2.imwrite(\"images/opencv-seamless-cloning-example.jpg\", output);\n\n\n\n```\n```C++\n//# 基本\n//\n//# 导入相关的包\n\n#include \"opencv2/opencv.hpp\"\n\nusing namespace cv;\nusing namespace std;\n\nint main( int argc, char** argv )\n{\n    // 读入图片\n    Mat src = imread(\"../images/airplane.jpg\");\n    Mat dst = imread(\"../images/sky.jpg\");\n    \n\n    // 在飞机周围创建一个粗糙的mask。\n    Mat src_mask = Mat::zeros(src.rows, src.cols, src.depth());\n    \n    // 将遮罩定义为封闭的多边形\n    Point poly[1][7];\n    poly[0][0] = Point(4, 80);\n    poly[0][1] = Point(30, 54);\n    poly[0][2] = Point(151,63);\n    poly[0][3] = Point(254,37);\n    poly[0][4] = Point(298,90);\n    poly[0][5] = Point(272,134);\n    poly[0][6] = Point(43,122);\n    \n    const Point* polygons[1] = { poly[0] };\n    int num_points[] = { 7 };\n    \n    // 通过填充多边形来创建蒙版n\n    fillPoly(src_mask, polygons, num_points, 1, Scalar(255,255,255));\n    \n    // 飞机中心的位置\n    Point center(800,100);\n    \n    // 将src无缝克隆到dst中，然后将结果放入输出中\n    Mat output;\n    seamlessClone(src, dst, src_mask, center, output, NORMAL_CLONE);\n    \n    // 保存结果\n    imwrite(\"../images/opencv-seamless-cloning-example.jpg\", output);\n    \n}\n\n\n```\n\n![image.png](https://blog.mviai.com/images/Fts1LG2qSBpltPS2Tr6h27YVPG0Q)\n\n\n# 高级版\n```python\n\nimport cv2\nimport numpy as np\n\n#读取图像\nim = cv2.imread(\"images/wood-texture.jpg\")\nobj= cv2.imread(\"images/iloveyouticket.jpg\")\n\n# 创建全白图像\nmask = 255 * np.ones(obj.shape, obj.dtype)\n\n# dst中src中心的位置\nwidth, height, channels = im.shape\ncenter = (int(height/2), int(width/2))\n\n#将src无缝克隆到dst中，然后将结果放入输出中\nnormal_clone = cv2.seamlessClone(obj, im, mask, center, cv2.NORMAL_CLONE)\nmixed_clone = cv2.seamlessClone(obj, im, mask, center, cv2.MIXED_CLONE)\n\n# 写入结果\ncv2.imwrite(\"images/opencv-normal-clone-example.jpg\", normal_clone)\ncv2.imwrite(\"images/opencv-mixed-clone-example.jpg\", mixed_clone)\n\n\n```\n\n```c++\n\n#include \"opencv2/opencv.hpp\"\n\nusing namespace cv;\nusing namespace std;\n\nint main( int argc, char** argv )\n{\n    // 读取图像：src图像将被克隆到dst中\n    Mat src = imread(\"images/iloveyouticket.jpg\");\n    Mat dst = imread(\"images/wood-texture.jpg\");\n    \n\n    // 创建全白mask\n    Mat src_mask = 255 * Mat::ones(src.rows, src.cols, src.depth());\n    \n    \n    // dst中src中心的位置\n    Point center(dst.cols/2,dst.rows/2);\n    \n    // 将src无缝克隆到dst中，然后将结果放入输出中\n    Mat normal_clone;\n    Mat mixed_clone;\n    \n    seamlessClone(src, dst, src_mask, center, normal_clone, NORMAL_CLONE);\n    seamlessClone(src, dst, src_mask, center, mixed_clone, MIXED_CLONE);\n    \n    // 写入图像\n    imwrite(\"images/opencv-normal-clone-example.jpg\", normal_clone);\n    imwrite(\"images/opencv-mixed-clone-example.jpg\", mixed_clone);\n    \n    \n}\n\n\n```\n![image.png](https://blog.mviai.com/images/FgCBXytyYenRRRGBK70Sz1RTUk6Z)\n![image.png](https://blog.mviai.com/images/FgzxGclKjyu_Cq3m436y2fWbrZ7I)\n![image.png](https://blog.mviai.com/images/FqHI0kWMsDBdLYrfsI_R4r6ERFvs)\n\n# 大师版\n\n```python\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n# 读取图片\nA = cv2.imread(\"images/man.jpg\")\nB = cv2.imread(\"images/woman.jpg\")\n\n# 转换成浮点数\nA = np.float32(A) / 255.0\nB = np.float32(B) / 255.0\n\n#\n# 在A中的人脸周围创建一个粗糙的mask\nmask = np.zeros(A.shape,A.dtype)\npolygon = np.array([[164,226], [209,225], [238,188], [252,133], [248,75], [240,29], [192,15], [150,15], [100,70], [106,133], [123,194] ], np.int32)\ncv2.fillPoly(mask, [polygon], (255, 255, 255))\n# 将mask转换浮点数\nmask = np.float32(mask) / 255.0\n\n# 浮点数<1.0 就乘以获取男女mask的加权平均值\nmask = mask * 0.7 # 0.7 for man, 0.3 for woman\n\n# 调整大小为 2^（金字塔中的级别）的倍数，因此在本例中为32\nA = cv2.resize(A,(384,352))\n\n# B的mask的大小应与A相同，以便以后进行乘法和加法运算\nB = cv2.resize(B,(A.shape[1],A.shape[0]))\nmask = cv2.resize(mask,(A.shape[1],A.shape[0]))\n\n# 从原始图像开始（金字塔底）\nguassianA = A.copy()\nguassianB = B.copy()\nguassianMask = mask.copy()\ncv2.imshow('guass',guassianMask)\n\n# 两种图像的拉普拉斯金字塔相结合\ncombinedLaplacianPyramids = []\n\n# 金字塔中的级别数，尝试使用不同的值，请注意图像大小\nmaxIterations = 5\n\nfor i in range(maxIterations):\n\n\t# 计算两个图像的拉普拉斯金字塔\n\tlaplacianA = cv2.subtract(guassianA, cv2.pyrUp(cv2.pyrDown(guassianA)))\n\tlaplacianB = cv2.subtract(guassianB, cv2.pyrUp(cv2.pyrDown(guassianB)))\n\n\t# 结合两个拉普拉斯金字塔，将加权平均与mask金字塔金字塔相结合\n\tcombinedLaplacian = guassianMask * laplacianA + (1.0 - guassianMask) * laplacianB\n\n\t# 在合并的拉普拉斯金字塔列表的开头添加CombinedLaplacian\n\tcombinedLaplacianPyramids.insert(0,combinedLaplacian)\n\n\t# 更新高斯金字塔以进行下一次迭代\n\tguassianA = cv2.pyrDown(guassianA)\n\tguassianB = cv2.pyrDown(guassianB)\n\tguassianMask = cv2.pyrDown(guassianMask)\n\n# 添加拉普拉斯金字塔的最后一个组合（金字塔的最高层）\nlastCombined = guassianMask * guassianA + (1.0 - guassianMask) * guassianB\ncombinedLaplacianPyramids.insert(0,lastCombined)\n\n# 重建影像\nblendedImage = combinedLaplacianPyramids[0]\nfor i in range(1,len(combinedLaplacianPyramids)):\n    # upSample并添加到下一个级别\n    blendedImage = cv2.pyrUp(blendedImage)\n    blendedImage = cv2.add(blendedImage, combinedLaplacianPyramids[i])\n\ncv2.imshow('Blended',blendedImage)\n\n# 直接融合两个图像进行比较\ndirectCombination = mask * A + (1.0 - mask) * B\ncv2.imshow('Direct combination',directCombination)\n\ncv2.waitKey(0)\n\n```\n\n```c++\n\n\n#include \"opencv2/opencv.hpp\"\n\nusing namespace cv;\nusing namespace std;\n\nvoid getLaplacianPyramid(Mat& guassianPyramid, Mat& laplacianPyramid){\n    // 从高斯金字塔计算拉普拉斯金字塔\n    Mat downSampled;\n    pyrDown(guassianPyramid,downSampled);\n\n    // 上采样下采样\n    Mat blurred;\n    pyrUp(downSampled,blurred);\n\n    subtract(guassianPyramid, blurred, laplacianPyramid);\n\n}\n\nvoid combineImages(Mat& A, Mat& B, Mat& mask, Mat& destination){\n    \n    destination = Mat::zeros(A.rows, A.cols, CV_32FC3);\n    \n    // 目的是求A和B的加权总和，分别具有权重掩码和1-掩码\n    for(int y = 0; y < A.rows; y++)\n    {\n        for(int x = 0; x < A.cols; x++)\n        {   \n            Vec3f a = A.at<Vec3f>(Point(x,y));\n            Vec3f b = B.at<Vec3f>(Point(x,y));\n            Vec3f m = mask.at<Vec3f>(Point(x,y));\n            \n            float b_ = a[0]*m[0]+(1-m[0])*b[0];\n            float g_ = a[1]*m[1]+(1-m[1])*b[1];\n            float r_ = a[2]*m[2]+(1-m[2])*b[2];\n\n            destination.at<Vec3f>(y,x)[0] = b_;\n            destination.at<Vec3f>(y,x)[1] = g_;\n            destination.at<Vec3f>(y,x)[2] = r_;\n        }\n    }\n}\n\nint main( int argc, char** argv )\n{\n    // 读取图片\n    Mat A = imread(\"images/man.jpg\");\n    Mat B = imread(\"images/woman.jpg\");\n\n    // 转换成浮点数\n    A.convertTo(A, CV_32FC3, 1/255.0);\n    B.convertTo(B, CV_32FC3, 1/255.0);\n\n    //在A的人脸周围创建一个粗糙的mask。\n    Mat mask = Mat::zeros(A.rows, A.cols, CV_8UC3);\n\n    // 创建飞机的边缘点\n    Point points[11];\n    points[0] = Point(164,226);\n    points[1] = Point(209,225);\n    points[2] = Point(238,188);\n    points[3] = Point(252,133);\n    points[4] = Point(248,75);\n    points[5] = Point(240,29);\n    points[6] = Point(192,15);\n    points[7] = Point(150,15);\n    points[8] = Point(100,70);\n    points[9] = Point(106,133);\n    points[10] = Point(123,194);\n\n    const Point* polygon[1] = {points}; //构成点数组\n    int npt[] = {11}; // 点数组的长度\n    \n    //填充由点形成的多边形\n    fillPoly(mask, polygon, npt, 1, Scalar(255, 255, 255));\n\n    // 转换成浮点数\n    mask.convertTo(mask, CV_32FC3, 1/255.0);\n\n    // 用 浮点数<1.0 乘以获取男女面部的加权平均值\n    mask = mask * 0.7;\n\n    // 调整大小为2^（金字塔中的级别）的倍数，因此在本例中为32\n    resize(A, A, Size(384,352));\n\n    //B mask的大小应与A相同，以便以后进行乘法和加法运算\n    resize(B, B, A.size());\n    resize(mask, mask, A.size());\n\n    //从原始图像开始（金字塔底）\n    Mat guassianA = A.clone();\n    Mat guassianB = B.clone();\n    Mat guassianMask = mask.clone();\n\n    // 金字塔中的级别数，尝试使用不同的值。注意图像尺寸\n    int maxIterations = 2;\n\n    // 两种图像的组合拉普拉斯金字塔\n    vector<Mat> combinedLaplacianPyramids;\n\n    for (int i = 0; i < maxIterations; i++){\n        // 计算A的拉普拉斯金字塔\n        Mat laplacianA;\n        getLaplacianPyramid(guassianA,laplacianA);\n\n        // 计算B的拉普拉斯金字塔\n        Mat laplacianB;\n        getLaplacianPyramid(guassianB,laplacianB);\n\n        // 结合拉普拉斯金字塔\n        Mat combinedLaplacian;\n        combineImages(laplacianA, laplacianB, guassianMask, combinedLaplacian);\n \n        //在合并的拉普拉斯金字塔列表的开头插入combinedLaplacian\n        combinedLaplacianPyramids.insert(combinedLaplacianPyramids.begin(),combinedLaplacian);\n\n        // 更新高斯金字塔以进行下一次迭代\n        pyrDown(guassianA,guassianA);\n        pyrDown(guassianB,guassianB);\n        pyrDown(guassianMask,guassianMask);\n\n    }\n\n    //合并最后一个guassian（拉普拉斯金字塔的顶层与guassian的金字塔相同）\n    Mat lastCombined;\n    combineImages(guassianA, guassianB, guassianMask, lastCombined);\n\n    // 在合并的拉普拉斯金字塔列表的开头插入lastCombined\n    combinedLaplacianPyramids.insert(combinedLaplacianPyramids.begin(),lastCombined);\n\n    // 重建影像\n    Mat blendedImage = combinedLaplacianPyramids[0];\n\n    for (int i = 1; i < combinedLaplacianPyramids.size(); i++){\n        // upSample并添加到下一个级别\n        pyrUp(blendedImage,blendedImage);\n        add(blendedImage, combinedLaplacianPyramids[i],blendedImage);\n    }\n\n    // 将混合图像放回原始位置的天空图像\n    imshow(\"blended\",blendedImage);\n\n    // 将混合图像放回原始位置的天空图像\n    Mat directCombined;\n    combineImages(A, B, mask, directCombined);\n    imshow(\"directCombined\",directCombined);\n    waitKey(0);\n\n\n    return 0;\n}\n\n\n```\n![image.png](https://blog.mviai.com/images/FmB86oMyDHvbEWkBhIR11rOqea_E)","source":"_posts/P图-无缝克隆.md","raw":"---\ntitle: P图(无缝克隆)\ntags:\n  - cv\ncategories:\n  - 框架\n  - opencv\ntoc: false\ndate: 2020-03-09 01:58:44\n---\n\n# 无缝克隆是什么\n两张图片合在一起,一般有以下三种方式\n-\t新手方式\n-\t![image.png](https://blog.mviai.com/images/Fs9r1gVdpyhIPnBve931nF2gPvbb)\n-\tPhotoshop(遮罩)\n-\t![image.png](https://blog.mviai.com/images/FnwLXFbvhoNJfYZOpkMRLqslvIzb)\n-\topencv方式\n-\t![image.png]https://blog.mviai.com/images/FprK2rkiGOSWO25lKuShhVluN77_)\n\n\n# 原理\nOpenCV中的无缝克隆是SIGGRAPH 2003有影响力的论文的实现，该论文名为Patrick Poez，Michel Gangnet和Andrew Blake，名称为[“ Poisson Image Editing”](http://www.irisa.fr/vista/Papers/2003_siggraph_perez.pdf)。\n\n现在我们知道，如果使用精心创建的遮罩将源图像（飞机）的强度（RGB值）与目标图像（天空）混合，我们将获得如图3所示的结果。本文的中心思想是使用图像梯度而不是图像强度可以产生更真实的结果。无缝克隆后，蒙版区域中结果图像的强度与蒙版区域中源区域的强度不同。相反，结果图像在遮罩区域中的梯度与源区域在遮罩区域中的梯度大约相同。另外，在被遮蔽区域的边界处的结果图像的强度与目的地图像（天空）的强度相同。\n\n作者表明，这是通过求解泊松方程来完成的，因此可以解决论文的标题-泊松图像编辑。该论文的理论和实现细节实际上非常酷.\n\n\n\n# 主要函数\n```python\noutput = cv2.seamlessClone(src, dst, mask, center, flags)\n```\n\n```c++\nseamlessClone(Mat src, Mat dst, Mat mask, Point center, Mat output, int flags)\n\n```\n\nsrc\t        将被复制到目标图像的源图像。在我们的示例中是飞机。\ndst\t        源映像将被克隆到的目标映像。在我们的示例中，它是天空图像。\nmask\t要克隆的对象周围的粗糙蒙版。这应该是源图像的大小。如果您很懒，请将其设置为全白图像！\ncenter \t源图像中心在目标图像中的位置。\nflags\t当前起作用的两个标志是NORMAL_CLONE和MIXED_CLONE。正常克隆和无缝克隆。\noutput\t输出结果图像。\n\n\n# 基础版\n```python\n# 基本\n\n# 导入相关的包\nimport cv2\nimport numpy as np \n\n# 读入图片\nsrc = cv2.imread(\"images/airplane.jpg\")\ndst = cv2.imread(\"images/sky.jpg\")\n\n\n#在飞机周围创建一个粗糙的mask。\nsrc_mask = np.zeros(src.shape, src.dtype)\n#将遮罩定义为封闭的多边形\npoly = np.array([ [4,80], [30,54], [151,63], [254,37], [298,90], [272,134], [43,122] ], np.int32)\n#函数cv :: fillPoly填充由多个多边形轮廓所界定的区域。该函数可以填充。复杂区域，例如，带有孔的区域，具有自相交的轮廓（它们的某些部分）等等\ncv2.fillPoly(src_mask, [poly], (255, 255, 255))\n\n# 飞机中心的位置\ncenter = (800,100)\n\n# 完成克隆\noutput = cv2.seamlessClone(src, dst, src_mask, center, cv2.NORMAL_CLONE)\n\n# 保存结果\ncv2.imwrite(\"images/opencv-seamless-cloning-example.jpg\", output);\n\n\n\n```\n```C++\n//# 基本\n//\n//# 导入相关的包\n\n#include \"opencv2/opencv.hpp\"\n\nusing namespace cv;\nusing namespace std;\n\nint main( int argc, char** argv )\n{\n    // 读入图片\n    Mat src = imread(\"../images/airplane.jpg\");\n    Mat dst = imread(\"../images/sky.jpg\");\n    \n\n    // 在飞机周围创建一个粗糙的mask。\n    Mat src_mask = Mat::zeros(src.rows, src.cols, src.depth());\n    \n    // 将遮罩定义为封闭的多边形\n    Point poly[1][7];\n    poly[0][0] = Point(4, 80);\n    poly[0][1] = Point(30, 54);\n    poly[0][2] = Point(151,63);\n    poly[0][3] = Point(254,37);\n    poly[0][4] = Point(298,90);\n    poly[0][5] = Point(272,134);\n    poly[0][6] = Point(43,122);\n    \n    const Point* polygons[1] = { poly[0] };\n    int num_points[] = { 7 };\n    \n    // 通过填充多边形来创建蒙版n\n    fillPoly(src_mask, polygons, num_points, 1, Scalar(255,255,255));\n    \n    // 飞机中心的位置\n    Point center(800,100);\n    \n    // 将src无缝克隆到dst中，然后将结果放入输出中\n    Mat output;\n    seamlessClone(src, dst, src_mask, center, output, NORMAL_CLONE);\n    \n    // 保存结果\n    imwrite(\"../images/opencv-seamless-cloning-example.jpg\", output);\n    \n}\n\n\n```\n\n![image.png](https://blog.mviai.com/images/Fts1LG2qSBpltPS2Tr6h27YVPG0Q)\n\n\n# 高级版\n```python\n\nimport cv2\nimport numpy as np\n\n#读取图像\nim = cv2.imread(\"images/wood-texture.jpg\")\nobj= cv2.imread(\"images/iloveyouticket.jpg\")\n\n# 创建全白图像\nmask = 255 * np.ones(obj.shape, obj.dtype)\n\n# dst中src中心的位置\nwidth, height, channels = im.shape\ncenter = (int(height/2), int(width/2))\n\n#将src无缝克隆到dst中，然后将结果放入输出中\nnormal_clone = cv2.seamlessClone(obj, im, mask, center, cv2.NORMAL_CLONE)\nmixed_clone = cv2.seamlessClone(obj, im, mask, center, cv2.MIXED_CLONE)\n\n# 写入结果\ncv2.imwrite(\"images/opencv-normal-clone-example.jpg\", normal_clone)\ncv2.imwrite(\"images/opencv-mixed-clone-example.jpg\", mixed_clone)\n\n\n```\n\n```c++\n\n#include \"opencv2/opencv.hpp\"\n\nusing namespace cv;\nusing namespace std;\n\nint main( int argc, char** argv )\n{\n    // 读取图像：src图像将被克隆到dst中\n    Mat src = imread(\"images/iloveyouticket.jpg\");\n    Mat dst = imread(\"images/wood-texture.jpg\");\n    \n\n    // 创建全白mask\n    Mat src_mask = 255 * Mat::ones(src.rows, src.cols, src.depth());\n    \n    \n    // dst中src中心的位置\n    Point center(dst.cols/2,dst.rows/2);\n    \n    // 将src无缝克隆到dst中，然后将结果放入输出中\n    Mat normal_clone;\n    Mat mixed_clone;\n    \n    seamlessClone(src, dst, src_mask, center, normal_clone, NORMAL_CLONE);\n    seamlessClone(src, dst, src_mask, center, mixed_clone, MIXED_CLONE);\n    \n    // 写入图像\n    imwrite(\"images/opencv-normal-clone-example.jpg\", normal_clone);\n    imwrite(\"images/opencv-mixed-clone-example.jpg\", mixed_clone);\n    \n    \n}\n\n\n```\n![image.png](https://blog.mviai.com/images/FgCBXytyYenRRRGBK70Sz1RTUk6Z)\n![image.png](https://blog.mviai.com/images/FgzxGclKjyu_Cq3m436y2fWbrZ7I)\n![image.png](https://blog.mviai.com/images/FqHI0kWMsDBdLYrfsI_R4r6ERFvs)\n\n# 大师版\n\n```python\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n# 读取图片\nA = cv2.imread(\"images/man.jpg\")\nB = cv2.imread(\"images/woman.jpg\")\n\n# 转换成浮点数\nA = np.float32(A) / 255.0\nB = np.float32(B) / 255.0\n\n#\n# 在A中的人脸周围创建一个粗糙的mask\nmask = np.zeros(A.shape,A.dtype)\npolygon = np.array([[164,226], [209,225], [238,188], [252,133], [248,75], [240,29], [192,15], [150,15], [100,70], [106,133], [123,194] ], np.int32)\ncv2.fillPoly(mask, [polygon], (255, 255, 255))\n# 将mask转换浮点数\nmask = np.float32(mask) / 255.0\n\n# 浮点数<1.0 就乘以获取男女mask的加权平均值\nmask = mask * 0.7 # 0.7 for man, 0.3 for woman\n\n# 调整大小为 2^（金字塔中的级别）的倍数，因此在本例中为32\nA = cv2.resize(A,(384,352))\n\n# B的mask的大小应与A相同，以便以后进行乘法和加法运算\nB = cv2.resize(B,(A.shape[1],A.shape[0]))\nmask = cv2.resize(mask,(A.shape[1],A.shape[0]))\n\n# 从原始图像开始（金字塔底）\nguassianA = A.copy()\nguassianB = B.copy()\nguassianMask = mask.copy()\ncv2.imshow('guass',guassianMask)\n\n# 两种图像的拉普拉斯金字塔相结合\ncombinedLaplacianPyramids = []\n\n# 金字塔中的级别数，尝试使用不同的值，请注意图像大小\nmaxIterations = 5\n\nfor i in range(maxIterations):\n\n\t# 计算两个图像的拉普拉斯金字塔\n\tlaplacianA = cv2.subtract(guassianA, cv2.pyrUp(cv2.pyrDown(guassianA)))\n\tlaplacianB = cv2.subtract(guassianB, cv2.pyrUp(cv2.pyrDown(guassianB)))\n\n\t# 结合两个拉普拉斯金字塔，将加权平均与mask金字塔金字塔相结合\n\tcombinedLaplacian = guassianMask * laplacianA + (1.0 - guassianMask) * laplacianB\n\n\t# 在合并的拉普拉斯金字塔列表的开头添加CombinedLaplacian\n\tcombinedLaplacianPyramids.insert(0,combinedLaplacian)\n\n\t# 更新高斯金字塔以进行下一次迭代\n\tguassianA = cv2.pyrDown(guassianA)\n\tguassianB = cv2.pyrDown(guassianB)\n\tguassianMask = cv2.pyrDown(guassianMask)\n\n# 添加拉普拉斯金字塔的最后一个组合（金字塔的最高层）\nlastCombined = guassianMask * guassianA + (1.0 - guassianMask) * guassianB\ncombinedLaplacianPyramids.insert(0,lastCombined)\n\n# 重建影像\nblendedImage = combinedLaplacianPyramids[0]\nfor i in range(1,len(combinedLaplacianPyramids)):\n    # upSample并添加到下一个级别\n    blendedImage = cv2.pyrUp(blendedImage)\n    blendedImage = cv2.add(blendedImage, combinedLaplacianPyramids[i])\n\ncv2.imshow('Blended',blendedImage)\n\n# 直接融合两个图像进行比较\ndirectCombination = mask * A + (1.0 - mask) * B\ncv2.imshow('Direct combination',directCombination)\n\ncv2.waitKey(0)\n\n```\n\n```c++\n\n\n#include \"opencv2/opencv.hpp\"\n\nusing namespace cv;\nusing namespace std;\n\nvoid getLaplacianPyramid(Mat& guassianPyramid, Mat& laplacianPyramid){\n    // 从高斯金字塔计算拉普拉斯金字塔\n    Mat downSampled;\n    pyrDown(guassianPyramid,downSampled);\n\n    // 上采样下采样\n    Mat blurred;\n    pyrUp(downSampled,blurred);\n\n    subtract(guassianPyramid, blurred, laplacianPyramid);\n\n}\n\nvoid combineImages(Mat& A, Mat& B, Mat& mask, Mat& destination){\n    \n    destination = Mat::zeros(A.rows, A.cols, CV_32FC3);\n    \n    // 目的是求A和B的加权总和，分别具有权重掩码和1-掩码\n    for(int y = 0; y < A.rows; y++)\n    {\n        for(int x = 0; x < A.cols; x++)\n        {   \n            Vec3f a = A.at<Vec3f>(Point(x,y));\n            Vec3f b = B.at<Vec3f>(Point(x,y));\n            Vec3f m = mask.at<Vec3f>(Point(x,y));\n            \n            float b_ = a[0]*m[0]+(1-m[0])*b[0];\n            float g_ = a[1]*m[1]+(1-m[1])*b[1];\n            float r_ = a[2]*m[2]+(1-m[2])*b[2];\n\n            destination.at<Vec3f>(y,x)[0] = b_;\n            destination.at<Vec3f>(y,x)[1] = g_;\n            destination.at<Vec3f>(y,x)[2] = r_;\n        }\n    }\n}\n\nint main( int argc, char** argv )\n{\n    // 读取图片\n    Mat A = imread(\"images/man.jpg\");\n    Mat B = imread(\"images/woman.jpg\");\n\n    // 转换成浮点数\n    A.convertTo(A, CV_32FC3, 1/255.0);\n    B.convertTo(B, CV_32FC3, 1/255.0);\n\n    //在A的人脸周围创建一个粗糙的mask。\n    Mat mask = Mat::zeros(A.rows, A.cols, CV_8UC3);\n\n    // 创建飞机的边缘点\n    Point points[11];\n    points[0] = Point(164,226);\n    points[1] = Point(209,225);\n    points[2] = Point(238,188);\n    points[3] = Point(252,133);\n    points[4] = Point(248,75);\n    points[5] = Point(240,29);\n    points[6] = Point(192,15);\n    points[7] = Point(150,15);\n    points[8] = Point(100,70);\n    points[9] = Point(106,133);\n    points[10] = Point(123,194);\n\n    const Point* polygon[1] = {points}; //构成点数组\n    int npt[] = {11}; // 点数组的长度\n    \n    //填充由点形成的多边形\n    fillPoly(mask, polygon, npt, 1, Scalar(255, 255, 255));\n\n    // 转换成浮点数\n    mask.convertTo(mask, CV_32FC3, 1/255.0);\n\n    // 用 浮点数<1.0 乘以获取男女面部的加权平均值\n    mask = mask * 0.7;\n\n    // 调整大小为2^（金字塔中的级别）的倍数，因此在本例中为32\n    resize(A, A, Size(384,352));\n\n    //B mask的大小应与A相同，以便以后进行乘法和加法运算\n    resize(B, B, A.size());\n    resize(mask, mask, A.size());\n\n    //从原始图像开始（金字塔底）\n    Mat guassianA = A.clone();\n    Mat guassianB = B.clone();\n    Mat guassianMask = mask.clone();\n\n    // 金字塔中的级别数，尝试使用不同的值。注意图像尺寸\n    int maxIterations = 2;\n\n    // 两种图像的组合拉普拉斯金字塔\n    vector<Mat> combinedLaplacianPyramids;\n\n    for (int i = 0; i < maxIterations; i++){\n        // 计算A的拉普拉斯金字塔\n        Mat laplacianA;\n        getLaplacianPyramid(guassianA,laplacianA);\n\n        // 计算B的拉普拉斯金字塔\n        Mat laplacianB;\n        getLaplacianPyramid(guassianB,laplacianB);\n\n        // 结合拉普拉斯金字塔\n        Mat combinedLaplacian;\n        combineImages(laplacianA, laplacianB, guassianMask, combinedLaplacian);\n \n        //在合并的拉普拉斯金字塔列表的开头插入combinedLaplacian\n        combinedLaplacianPyramids.insert(combinedLaplacianPyramids.begin(),combinedLaplacian);\n\n        // 更新高斯金字塔以进行下一次迭代\n        pyrDown(guassianA,guassianA);\n        pyrDown(guassianB,guassianB);\n        pyrDown(guassianMask,guassianMask);\n\n    }\n\n    //合并最后一个guassian（拉普拉斯金字塔的顶层与guassian的金字塔相同）\n    Mat lastCombined;\n    combineImages(guassianA, guassianB, guassianMask, lastCombined);\n\n    // 在合并的拉普拉斯金字塔列表的开头插入lastCombined\n    combinedLaplacianPyramids.insert(combinedLaplacianPyramids.begin(),lastCombined);\n\n    // 重建影像\n    Mat blendedImage = combinedLaplacianPyramids[0];\n\n    for (int i = 1; i < combinedLaplacianPyramids.size(); i++){\n        // upSample并添加到下一个级别\n        pyrUp(blendedImage,blendedImage);\n        add(blendedImage, combinedLaplacianPyramids[i],blendedImage);\n    }\n\n    // 将混合图像放回原始位置的天空图像\n    imshow(\"blended\",blendedImage);\n\n    // 将混合图像放回原始位置的天空图像\n    Mat directCombined;\n    combineImages(A, B, mask, directCombined);\n    imshow(\"directCombined\",directCombined);\n    waitKey(0);\n\n\n    return 0;\n}\n\n\n```\n![image.png](https://blog.mviai.com/images/FmB86oMyDHvbEWkBhIR11rOqea_E)","slug":"P图-无缝克隆","published":1,"updated":"2021-07-26T09:58:02.569Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m17000aigta69m0mseq","content":"<h1 id=\"无缝克隆是什么\"><a href=\"#无缝克隆是什么\" class=\"headerlink\" title=\"无缝克隆是什么\"></a>无缝克隆是什么</h1><p>两张图片合在一起,一般有以下三种方式</p>\n<ul>\n<li>新手方式</li>\n<li><img src=\"https://blog.mviai.com/images/Fs9r1gVdpyhIPnBve931nF2gPvbb\" alt=\"image.png\"></li>\n<li>Photoshop(遮罩)</li>\n<li><img src=\"https://blog.mviai.com/images/FnwLXFbvhoNJfYZOpkMRLqslvIzb\" alt=\"image.png\"></li>\n<li>opencv方式</li>\n<li>![image.png]<a href=\"https://blog.mviai.com/images/FprK2rkiGOSWO25lKuShhVluN77_\" target=\"_blank\" rel=\"noopener\">https://blog.mviai.com/images/FprK2rkiGOSWO25lKuShhVluN77_</a>)</li>\n</ul>\n<h1 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h1><p>OpenCV中的无缝克隆是SIGGRAPH 2003有影响力的论文的实现，该论文名为Patrick Poez，Michel Gangnet和Andrew Blake，名称为<a href=\"http://www.irisa.fr/vista/Papers/2003_siggraph_perez.pdf\" target=\"_blank\" rel=\"noopener\">“ Poisson Image Editing”</a>。</p>\n<p>现在我们知道，如果使用精心创建的遮罩将源图像（飞机）的强度（RGB值）与目标图像（天空）混合，我们将获得如图3所示的结果。本文的中心思想是使用图像梯度而不是图像强度可以产生更真实的结果。无缝克隆后，蒙版区域中结果图像的强度与蒙版区域中源区域的强度不同。相反，结果图像在遮罩区域中的梯度与源区域在遮罩区域中的梯度大约相同。另外，在被遮蔽区域的边界处的结果图像的强度与目的地图像（天空）的强度相同。</p>\n<p>作者表明，这是通过求解泊松方程来完成的，因此可以解决论文的标题-泊松图像编辑。该论文的理论和实现细节实际上非常酷.</p>\n<h1 id=\"主要函数\"><a href=\"#主要函数\" class=\"headerlink\" title=\"主要函数\"></a>主要函数</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">output = cv2.seamlessClone(src, dst, mask, center, flags)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">seamlessClone(Mat src, Mat dst, Mat mask, Point center, Mat output, <span class=\"keyword\">int</span> flags)</span><br></pre></td></tr></table></figure>\n<p>src            将被复制到目标图像的源图像。在我们的示例中是飞机。<br>dst            源映像将被克隆到的目标映像。在我们的示例中，它是天空图像。<br>mask    要克隆的对象周围的粗糙蒙版。这应该是源图像的大小。如果您很懒，请将其设置为全白图像！<br>center     源图像中心在目标图像中的位置。<br>flags    当前起作用的两个标志是NORMAL_CLONE和MIXED_CLONE。正常克隆和无缝克隆。<br>output    输出结果图像。</p>\n<h1 id=\"基础版\"><a href=\"#基础版\" class=\"headerlink\" title=\"基础版\"></a>基础版</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 基本</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 导入相关的包</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 读入图片</span></span><br><span class=\"line\">src = cv2.imread(<span class=\"string\">\"images/airplane.jpg\"</span>)</span><br><span class=\"line\">dst = cv2.imread(<span class=\"string\">\"images/sky.jpg\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#在飞机周围创建一个粗糙的mask。</span></span><br><span class=\"line\">src_mask = np.zeros(src.shape, src.dtype)</span><br><span class=\"line\"><span class=\"comment\">#将遮罩定义为封闭的多边形</span></span><br><span class=\"line\">poly = np.array([ [<span class=\"number\">4</span>,<span class=\"number\">80</span>], [<span class=\"number\">30</span>,<span class=\"number\">54</span>], [<span class=\"number\">151</span>,<span class=\"number\">63</span>], [<span class=\"number\">254</span>,<span class=\"number\">37</span>], [<span class=\"number\">298</span>,<span class=\"number\">90</span>], [<span class=\"number\">272</span>,<span class=\"number\">134</span>], [<span class=\"number\">43</span>,<span class=\"number\">122</span>] ], np.int32)</span><br><span class=\"line\"><span class=\"comment\">#函数cv :: fillPoly填充由多个多边形轮廓所界定的区域。该函数可以填充。复杂区域，例如，带有孔的区域，具有自相交的轮廓（它们的某些部分）等等</span></span><br><span class=\"line\">cv2.fillPoly(src_mask, [poly], (<span class=\"number\">255</span>, <span class=\"number\">255</span>, <span class=\"number\">255</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 飞机中心的位置</span></span><br><span class=\"line\">center = (<span class=\"number\">800</span>,<span class=\"number\">100</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 完成克隆</span></span><br><span class=\"line\">output = cv2.seamlessClone(src, dst, src_mask, center, cv2.NORMAL_CLONE)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 保存结果</span></span><br><span class=\"line\">cv2.imwrite(<span class=\"string\">\"images/opencv-seamless-cloning-example.jpg\"</span>, output);</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//# 基本</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">//# 导入相关的包</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"opencv2/opencv.hpp\"</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> cv;</span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">( <span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv )</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 读入图片</span></span><br><span class=\"line\">    Mat src = imread(<span class=\"string\">\"../images/airplane.jpg\"</span>);</span><br><span class=\"line\">    Mat dst = imread(<span class=\"string\">\"../images/sky.jpg\"</span>);</span><br><span class=\"line\">    </span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 在飞机周围创建一个粗糙的mask。</span></span><br><span class=\"line\">    Mat src_mask = Mat::zeros(src.rows, src.cols, src.depth());</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// 将遮罩定义为封闭的多边形</span></span><br><span class=\"line\">    Point poly[<span class=\"number\">1</span>][<span class=\"number\">7</span>];</span><br><span class=\"line\">    poly[<span class=\"number\">0</span>][<span class=\"number\">0</span>] = Point(<span class=\"number\">4</span>, <span class=\"number\">80</span>);</span><br><span class=\"line\">    poly[<span class=\"number\">0</span>][<span class=\"number\">1</span>] = Point(<span class=\"number\">30</span>, <span class=\"number\">54</span>);</span><br><span class=\"line\">    poly[<span class=\"number\">0</span>][<span class=\"number\">2</span>] = Point(<span class=\"number\">151</span>,<span class=\"number\">63</span>);</span><br><span class=\"line\">    poly[<span class=\"number\">0</span>][<span class=\"number\">3</span>] = Point(<span class=\"number\">254</span>,<span class=\"number\">37</span>);</span><br><span class=\"line\">    poly[<span class=\"number\">0</span>][<span class=\"number\">4</span>] = Point(<span class=\"number\">298</span>,<span class=\"number\">90</span>);</span><br><span class=\"line\">    poly[<span class=\"number\">0</span>][<span class=\"number\">5</span>] = Point(<span class=\"number\">272</span>,<span class=\"number\">134</span>);</span><br><span class=\"line\">    poly[<span class=\"number\">0</span>][<span class=\"number\">6</span>] = Point(<span class=\"number\">43</span>,<span class=\"number\">122</span>);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">const</span> Point* polygons[<span class=\"number\">1</span>] = &#123; poly[<span class=\"number\">0</span>] &#125;;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> num_points[] = &#123; <span class=\"number\">7</span> &#125;;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// 通过填充多边形来创建蒙版n</span></span><br><span class=\"line\">    fillPoly(src_mask, polygons, num_points, <span class=\"number\">1</span>, Scalar(<span class=\"number\">255</span>,<span class=\"number\">255</span>,<span class=\"number\">255</span>));</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// 飞机中心的位置</span></span><br><span class=\"line\">    <span class=\"function\">Point <span class=\"title\">center</span><span class=\"params\">(<span class=\"number\">800</span>,<span class=\"number\">100</span>)</span></span>;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// 将src无缝克隆到dst中，然后将结果放入输出中</span></span><br><span class=\"line\">    Mat output;</span><br><span class=\"line\">    seamlessClone(src, dst, src_mask, center, output, NORMAL_CLONE);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// 保存结果</span></span><br><span class=\"line\">    imwrite(<span class=\"string\">\"../images/opencv-seamless-cloning-example.jpg\"</span>, output);</span><br><span class=\"line\">    </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://blog.mviai.com/images/Fts1LG2qSBpltPS2Tr6h27YVPG0Q\" alt=\"image.png\"></p>\n<h1 id=\"高级版\"><a href=\"#高级版\" class=\"headerlink\" title=\"高级版\"></a>高级版</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#读取图像</span></span><br><span class=\"line\">im = cv2.imread(<span class=\"string\">\"images/wood-texture.jpg\"</span>)</span><br><span class=\"line\">obj= cv2.imread(<span class=\"string\">\"images/iloveyouticket.jpg\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建全白图像</span></span><br><span class=\"line\">mask = <span class=\"number\">255</span> * np.ones(obj.shape, obj.dtype)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># dst中src中心的位置</span></span><br><span class=\"line\">width, height, channels = im.shape</span><br><span class=\"line\">center = (int(height/<span class=\"number\">2</span>), int(width/<span class=\"number\">2</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#将src无缝克隆到dst中，然后将结果放入输出中</span></span><br><span class=\"line\">normal_clone = cv2.seamlessClone(obj, im, mask, center, cv2.NORMAL_CLONE)</span><br><span class=\"line\">mixed_clone = cv2.seamlessClone(obj, im, mask, center, cv2.MIXED_CLONE)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 写入结果</span></span><br><span class=\"line\">cv2.imwrite(<span class=\"string\">\"images/opencv-normal-clone-example.jpg\"</span>, normal_clone)</span><br><span class=\"line\">cv2.imwrite(<span class=\"string\">\"images/opencv-mixed-clone-example.jpg\"</span>, mixed_clone)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"opencv2/opencv.hpp\"</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> cv;</span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">( <span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv )</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 读取图像：src图像将被克隆到dst中</span></span><br><span class=\"line\">    Mat src = imread(<span class=\"string\">\"images/iloveyouticket.jpg\"</span>);</span><br><span class=\"line\">    Mat dst = imread(<span class=\"string\">\"images/wood-texture.jpg\"</span>);</span><br><span class=\"line\">    </span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 创建全白mask</span></span><br><span class=\"line\">    Mat src_mask = <span class=\"number\">255</span> * Mat::ones(src.rows, src.cols, src.depth());</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// dst中src中心的位置</span></span><br><span class=\"line\">    <span class=\"function\">Point <span class=\"title\">center</span><span class=\"params\">(dst.cols/<span class=\"number\">2</span>,dst.rows/<span class=\"number\">2</span>)</span></span>;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// 将src无缝克隆到dst中，然后将结果放入输出中</span></span><br><span class=\"line\">    Mat normal_clone;</span><br><span class=\"line\">    Mat mixed_clone;</span><br><span class=\"line\">    </span><br><span class=\"line\">    seamlessClone(src, dst, src_mask, center, normal_clone, NORMAL_CLONE);</span><br><span class=\"line\">    seamlessClone(src, dst, src_mask, center, mixed_clone, MIXED_CLONE);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// 写入图像</span></span><br><span class=\"line\">    imwrite(<span class=\"string\">\"images/opencv-normal-clone-example.jpg\"</span>, normal_clone);</span><br><span class=\"line\">    imwrite(<span class=\"string\">\"images/opencv-mixed-clone-example.jpg\"</span>, mixed_clone);</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://blog.mviai.com/images/FgCBXytyYenRRRGBK70Sz1RTUk6Z\" alt=\"image.png\"><br><img src=\"https://blog.mviai.com/images/FgzxGclKjyu_Cq3m436y2fWbrZ7I\" alt=\"image.png\"><br><img src=\"https://blog.mviai.com/images/FqHI0kWMsDBdLYrfsI_R4r6ERFvs\" alt=\"image.png\"></p>\n<h1 id=\"大师版\"><a href=\"#大师版\" class=\"headerlink\" title=\"大师版\"></a>大师版</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.image <span class=\"keyword\">as</span> mpimg</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 读取图片</span></span><br><span class=\"line\">A = cv2.imread(<span class=\"string\">\"images/man.jpg\"</span>)</span><br><span class=\"line\">B = cv2.imread(<span class=\"string\">\"images/woman.jpg\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 转换成浮点数</span></span><br><span class=\"line\">A = np.float32(A) / <span class=\"number\">255.0</span></span><br><span class=\"line\">B = np.float32(B) / <span class=\"number\">255.0</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># 在A中的人脸周围创建一个粗糙的mask</span></span><br><span class=\"line\">mask = np.zeros(A.shape,A.dtype)</span><br><span class=\"line\">polygon = np.array([[<span class=\"number\">164</span>,<span class=\"number\">226</span>], [<span class=\"number\">209</span>,<span class=\"number\">225</span>], [<span class=\"number\">238</span>,<span class=\"number\">188</span>], [<span class=\"number\">252</span>,<span class=\"number\">133</span>], [<span class=\"number\">248</span>,<span class=\"number\">75</span>], [<span class=\"number\">240</span>,<span class=\"number\">29</span>], [<span class=\"number\">192</span>,<span class=\"number\">15</span>], [<span class=\"number\">150</span>,<span class=\"number\">15</span>], [<span class=\"number\">100</span>,<span class=\"number\">70</span>], [<span class=\"number\">106</span>,<span class=\"number\">133</span>], [<span class=\"number\">123</span>,<span class=\"number\">194</span>] ], np.int32)</span><br><span class=\"line\">cv2.fillPoly(mask, [polygon], (<span class=\"number\">255</span>, <span class=\"number\">255</span>, <span class=\"number\">255</span>))</span><br><span class=\"line\"><span class=\"comment\"># 将mask转换浮点数</span></span><br><span class=\"line\">mask = np.float32(mask) / <span class=\"number\">255.0</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 浮点数&lt;1.0 就乘以获取男女mask的加权平均值</span></span><br><span class=\"line\">mask = mask * <span class=\"number\">0.7</span> <span class=\"comment\"># 0.7 for man, 0.3 for woman</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 调整大小为 2^（金字塔中的级别）的倍数，因此在本例中为32</span></span><br><span class=\"line\">A = cv2.resize(A,(<span class=\"number\">384</span>,<span class=\"number\">352</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># B的mask的大小应与A相同，以便以后进行乘法和加法运算</span></span><br><span class=\"line\">B = cv2.resize(B,(A.shape[<span class=\"number\">1</span>],A.shape[<span class=\"number\">0</span>]))</span><br><span class=\"line\">mask = cv2.resize(mask,(A.shape[<span class=\"number\">1</span>],A.shape[<span class=\"number\">0</span>]))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 从原始图像开始（金字塔底）</span></span><br><span class=\"line\">guassianA = A.copy()</span><br><span class=\"line\">guassianB = B.copy()</span><br><span class=\"line\">guassianMask = mask.copy()</span><br><span class=\"line\">cv2.imshow(<span class=\"string\">'guass'</span>,guassianMask)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 两种图像的拉普拉斯金字塔相结合</span></span><br><span class=\"line\">combinedLaplacianPyramids = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 金字塔中的级别数，尝试使用不同的值，请注意图像大小</span></span><br><span class=\"line\">maxIterations = <span class=\"number\">5</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(maxIterations):</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\"># 计算两个图像的拉普拉斯金字塔</span></span><br><span class=\"line\">\tlaplacianA = cv2.subtract(guassianA, cv2.pyrUp(cv2.pyrDown(guassianA)))</span><br><span class=\"line\">\tlaplacianB = cv2.subtract(guassianB, cv2.pyrUp(cv2.pyrDown(guassianB)))</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\"># 结合两个拉普拉斯金字塔，将加权平均与mask金字塔金字塔相结合</span></span><br><span class=\"line\">\tcombinedLaplacian = guassianMask * laplacianA + (<span class=\"number\">1.0</span> - guassianMask) * laplacianB</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\"># 在合并的拉普拉斯金字塔列表的开头添加CombinedLaplacian</span></span><br><span class=\"line\">\tcombinedLaplacianPyramids.insert(<span class=\"number\">0</span>,combinedLaplacian)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\"># 更新高斯金字塔以进行下一次迭代</span></span><br><span class=\"line\">\tguassianA = cv2.pyrDown(guassianA)</span><br><span class=\"line\">\tguassianB = cv2.pyrDown(guassianB)</span><br><span class=\"line\">\tguassianMask = cv2.pyrDown(guassianMask)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 添加拉普拉斯金字塔的最后一个组合（金字塔的最高层）</span></span><br><span class=\"line\">lastCombined = guassianMask * guassianA + (<span class=\"number\">1.0</span> - guassianMask) * guassianB</span><br><span class=\"line\">combinedLaplacianPyramids.insert(<span class=\"number\">0</span>,lastCombined)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 重建影像</span></span><br><span class=\"line\">blendedImage = combinedLaplacianPyramids[<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>,len(combinedLaplacianPyramids)):</span><br><span class=\"line\">    <span class=\"comment\"># upSample并添加到下一个级别</span></span><br><span class=\"line\">    blendedImage = cv2.pyrUp(blendedImage)</span><br><span class=\"line\">    blendedImage = cv2.add(blendedImage, combinedLaplacianPyramids[i])</span><br><span class=\"line\"></span><br><span class=\"line\">cv2.imshow(<span class=\"string\">'Blended'</span>,blendedImage)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 直接融合两个图像进行比较</span></span><br><span class=\"line\">directCombination = mask * A + (<span class=\"number\">1.0</span> - mask) * B</span><br><span class=\"line\">cv2.imshow(<span class=\"string\">'Direct combination'</span>,directCombination)</span><br><span class=\"line\"></span><br><span class=\"line\">cv2.waitKey(<span class=\"number\">0</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"opencv2/opencv.hpp\"</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> cv;</span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">getLaplacianPyramid</span><span class=\"params\">(Mat&amp; guassianPyramid, Mat&amp; laplacianPyramid)</span></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 从高斯金字塔计算拉普拉斯金字塔</span></span><br><span class=\"line\">    Mat downSampled;</span><br><span class=\"line\">    pyrDown(guassianPyramid,downSampled);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 上采样下采样</span></span><br><span class=\"line\">    Mat blurred;</span><br><span class=\"line\">    pyrUp(downSampled,blurred);</span><br><span class=\"line\"></span><br><span class=\"line\">    subtract(guassianPyramid, blurred, laplacianPyramid);</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">combineImages</span><span class=\"params\">(Mat&amp; A, Mat&amp; B, Mat&amp; mask, Mat&amp; destination)</span></span>&#123;</span><br><span class=\"line\">    </span><br><span class=\"line\">    destination = Mat::zeros(A.rows, A.cols, CV_32FC3);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// 目的是求A和B的加权总和，分别具有权重掩码和1-掩码</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> y = <span class=\"number\">0</span>; y &lt; A.rows; y++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> x = <span class=\"number\">0</span>; x &lt; A.cols; x++)</span><br><span class=\"line\">        &#123;   </span><br><span class=\"line\">            Vec3f a = A.at&lt;Vec3f&gt;(Point(x,y));</span><br><span class=\"line\">            Vec3f b = B.at&lt;Vec3f&gt;(Point(x,y));</span><br><span class=\"line\">            Vec3f m = mask.at&lt;Vec3f&gt;(Point(x,y));</span><br><span class=\"line\">            </span><br><span class=\"line\">            <span class=\"keyword\">float</span> b_ = a[<span class=\"number\">0</span>]*m[<span class=\"number\">0</span>]+(<span class=\"number\">1</span>-m[<span class=\"number\">0</span>])*b[<span class=\"number\">0</span>];</span><br><span class=\"line\">            <span class=\"keyword\">float</span> g_ = a[<span class=\"number\">1</span>]*m[<span class=\"number\">1</span>]+(<span class=\"number\">1</span>-m[<span class=\"number\">1</span>])*b[<span class=\"number\">1</span>];</span><br><span class=\"line\">            <span class=\"keyword\">float</span> r_ = a[<span class=\"number\">2</span>]*m[<span class=\"number\">2</span>]+(<span class=\"number\">1</span>-m[<span class=\"number\">2</span>])*b[<span class=\"number\">2</span>];</span><br><span class=\"line\"></span><br><span class=\"line\">            destination.at&lt;Vec3f&gt;(y,x)[<span class=\"number\">0</span>] = b_;</span><br><span class=\"line\">            destination.at&lt;Vec3f&gt;(y,x)[<span class=\"number\">1</span>] = g_;</span><br><span class=\"line\">            destination.at&lt;Vec3f&gt;(y,x)[<span class=\"number\">2</span>] = r_;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">( <span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv )</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 读取图片</span></span><br><span class=\"line\">    Mat A = imread(<span class=\"string\">\"images/man.jpg\"</span>);</span><br><span class=\"line\">    Mat B = imread(<span class=\"string\">\"images/woman.jpg\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 转换成浮点数</span></span><br><span class=\"line\">    A.convertTo(A, CV_32FC3, <span class=\"number\">1</span>/<span class=\"number\">255.0</span>);</span><br><span class=\"line\">    B.convertTo(B, CV_32FC3, <span class=\"number\">1</span>/<span class=\"number\">255.0</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//在A的人脸周围创建一个粗糙的mask。</span></span><br><span class=\"line\">    Mat mask = Mat::zeros(A.rows, A.cols, CV_8UC3);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 创建飞机的边缘点</span></span><br><span class=\"line\">    Point points[<span class=\"number\">11</span>];</span><br><span class=\"line\">    points[<span class=\"number\">0</span>] = Point(<span class=\"number\">164</span>,<span class=\"number\">226</span>);</span><br><span class=\"line\">    points[<span class=\"number\">1</span>] = Point(<span class=\"number\">209</span>,<span class=\"number\">225</span>);</span><br><span class=\"line\">    points[<span class=\"number\">2</span>] = Point(<span class=\"number\">238</span>,<span class=\"number\">188</span>);</span><br><span class=\"line\">    points[<span class=\"number\">3</span>] = Point(<span class=\"number\">252</span>,<span class=\"number\">133</span>);</span><br><span class=\"line\">    points[<span class=\"number\">4</span>] = Point(<span class=\"number\">248</span>,<span class=\"number\">75</span>);</span><br><span class=\"line\">    points[<span class=\"number\">5</span>] = Point(<span class=\"number\">240</span>,<span class=\"number\">29</span>);</span><br><span class=\"line\">    points[<span class=\"number\">6</span>] = Point(<span class=\"number\">192</span>,<span class=\"number\">15</span>);</span><br><span class=\"line\">    points[<span class=\"number\">7</span>] = Point(<span class=\"number\">150</span>,<span class=\"number\">15</span>);</span><br><span class=\"line\">    points[<span class=\"number\">8</span>] = Point(<span class=\"number\">100</span>,<span class=\"number\">70</span>);</span><br><span class=\"line\">    points[<span class=\"number\">9</span>] = Point(<span class=\"number\">106</span>,<span class=\"number\">133</span>);</span><br><span class=\"line\">    points[<span class=\"number\">10</span>] = Point(<span class=\"number\">123</span>,<span class=\"number\">194</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">const</span> Point* polygon[<span class=\"number\">1</span>] = &#123;points&#125;; <span class=\"comment\">//构成点数组</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> npt[] = &#123;<span class=\"number\">11</span>&#125;; <span class=\"comment\">// 点数组的长度</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">//填充由点形成的多边形</span></span><br><span class=\"line\">    fillPoly(mask, polygon, npt, <span class=\"number\">1</span>, Scalar(<span class=\"number\">255</span>, <span class=\"number\">255</span>, <span class=\"number\">255</span>));</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 转换成浮点数</span></span><br><span class=\"line\">    mask.convertTo(mask, CV_32FC3, <span class=\"number\">1</span>/<span class=\"number\">255.0</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 用 浮点数&lt;1.0 乘以获取男女面部的加权平均值</span></span><br><span class=\"line\">    mask = mask * <span class=\"number\">0.7</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 调整大小为2^（金字塔中的级别）的倍数，因此在本例中为32</span></span><br><span class=\"line\">    resize(A, A, Size(<span class=\"number\">384</span>,<span class=\"number\">352</span>));</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//B mask的大小应与A相同，以便以后进行乘法和加法运算</span></span><br><span class=\"line\">    resize(B, B, A.size());</span><br><span class=\"line\">    resize(mask, mask, A.size());</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//从原始图像开始（金字塔底）</span></span><br><span class=\"line\">    Mat guassianA = A.clone();</span><br><span class=\"line\">    Mat guassianB = B.clone();</span><br><span class=\"line\">    Mat guassianMask = mask.clone();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 金字塔中的级别数，尝试使用不同的值。注意图像尺寸</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> maxIterations = <span class=\"number\">2</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 两种图像的组合拉普拉斯金字塔</span></span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;Mat&gt; combinedLaplacianPyramids;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; maxIterations; i++)&#123;</span><br><span class=\"line\">        <span class=\"comment\">// 计算A的拉普拉斯金字塔</span></span><br><span class=\"line\">        Mat laplacianA;</span><br><span class=\"line\">        getLaplacianPyramid(guassianA,laplacianA);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// 计算B的拉普拉斯金字塔</span></span><br><span class=\"line\">        Mat laplacianB;</span><br><span class=\"line\">        getLaplacianPyramid(guassianB,laplacianB);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// 结合拉普拉斯金字塔</span></span><br><span class=\"line\">        Mat combinedLaplacian;</span><br><span class=\"line\">        combineImages(laplacianA, laplacianB, guassianMask, combinedLaplacian);</span><br><span class=\"line\"> </span><br><span class=\"line\">        <span class=\"comment\">//在合并的拉普拉斯金字塔列表的开头插入combinedLaplacian</span></span><br><span class=\"line\">        combinedLaplacianPyramids.insert(combinedLaplacianPyramids.begin(),combinedLaplacian);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// 更新高斯金字塔以进行下一次迭代</span></span><br><span class=\"line\">        pyrDown(guassianA,guassianA);</span><br><span class=\"line\">        pyrDown(guassianB,guassianB);</span><br><span class=\"line\">        pyrDown(guassianMask,guassianMask);</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//合并最后一个guassian（拉普拉斯金字塔的顶层与guassian的金字塔相同）</span></span><br><span class=\"line\">    Mat lastCombined;</span><br><span class=\"line\">    combineImages(guassianA, guassianB, guassianMask, lastCombined);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 在合并的拉普拉斯金字塔列表的开头插入lastCombined</span></span><br><span class=\"line\">    combinedLaplacianPyramids.insert(combinedLaplacianPyramids.begin(),lastCombined);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 重建影像</span></span><br><span class=\"line\">    Mat blendedImage = combinedLaplacianPyramids[<span class=\"number\">0</span>];</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>; i &lt; combinedLaplacianPyramids.size(); i++)&#123;</span><br><span class=\"line\">        <span class=\"comment\">// upSample并添加到下一个级别</span></span><br><span class=\"line\">        pyrUp(blendedImage,blendedImage);</span><br><span class=\"line\">        add(blendedImage, combinedLaplacianPyramids[i],blendedImage);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 将混合图像放回原始位置的天空图像</span></span><br><span class=\"line\">    imshow(<span class=\"string\">\"blended\"</span>,blendedImage);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 将混合图像放回原始位置的天空图像</span></span><br><span class=\"line\">    Mat directCombined;</span><br><span class=\"line\">    combineImages(A, B, mask, directCombined);</span><br><span class=\"line\">    imshow(<span class=\"string\">\"directCombined\"</span>,directCombined);</span><br><span class=\"line\">    waitKey(<span class=\"number\">0</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://blog.mviai.com/images/FmB86oMyDHvbEWkBhIR11rOqea_E\" alt=\"image.png\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"无缝克隆是什么\"><a href=\"#无缝克隆是什么\" class=\"headerlink\" title=\"无缝克隆是什么\"></a>无缝克隆是什么</h1><p>两张图片合在一起,一般有以下三种方式</p>\n<ul>\n<li>新手方式</li>\n<li><img src=\"https://blog.mviai.com/images/Fs9r1gVdpyhIPnBve931nF2gPvbb\" alt=\"image.png\"></li>\n<li>Photoshop(遮罩)</li>\n<li><img src=\"https://blog.mviai.com/images/FnwLXFbvhoNJfYZOpkMRLqslvIzb\" alt=\"image.png\"></li>\n<li>opencv方式</li>\n<li>![image.png]<a href=\"https://blog.mviai.com/images/FprK2rkiGOSWO25lKuShhVluN77_\" target=\"_blank\" rel=\"noopener\">https://blog.mviai.com/images/FprK2rkiGOSWO25lKuShhVluN77_</a>)</li>\n</ul>\n<h1 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h1><p>OpenCV中的无缝克隆是SIGGRAPH 2003有影响力的论文的实现，该论文名为Patrick Poez，Michel Gangnet和Andrew Blake，名称为<a href=\"http://www.irisa.fr/vista/Papers/2003_siggraph_perez.pdf\" target=\"_blank\" rel=\"noopener\">“ Poisson Image Editing”</a>。</p>\n<p>现在我们知道，如果使用精心创建的遮罩将源图像（飞机）的强度（RGB值）与目标图像（天空）混合，我们将获得如图3所示的结果。本文的中心思想是使用图像梯度而不是图像强度可以产生更真实的结果。无缝克隆后，蒙版区域中结果图像的强度与蒙版区域中源区域的强度不同。相反，结果图像在遮罩区域中的梯度与源区域在遮罩区域中的梯度大约相同。另外，在被遮蔽区域的边界处的结果图像的强度与目的地图像（天空）的强度相同。</p>\n<p>作者表明，这是通过求解泊松方程来完成的，因此可以解决论文的标题-泊松图像编辑。该论文的理论和实现细节实际上非常酷.</p>\n<h1 id=\"主要函数\"><a href=\"#主要函数\" class=\"headerlink\" title=\"主要函数\"></a>主要函数</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">output = cv2.seamlessClone(src, dst, mask, center, flags)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">seamlessClone(Mat src, Mat dst, Mat mask, Point center, Mat output, <span class=\"keyword\">int</span> flags)</span><br></pre></td></tr></table></figure>\n<p>src            将被复制到目标图像的源图像。在我们的示例中是飞机。<br>dst            源映像将被克隆到的目标映像。在我们的示例中，它是天空图像。<br>mask    要克隆的对象周围的粗糙蒙版。这应该是源图像的大小。如果您很懒，请将其设置为全白图像！<br>center     源图像中心在目标图像中的位置。<br>flags    当前起作用的两个标志是NORMAL_CLONE和MIXED_CLONE。正常克隆和无缝克隆。<br>output    输出结果图像。</p>\n<h1 id=\"基础版\"><a href=\"#基础版\" class=\"headerlink\" title=\"基础版\"></a>基础版</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 基本</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 导入相关的包</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 读入图片</span></span><br><span class=\"line\">src = cv2.imread(<span class=\"string\">\"images/airplane.jpg\"</span>)</span><br><span class=\"line\">dst = cv2.imread(<span class=\"string\">\"images/sky.jpg\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#在飞机周围创建一个粗糙的mask。</span></span><br><span class=\"line\">src_mask = np.zeros(src.shape, src.dtype)</span><br><span class=\"line\"><span class=\"comment\">#将遮罩定义为封闭的多边形</span></span><br><span class=\"line\">poly = np.array([ [<span class=\"number\">4</span>,<span class=\"number\">80</span>], [<span class=\"number\">30</span>,<span class=\"number\">54</span>], [<span class=\"number\">151</span>,<span class=\"number\">63</span>], [<span class=\"number\">254</span>,<span class=\"number\">37</span>], [<span class=\"number\">298</span>,<span class=\"number\">90</span>], [<span class=\"number\">272</span>,<span class=\"number\">134</span>], [<span class=\"number\">43</span>,<span class=\"number\">122</span>] ], np.int32)</span><br><span class=\"line\"><span class=\"comment\">#函数cv :: fillPoly填充由多个多边形轮廓所界定的区域。该函数可以填充。复杂区域，例如，带有孔的区域，具有自相交的轮廓（它们的某些部分）等等</span></span><br><span class=\"line\">cv2.fillPoly(src_mask, [poly], (<span class=\"number\">255</span>, <span class=\"number\">255</span>, <span class=\"number\">255</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 飞机中心的位置</span></span><br><span class=\"line\">center = (<span class=\"number\">800</span>,<span class=\"number\">100</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 完成克隆</span></span><br><span class=\"line\">output = cv2.seamlessClone(src, dst, src_mask, center, cv2.NORMAL_CLONE)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 保存结果</span></span><br><span class=\"line\">cv2.imwrite(<span class=\"string\">\"images/opencv-seamless-cloning-example.jpg\"</span>, output);</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//# 基本</span></span><br><span class=\"line\"><span class=\"comment\">//</span></span><br><span class=\"line\"><span class=\"comment\">//# 导入相关的包</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"opencv2/opencv.hpp\"</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> cv;</span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">( <span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv )</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 读入图片</span></span><br><span class=\"line\">    Mat src = imread(<span class=\"string\">\"../images/airplane.jpg\"</span>);</span><br><span class=\"line\">    Mat dst = imread(<span class=\"string\">\"../images/sky.jpg\"</span>);</span><br><span class=\"line\">    </span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 在飞机周围创建一个粗糙的mask。</span></span><br><span class=\"line\">    Mat src_mask = Mat::zeros(src.rows, src.cols, src.depth());</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// 将遮罩定义为封闭的多边形</span></span><br><span class=\"line\">    Point poly[<span class=\"number\">1</span>][<span class=\"number\">7</span>];</span><br><span class=\"line\">    poly[<span class=\"number\">0</span>][<span class=\"number\">0</span>] = Point(<span class=\"number\">4</span>, <span class=\"number\">80</span>);</span><br><span class=\"line\">    poly[<span class=\"number\">0</span>][<span class=\"number\">1</span>] = Point(<span class=\"number\">30</span>, <span class=\"number\">54</span>);</span><br><span class=\"line\">    poly[<span class=\"number\">0</span>][<span class=\"number\">2</span>] = Point(<span class=\"number\">151</span>,<span class=\"number\">63</span>);</span><br><span class=\"line\">    poly[<span class=\"number\">0</span>][<span class=\"number\">3</span>] = Point(<span class=\"number\">254</span>,<span class=\"number\">37</span>);</span><br><span class=\"line\">    poly[<span class=\"number\">0</span>][<span class=\"number\">4</span>] = Point(<span class=\"number\">298</span>,<span class=\"number\">90</span>);</span><br><span class=\"line\">    poly[<span class=\"number\">0</span>][<span class=\"number\">5</span>] = Point(<span class=\"number\">272</span>,<span class=\"number\">134</span>);</span><br><span class=\"line\">    poly[<span class=\"number\">0</span>][<span class=\"number\">6</span>] = Point(<span class=\"number\">43</span>,<span class=\"number\">122</span>);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"keyword\">const</span> Point* polygons[<span class=\"number\">1</span>] = &#123; poly[<span class=\"number\">0</span>] &#125;;</span><br><span class=\"line\">    <span class=\"keyword\">int</span> num_points[] = &#123; <span class=\"number\">7</span> &#125;;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// 通过填充多边形来创建蒙版n</span></span><br><span class=\"line\">    fillPoly(src_mask, polygons, num_points, <span class=\"number\">1</span>, Scalar(<span class=\"number\">255</span>,<span class=\"number\">255</span>,<span class=\"number\">255</span>));</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// 飞机中心的位置</span></span><br><span class=\"line\">    <span class=\"function\">Point <span class=\"title\">center</span><span class=\"params\">(<span class=\"number\">800</span>,<span class=\"number\">100</span>)</span></span>;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// 将src无缝克隆到dst中，然后将结果放入输出中</span></span><br><span class=\"line\">    Mat output;</span><br><span class=\"line\">    seamlessClone(src, dst, src_mask, center, output, NORMAL_CLONE);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// 保存结果</span></span><br><span class=\"line\">    imwrite(<span class=\"string\">\"../images/opencv-seamless-cloning-example.jpg\"</span>, output);</span><br><span class=\"line\">    </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://blog.mviai.com/images/Fts1LG2qSBpltPS2Tr6h27YVPG0Q\" alt=\"image.png\"></p>\n<h1 id=\"高级版\"><a href=\"#高级版\" class=\"headerlink\" title=\"高级版\"></a>高级版</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#读取图像</span></span><br><span class=\"line\">im = cv2.imread(<span class=\"string\">\"images/wood-texture.jpg\"</span>)</span><br><span class=\"line\">obj= cv2.imread(<span class=\"string\">\"images/iloveyouticket.jpg\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 创建全白图像</span></span><br><span class=\"line\">mask = <span class=\"number\">255</span> * np.ones(obj.shape, obj.dtype)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># dst中src中心的位置</span></span><br><span class=\"line\">width, height, channels = im.shape</span><br><span class=\"line\">center = (int(height/<span class=\"number\">2</span>), int(width/<span class=\"number\">2</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#将src无缝克隆到dst中，然后将结果放入输出中</span></span><br><span class=\"line\">normal_clone = cv2.seamlessClone(obj, im, mask, center, cv2.NORMAL_CLONE)</span><br><span class=\"line\">mixed_clone = cv2.seamlessClone(obj, im, mask, center, cv2.MIXED_CLONE)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 写入结果</span></span><br><span class=\"line\">cv2.imwrite(<span class=\"string\">\"images/opencv-normal-clone-example.jpg\"</span>, normal_clone)</span><br><span class=\"line\">cv2.imwrite(<span class=\"string\">\"images/opencv-mixed-clone-example.jpg\"</span>, mixed_clone)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"opencv2/opencv.hpp\"</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> cv;</span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">( <span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv )</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 读取图像：src图像将被克隆到dst中</span></span><br><span class=\"line\">    Mat src = imread(<span class=\"string\">\"images/iloveyouticket.jpg\"</span>);</span><br><span class=\"line\">    Mat dst = imread(<span class=\"string\">\"images/wood-texture.jpg\"</span>);</span><br><span class=\"line\">    </span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 创建全白mask</span></span><br><span class=\"line\">    Mat src_mask = <span class=\"number\">255</span> * Mat::ones(src.rows, src.cols, src.depth());</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// dst中src中心的位置</span></span><br><span class=\"line\">    <span class=\"function\">Point <span class=\"title\">center</span><span class=\"params\">(dst.cols/<span class=\"number\">2</span>,dst.rows/<span class=\"number\">2</span>)</span></span>;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// 将src无缝克隆到dst中，然后将结果放入输出中</span></span><br><span class=\"line\">    Mat normal_clone;</span><br><span class=\"line\">    Mat mixed_clone;</span><br><span class=\"line\">    </span><br><span class=\"line\">    seamlessClone(src, dst, src_mask, center, normal_clone, NORMAL_CLONE);</span><br><span class=\"line\">    seamlessClone(src, dst, src_mask, center, mixed_clone, MIXED_CLONE);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// 写入图像</span></span><br><span class=\"line\">    imwrite(<span class=\"string\">\"images/opencv-normal-clone-example.jpg\"</span>, normal_clone);</span><br><span class=\"line\">    imwrite(<span class=\"string\">\"images/opencv-mixed-clone-example.jpg\"</span>, mixed_clone);</span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://blog.mviai.com/images/FgCBXytyYenRRRGBK70Sz1RTUk6Z\" alt=\"image.png\"><br><img src=\"https://blog.mviai.com/images/FgzxGclKjyu_Cq3m436y2fWbrZ7I\" alt=\"image.png\"><br><img src=\"https://blog.mviai.com/images/FqHI0kWMsDBdLYrfsI_R4r6ERFvs\" alt=\"image.png\"></p>\n<h1 id=\"大师版\"><a href=\"#大师版\" class=\"headerlink\" title=\"大师版\"></a>大师版</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.image <span class=\"keyword\">as</span> mpimg</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 读取图片</span></span><br><span class=\"line\">A = cv2.imread(<span class=\"string\">\"images/man.jpg\"</span>)</span><br><span class=\"line\">B = cv2.imread(<span class=\"string\">\"images/woman.jpg\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 转换成浮点数</span></span><br><span class=\"line\">A = np.float32(A) / <span class=\"number\">255.0</span></span><br><span class=\"line\">B = np.float32(B) / <span class=\"number\">255.0</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># 在A中的人脸周围创建一个粗糙的mask</span></span><br><span class=\"line\">mask = np.zeros(A.shape,A.dtype)</span><br><span class=\"line\">polygon = np.array([[<span class=\"number\">164</span>,<span class=\"number\">226</span>], [<span class=\"number\">209</span>,<span class=\"number\">225</span>], [<span class=\"number\">238</span>,<span class=\"number\">188</span>], [<span class=\"number\">252</span>,<span class=\"number\">133</span>], [<span class=\"number\">248</span>,<span class=\"number\">75</span>], [<span class=\"number\">240</span>,<span class=\"number\">29</span>], [<span class=\"number\">192</span>,<span class=\"number\">15</span>], [<span class=\"number\">150</span>,<span class=\"number\">15</span>], [<span class=\"number\">100</span>,<span class=\"number\">70</span>], [<span class=\"number\">106</span>,<span class=\"number\">133</span>], [<span class=\"number\">123</span>,<span class=\"number\">194</span>] ], np.int32)</span><br><span class=\"line\">cv2.fillPoly(mask, [polygon], (<span class=\"number\">255</span>, <span class=\"number\">255</span>, <span class=\"number\">255</span>))</span><br><span class=\"line\"><span class=\"comment\"># 将mask转换浮点数</span></span><br><span class=\"line\">mask = np.float32(mask) / <span class=\"number\">255.0</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 浮点数&lt;1.0 就乘以获取男女mask的加权平均值</span></span><br><span class=\"line\">mask = mask * <span class=\"number\">0.7</span> <span class=\"comment\"># 0.7 for man, 0.3 for woman</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 调整大小为 2^（金字塔中的级别）的倍数，因此在本例中为32</span></span><br><span class=\"line\">A = cv2.resize(A,(<span class=\"number\">384</span>,<span class=\"number\">352</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># B的mask的大小应与A相同，以便以后进行乘法和加法运算</span></span><br><span class=\"line\">B = cv2.resize(B,(A.shape[<span class=\"number\">1</span>],A.shape[<span class=\"number\">0</span>]))</span><br><span class=\"line\">mask = cv2.resize(mask,(A.shape[<span class=\"number\">1</span>],A.shape[<span class=\"number\">0</span>]))</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 从原始图像开始（金字塔底）</span></span><br><span class=\"line\">guassianA = A.copy()</span><br><span class=\"line\">guassianB = B.copy()</span><br><span class=\"line\">guassianMask = mask.copy()</span><br><span class=\"line\">cv2.imshow(<span class=\"string\">'guass'</span>,guassianMask)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 两种图像的拉普拉斯金字塔相结合</span></span><br><span class=\"line\">combinedLaplacianPyramids = []</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 金字塔中的级别数，尝试使用不同的值，请注意图像大小</span></span><br><span class=\"line\">maxIterations = <span class=\"number\">5</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(maxIterations):</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\"># 计算两个图像的拉普拉斯金字塔</span></span><br><span class=\"line\">\tlaplacianA = cv2.subtract(guassianA, cv2.pyrUp(cv2.pyrDown(guassianA)))</span><br><span class=\"line\">\tlaplacianB = cv2.subtract(guassianB, cv2.pyrUp(cv2.pyrDown(guassianB)))</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\"># 结合两个拉普拉斯金字塔，将加权平均与mask金字塔金字塔相结合</span></span><br><span class=\"line\">\tcombinedLaplacian = guassianMask * laplacianA + (<span class=\"number\">1.0</span> - guassianMask) * laplacianB</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\"># 在合并的拉普拉斯金字塔列表的开头添加CombinedLaplacian</span></span><br><span class=\"line\">\tcombinedLaplacianPyramids.insert(<span class=\"number\">0</span>,combinedLaplacian)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\"># 更新高斯金字塔以进行下一次迭代</span></span><br><span class=\"line\">\tguassianA = cv2.pyrDown(guassianA)</span><br><span class=\"line\">\tguassianB = cv2.pyrDown(guassianB)</span><br><span class=\"line\">\tguassianMask = cv2.pyrDown(guassianMask)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 添加拉普拉斯金字塔的最后一个组合（金字塔的最高层）</span></span><br><span class=\"line\">lastCombined = guassianMask * guassianA + (<span class=\"number\">1.0</span> - guassianMask) * guassianB</span><br><span class=\"line\">combinedLaplacianPyramids.insert(<span class=\"number\">0</span>,lastCombined)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 重建影像</span></span><br><span class=\"line\">blendedImage = combinedLaplacianPyramids[<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>,len(combinedLaplacianPyramids)):</span><br><span class=\"line\">    <span class=\"comment\"># upSample并添加到下一个级别</span></span><br><span class=\"line\">    blendedImage = cv2.pyrUp(blendedImage)</span><br><span class=\"line\">    blendedImage = cv2.add(blendedImage, combinedLaplacianPyramids[i])</span><br><span class=\"line\"></span><br><span class=\"line\">cv2.imshow(<span class=\"string\">'Blended'</span>,blendedImage)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 直接融合两个图像进行比较</span></span><br><span class=\"line\">directCombination = mask * A + (<span class=\"number\">1.0</span> - mask) * B</span><br><span class=\"line\">cv2.imshow(<span class=\"string\">'Direct combination'</span>,directCombination)</span><br><span class=\"line\"></span><br><span class=\"line\">cv2.waitKey(<span class=\"number\">0</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"opencv2/opencv.hpp\"</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> cv;</span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">getLaplacianPyramid</span><span class=\"params\">(Mat&amp; guassianPyramid, Mat&amp; laplacianPyramid)</span></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 从高斯金字塔计算拉普拉斯金字塔</span></span><br><span class=\"line\">    Mat downSampled;</span><br><span class=\"line\">    pyrDown(guassianPyramid,downSampled);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 上采样下采样</span></span><br><span class=\"line\">    Mat blurred;</span><br><span class=\"line\">    pyrUp(downSampled,blurred);</span><br><span class=\"line\"></span><br><span class=\"line\">    subtract(guassianPyramid, blurred, laplacianPyramid);</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">void</span> <span class=\"title\">combineImages</span><span class=\"params\">(Mat&amp; A, Mat&amp; B, Mat&amp; mask, Mat&amp; destination)</span></span>&#123;</span><br><span class=\"line\">    </span><br><span class=\"line\">    destination = Mat::zeros(A.rows, A.cols, CV_32FC3);</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">// 目的是求A和B的加权总和，分别具有权重掩码和1-掩码</span></span><br><span class=\"line\">    <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> y = <span class=\"number\">0</span>; y &lt; A.rows; y++)</span><br><span class=\"line\">    &#123;</span><br><span class=\"line\">        <span class=\"keyword\">for</span>(<span class=\"keyword\">int</span> x = <span class=\"number\">0</span>; x &lt; A.cols; x++)</span><br><span class=\"line\">        &#123;   </span><br><span class=\"line\">            Vec3f a = A.at&lt;Vec3f&gt;(Point(x,y));</span><br><span class=\"line\">            Vec3f b = B.at&lt;Vec3f&gt;(Point(x,y));</span><br><span class=\"line\">            Vec3f m = mask.at&lt;Vec3f&gt;(Point(x,y));</span><br><span class=\"line\">            </span><br><span class=\"line\">            <span class=\"keyword\">float</span> b_ = a[<span class=\"number\">0</span>]*m[<span class=\"number\">0</span>]+(<span class=\"number\">1</span>-m[<span class=\"number\">0</span>])*b[<span class=\"number\">0</span>];</span><br><span class=\"line\">            <span class=\"keyword\">float</span> g_ = a[<span class=\"number\">1</span>]*m[<span class=\"number\">1</span>]+(<span class=\"number\">1</span>-m[<span class=\"number\">1</span>])*b[<span class=\"number\">1</span>];</span><br><span class=\"line\">            <span class=\"keyword\">float</span> r_ = a[<span class=\"number\">2</span>]*m[<span class=\"number\">2</span>]+(<span class=\"number\">1</span>-m[<span class=\"number\">2</span>])*b[<span class=\"number\">2</span>];</span><br><span class=\"line\"></span><br><span class=\"line\">            destination.at&lt;Vec3f&gt;(y,x)[<span class=\"number\">0</span>] = b_;</span><br><span class=\"line\">            destination.at&lt;Vec3f&gt;(y,x)[<span class=\"number\">1</span>] = g_;</span><br><span class=\"line\">            destination.at&lt;Vec3f&gt;(y,x)[<span class=\"number\">2</span>] = r_;</span><br><span class=\"line\">        &#125;</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\">&#125;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">( <span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv )</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\">    <span class=\"comment\">// 读取图片</span></span><br><span class=\"line\">    Mat A = imread(<span class=\"string\">\"images/man.jpg\"</span>);</span><br><span class=\"line\">    Mat B = imread(<span class=\"string\">\"images/woman.jpg\"</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 转换成浮点数</span></span><br><span class=\"line\">    A.convertTo(A, CV_32FC3, <span class=\"number\">1</span>/<span class=\"number\">255.0</span>);</span><br><span class=\"line\">    B.convertTo(B, CV_32FC3, <span class=\"number\">1</span>/<span class=\"number\">255.0</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//在A的人脸周围创建一个粗糙的mask。</span></span><br><span class=\"line\">    Mat mask = Mat::zeros(A.rows, A.cols, CV_8UC3);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 创建飞机的边缘点</span></span><br><span class=\"line\">    Point points[<span class=\"number\">11</span>];</span><br><span class=\"line\">    points[<span class=\"number\">0</span>] = Point(<span class=\"number\">164</span>,<span class=\"number\">226</span>);</span><br><span class=\"line\">    points[<span class=\"number\">1</span>] = Point(<span class=\"number\">209</span>,<span class=\"number\">225</span>);</span><br><span class=\"line\">    points[<span class=\"number\">2</span>] = Point(<span class=\"number\">238</span>,<span class=\"number\">188</span>);</span><br><span class=\"line\">    points[<span class=\"number\">3</span>] = Point(<span class=\"number\">252</span>,<span class=\"number\">133</span>);</span><br><span class=\"line\">    points[<span class=\"number\">4</span>] = Point(<span class=\"number\">248</span>,<span class=\"number\">75</span>);</span><br><span class=\"line\">    points[<span class=\"number\">5</span>] = Point(<span class=\"number\">240</span>,<span class=\"number\">29</span>);</span><br><span class=\"line\">    points[<span class=\"number\">6</span>] = Point(<span class=\"number\">192</span>,<span class=\"number\">15</span>);</span><br><span class=\"line\">    points[<span class=\"number\">7</span>] = Point(<span class=\"number\">150</span>,<span class=\"number\">15</span>);</span><br><span class=\"line\">    points[<span class=\"number\">8</span>] = Point(<span class=\"number\">100</span>,<span class=\"number\">70</span>);</span><br><span class=\"line\">    points[<span class=\"number\">9</span>] = Point(<span class=\"number\">106</span>,<span class=\"number\">133</span>);</span><br><span class=\"line\">    points[<span class=\"number\">10</span>] = Point(<span class=\"number\">123</span>,<span class=\"number\">194</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">const</span> Point* polygon[<span class=\"number\">1</span>] = &#123;points&#125;; <span class=\"comment\">//构成点数组</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> npt[] = &#123;<span class=\"number\">11</span>&#125;; <span class=\"comment\">// 点数组的长度</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\">//填充由点形成的多边形</span></span><br><span class=\"line\">    fillPoly(mask, polygon, npt, <span class=\"number\">1</span>, Scalar(<span class=\"number\">255</span>, <span class=\"number\">255</span>, <span class=\"number\">255</span>));</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 转换成浮点数</span></span><br><span class=\"line\">    mask.convertTo(mask, CV_32FC3, <span class=\"number\">1</span>/<span class=\"number\">255.0</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 用 浮点数&lt;1.0 乘以获取男女面部的加权平均值</span></span><br><span class=\"line\">    mask = mask * <span class=\"number\">0.7</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 调整大小为2^（金字塔中的级别）的倍数，因此在本例中为32</span></span><br><span class=\"line\">    resize(A, A, Size(<span class=\"number\">384</span>,<span class=\"number\">352</span>));</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//B mask的大小应与A相同，以便以后进行乘法和加法运算</span></span><br><span class=\"line\">    resize(B, B, A.size());</span><br><span class=\"line\">    resize(mask, mask, A.size());</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//从原始图像开始（金字塔底）</span></span><br><span class=\"line\">    Mat guassianA = A.clone();</span><br><span class=\"line\">    Mat guassianB = B.clone();</span><br><span class=\"line\">    Mat guassianMask = mask.clone();</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 金字塔中的级别数，尝试使用不同的值。注意图像尺寸</span></span><br><span class=\"line\">    <span class=\"keyword\">int</span> maxIterations = <span class=\"number\">2</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 两种图像的组合拉普拉斯金字塔</span></span><br><span class=\"line\">    <span class=\"built_in\">vector</span>&lt;Mat&gt; combinedLaplacianPyramids;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">0</span>; i &lt; maxIterations; i++)&#123;</span><br><span class=\"line\">        <span class=\"comment\">// 计算A的拉普拉斯金字塔</span></span><br><span class=\"line\">        Mat laplacianA;</span><br><span class=\"line\">        getLaplacianPyramid(guassianA,laplacianA);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// 计算B的拉普拉斯金字塔</span></span><br><span class=\"line\">        Mat laplacianB;</span><br><span class=\"line\">        getLaplacianPyramid(guassianB,laplacianB);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// 结合拉普拉斯金字塔</span></span><br><span class=\"line\">        Mat combinedLaplacian;</span><br><span class=\"line\">        combineImages(laplacianA, laplacianB, guassianMask, combinedLaplacian);</span><br><span class=\"line\"> </span><br><span class=\"line\">        <span class=\"comment\">//在合并的拉普拉斯金字塔列表的开头插入combinedLaplacian</span></span><br><span class=\"line\">        combinedLaplacianPyramids.insert(combinedLaplacianPyramids.begin(),combinedLaplacian);</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">// 更新高斯金字塔以进行下一次迭代</span></span><br><span class=\"line\">        pyrDown(guassianA,guassianA);</span><br><span class=\"line\">        pyrDown(guassianB,guassianB);</span><br><span class=\"line\">        pyrDown(guassianMask,guassianMask);</span><br><span class=\"line\"></span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//合并最后一个guassian（拉普拉斯金字塔的顶层与guassian的金字塔相同）</span></span><br><span class=\"line\">    Mat lastCombined;</span><br><span class=\"line\">    combineImages(guassianA, guassianB, guassianMask, lastCombined);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 在合并的拉普拉斯金字塔列表的开头插入lastCombined</span></span><br><span class=\"line\">    combinedLaplacianPyramids.insert(combinedLaplacianPyramids.begin(),lastCombined);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 重建影像</span></span><br><span class=\"line\">    Mat blendedImage = combinedLaplacianPyramids[<span class=\"number\">0</span>];</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">for</span> (<span class=\"keyword\">int</span> i = <span class=\"number\">1</span>; i &lt; combinedLaplacianPyramids.size(); i++)&#123;</span><br><span class=\"line\">        <span class=\"comment\">// upSample并添加到下一个级别</span></span><br><span class=\"line\">        pyrUp(blendedImage,blendedImage);</span><br><span class=\"line\">        add(blendedImage, combinedLaplacianPyramids[i],blendedImage);</span><br><span class=\"line\">    &#125;</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 将混合图像放回原始位置的天空图像</span></span><br><span class=\"line\">    imshow(<span class=\"string\">\"blended\"</span>,blendedImage);</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">// 将混合图像放回原始位置的天空图像</span></span><br><span class=\"line\">    Mat directCombined;</span><br><span class=\"line\">    combineImages(A, B, mask, directCombined);</span><br><span class=\"line\">    imshow(<span class=\"string\">\"directCombined\"</span>,directCombined);</span><br><span class=\"line\">    waitKey(<span class=\"number\">0</span>);</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">return</span> <span class=\"number\">0</span>;</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://blog.mviai.com/images/FmB86oMyDHvbEWkBhIR11rOqea_E\" alt=\"image.png\"></p>\n"},{"title":"Jetson nano 配置","toc":false,"date":"2019-06-10T02:52:43.000Z","_content":"\n通过设置（system settings）-->network-->ipv4是查看dhcp分配ip为192.108.1.105；\njetson nano已经默认开启了openssh-server服务。\n可以通过xshell直接连上，用教程一中设置的jetson登录；\n\n![](https://blog.mviai.com/images/n1/n21.webp)\n\n可见Ubuntu版本是18.04.2\n为了方便操作，设置初始化root的密码；设置为jetson,具体操作如下；\n```\njetson@jetson-desktop:~$ sudo passwd\n[sudo] password for jetson: \nEnter new UNIX password: \nRetype new UNIX password: \npasswd: password updated successfully\njetson@jetson-desktop:~$ su\nPassword: \nroot@jetson-desktop:/home/jetson# \n\n\n设置允许超级管理员远程访问\n# vi /etc/ssh/sshd_config\n找到并用#注释掉这行：PermitRootLogin prohibit-password\n\n新建一行 添加：PermitRootLogin yes\n```\n重启服务\n```\n# service ssh restart\n```\n设置固定ip\n```\n/etc/network/interfaces\n# interfaces(5) file used by ifup(8) and ifdown(8)\n# Include files from /etc/network/interfaces.d:\nsource-directory /etc/network/interfaces.d\n\nauto eth0\niface eth0 inet static\naddress 192.168.1.105\nnetmask 255.255.255.0\ngateway 192.168.1.1\n\n\n\n/etc/systemd/resolved.conf\n[Resolve]\nDNS==8.8.8.8 223.5.5.5\n#FallbackDNS=8.8.8.8\n#Domains=\n#LLMNR=no\n#MulticastDNS=no\n#DNSSEC=no\n#Cache=yes\n#DNSStubListener=yes\n```\n\n重启再连接；联网正常；\n```\nroot@jetson-desktop:~# ping www.yangxin.com\nPING www.a.shifen.com (183.232.231.174) 56(84) bytes of data.\n64 bytes from 183.232.231.174 (183.232.231.174): icmp_seq=1 ttl=57 time=5.70 ms\n64 bytes from 183.232.231.174 (183.232.231.174): icmp_seq=2 ttl=57 time=5.61 ms\n^C\n--- www.a.shifen.com ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 1002ms\nrtt min/avg/max/mdev = 5.617/5.661/5.706/0.087 ms\n```\n\n2、默认组件\nJetson nano的镜像已经自带了JetPack，cuda，cudnn，opencv组件和sample，这些例子安装路径如下所示\n```\nTensorRT    /usr/src/tensorrt/samples/\nCUDA    /usr/local/cuda-/samples/\ncuDNN   /usr/src/cudnn_samples_v7/\nMultimedia API  /usr/src/tegra_multimedia_api/\nVisionWorks /usr/share/visionworks/sources/samples/ /usr/share/visionworks-tracking/sources/samples/ /usr/share/visionworks-sfm/sources/samples/\nOpenCV  /usr/share/OpenCV/samples/\n```\n2.0获取超级\n\n```\nsudo su\n```\n\n2.1核对CUDA\n```\nroot@jetson-desktop:/# nvcc -V\n-bash: nvcc: command not found\n```\n加入路径\n```\ngedit  ~/.bashrc\n```\n文件最后加入\n```\n\nexport CUBA_HOME=/usr/local/cuda-10.0\nexport LD_LIBRARY_PATH=/usr/local/cuda-10.0/lib64:$LD_LIBRARY_PATH\nexport PATH=/usr/local/cuda-10.0/bin:$PATH\n\n```\n\n\n执行使生效\n```\nsource ~/.bashrc\n```\n再次执行,显示cuda10.0\n```\nroot@jetson-desktop:/# source ~/.bashrc\nroot@jetson-desktop:/# nvcc -V\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2018 NVIDIA Corporation\nBuilt on Sun_Sep_30_21:09:22_CDT_2018\nCuda compilation tools, release 10.0, V10.0.166\nroot@jetson-desktop:/# \n```\n2.2核对opencv\n\n```\nroot@jetson-desktop:/# pkg-config opencv --modversion\n3.3.1\n```\n\n显示opencv当前版本是3.3.1\n2.3核对cuDNN\n```\nroot@jetson-desktop:/# cd /usr/src/cudnn_samples_v7/mnistCUDNN/\nroot@jetson-desktop:/usr/src/cudnn_samples_v7/mnistCUDNN# make\n/usr/local/cuda/bin/nvcc -ccbin g++ -I/usr/local/cuda/include -IFreeImage/include  -m64    -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_53,code=sm_53 -gencode arch=compute_53,code=compute_53 -o fp16_dev.o -c fp16_dev.cu\ng++ -I/usr/local/cuda/include -IFreeImage/include   -o fp16_emu.o -c fp16_emu.cpp\ng++ -I/usr/local/cuda/include -IFreeImage/include   -o mnistCUDNN.o -c mnistCUDNN.cpp\n/usr/local/cuda/bin/nvcc -ccbin g++   -m64      -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_53,code=sm_53 -gencode arch=compute_53,code=compute_53 -o mnistCUDNN fp16_dev.o fp16_emu.o mnistCUDNN.o -I/usr/local/cuda/include -IFreeImage/include  -LFreeImage/lib/linux/aarch64 -LFreeImage/lib/linux -lcudart -lcublas -lcudnn -lfreeimage -lstdc++ -lm\nFreeImage/lib/linux/aarch64/libfreeimage.a(strenc.o): In function `StrIOEncInit':\nstrenc.c:(.text+0x1294): warning: the use of `tmpnam' is dangerous, better use `mkstemp'\n\n\n执行sample\nroot@jetson-desktop:/usr/src/cudnn_samples_v7/mnistCUDNN# chmod a+x mnistCUDNN\nroot@jetson-desktop:/usr/src/cudnn_samples_v7/mnistCUDNN# ./mnistCUDNN \ncudnnGetVersion() : 7301 , CUDNN_VERSION from cudnn.h : 7301 (7.3.1)\nHost compiler version : GCC 7.3.0\nThere are 1 CUDA capable devices on your machine :\ndevice 0 : sms  1  Capabilities 5.3, SmClock 921.6 Mhz, MemSize (Mb) 3964, MemClock 12.8 Mhz, Ecc=0, boardGroupID=0\nUsing device 0\n\nTesting single precision\nLoading image data/one_28x28.pgm\nPerforming forward propagation ...\nTesting cudnnGetConvolutionForwardAlgorithm ...\nFastest algorithm is Algo 1\nTesting cudnnFindConvolutionForwardAlgorithm ...\n^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.341979 time requiring 3464 memory\n^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.395625 time requiring 0 memory\n^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 5.210573 time requiring 207360 memory\n^^^^ CUDNN_STATUS_SUCCESS for Algo 7: 5.213230 time requiring 2057744 memory\n^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 14.978802 time requiring 57600 memory\nResulting weights from Softmax:\n0.0000000 0.9999399 0.0000000 0.0000000 0.0000561 0.0000000 0.0000012 0.0000017 0.0000010 0.0000000 \nLoading image data/three_28x28.pgm\nPerforming forward propagation ...\nResulting weights from Softmax:\n0.0000000 0.0000000 0.0000000 0.9999288 0.0000000 0.0000711 0.0000000 0.0000000 0.0000000 0.0000000 \nLoading image data/five_28x28.pgm\nPerforming forward propagation ...\nResulting weights from Softmax:\n0.0000000 0.0000008 0.0000000 0.0000002 0.0000000 0.9999820 0.0000154 0.0000000 0.0000012 0.0000006 \n\nResult of classification: 1 3 5\n\nTest passed!\n\nTesting half precision (math in single precision)\nLoading image data/one_28x28.pgm\nPerforming forward propagation ...\nTesting cudnnGetConvolutionForwardAlgorithm ...\nFastest algorithm is Algo 1\nTesting cudnnFindConvolutionForwardAlgorithm ...\n^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.135000 time requiring 0 memory\n^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.170885 time requiring 3464 memory\n^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 0.282708 time requiring 28800 memory\n^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 1.206094 time requiring 207360 memory\n^^^^ CUDNN_STATUS_SUCCESS for Algo 5: 5.214895 time requiring 203008 memory\nResulting weights from Softmax:\n0.0000001 1.0000000 0.0000001 0.0000000 0.0000563 0.0000001 0.0000012 0.0000017 0.0000010 0.0000001 \nLoading image data/three_28x28.pgm\nPerforming forward propagation ...\nResulting weights from Softmax:\n0.0000000 0.0000000 0.0000000 1.0000000 0.0000000 0.0000714 0.0000000 0.0000000 0.0000000 0.0000000 \nLoading image data/five_28x28.pgm\nPerforming forward propagation ...\nResulting weights from Softmax:\n0.0000000 0.0000008 0.0000000 0.0000002 0.0000000 1.0000000 0.0000154 0.0000000 0.0000012 0.0000006 \n\nResult of classification: 1 3 5\n\nTest passed!\n```\n\n测试通过；\n2.4核对python\n```\nroot@jetson-desktop:/# python3\nPython 3.6.7 (default, Oct 22 2018, 11:32:17)\n[GCC 8.2.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n\n```\n\n\n\n\n默认已经安装python2.7 和python3.6.7版本\n3、增加python相关内容\n3.1安装pip3\n```\nroot@jetson-desktop:/# apt-get install python3-pip\n正在读取软件包列表... 完成\n正在分析软件包的依赖关系树       \n\n\nroot@jetson-desktop:/# pip3 -V\npip 9.0.1 from /usr/lib/python3/dist-packages (python 3.6)\n\n升级下版本到19.1;\nroot@jetson-desktop:~# python3 -m pip install --upgrade pip\nCollecting pip\n  Downloading https://files.pythonhosted.org/packages/f9/fb/863012b13912709c13cf5cfdbfb304fa6c727659d6290438e1a88df9d848/pip-19.1-py2.py3-none-any.whl (1.4MB)\n    100% |████████████████████████████████| 1.4MB 279kB/s \nInstalling collected packages: pip\n  Found existing installation: pip 9.0.1\n    Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usr\nSuccessfully installed pip-19.1\n\nroot@jetson-desktop:~# pip3 -V\npip 19.1 from /usr/local/lib/python3.6/dist-packages/pip (python 3.6)\n\n```\n3.2安装python-OpenCV\n```\nroot@jetson-desktop:/# sudo apt-get install python3-opencv\n正在读取软件包列表... 完成\n正在分析软件包的依赖关系树       \n正在读取状态信息... 完成       \n下列软件包是自动安装的并且现在不需要了：\n  apt-clone archdetect-deb busybox-static cryptsetup-bin dpkg-repack gir1.2-timezonemap-1.0 gir1.2-xkl-1.0 grub-common kde-window-manager kinit kio kpackagetool5 kwayland-data kwin-common kwin-data kwin-x11 libdebian-installer4\n  libkdecorations2-5v5 libkdecorations2private5v5 libkf5activities5 libkf5attica5 libkf5completion-data libkf5completion5 libkf5declarative-data libkf5declarative5 libkf5doctools5 libkf5globalaccel-data libkf5globalaccel5\n  libkf5globalaccelprivate5 libkf5idletime5 libkf5jobwidgets-data libkf5jobwidgets5 libkf5kcmutils-data libkf5kcmutils5 libkf5kiocore5 libkf5kiontlm5 libkf5kiowidgets5 libkf5newstuff-data libkf5newstuff5 libkf5newstuffcore5\n  libkf5package-data libkf5package5 libkf5plasma5 libkf5quickaddons5 libkf5solid5 libkf5solid5-data libkf5sonnet5-data libkf5sonnetcore5 libkf5sonnetui5 libkf5textwidgets-data libkf5textwidgets5 libkf5waylandclient5 libkf5waylandserver5\n  libkf5xmlgui-bin libkf5xmlgui-data libkf5xmlgui5 libkscreenlocker5 libkwin4-effect-builtins1 libkwineffects11 libkwinglutils11 libkwinxrenderutils11 libqgsttools-p1 libqt5designer5 libqt5help5 libqt5multimedia5 libqt5multimedia5-plugins\n  libqt5multimediaquick-p5 libqt5multimediawidgets5 libqt5opengl5 libqt5positioning5 libqt5printsupport5 libqt5qml5 libqt5quick5 libqt5quickwidgets5 libqt5sensors5 libqt5sql5 libqt5test5 libqt5webchannel5 libqt5webkit5 libxcb-composite0\n  libxcb-cursor0 libxcb-damage0 os-prober python3-dbus.mainloop.pyqt5 python3-icu python3-pam python3-pyqt5 python3-pyqt5.qtsvg python3-pyqt5.qtwebkit python3-sip qml-module-org-kde-kquickcontrolsaddons qml-module-qtmultimedia\n  qml-module-qtquick2 rdate\n使用'sudo apt autoremove'来卸载它(它们)。\n将会同时安装下列软件：\n  gdal-data libaec0 libarmadillo8 libarpack2 libcharls1 libdap25 libdapclient6v5 libepsilon1 libfreexl1 libfyba0 libgdal20 libgdcm2.8 libgeos-3.6.2 libgeos-c1v5 libgeotiff2 libgif7 libgl2ps1.4 libhdf4-0-alt libhdf5-100 libhdf5-openmpi-100\n  libjsoncpp1 libkmlbase1 libkmldom1 libkmlengine1 liblept5 libminizip1 libnetcdf-c++4 libnetcdf13 libodbc1 libogdi3.2 libopencv-calib3d3.2 libopencv-contrib3.2 libopencv-core3.2 libopencv-features2d3.2 libopencv-flann3.2\n  libopencv-highgui3.2 libopencv-imgcodecs3.2 libopencv-imgproc3.2 libopencv-ml3.2 libopencv-objdetect3.2 libopencv-photo3.2 libopencv-shape3.2 libopencv-stitching3.2 libopencv-superres3.2 libopencv-video3.2 libopencv-videoio3.2\n  libopencv-videostab3.2 libopencv-viz3.2 libpq5 libproj12 libqhull7 libsocket++1 libspatialite7 libsuperlu5 libsz2 libtcl8.6 libtesseract4 libtk8.6 liburiparser1 libvtk6.3 libxerces-c3.2 odbcinst odbcinst1debian2 proj-bin proj-data\n  python3-numpy\n建议安装：\n  geotiff-bin gdal-bin libgeotiff-epsg libhdf4-doc libhdf4-alt-dev hdf4-tools libmyodbc odbc-postgresql tdsodbc unixodbc-bin ogdi-bin tcl8.6 tk8.6 mpi-default-bin vtk6-doc vtk6-examples gfortran python-numpy-doc python3-nose\n  python3-numpy-dbg\n下列【新】软件包将被安装：\n  gdal-data libaec0 libarmadillo8 libarpack2 libcharls1 libdap25 libdapclient6v5 libepsilon1 libfreexl1 libfyba0 libgdal20 libgdcm2.8 libgeos-3.6.2 libgeos-c1v5 libgeotiff2 libgif7 libgl2ps1.4 libhdf4-0-alt libhdf5-100 libhdf5-openmpi-100\n  libjsoncpp1 libkmlbase1 libkmldom1 libkmlengine1 liblept5 libminizip1 libnetcdf-c++4 libnetcdf13 libodbc1 libogdi3.2 libopencv-calib3d3.2 libopencv-contrib3.2 libopencv-core3.2 libopencv-features2d3.2 libopencv-flann3.2\n  libopencv-highgui3.2 libopencv-imgcodecs3.2 libopencv-imgproc3.2 libopencv-ml3.2 libopencv-objdetect3.2 libopencv-photo3.2 libopencv-shape3.2 libopencv-stitching3.2 libopencv-superres3.2 libopencv-video3.2 libopencv-videoio3.2\n  libopencv-videostab3.2 libopencv-viz3.2 libpq5 libproj12 libqhull7 libsocket++1 libspatialite7 libsuperlu5 libsz2 libtcl8.6 libtesseract4 libtk8.6 liburiparser1 libvtk6.3 libxerces-c3.2 odbcinst odbcinst1debian2 proj-bin proj-data\n  python3-numpy python3-opencv\n升级了 0 个软件包，新安装了 67 个软件包，要卸载 0 个软件包，有 315 个软件包未被升级。\n需要下载 55.8 MB 的归档。\n解压缩后会消耗 265 MB 的额外空间。\n您希望继续执行吗？ [Y/n] y\n```\n\n测试下看看\n```\nroot@jetson-desktop:~# python3\nPython 3.6.7 (default, Oct 22 2018, 11:32:17) \n[GCC 8.2.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import cv2\n>>> print(cv2.__version__)\n3.2.0\n>>> \n\n```\n默认3.2版本，和系统本身自带的不统一; \npython2.7版本自带的opencv\n```\nroot@jetson-desktop:~# python\nPython 2.7.15rc1 (default, Nov 12 2018, 14:31:15) \n[GCC 7.3.0] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import cv2\n>>>  print(cv2.__version__)\n  File \"<stdin>\", line 1\n    print(cv2.__version__)\n    ^\nIndentationError: unexpected indent\n>>> print(cv2.__version__)\n3.3.1\n>>> \n```\n\npython3能安装的OpenCV的版本太低;稍后再解决;\n4，更新系统\n\n\n执行命令\n```\napt-get update && apt-get upgrade -y\n```\n```\n效果片段如下：下载内容较多，可能时间会很长。\n升级了 305 个软件包，新安装了 0 个软件包，要卸载 0 个软件包，有 10 个软件包未被升级。\n需要下载 396 MB/396 MB 的归档。\n解压缩后会消耗 69.5 MB 的额外空间。\n命中:13 http://ports.ubuntu.com/ubuntu-ports bionic InRelease                                             \n获取:1 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 login arm64 1:4.5-1ubuntu2 [301 kB]\n命中:14 http://ports.ubuntu.com/ubuntu-ports bionic-updates InRelease                                     \n命中:15 http://ports.ubuntu.com/ubuntu-ports bionic-backports InRelease                                   \n命中:16 http://ports.ubuntu.com/ubuntu-ports bionic-security InRelease                                    \n正在读取软件包列表... 完成 20%]                                              80.2 kB/s 1小时 22分 13秒    \n获取:2 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libgomp1 arm64 8.3.0-6ubuntu1~18.04 [69.6 kB]                                                                                                                             \n获取:3 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libitm1 arm64 8.3.0-6ubuntu1~18.04 [24.3 kB]                                                                                                                              \n获取:4 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 gcc-8-base arm64 8.3.0-6ubuntu1~18.04 [18.7 kB]                                                                                                                           \n获取:5 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libgcc1 arm64 1:8.3.0-6ubuntu1~18.04 [34.4 kB]                                                                                                                            \n获取:6 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 liblsan0 arm64 8.3.0-6ubuntu1~18.04 [121 kB]                                                                                                                              \n获取:7 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libtsan0 arm64 8.3.0-6ubuntu1~18.04 [269 kB]                                                                                                                              \n获取:8 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libcc1-0 arm64 8.3.0-6ubuntu1~18.04 [46.4 kB]                                                                                                                             \n获取:9 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libatomic1 arm64 8.3.0-6ubuntu1~18.04 [9,164 B]                                                                                                                           \n获取:10 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libstdc++6 arm64 8.3.0-6ubuntu1~18.04 [372 kB]                                                                                                                           \n获取:11 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libnss-systemd arm64 237-3ubuntu10.21 [90.1 kB]                                                                                                                          \n获取:12 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libudev1 arm64 237-3ubuntu10.21 [45.2 kB]                                                                                                                                \n获取:13 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 udev arm64 237-3ubuntu10.21 [1,050 kB]                                                                                                                                   \n获取:14 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libnss-myhostname arm64 237-3ubuntu10.21 [30.2 kB]                                                                                                                       \n获取:15 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libpam-systemd arm64 237-3ubuntu10.21 [92.8 kB]                                                                                                                          \n获取:17 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libsystemd0 arm64 237-3ubuntu10.21 [171 kB]                                                                                                                              \n获取:18 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libpam0g arm64 1.1.8-3.6ubuntu2.18.04.1 [51.1 kB]                                                                                                                        \n获取:16 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 systemd arm64 237-3ubuntu10.21 [2,551 kB]                                                                                                                                \n获取:19 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libpam-modules-bin arm64 1.1.8-3.6ubuntu2.18.04.1 [32.7 kB]\n```\n默认的更新源国内访问实在太慢了。\n/etc/apt/sources.list文件\n```\ngudit /etc/apt/sources.list \n```\n里面的链接全部替换成清华的源\n```\ndeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main multiverse restricted universe\ndeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main multiverse restricted universe\ndeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main multiverse restricted universe\ndeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main multiverse restricted universe\ndeb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main multiverse restricted universe\ndeb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main multiverse restricted universe\ndeb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main multiverse restricted universe\ndeb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main multiverse restricted universe\n\n然后重新执行;\n获取:84 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/main arm64 Packages [1,024 B]                                                                                                                                         \n获取:85 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/main Translation-en [448 B]                                                                                                                                           \n获取:86 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/universe arm64 Packages [3,468 B]                                                                                                                                     \n获取:87 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/universe Translation-en [1,604 B]                                                                                                                                     \n获取:88 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/universe arm64 DEP-11 Metadata [7,156 B]                                                                                                                              \n获取:89 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/universe DEP-11 48x48 Icons [29 B]                                                                                                                                    \n获取:90 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/universe DEP-11 64x64 Icons [29 B]                                                                                                                                    \n已下载 45.5 MB，耗时 16秒 (2,900 kB/s)    \n```\n速度超快！\n5，关闭桌面系统\n先看下内存\n```\nroot@jetson-desktop:~# free\n              total        used        free      shared  buff/cache   available\nMem:        4059712      572136     2529292       19044      958284     3304544\nSwap:             0           0           0\nroot@jetson-desktop:~# \n```\n\n关闭桌面\n```\nroot@jetson-desktop:~# sudo systemctl set-default multi-user.target\nRemoved /etc/systemd/system/default.target.\nCreated symlink /etc/systemd/system/default.target → /lib/systemd/system/multi-user.target.\nroot@jetson-desktop:~# reboot\n```\n再看内存\n```\nroot@jetson-desktop:~# free\n              total        used        free      shared  buff/cache   available\nMem:        4059712      321340     3511972       17616      226400     3573020\nSwap:             0           0           0\nroot@jetson-desktop:~#\n```\n参考链接：https://www.jianshu.com/p/1fac6cdedd0d","source":"_posts/Nvidia-Jetson-nano-配置.md","raw":"---\ntitle: Jetson nano 配置\ntags:\n  - jetson nano\ncategories:\n  - 工具\n  - 嵌入式\n  - nvidia\ntoc: false\ndate: 2019-06-10 10:52:43\n---\n\n通过设置（system settings）-->network-->ipv4是查看dhcp分配ip为192.108.1.105；\njetson nano已经默认开启了openssh-server服务。\n可以通过xshell直接连上，用教程一中设置的jetson登录；\n\n![](https://blog.mviai.com/images/n1/n21.webp)\n\n可见Ubuntu版本是18.04.2\n为了方便操作，设置初始化root的密码；设置为jetson,具体操作如下；\n```\njetson@jetson-desktop:~$ sudo passwd\n[sudo] password for jetson: \nEnter new UNIX password: \nRetype new UNIX password: \npasswd: password updated successfully\njetson@jetson-desktop:~$ su\nPassword: \nroot@jetson-desktop:/home/jetson# \n\n\n设置允许超级管理员远程访问\n# vi /etc/ssh/sshd_config\n找到并用#注释掉这行：PermitRootLogin prohibit-password\n\n新建一行 添加：PermitRootLogin yes\n```\n重启服务\n```\n# service ssh restart\n```\n设置固定ip\n```\n/etc/network/interfaces\n# interfaces(5) file used by ifup(8) and ifdown(8)\n# Include files from /etc/network/interfaces.d:\nsource-directory /etc/network/interfaces.d\n\nauto eth0\niface eth0 inet static\naddress 192.168.1.105\nnetmask 255.255.255.0\ngateway 192.168.1.1\n\n\n\n/etc/systemd/resolved.conf\n[Resolve]\nDNS==8.8.8.8 223.5.5.5\n#FallbackDNS=8.8.8.8\n#Domains=\n#LLMNR=no\n#MulticastDNS=no\n#DNSSEC=no\n#Cache=yes\n#DNSStubListener=yes\n```\n\n重启再连接；联网正常；\n```\nroot@jetson-desktop:~# ping www.yangxin.com\nPING www.a.shifen.com (183.232.231.174) 56(84) bytes of data.\n64 bytes from 183.232.231.174 (183.232.231.174): icmp_seq=1 ttl=57 time=5.70 ms\n64 bytes from 183.232.231.174 (183.232.231.174): icmp_seq=2 ttl=57 time=5.61 ms\n^C\n--- www.a.shifen.com ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 1002ms\nrtt min/avg/max/mdev = 5.617/5.661/5.706/0.087 ms\n```\n\n2、默认组件\nJetson nano的镜像已经自带了JetPack，cuda，cudnn，opencv组件和sample，这些例子安装路径如下所示\n```\nTensorRT    /usr/src/tensorrt/samples/\nCUDA    /usr/local/cuda-/samples/\ncuDNN   /usr/src/cudnn_samples_v7/\nMultimedia API  /usr/src/tegra_multimedia_api/\nVisionWorks /usr/share/visionworks/sources/samples/ /usr/share/visionworks-tracking/sources/samples/ /usr/share/visionworks-sfm/sources/samples/\nOpenCV  /usr/share/OpenCV/samples/\n```\n2.0获取超级\n\n```\nsudo su\n```\n\n2.1核对CUDA\n```\nroot@jetson-desktop:/# nvcc -V\n-bash: nvcc: command not found\n```\n加入路径\n```\ngedit  ~/.bashrc\n```\n文件最后加入\n```\n\nexport CUBA_HOME=/usr/local/cuda-10.0\nexport LD_LIBRARY_PATH=/usr/local/cuda-10.0/lib64:$LD_LIBRARY_PATH\nexport PATH=/usr/local/cuda-10.0/bin:$PATH\n\n```\n\n\n执行使生效\n```\nsource ~/.bashrc\n```\n再次执行,显示cuda10.0\n```\nroot@jetson-desktop:/# source ~/.bashrc\nroot@jetson-desktop:/# nvcc -V\nnvcc: NVIDIA (R) Cuda compiler driver\nCopyright (c) 2005-2018 NVIDIA Corporation\nBuilt on Sun_Sep_30_21:09:22_CDT_2018\nCuda compilation tools, release 10.0, V10.0.166\nroot@jetson-desktop:/# \n```\n2.2核对opencv\n\n```\nroot@jetson-desktop:/# pkg-config opencv --modversion\n3.3.1\n```\n\n显示opencv当前版本是3.3.1\n2.3核对cuDNN\n```\nroot@jetson-desktop:/# cd /usr/src/cudnn_samples_v7/mnistCUDNN/\nroot@jetson-desktop:/usr/src/cudnn_samples_v7/mnistCUDNN# make\n/usr/local/cuda/bin/nvcc -ccbin g++ -I/usr/local/cuda/include -IFreeImage/include  -m64    -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_53,code=sm_53 -gencode arch=compute_53,code=compute_53 -o fp16_dev.o -c fp16_dev.cu\ng++ -I/usr/local/cuda/include -IFreeImage/include   -o fp16_emu.o -c fp16_emu.cpp\ng++ -I/usr/local/cuda/include -IFreeImage/include   -o mnistCUDNN.o -c mnistCUDNN.cpp\n/usr/local/cuda/bin/nvcc -ccbin g++   -m64      -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_53,code=sm_53 -gencode arch=compute_53,code=compute_53 -o mnistCUDNN fp16_dev.o fp16_emu.o mnistCUDNN.o -I/usr/local/cuda/include -IFreeImage/include  -LFreeImage/lib/linux/aarch64 -LFreeImage/lib/linux -lcudart -lcublas -lcudnn -lfreeimage -lstdc++ -lm\nFreeImage/lib/linux/aarch64/libfreeimage.a(strenc.o): In function `StrIOEncInit':\nstrenc.c:(.text+0x1294): warning: the use of `tmpnam' is dangerous, better use `mkstemp'\n\n\n执行sample\nroot@jetson-desktop:/usr/src/cudnn_samples_v7/mnistCUDNN# chmod a+x mnistCUDNN\nroot@jetson-desktop:/usr/src/cudnn_samples_v7/mnistCUDNN# ./mnistCUDNN \ncudnnGetVersion() : 7301 , CUDNN_VERSION from cudnn.h : 7301 (7.3.1)\nHost compiler version : GCC 7.3.0\nThere are 1 CUDA capable devices on your machine :\ndevice 0 : sms  1  Capabilities 5.3, SmClock 921.6 Mhz, MemSize (Mb) 3964, MemClock 12.8 Mhz, Ecc=0, boardGroupID=0\nUsing device 0\n\nTesting single precision\nLoading image data/one_28x28.pgm\nPerforming forward propagation ...\nTesting cudnnGetConvolutionForwardAlgorithm ...\nFastest algorithm is Algo 1\nTesting cudnnFindConvolutionForwardAlgorithm ...\n^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.341979 time requiring 3464 memory\n^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.395625 time requiring 0 memory\n^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 5.210573 time requiring 207360 memory\n^^^^ CUDNN_STATUS_SUCCESS for Algo 7: 5.213230 time requiring 2057744 memory\n^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 14.978802 time requiring 57600 memory\nResulting weights from Softmax:\n0.0000000 0.9999399 0.0000000 0.0000000 0.0000561 0.0000000 0.0000012 0.0000017 0.0000010 0.0000000 \nLoading image data/three_28x28.pgm\nPerforming forward propagation ...\nResulting weights from Softmax:\n0.0000000 0.0000000 0.0000000 0.9999288 0.0000000 0.0000711 0.0000000 0.0000000 0.0000000 0.0000000 \nLoading image data/five_28x28.pgm\nPerforming forward propagation ...\nResulting weights from Softmax:\n0.0000000 0.0000008 0.0000000 0.0000002 0.0000000 0.9999820 0.0000154 0.0000000 0.0000012 0.0000006 \n\nResult of classification: 1 3 5\n\nTest passed!\n\nTesting half precision (math in single precision)\nLoading image data/one_28x28.pgm\nPerforming forward propagation ...\nTesting cudnnGetConvolutionForwardAlgorithm ...\nFastest algorithm is Algo 1\nTesting cudnnFindConvolutionForwardAlgorithm ...\n^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.135000 time requiring 0 memory\n^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.170885 time requiring 3464 memory\n^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 0.282708 time requiring 28800 memory\n^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 1.206094 time requiring 207360 memory\n^^^^ CUDNN_STATUS_SUCCESS for Algo 5: 5.214895 time requiring 203008 memory\nResulting weights from Softmax:\n0.0000001 1.0000000 0.0000001 0.0000000 0.0000563 0.0000001 0.0000012 0.0000017 0.0000010 0.0000001 \nLoading image data/three_28x28.pgm\nPerforming forward propagation ...\nResulting weights from Softmax:\n0.0000000 0.0000000 0.0000000 1.0000000 0.0000000 0.0000714 0.0000000 0.0000000 0.0000000 0.0000000 \nLoading image data/five_28x28.pgm\nPerforming forward propagation ...\nResulting weights from Softmax:\n0.0000000 0.0000008 0.0000000 0.0000002 0.0000000 1.0000000 0.0000154 0.0000000 0.0000012 0.0000006 \n\nResult of classification: 1 3 5\n\nTest passed!\n```\n\n测试通过；\n2.4核对python\n```\nroot@jetson-desktop:/# python3\nPython 3.6.7 (default, Oct 22 2018, 11:32:17)\n[GCC 8.2.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n\n```\n\n\n\n\n默认已经安装python2.7 和python3.6.7版本\n3、增加python相关内容\n3.1安装pip3\n```\nroot@jetson-desktop:/# apt-get install python3-pip\n正在读取软件包列表... 完成\n正在分析软件包的依赖关系树       \n\n\nroot@jetson-desktop:/# pip3 -V\npip 9.0.1 from /usr/lib/python3/dist-packages (python 3.6)\n\n升级下版本到19.1;\nroot@jetson-desktop:~# python3 -m pip install --upgrade pip\nCollecting pip\n  Downloading https://files.pythonhosted.org/packages/f9/fb/863012b13912709c13cf5cfdbfb304fa6c727659d6290438e1a88df9d848/pip-19.1-py2.py3-none-any.whl (1.4MB)\n    100% |████████████████████████████████| 1.4MB 279kB/s \nInstalling collected packages: pip\n  Found existing installation: pip 9.0.1\n    Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usr\nSuccessfully installed pip-19.1\n\nroot@jetson-desktop:~# pip3 -V\npip 19.1 from /usr/local/lib/python3.6/dist-packages/pip (python 3.6)\n\n```\n3.2安装python-OpenCV\n```\nroot@jetson-desktop:/# sudo apt-get install python3-opencv\n正在读取软件包列表... 完成\n正在分析软件包的依赖关系树       \n正在读取状态信息... 完成       \n下列软件包是自动安装的并且现在不需要了：\n  apt-clone archdetect-deb busybox-static cryptsetup-bin dpkg-repack gir1.2-timezonemap-1.0 gir1.2-xkl-1.0 grub-common kde-window-manager kinit kio kpackagetool5 kwayland-data kwin-common kwin-data kwin-x11 libdebian-installer4\n  libkdecorations2-5v5 libkdecorations2private5v5 libkf5activities5 libkf5attica5 libkf5completion-data libkf5completion5 libkf5declarative-data libkf5declarative5 libkf5doctools5 libkf5globalaccel-data libkf5globalaccel5\n  libkf5globalaccelprivate5 libkf5idletime5 libkf5jobwidgets-data libkf5jobwidgets5 libkf5kcmutils-data libkf5kcmutils5 libkf5kiocore5 libkf5kiontlm5 libkf5kiowidgets5 libkf5newstuff-data libkf5newstuff5 libkf5newstuffcore5\n  libkf5package-data libkf5package5 libkf5plasma5 libkf5quickaddons5 libkf5solid5 libkf5solid5-data libkf5sonnet5-data libkf5sonnetcore5 libkf5sonnetui5 libkf5textwidgets-data libkf5textwidgets5 libkf5waylandclient5 libkf5waylandserver5\n  libkf5xmlgui-bin libkf5xmlgui-data libkf5xmlgui5 libkscreenlocker5 libkwin4-effect-builtins1 libkwineffects11 libkwinglutils11 libkwinxrenderutils11 libqgsttools-p1 libqt5designer5 libqt5help5 libqt5multimedia5 libqt5multimedia5-plugins\n  libqt5multimediaquick-p5 libqt5multimediawidgets5 libqt5opengl5 libqt5positioning5 libqt5printsupport5 libqt5qml5 libqt5quick5 libqt5quickwidgets5 libqt5sensors5 libqt5sql5 libqt5test5 libqt5webchannel5 libqt5webkit5 libxcb-composite0\n  libxcb-cursor0 libxcb-damage0 os-prober python3-dbus.mainloop.pyqt5 python3-icu python3-pam python3-pyqt5 python3-pyqt5.qtsvg python3-pyqt5.qtwebkit python3-sip qml-module-org-kde-kquickcontrolsaddons qml-module-qtmultimedia\n  qml-module-qtquick2 rdate\n使用'sudo apt autoremove'来卸载它(它们)。\n将会同时安装下列软件：\n  gdal-data libaec0 libarmadillo8 libarpack2 libcharls1 libdap25 libdapclient6v5 libepsilon1 libfreexl1 libfyba0 libgdal20 libgdcm2.8 libgeos-3.6.2 libgeos-c1v5 libgeotiff2 libgif7 libgl2ps1.4 libhdf4-0-alt libhdf5-100 libhdf5-openmpi-100\n  libjsoncpp1 libkmlbase1 libkmldom1 libkmlengine1 liblept5 libminizip1 libnetcdf-c++4 libnetcdf13 libodbc1 libogdi3.2 libopencv-calib3d3.2 libopencv-contrib3.2 libopencv-core3.2 libopencv-features2d3.2 libopencv-flann3.2\n  libopencv-highgui3.2 libopencv-imgcodecs3.2 libopencv-imgproc3.2 libopencv-ml3.2 libopencv-objdetect3.2 libopencv-photo3.2 libopencv-shape3.2 libopencv-stitching3.2 libopencv-superres3.2 libopencv-video3.2 libopencv-videoio3.2\n  libopencv-videostab3.2 libopencv-viz3.2 libpq5 libproj12 libqhull7 libsocket++1 libspatialite7 libsuperlu5 libsz2 libtcl8.6 libtesseract4 libtk8.6 liburiparser1 libvtk6.3 libxerces-c3.2 odbcinst odbcinst1debian2 proj-bin proj-data\n  python3-numpy\n建议安装：\n  geotiff-bin gdal-bin libgeotiff-epsg libhdf4-doc libhdf4-alt-dev hdf4-tools libmyodbc odbc-postgresql tdsodbc unixodbc-bin ogdi-bin tcl8.6 tk8.6 mpi-default-bin vtk6-doc vtk6-examples gfortran python-numpy-doc python3-nose\n  python3-numpy-dbg\n下列【新】软件包将被安装：\n  gdal-data libaec0 libarmadillo8 libarpack2 libcharls1 libdap25 libdapclient6v5 libepsilon1 libfreexl1 libfyba0 libgdal20 libgdcm2.8 libgeos-3.6.2 libgeos-c1v5 libgeotiff2 libgif7 libgl2ps1.4 libhdf4-0-alt libhdf5-100 libhdf5-openmpi-100\n  libjsoncpp1 libkmlbase1 libkmldom1 libkmlengine1 liblept5 libminizip1 libnetcdf-c++4 libnetcdf13 libodbc1 libogdi3.2 libopencv-calib3d3.2 libopencv-contrib3.2 libopencv-core3.2 libopencv-features2d3.2 libopencv-flann3.2\n  libopencv-highgui3.2 libopencv-imgcodecs3.2 libopencv-imgproc3.2 libopencv-ml3.2 libopencv-objdetect3.2 libopencv-photo3.2 libopencv-shape3.2 libopencv-stitching3.2 libopencv-superres3.2 libopencv-video3.2 libopencv-videoio3.2\n  libopencv-videostab3.2 libopencv-viz3.2 libpq5 libproj12 libqhull7 libsocket++1 libspatialite7 libsuperlu5 libsz2 libtcl8.6 libtesseract4 libtk8.6 liburiparser1 libvtk6.3 libxerces-c3.2 odbcinst odbcinst1debian2 proj-bin proj-data\n  python3-numpy python3-opencv\n升级了 0 个软件包，新安装了 67 个软件包，要卸载 0 个软件包，有 315 个软件包未被升级。\n需要下载 55.8 MB 的归档。\n解压缩后会消耗 265 MB 的额外空间。\n您希望继续执行吗？ [Y/n] y\n```\n\n测试下看看\n```\nroot@jetson-desktop:~# python3\nPython 3.6.7 (default, Oct 22 2018, 11:32:17) \n[GCC 8.2.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import cv2\n>>> print(cv2.__version__)\n3.2.0\n>>> \n\n```\n默认3.2版本，和系统本身自带的不统一; \npython2.7版本自带的opencv\n```\nroot@jetson-desktop:~# python\nPython 2.7.15rc1 (default, Nov 12 2018, 14:31:15) \n[GCC 7.3.0] on linux2\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n>>> import cv2\n>>>  print(cv2.__version__)\n  File \"<stdin>\", line 1\n    print(cv2.__version__)\n    ^\nIndentationError: unexpected indent\n>>> print(cv2.__version__)\n3.3.1\n>>> \n```\n\npython3能安装的OpenCV的版本太低;稍后再解决;\n4，更新系统\n\n\n执行命令\n```\napt-get update && apt-get upgrade -y\n```\n```\n效果片段如下：下载内容较多，可能时间会很长。\n升级了 305 个软件包，新安装了 0 个软件包，要卸载 0 个软件包，有 10 个软件包未被升级。\n需要下载 396 MB/396 MB 的归档。\n解压缩后会消耗 69.5 MB 的额外空间。\n命中:13 http://ports.ubuntu.com/ubuntu-ports bionic InRelease                                             \n获取:1 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 login arm64 1:4.5-1ubuntu2 [301 kB]\n命中:14 http://ports.ubuntu.com/ubuntu-ports bionic-updates InRelease                                     \n命中:15 http://ports.ubuntu.com/ubuntu-ports bionic-backports InRelease                                   \n命中:16 http://ports.ubuntu.com/ubuntu-ports bionic-security InRelease                                    \n正在读取软件包列表... 完成 20%]                                              80.2 kB/s 1小时 22分 13秒    \n获取:2 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libgomp1 arm64 8.3.0-6ubuntu1~18.04 [69.6 kB]                                                                                                                             \n获取:3 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libitm1 arm64 8.3.0-6ubuntu1~18.04 [24.3 kB]                                                                                                                              \n获取:4 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 gcc-8-base arm64 8.3.0-6ubuntu1~18.04 [18.7 kB]                                                                                                                           \n获取:5 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libgcc1 arm64 1:8.3.0-6ubuntu1~18.04 [34.4 kB]                                                                                                                            \n获取:6 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 liblsan0 arm64 8.3.0-6ubuntu1~18.04 [121 kB]                                                                                                                              \n获取:7 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libtsan0 arm64 8.3.0-6ubuntu1~18.04 [269 kB]                                                                                                                              \n获取:8 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libcc1-0 arm64 8.3.0-6ubuntu1~18.04 [46.4 kB]                                                                                                                             \n获取:9 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libatomic1 arm64 8.3.0-6ubuntu1~18.04 [9,164 B]                                                                                                                           \n获取:10 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libstdc++6 arm64 8.3.0-6ubuntu1~18.04 [372 kB]                                                                                                                           \n获取:11 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libnss-systemd arm64 237-3ubuntu10.21 [90.1 kB]                                                                                                                          \n获取:12 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libudev1 arm64 237-3ubuntu10.21 [45.2 kB]                                                                                                                                \n获取:13 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 udev arm64 237-3ubuntu10.21 [1,050 kB]                                                                                                                                   \n获取:14 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libnss-myhostname arm64 237-3ubuntu10.21 [30.2 kB]                                                                                                                       \n获取:15 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libpam-systemd arm64 237-3ubuntu10.21 [92.8 kB]                                                                                                                          \n获取:17 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libsystemd0 arm64 237-3ubuntu10.21 [171 kB]                                                                                                                              \n获取:18 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libpam0g arm64 1.1.8-3.6ubuntu2.18.04.1 [51.1 kB]                                                                                                                        \n获取:16 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 systemd arm64 237-3ubuntu10.21 [2,551 kB]                                                                                                                                \n获取:19 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libpam-modules-bin arm64 1.1.8-3.6ubuntu2.18.04.1 [32.7 kB]\n```\n默认的更新源国内访问实在太慢了。\n/etc/apt/sources.list文件\n```\ngudit /etc/apt/sources.list \n```\n里面的链接全部替换成清华的源\n```\ndeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main multiverse restricted universe\ndeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main multiverse restricted universe\ndeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main multiverse restricted universe\ndeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main multiverse restricted universe\ndeb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main multiverse restricted universe\ndeb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main multiverse restricted universe\ndeb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main multiverse restricted universe\ndeb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main multiverse restricted universe\n\n然后重新执行;\n获取:84 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/main arm64 Packages [1,024 B]                                                                                                                                         \n获取:85 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/main Translation-en [448 B]                                                                                                                                           \n获取:86 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/universe arm64 Packages [3,468 B]                                                                                                                                     \n获取:87 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/universe Translation-en [1,604 B]                                                                                                                                     \n获取:88 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/universe arm64 DEP-11 Metadata [7,156 B]                                                                                                                              \n获取:89 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/universe DEP-11 48x48 Icons [29 B]                                                                                                                                    \n获取:90 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/universe DEP-11 64x64 Icons [29 B]                                                                                                                                    \n已下载 45.5 MB，耗时 16秒 (2,900 kB/s)    \n```\n速度超快！\n5，关闭桌面系统\n先看下内存\n```\nroot@jetson-desktop:~# free\n              total        used        free      shared  buff/cache   available\nMem:        4059712      572136     2529292       19044      958284     3304544\nSwap:             0           0           0\nroot@jetson-desktop:~# \n```\n\n关闭桌面\n```\nroot@jetson-desktop:~# sudo systemctl set-default multi-user.target\nRemoved /etc/systemd/system/default.target.\nCreated symlink /etc/systemd/system/default.target → /lib/systemd/system/multi-user.target.\nroot@jetson-desktop:~# reboot\n```\n再看内存\n```\nroot@jetson-desktop:~# free\n              total        used        free      shared  buff/cache   available\nMem:        4059712      321340     3511972       17616      226400     3573020\nSwap:             0           0           0\nroot@jetson-desktop:~#\n```\n参考链接：https://www.jianshu.com/p/1fac6cdedd0d","slug":"Nvidia-Jetson-nano-配置","published":1,"updated":"2021-07-26T10:01:05.508Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m19000digtaprt0ukxv","content":"<p>通过设置（system settings）–&gt;network–&gt;ipv4是查看dhcp分配ip为192.108.1.105；<br>jetson nano已经默认开启了openssh-server服务。<br>可以通过xshell直接连上，用教程一中设置的jetson登录；</p>\n<p><img src=\"https://blog.mviai.com/images/n1/n21.webp\" alt></p>\n<p>可见Ubuntu版本是18.04.2<br>为了方便操作，设置初始化root的密码；设置为jetson,具体操作如下；<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">jetson@jetson-desktop:~$ sudo passwd</span><br><span class=\"line\">[sudo] password for jetson: </span><br><span class=\"line\">Enter new UNIX password: </span><br><span class=\"line\">Retype new UNIX password: </span><br><span class=\"line\">passwd: password updated successfully</span><br><span class=\"line\">jetson@jetson-desktop:~$ su</span><br><span class=\"line\">Password: </span><br><span class=\"line\">root@jetson-desktop:/home/jetson# </span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">设置允许超级管理员远程访问</span><br><span class=\"line\"># vi /etc/ssh/sshd_config</span><br><span class=\"line\">找到并用#注释掉这行：PermitRootLogin prohibit-password</span><br><span class=\"line\"></span><br><span class=\"line\">新建一行 添加：PermitRootLogin yes</span><br></pre></td></tr></table></figure></p>\n<p>重启服务<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># service ssh restart</span><br></pre></td></tr></table></figure></p>\n<p>设置固定ip<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/etc/network/interfaces</span><br><span class=\"line\"># interfaces(5) file used by ifup(8) and ifdown(8)</span><br><span class=\"line\"># Include files from /etc/network/interfaces.d:</span><br><span class=\"line\">source-directory /etc/network/interfaces.d</span><br><span class=\"line\"></span><br><span class=\"line\">auto eth0</span><br><span class=\"line\">iface eth0 inet static</span><br><span class=\"line\">address 192.168.1.105</span><br><span class=\"line\">netmask 255.255.255.0</span><br><span class=\"line\">gateway 192.168.1.1</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">/etc/systemd/resolved.conf</span><br><span class=\"line\">[Resolve]</span><br><span class=\"line\">DNS==8.8.8.8 223.5.5.5</span><br><span class=\"line\">#FallbackDNS=8.8.8.8</span><br><span class=\"line\">#Domains=</span><br><span class=\"line\">#LLMNR=no</span><br><span class=\"line\">#MulticastDNS=no</span><br><span class=\"line\">#DNSSEC=no</span><br><span class=\"line\">#Cache=yes</span><br><span class=\"line\">#DNSStubListener=yes</span><br></pre></td></tr></table></figure></p>\n<p>重启再连接；联网正常；<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:~# ping www.yangxin.com</span><br><span class=\"line\">PING www.a.shifen.com (183.232.231.174) 56(84) bytes of data.</span><br><span class=\"line\">64 bytes from 183.232.231.174 (183.232.231.174): icmp_seq=1 ttl=57 time=5.70 ms</span><br><span class=\"line\">64 bytes from 183.232.231.174 (183.232.231.174): icmp_seq=2 ttl=57 time=5.61 ms</span><br><span class=\"line\">^C</span><br><span class=\"line\">--- www.a.shifen.com ping statistics ---</span><br><span class=\"line\">2 packets transmitted, 2 received, 0% packet loss, time 1002ms</span><br><span class=\"line\">rtt min/avg/max/mdev = 5.617/5.661/5.706/0.087 ms</span><br></pre></td></tr></table></figure></p>\n<p>2、默认组件<br>Jetson nano的镜像已经自带了JetPack，cuda，cudnn，opencv组件和sample，这些例子安装路径如下所示<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TensorRT    /usr/src/tensorrt/samples/</span><br><span class=\"line\">CUDA    /usr/local/cuda-/samples/</span><br><span class=\"line\">cuDNN   /usr/src/cudnn_samples_v7/</span><br><span class=\"line\">Multimedia API  /usr/src/tegra_multimedia_api/</span><br><span class=\"line\">VisionWorks /usr/share/visionworks/sources/samples/ /usr/share/visionworks-tracking/sources/samples/ /usr/share/visionworks-sfm/sources/samples/</span><br><span class=\"line\">OpenCV  /usr/share/OpenCV/samples/</span><br></pre></td></tr></table></figure></p>\n<p>2.0获取超级</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo su</span><br></pre></td></tr></table></figure>\n<p>2.1核对CUDA<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:/# nvcc -V</span><br><span class=\"line\">-bash: nvcc: command not found</span><br></pre></td></tr></table></figure></p>\n<p>加入路径<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gedit  ~/.bashrc</span><br></pre></td></tr></table></figure></p>\n<p>文件最后加入<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">export CUBA_HOME=/usr/local/cuda-10.0</span><br><span class=\"line\">export LD_LIBRARY_PATH=/usr/local/cuda-10.0/lib64:$LD_LIBRARY_PATH</span><br><span class=\"line\">export PATH=/usr/local/cuda-10.0/bin:$PATH</span><br></pre></td></tr></table></figure></p>\n<p>执行使生效<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">source ~/.bashrc</span><br></pre></td></tr></table></figure></p>\n<p>再次执行,显示cuda10.0<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:/# source ~/.bashrc</span><br><span class=\"line\">root@jetson-desktop:/# nvcc -V</span><br><span class=\"line\">nvcc: NVIDIA (R) Cuda compiler driver</span><br><span class=\"line\">Copyright (c) 2005-2018 NVIDIA Corporation</span><br><span class=\"line\">Built on Sun_Sep_30_21:09:22_CDT_2018</span><br><span class=\"line\">Cuda compilation tools, release 10.0, V10.0.166</span><br><span class=\"line\">root@jetson-desktop:/#</span><br></pre></td></tr></table></figure></p>\n<p>2.2核对opencv</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:/# pkg-config opencv --modversion</span><br><span class=\"line\">3.3.1</span><br></pre></td></tr></table></figure>\n<p>显示opencv当前版本是3.3.1<br>2.3核对cuDNN<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:/# cd /usr/src/cudnn_samples_v7/mnistCUDNN/</span><br><span class=\"line\">root@jetson-desktop:/usr/src/cudnn_samples_v7/mnistCUDNN# make</span><br><span class=\"line\">/usr/local/cuda/bin/nvcc -ccbin g++ -I/usr/local/cuda/include -IFreeImage/include  -m64    -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_53,code=sm_53 -gencode arch=compute_53,code=compute_53 -o fp16_dev.o -c fp16_dev.cu</span><br><span class=\"line\">g++ -I/usr/local/cuda/include -IFreeImage/include   -o fp16_emu.o -c fp16_emu.cpp</span><br><span class=\"line\">g++ -I/usr/local/cuda/include -IFreeImage/include   -o mnistCUDNN.o -c mnistCUDNN.cpp</span><br><span class=\"line\">/usr/local/cuda/bin/nvcc -ccbin g++   -m64      -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_53,code=sm_53 -gencode arch=compute_53,code=compute_53 -o mnistCUDNN fp16_dev.o fp16_emu.o mnistCUDNN.o -I/usr/local/cuda/include -IFreeImage/include  -LFreeImage/lib/linux/aarch64 -LFreeImage/lib/linux -lcudart -lcublas -lcudnn -lfreeimage -lstdc++ -lm</span><br><span class=\"line\">FreeImage/lib/linux/aarch64/libfreeimage.a(strenc.o): In function `StrIOEncInit&apos;:</span><br><span class=\"line\">strenc.c:(.text+0x1294): warning: the use of `tmpnam&apos; is dangerous, better use `mkstemp&apos;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">执行sample</span><br><span class=\"line\">root@jetson-desktop:/usr/src/cudnn_samples_v7/mnistCUDNN# chmod a+x mnistCUDNN</span><br><span class=\"line\">root@jetson-desktop:/usr/src/cudnn_samples_v7/mnistCUDNN# ./mnistCUDNN </span><br><span class=\"line\">cudnnGetVersion() : 7301 , CUDNN_VERSION from cudnn.h : 7301 (7.3.1)</span><br><span class=\"line\">Host compiler version : GCC 7.3.0</span><br><span class=\"line\">There are 1 CUDA capable devices on your machine :</span><br><span class=\"line\">device 0 : sms  1  Capabilities 5.3, SmClock 921.6 Mhz, MemSize (Mb) 3964, MemClock 12.8 Mhz, Ecc=0, boardGroupID=0</span><br><span class=\"line\">Using device 0</span><br><span class=\"line\"></span><br><span class=\"line\">Testing single precision</span><br><span class=\"line\">Loading image data/one_28x28.pgm</span><br><span class=\"line\">Performing forward propagation ...</span><br><span class=\"line\">Testing cudnnGetConvolutionForwardAlgorithm ...</span><br><span class=\"line\">Fastest algorithm is Algo 1</span><br><span class=\"line\">Testing cudnnFindConvolutionForwardAlgorithm ...</span><br><span class=\"line\">^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.341979 time requiring 3464 memory</span><br><span class=\"line\">^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.395625 time requiring 0 memory</span><br><span class=\"line\">^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 5.210573 time requiring 207360 memory</span><br><span class=\"line\">^^^^ CUDNN_STATUS_SUCCESS for Algo 7: 5.213230 time requiring 2057744 memory</span><br><span class=\"line\">^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 14.978802 time requiring 57600 memory</span><br><span class=\"line\">Resulting weights from Softmax:</span><br><span class=\"line\">0.0000000 0.9999399 0.0000000 0.0000000 0.0000561 0.0000000 0.0000012 0.0000017 0.0000010 0.0000000 </span><br><span class=\"line\">Loading image data/three_28x28.pgm</span><br><span class=\"line\">Performing forward propagation ...</span><br><span class=\"line\">Resulting weights from Softmax:</span><br><span class=\"line\">0.0000000 0.0000000 0.0000000 0.9999288 0.0000000 0.0000711 0.0000000 0.0000000 0.0000000 0.0000000 </span><br><span class=\"line\">Loading image data/five_28x28.pgm</span><br><span class=\"line\">Performing forward propagation ...</span><br><span class=\"line\">Resulting weights from Softmax:</span><br><span class=\"line\">0.0000000 0.0000008 0.0000000 0.0000002 0.0000000 0.9999820 0.0000154 0.0000000 0.0000012 0.0000006 </span><br><span class=\"line\"></span><br><span class=\"line\">Result of classification: 1 3 5</span><br><span class=\"line\"></span><br><span class=\"line\">Test passed!</span><br><span class=\"line\"></span><br><span class=\"line\">Testing half precision (math in single precision)</span><br><span class=\"line\">Loading image data/one_28x28.pgm</span><br><span class=\"line\">Performing forward propagation ...</span><br><span class=\"line\">Testing cudnnGetConvolutionForwardAlgorithm ...</span><br><span class=\"line\">Fastest algorithm is Algo 1</span><br><span class=\"line\">Testing cudnnFindConvolutionForwardAlgorithm ...</span><br><span class=\"line\">^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.135000 time requiring 0 memory</span><br><span class=\"line\">^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.170885 time requiring 3464 memory</span><br><span class=\"line\">^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 0.282708 time requiring 28800 memory</span><br><span class=\"line\">^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 1.206094 time requiring 207360 memory</span><br><span class=\"line\">^^^^ CUDNN_STATUS_SUCCESS for Algo 5: 5.214895 time requiring 203008 memory</span><br><span class=\"line\">Resulting weights from Softmax:</span><br><span class=\"line\">0.0000001 1.0000000 0.0000001 0.0000000 0.0000563 0.0000001 0.0000012 0.0000017 0.0000010 0.0000001 </span><br><span class=\"line\">Loading image data/three_28x28.pgm</span><br><span class=\"line\">Performing forward propagation ...</span><br><span class=\"line\">Resulting weights from Softmax:</span><br><span class=\"line\">0.0000000 0.0000000 0.0000000 1.0000000 0.0000000 0.0000714 0.0000000 0.0000000 0.0000000 0.0000000 </span><br><span class=\"line\">Loading image data/five_28x28.pgm</span><br><span class=\"line\">Performing forward propagation ...</span><br><span class=\"line\">Resulting weights from Softmax:</span><br><span class=\"line\">0.0000000 0.0000008 0.0000000 0.0000002 0.0000000 1.0000000 0.0000154 0.0000000 0.0000012 0.0000006 </span><br><span class=\"line\"></span><br><span class=\"line\">Result of classification: 1 3 5</span><br><span class=\"line\"></span><br><span class=\"line\">Test passed!</span><br></pre></td></tr></table></figure></p>\n<p>测试通过；<br>2.4核对python<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:/# python3</span><br><span class=\"line\">Python 3.6.7 (default, Oct 22 2018, 11:32:17)</span><br><span class=\"line\">[GCC 8.2.0] on linux</span><br><span class=\"line\">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span><br></pre></td></tr></table></figure></p>\n<p>默认已经安装python2.7 和python3.6.7版本<br>3、增加python相关内容<br>3.1安装pip3<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:/# apt-get install python3-pip</span><br><span class=\"line\">正在读取软件包列表... 完成</span><br><span class=\"line\">正在分析软件包的依赖关系树       </span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">root@jetson-desktop:/# pip3 -V</span><br><span class=\"line\">pip 9.0.1 from /usr/lib/python3/dist-packages (python 3.6)</span><br><span class=\"line\"></span><br><span class=\"line\">升级下版本到19.1;</span><br><span class=\"line\">root@jetson-desktop:~# python3 -m pip install --upgrade pip</span><br><span class=\"line\">Collecting pip</span><br><span class=\"line\">  Downloading https://files.pythonhosted.org/packages/f9/fb/863012b13912709c13cf5cfdbfb304fa6c727659d6290438e1a88df9d848/pip-19.1-py2.py3-none-any.whl (1.4MB)</span><br><span class=\"line\">    100% |████████████████████████████████| 1.4MB 279kB/s </span><br><span class=\"line\">Installing collected packages: pip</span><br><span class=\"line\">  Found existing installation: pip 9.0.1</span><br><span class=\"line\">    Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usr</span><br><span class=\"line\">Successfully installed pip-19.1</span><br><span class=\"line\"></span><br><span class=\"line\">root@jetson-desktop:~# pip3 -V</span><br><span class=\"line\">pip 19.1 from /usr/local/lib/python3.6/dist-packages/pip (python 3.6)</span><br></pre></td></tr></table></figure></p>\n<p>3.2安装python-OpenCV<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:/# sudo apt-get install python3-opencv</span><br><span class=\"line\">正在读取软件包列表... 完成</span><br><span class=\"line\">正在分析软件包的依赖关系树       </span><br><span class=\"line\">正在读取状态信息... 完成       </span><br><span class=\"line\">下列软件包是自动安装的并且现在不需要了：</span><br><span class=\"line\">  apt-clone archdetect-deb busybox-static cryptsetup-bin dpkg-repack gir1.2-timezonemap-1.0 gir1.2-xkl-1.0 grub-common kde-window-manager kinit kio kpackagetool5 kwayland-data kwin-common kwin-data kwin-x11 libdebian-installer4</span><br><span class=\"line\">  libkdecorations2-5v5 libkdecorations2private5v5 libkf5activities5 libkf5attica5 libkf5completion-data libkf5completion5 libkf5declarative-data libkf5declarative5 libkf5doctools5 libkf5globalaccel-data libkf5globalaccel5</span><br><span class=\"line\">  libkf5globalaccelprivate5 libkf5idletime5 libkf5jobwidgets-data libkf5jobwidgets5 libkf5kcmutils-data libkf5kcmutils5 libkf5kiocore5 libkf5kiontlm5 libkf5kiowidgets5 libkf5newstuff-data libkf5newstuff5 libkf5newstuffcore5</span><br><span class=\"line\">  libkf5package-data libkf5package5 libkf5plasma5 libkf5quickaddons5 libkf5solid5 libkf5solid5-data libkf5sonnet5-data libkf5sonnetcore5 libkf5sonnetui5 libkf5textwidgets-data libkf5textwidgets5 libkf5waylandclient5 libkf5waylandserver5</span><br><span class=\"line\">  libkf5xmlgui-bin libkf5xmlgui-data libkf5xmlgui5 libkscreenlocker5 libkwin4-effect-builtins1 libkwineffects11 libkwinglutils11 libkwinxrenderutils11 libqgsttools-p1 libqt5designer5 libqt5help5 libqt5multimedia5 libqt5multimedia5-plugins</span><br><span class=\"line\">  libqt5multimediaquick-p5 libqt5multimediawidgets5 libqt5opengl5 libqt5positioning5 libqt5printsupport5 libqt5qml5 libqt5quick5 libqt5quickwidgets5 libqt5sensors5 libqt5sql5 libqt5test5 libqt5webchannel5 libqt5webkit5 libxcb-composite0</span><br><span class=\"line\">  libxcb-cursor0 libxcb-damage0 os-prober python3-dbus.mainloop.pyqt5 python3-icu python3-pam python3-pyqt5 python3-pyqt5.qtsvg python3-pyqt5.qtwebkit python3-sip qml-module-org-kde-kquickcontrolsaddons qml-module-qtmultimedia</span><br><span class=\"line\">  qml-module-qtquick2 rdate</span><br><span class=\"line\">使用&apos;sudo apt autoremove&apos;来卸载它(它们)。</span><br><span class=\"line\">将会同时安装下列软件：</span><br><span class=\"line\">  gdal-data libaec0 libarmadillo8 libarpack2 libcharls1 libdap25 libdapclient6v5 libepsilon1 libfreexl1 libfyba0 libgdal20 libgdcm2.8 libgeos-3.6.2 libgeos-c1v5 libgeotiff2 libgif7 libgl2ps1.4 libhdf4-0-alt libhdf5-100 libhdf5-openmpi-100</span><br><span class=\"line\">  libjsoncpp1 libkmlbase1 libkmldom1 libkmlengine1 liblept5 libminizip1 libnetcdf-c++4 libnetcdf13 libodbc1 libogdi3.2 libopencv-calib3d3.2 libopencv-contrib3.2 libopencv-core3.2 libopencv-features2d3.2 libopencv-flann3.2</span><br><span class=\"line\">  libopencv-highgui3.2 libopencv-imgcodecs3.2 libopencv-imgproc3.2 libopencv-ml3.2 libopencv-objdetect3.2 libopencv-photo3.2 libopencv-shape3.2 libopencv-stitching3.2 libopencv-superres3.2 libopencv-video3.2 libopencv-videoio3.2</span><br><span class=\"line\">  libopencv-videostab3.2 libopencv-viz3.2 libpq5 libproj12 libqhull7 libsocket++1 libspatialite7 libsuperlu5 libsz2 libtcl8.6 libtesseract4 libtk8.6 liburiparser1 libvtk6.3 libxerces-c3.2 odbcinst odbcinst1debian2 proj-bin proj-data</span><br><span class=\"line\">  python3-numpy</span><br><span class=\"line\">建议安装：</span><br><span class=\"line\">  geotiff-bin gdal-bin libgeotiff-epsg libhdf4-doc libhdf4-alt-dev hdf4-tools libmyodbc odbc-postgresql tdsodbc unixodbc-bin ogdi-bin tcl8.6 tk8.6 mpi-default-bin vtk6-doc vtk6-examples gfortran python-numpy-doc python3-nose</span><br><span class=\"line\">  python3-numpy-dbg</span><br><span class=\"line\">下列【新】软件包将被安装：</span><br><span class=\"line\">  gdal-data libaec0 libarmadillo8 libarpack2 libcharls1 libdap25 libdapclient6v5 libepsilon1 libfreexl1 libfyba0 libgdal20 libgdcm2.8 libgeos-3.6.2 libgeos-c1v5 libgeotiff2 libgif7 libgl2ps1.4 libhdf4-0-alt libhdf5-100 libhdf5-openmpi-100</span><br><span class=\"line\">  libjsoncpp1 libkmlbase1 libkmldom1 libkmlengine1 liblept5 libminizip1 libnetcdf-c++4 libnetcdf13 libodbc1 libogdi3.2 libopencv-calib3d3.2 libopencv-contrib3.2 libopencv-core3.2 libopencv-features2d3.2 libopencv-flann3.2</span><br><span class=\"line\">  libopencv-highgui3.2 libopencv-imgcodecs3.2 libopencv-imgproc3.2 libopencv-ml3.2 libopencv-objdetect3.2 libopencv-photo3.2 libopencv-shape3.2 libopencv-stitching3.2 libopencv-superres3.2 libopencv-video3.2 libopencv-videoio3.2</span><br><span class=\"line\">  libopencv-videostab3.2 libopencv-viz3.2 libpq5 libproj12 libqhull7 libsocket++1 libspatialite7 libsuperlu5 libsz2 libtcl8.6 libtesseract4 libtk8.6 liburiparser1 libvtk6.3 libxerces-c3.2 odbcinst odbcinst1debian2 proj-bin proj-data</span><br><span class=\"line\">  python3-numpy python3-opencv</span><br><span class=\"line\">升级了 0 个软件包，新安装了 67 个软件包，要卸载 0 个软件包，有 315 个软件包未被升级。</span><br><span class=\"line\">需要下载 55.8 MB 的归档。</span><br><span class=\"line\">解压缩后会消耗 265 MB 的额外空间。</span><br><span class=\"line\">您希望继续执行吗？ [Y/n] y</span><br></pre></td></tr></table></figure></p>\n<p>测试下看看<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:~# python3</span><br><span class=\"line\">Python 3.6.7 (default, Oct 22 2018, 11:32:17) </span><br><span class=\"line\">[GCC 8.2.0] on linux</span><br><span class=\"line\">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span><br><span class=\"line\">&gt;&gt;&gt; import cv2</span><br><span class=\"line\">&gt;&gt;&gt; print(cv2.__version__)</span><br><span class=\"line\">3.2.0</span><br><span class=\"line\">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></p>\n<p>默认3.2版本，和系统本身自带的不统一;<br>python2.7版本自带的opencv<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:~# python</span><br><span class=\"line\">Python 2.7.15rc1 (default, Nov 12 2018, 14:31:15) </span><br><span class=\"line\">[GCC 7.3.0] on linux2</span><br><span class=\"line\">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span><br><span class=\"line\">&gt;&gt;&gt; import cv2</span><br><span class=\"line\">&gt;&gt;&gt;  print(cv2.__version__)</span><br><span class=\"line\">  File &quot;&lt;stdin&gt;&quot;, line 1</span><br><span class=\"line\">    print(cv2.__version__)</span><br><span class=\"line\">    ^</span><br><span class=\"line\">IndentationError: unexpected indent</span><br><span class=\"line\">&gt;&gt;&gt; print(cv2.__version__)</span><br><span class=\"line\">3.3.1</span><br><span class=\"line\">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></p>\n<p>python3能安装的OpenCV的版本太低;稍后再解决;<br>4，更新系统</p>\n<p>执行命令<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apt-get update &amp;&amp; apt-get upgrade -y</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">效果片段如下：下载内容较多，可能时间会很长。</span><br><span class=\"line\">升级了 305 个软件包，新安装了 0 个软件包，要卸载 0 个软件包，有 10 个软件包未被升级。</span><br><span class=\"line\">需要下载 396 MB/396 MB 的归档。</span><br><span class=\"line\">解压缩后会消耗 69.5 MB 的额外空间。</span><br><span class=\"line\">命中:13 http://ports.ubuntu.com/ubuntu-ports bionic InRelease                                             </span><br><span class=\"line\">获取:1 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 login arm64 1:4.5-1ubuntu2 [301 kB]</span><br><span class=\"line\">命中:14 http://ports.ubuntu.com/ubuntu-ports bionic-updates InRelease                                     </span><br><span class=\"line\">命中:15 http://ports.ubuntu.com/ubuntu-ports bionic-backports InRelease                                   </span><br><span class=\"line\">命中:16 http://ports.ubuntu.com/ubuntu-ports bionic-security InRelease                                    </span><br><span class=\"line\">正在读取软件包列表... 完成 20%]                                              80.2 kB/s 1小时 22分 13秒    </span><br><span class=\"line\">获取:2 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libgomp1 arm64 8.3.0-6ubuntu1~18.04 [69.6 kB]                                                                                                                             </span><br><span class=\"line\">获取:3 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libitm1 arm64 8.3.0-6ubuntu1~18.04 [24.3 kB]                                                                                                                              </span><br><span class=\"line\">获取:4 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 gcc-8-base arm64 8.3.0-6ubuntu1~18.04 [18.7 kB]                                                                                                                           </span><br><span class=\"line\">获取:5 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libgcc1 arm64 1:8.3.0-6ubuntu1~18.04 [34.4 kB]                                                                                                                            </span><br><span class=\"line\">获取:6 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 liblsan0 arm64 8.3.0-6ubuntu1~18.04 [121 kB]                                                                                                                              </span><br><span class=\"line\">获取:7 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libtsan0 arm64 8.3.0-6ubuntu1~18.04 [269 kB]                                                                                                                              </span><br><span class=\"line\">获取:8 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libcc1-0 arm64 8.3.0-6ubuntu1~18.04 [46.4 kB]                                                                                                                             </span><br><span class=\"line\">获取:9 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libatomic1 arm64 8.3.0-6ubuntu1~18.04 [9,164 B]                                                                                                                           </span><br><span class=\"line\">获取:10 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libstdc++6 arm64 8.3.0-6ubuntu1~18.04 [372 kB]                                                                                                                           </span><br><span class=\"line\">获取:11 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libnss-systemd arm64 237-3ubuntu10.21 [90.1 kB]                                                                                                                          </span><br><span class=\"line\">获取:12 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libudev1 arm64 237-3ubuntu10.21 [45.2 kB]                                                                                                                                </span><br><span class=\"line\">获取:13 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 udev arm64 237-3ubuntu10.21 [1,050 kB]                                                                                                                                   </span><br><span class=\"line\">获取:14 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libnss-myhostname arm64 237-3ubuntu10.21 [30.2 kB]                                                                                                                       </span><br><span class=\"line\">获取:15 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libpam-systemd arm64 237-3ubuntu10.21 [92.8 kB]                                                                                                                          </span><br><span class=\"line\">获取:17 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libsystemd0 arm64 237-3ubuntu10.21 [171 kB]                                                                                                                              </span><br><span class=\"line\">获取:18 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libpam0g arm64 1.1.8-3.6ubuntu2.18.04.1 [51.1 kB]                                                                                                                        </span><br><span class=\"line\">获取:16 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 systemd arm64 237-3ubuntu10.21 [2,551 kB]                                                                                                                                </span><br><span class=\"line\">获取:19 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libpam-modules-bin arm64 1.1.8-3.6ubuntu2.18.04.1 [32.7 kB]</span><br></pre></td></tr></table></figure>\n<p>默认的更新源国内访问实在太慢了。<br>/etc/apt/sources.list文件<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gudit /etc/apt/sources.list</span><br></pre></td></tr></table></figure></p>\n<p>里面的链接全部替换成清华的源<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main multiverse restricted universe</span><br><span class=\"line\">deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main multiverse restricted universe</span><br><span class=\"line\">deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main multiverse restricted universe</span><br><span class=\"line\">deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main multiverse restricted universe</span><br><span class=\"line\">deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main multiverse restricted universe</span><br><span class=\"line\">deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main multiverse restricted universe</span><br><span class=\"line\">deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main multiverse restricted universe</span><br><span class=\"line\">deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main multiverse restricted universe</span><br><span class=\"line\"></span><br><span class=\"line\">然后重新执行;</span><br><span class=\"line\">获取:84 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/main arm64 Packages [1,024 B]                                                                                                                                         </span><br><span class=\"line\">获取:85 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/main Translation-en [448 B]                                                                                                                                           </span><br><span class=\"line\">获取:86 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/universe arm64 Packages [3,468 B]                                                                                                                                     </span><br><span class=\"line\">获取:87 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/universe Translation-en [1,604 B]                                                                                                                                     </span><br><span class=\"line\">获取:88 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/universe arm64 DEP-11 Metadata [7,156 B]                                                                                                                              </span><br><span class=\"line\">获取:89 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/universe DEP-11 48x48 Icons [29 B]                                                                                                                                    </span><br><span class=\"line\">获取:90 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/universe DEP-11 64x64 Icons [29 B]                                                                                                                                    </span><br><span class=\"line\">已下载 45.5 MB，耗时 16秒 (2,900 kB/s)</span><br></pre></td></tr></table></figure></p>\n<p>速度超快！<br>5，关闭桌面系统<br>先看下内存<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:~# free</span><br><span class=\"line\">              total        used        free      shared  buff/cache   available</span><br><span class=\"line\">Mem:        4059712      572136     2529292       19044      958284     3304544</span><br><span class=\"line\">Swap:             0           0           0</span><br><span class=\"line\">root@jetson-desktop:~#</span><br></pre></td></tr></table></figure></p>\n<p>关闭桌面<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:~# sudo systemctl set-default multi-user.target</span><br><span class=\"line\">Removed /etc/systemd/system/default.target.</span><br><span class=\"line\">Created symlink /etc/systemd/system/default.target → /lib/systemd/system/multi-user.target.</span><br><span class=\"line\">root@jetson-desktop:~# reboot</span><br></pre></td></tr></table></figure></p>\n<p>再看内存<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:~# free</span><br><span class=\"line\">              total        used        free      shared  buff/cache   available</span><br><span class=\"line\">Mem:        4059712      321340     3511972       17616      226400     3573020</span><br><span class=\"line\">Swap:             0           0           0</span><br><span class=\"line\">root@jetson-desktop:~#</span><br></pre></td></tr></table></figure></p>\n<p>参考链接：<a href=\"https://www.jianshu.com/p/1fac6cdedd0d\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/1fac6cdedd0d</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>通过设置（system settings）–&gt;network–&gt;ipv4是查看dhcp分配ip为192.108.1.105；<br>jetson nano已经默认开启了openssh-server服务。<br>可以通过xshell直接连上，用教程一中设置的jetson登录；</p>\n<p><img src=\"https://blog.mviai.com/images/n1/n21.webp\" alt></p>\n<p>可见Ubuntu版本是18.04.2<br>为了方便操作，设置初始化root的密码；设置为jetson,具体操作如下；<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">jetson@jetson-desktop:~$ sudo passwd</span><br><span class=\"line\">[sudo] password for jetson: </span><br><span class=\"line\">Enter new UNIX password: </span><br><span class=\"line\">Retype new UNIX password: </span><br><span class=\"line\">passwd: password updated successfully</span><br><span class=\"line\">jetson@jetson-desktop:~$ su</span><br><span class=\"line\">Password: </span><br><span class=\"line\">root@jetson-desktop:/home/jetson# </span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">设置允许超级管理员远程访问</span><br><span class=\"line\"># vi /etc/ssh/sshd_config</span><br><span class=\"line\">找到并用#注释掉这行：PermitRootLogin prohibit-password</span><br><span class=\"line\"></span><br><span class=\"line\">新建一行 添加：PermitRootLogin yes</span><br></pre></td></tr></table></figure></p>\n<p>重启服务<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"># service ssh restart</span><br></pre></td></tr></table></figure></p>\n<p>设置固定ip<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">/etc/network/interfaces</span><br><span class=\"line\"># interfaces(5) file used by ifup(8) and ifdown(8)</span><br><span class=\"line\"># Include files from /etc/network/interfaces.d:</span><br><span class=\"line\">source-directory /etc/network/interfaces.d</span><br><span class=\"line\"></span><br><span class=\"line\">auto eth0</span><br><span class=\"line\">iface eth0 inet static</span><br><span class=\"line\">address 192.168.1.105</span><br><span class=\"line\">netmask 255.255.255.0</span><br><span class=\"line\">gateway 192.168.1.1</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">/etc/systemd/resolved.conf</span><br><span class=\"line\">[Resolve]</span><br><span class=\"line\">DNS==8.8.8.8 223.5.5.5</span><br><span class=\"line\">#FallbackDNS=8.8.8.8</span><br><span class=\"line\">#Domains=</span><br><span class=\"line\">#LLMNR=no</span><br><span class=\"line\">#MulticastDNS=no</span><br><span class=\"line\">#DNSSEC=no</span><br><span class=\"line\">#Cache=yes</span><br><span class=\"line\">#DNSStubListener=yes</span><br></pre></td></tr></table></figure></p>\n<p>重启再连接；联网正常；<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:~# ping www.yangxin.com</span><br><span class=\"line\">PING www.a.shifen.com (183.232.231.174) 56(84) bytes of data.</span><br><span class=\"line\">64 bytes from 183.232.231.174 (183.232.231.174): icmp_seq=1 ttl=57 time=5.70 ms</span><br><span class=\"line\">64 bytes from 183.232.231.174 (183.232.231.174): icmp_seq=2 ttl=57 time=5.61 ms</span><br><span class=\"line\">^C</span><br><span class=\"line\">--- www.a.shifen.com ping statistics ---</span><br><span class=\"line\">2 packets transmitted, 2 received, 0% packet loss, time 1002ms</span><br><span class=\"line\">rtt min/avg/max/mdev = 5.617/5.661/5.706/0.087 ms</span><br></pre></td></tr></table></figure></p>\n<p>2、默认组件<br>Jetson nano的镜像已经自带了JetPack，cuda，cudnn，opencv组件和sample，这些例子安装路径如下所示<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">TensorRT    /usr/src/tensorrt/samples/</span><br><span class=\"line\">CUDA    /usr/local/cuda-/samples/</span><br><span class=\"line\">cuDNN   /usr/src/cudnn_samples_v7/</span><br><span class=\"line\">Multimedia API  /usr/src/tegra_multimedia_api/</span><br><span class=\"line\">VisionWorks /usr/share/visionworks/sources/samples/ /usr/share/visionworks-tracking/sources/samples/ /usr/share/visionworks-sfm/sources/samples/</span><br><span class=\"line\">OpenCV  /usr/share/OpenCV/samples/</span><br></pre></td></tr></table></figure></p>\n<p>2.0获取超级</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo su</span><br></pre></td></tr></table></figure>\n<p>2.1核对CUDA<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:/# nvcc -V</span><br><span class=\"line\">-bash: nvcc: command not found</span><br></pre></td></tr></table></figure></p>\n<p>加入路径<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gedit  ~/.bashrc</span><br></pre></td></tr></table></figure></p>\n<p>文件最后加入<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\">export CUBA_HOME=/usr/local/cuda-10.0</span><br><span class=\"line\">export LD_LIBRARY_PATH=/usr/local/cuda-10.0/lib64:$LD_LIBRARY_PATH</span><br><span class=\"line\">export PATH=/usr/local/cuda-10.0/bin:$PATH</span><br></pre></td></tr></table></figure></p>\n<p>执行使生效<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">source ~/.bashrc</span><br></pre></td></tr></table></figure></p>\n<p>再次执行,显示cuda10.0<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:/# source ~/.bashrc</span><br><span class=\"line\">root@jetson-desktop:/# nvcc -V</span><br><span class=\"line\">nvcc: NVIDIA (R) Cuda compiler driver</span><br><span class=\"line\">Copyright (c) 2005-2018 NVIDIA Corporation</span><br><span class=\"line\">Built on Sun_Sep_30_21:09:22_CDT_2018</span><br><span class=\"line\">Cuda compilation tools, release 10.0, V10.0.166</span><br><span class=\"line\">root@jetson-desktop:/#</span><br></pre></td></tr></table></figure></p>\n<p>2.2核对opencv</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:/# pkg-config opencv --modversion</span><br><span class=\"line\">3.3.1</span><br></pre></td></tr></table></figure>\n<p>显示opencv当前版本是3.3.1<br>2.3核对cuDNN<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:/# cd /usr/src/cudnn_samples_v7/mnistCUDNN/</span><br><span class=\"line\">root@jetson-desktop:/usr/src/cudnn_samples_v7/mnistCUDNN# make</span><br><span class=\"line\">/usr/local/cuda/bin/nvcc -ccbin g++ -I/usr/local/cuda/include -IFreeImage/include  -m64    -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_53,code=sm_53 -gencode arch=compute_53,code=compute_53 -o fp16_dev.o -c fp16_dev.cu</span><br><span class=\"line\">g++ -I/usr/local/cuda/include -IFreeImage/include   -o fp16_emu.o -c fp16_emu.cpp</span><br><span class=\"line\">g++ -I/usr/local/cuda/include -IFreeImage/include   -o mnistCUDNN.o -c mnistCUDNN.cpp</span><br><span class=\"line\">/usr/local/cuda/bin/nvcc -ccbin g++   -m64      -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_53,code=sm_53 -gencode arch=compute_53,code=compute_53 -o mnistCUDNN fp16_dev.o fp16_emu.o mnistCUDNN.o -I/usr/local/cuda/include -IFreeImage/include  -LFreeImage/lib/linux/aarch64 -LFreeImage/lib/linux -lcudart -lcublas -lcudnn -lfreeimage -lstdc++ -lm</span><br><span class=\"line\">FreeImage/lib/linux/aarch64/libfreeimage.a(strenc.o): In function `StrIOEncInit&apos;:</span><br><span class=\"line\">strenc.c:(.text+0x1294): warning: the use of `tmpnam&apos; is dangerous, better use `mkstemp&apos;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">执行sample</span><br><span class=\"line\">root@jetson-desktop:/usr/src/cudnn_samples_v7/mnistCUDNN# chmod a+x mnistCUDNN</span><br><span class=\"line\">root@jetson-desktop:/usr/src/cudnn_samples_v7/mnistCUDNN# ./mnistCUDNN </span><br><span class=\"line\">cudnnGetVersion() : 7301 , CUDNN_VERSION from cudnn.h : 7301 (7.3.1)</span><br><span class=\"line\">Host compiler version : GCC 7.3.0</span><br><span class=\"line\">There are 1 CUDA capable devices on your machine :</span><br><span class=\"line\">device 0 : sms  1  Capabilities 5.3, SmClock 921.6 Mhz, MemSize (Mb) 3964, MemClock 12.8 Mhz, Ecc=0, boardGroupID=0</span><br><span class=\"line\">Using device 0</span><br><span class=\"line\"></span><br><span class=\"line\">Testing single precision</span><br><span class=\"line\">Loading image data/one_28x28.pgm</span><br><span class=\"line\">Performing forward propagation ...</span><br><span class=\"line\">Testing cudnnGetConvolutionForwardAlgorithm ...</span><br><span class=\"line\">Fastest algorithm is Algo 1</span><br><span class=\"line\">Testing cudnnFindConvolutionForwardAlgorithm ...</span><br><span class=\"line\">^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.341979 time requiring 3464 memory</span><br><span class=\"line\">^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.395625 time requiring 0 memory</span><br><span class=\"line\">^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 5.210573 time requiring 207360 memory</span><br><span class=\"line\">^^^^ CUDNN_STATUS_SUCCESS for Algo 7: 5.213230 time requiring 2057744 memory</span><br><span class=\"line\">^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 14.978802 time requiring 57600 memory</span><br><span class=\"line\">Resulting weights from Softmax:</span><br><span class=\"line\">0.0000000 0.9999399 0.0000000 0.0000000 0.0000561 0.0000000 0.0000012 0.0000017 0.0000010 0.0000000 </span><br><span class=\"line\">Loading image data/three_28x28.pgm</span><br><span class=\"line\">Performing forward propagation ...</span><br><span class=\"line\">Resulting weights from Softmax:</span><br><span class=\"line\">0.0000000 0.0000000 0.0000000 0.9999288 0.0000000 0.0000711 0.0000000 0.0000000 0.0000000 0.0000000 </span><br><span class=\"line\">Loading image data/five_28x28.pgm</span><br><span class=\"line\">Performing forward propagation ...</span><br><span class=\"line\">Resulting weights from Softmax:</span><br><span class=\"line\">0.0000000 0.0000008 0.0000000 0.0000002 0.0000000 0.9999820 0.0000154 0.0000000 0.0000012 0.0000006 </span><br><span class=\"line\"></span><br><span class=\"line\">Result of classification: 1 3 5</span><br><span class=\"line\"></span><br><span class=\"line\">Test passed!</span><br><span class=\"line\"></span><br><span class=\"line\">Testing half precision (math in single precision)</span><br><span class=\"line\">Loading image data/one_28x28.pgm</span><br><span class=\"line\">Performing forward propagation ...</span><br><span class=\"line\">Testing cudnnGetConvolutionForwardAlgorithm ...</span><br><span class=\"line\">Fastest algorithm is Algo 1</span><br><span class=\"line\">Testing cudnnFindConvolutionForwardAlgorithm ...</span><br><span class=\"line\">^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.135000 time requiring 0 memory</span><br><span class=\"line\">^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.170885 time requiring 3464 memory</span><br><span class=\"line\">^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 0.282708 time requiring 28800 memory</span><br><span class=\"line\">^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 1.206094 time requiring 207360 memory</span><br><span class=\"line\">^^^^ CUDNN_STATUS_SUCCESS for Algo 5: 5.214895 time requiring 203008 memory</span><br><span class=\"line\">Resulting weights from Softmax:</span><br><span class=\"line\">0.0000001 1.0000000 0.0000001 0.0000000 0.0000563 0.0000001 0.0000012 0.0000017 0.0000010 0.0000001 </span><br><span class=\"line\">Loading image data/three_28x28.pgm</span><br><span class=\"line\">Performing forward propagation ...</span><br><span class=\"line\">Resulting weights from Softmax:</span><br><span class=\"line\">0.0000000 0.0000000 0.0000000 1.0000000 0.0000000 0.0000714 0.0000000 0.0000000 0.0000000 0.0000000 </span><br><span class=\"line\">Loading image data/five_28x28.pgm</span><br><span class=\"line\">Performing forward propagation ...</span><br><span class=\"line\">Resulting weights from Softmax:</span><br><span class=\"line\">0.0000000 0.0000008 0.0000000 0.0000002 0.0000000 1.0000000 0.0000154 0.0000000 0.0000012 0.0000006 </span><br><span class=\"line\"></span><br><span class=\"line\">Result of classification: 1 3 5</span><br><span class=\"line\"></span><br><span class=\"line\">Test passed!</span><br></pre></td></tr></table></figure></p>\n<p>测试通过；<br>2.4核对python<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:/# python3</span><br><span class=\"line\">Python 3.6.7 (default, Oct 22 2018, 11:32:17)</span><br><span class=\"line\">[GCC 8.2.0] on linux</span><br><span class=\"line\">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span><br></pre></td></tr></table></figure></p>\n<p>默认已经安装python2.7 和python3.6.7版本<br>3、增加python相关内容<br>3.1安装pip3<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:/# apt-get install python3-pip</span><br><span class=\"line\">正在读取软件包列表... 完成</span><br><span class=\"line\">正在分析软件包的依赖关系树       </span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">root@jetson-desktop:/# pip3 -V</span><br><span class=\"line\">pip 9.0.1 from /usr/lib/python3/dist-packages (python 3.6)</span><br><span class=\"line\"></span><br><span class=\"line\">升级下版本到19.1;</span><br><span class=\"line\">root@jetson-desktop:~# python3 -m pip install --upgrade pip</span><br><span class=\"line\">Collecting pip</span><br><span class=\"line\">  Downloading https://files.pythonhosted.org/packages/f9/fb/863012b13912709c13cf5cfdbfb304fa6c727659d6290438e1a88df9d848/pip-19.1-py2.py3-none-any.whl (1.4MB)</span><br><span class=\"line\">    100% |████████████████████████████████| 1.4MB 279kB/s </span><br><span class=\"line\">Installing collected packages: pip</span><br><span class=\"line\">  Found existing installation: pip 9.0.1</span><br><span class=\"line\">    Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usr</span><br><span class=\"line\">Successfully installed pip-19.1</span><br><span class=\"line\"></span><br><span class=\"line\">root@jetson-desktop:~# pip3 -V</span><br><span class=\"line\">pip 19.1 from /usr/local/lib/python3.6/dist-packages/pip (python 3.6)</span><br></pre></td></tr></table></figure></p>\n<p>3.2安装python-OpenCV<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:/# sudo apt-get install python3-opencv</span><br><span class=\"line\">正在读取软件包列表... 完成</span><br><span class=\"line\">正在分析软件包的依赖关系树       </span><br><span class=\"line\">正在读取状态信息... 完成       </span><br><span class=\"line\">下列软件包是自动安装的并且现在不需要了：</span><br><span class=\"line\">  apt-clone archdetect-deb busybox-static cryptsetup-bin dpkg-repack gir1.2-timezonemap-1.0 gir1.2-xkl-1.0 grub-common kde-window-manager kinit kio kpackagetool5 kwayland-data kwin-common kwin-data kwin-x11 libdebian-installer4</span><br><span class=\"line\">  libkdecorations2-5v5 libkdecorations2private5v5 libkf5activities5 libkf5attica5 libkf5completion-data libkf5completion5 libkf5declarative-data libkf5declarative5 libkf5doctools5 libkf5globalaccel-data libkf5globalaccel5</span><br><span class=\"line\">  libkf5globalaccelprivate5 libkf5idletime5 libkf5jobwidgets-data libkf5jobwidgets5 libkf5kcmutils-data libkf5kcmutils5 libkf5kiocore5 libkf5kiontlm5 libkf5kiowidgets5 libkf5newstuff-data libkf5newstuff5 libkf5newstuffcore5</span><br><span class=\"line\">  libkf5package-data libkf5package5 libkf5plasma5 libkf5quickaddons5 libkf5solid5 libkf5solid5-data libkf5sonnet5-data libkf5sonnetcore5 libkf5sonnetui5 libkf5textwidgets-data libkf5textwidgets5 libkf5waylandclient5 libkf5waylandserver5</span><br><span class=\"line\">  libkf5xmlgui-bin libkf5xmlgui-data libkf5xmlgui5 libkscreenlocker5 libkwin4-effect-builtins1 libkwineffects11 libkwinglutils11 libkwinxrenderutils11 libqgsttools-p1 libqt5designer5 libqt5help5 libqt5multimedia5 libqt5multimedia5-plugins</span><br><span class=\"line\">  libqt5multimediaquick-p5 libqt5multimediawidgets5 libqt5opengl5 libqt5positioning5 libqt5printsupport5 libqt5qml5 libqt5quick5 libqt5quickwidgets5 libqt5sensors5 libqt5sql5 libqt5test5 libqt5webchannel5 libqt5webkit5 libxcb-composite0</span><br><span class=\"line\">  libxcb-cursor0 libxcb-damage0 os-prober python3-dbus.mainloop.pyqt5 python3-icu python3-pam python3-pyqt5 python3-pyqt5.qtsvg python3-pyqt5.qtwebkit python3-sip qml-module-org-kde-kquickcontrolsaddons qml-module-qtmultimedia</span><br><span class=\"line\">  qml-module-qtquick2 rdate</span><br><span class=\"line\">使用&apos;sudo apt autoremove&apos;来卸载它(它们)。</span><br><span class=\"line\">将会同时安装下列软件：</span><br><span class=\"line\">  gdal-data libaec0 libarmadillo8 libarpack2 libcharls1 libdap25 libdapclient6v5 libepsilon1 libfreexl1 libfyba0 libgdal20 libgdcm2.8 libgeos-3.6.2 libgeos-c1v5 libgeotiff2 libgif7 libgl2ps1.4 libhdf4-0-alt libhdf5-100 libhdf5-openmpi-100</span><br><span class=\"line\">  libjsoncpp1 libkmlbase1 libkmldom1 libkmlengine1 liblept5 libminizip1 libnetcdf-c++4 libnetcdf13 libodbc1 libogdi3.2 libopencv-calib3d3.2 libopencv-contrib3.2 libopencv-core3.2 libopencv-features2d3.2 libopencv-flann3.2</span><br><span class=\"line\">  libopencv-highgui3.2 libopencv-imgcodecs3.2 libopencv-imgproc3.2 libopencv-ml3.2 libopencv-objdetect3.2 libopencv-photo3.2 libopencv-shape3.2 libopencv-stitching3.2 libopencv-superres3.2 libopencv-video3.2 libopencv-videoio3.2</span><br><span class=\"line\">  libopencv-videostab3.2 libopencv-viz3.2 libpq5 libproj12 libqhull7 libsocket++1 libspatialite7 libsuperlu5 libsz2 libtcl8.6 libtesseract4 libtk8.6 liburiparser1 libvtk6.3 libxerces-c3.2 odbcinst odbcinst1debian2 proj-bin proj-data</span><br><span class=\"line\">  python3-numpy</span><br><span class=\"line\">建议安装：</span><br><span class=\"line\">  geotiff-bin gdal-bin libgeotiff-epsg libhdf4-doc libhdf4-alt-dev hdf4-tools libmyodbc odbc-postgresql tdsodbc unixodbc-bin ogdi-bin tcl8.6 tk8.6 mpi-default-bin vtk6-doc vtk6-examples gfortran python-numpy-doc python3-nose</span><br><span class=\"line\">  python3-numpy-dbg</span><br><span class=\"line\">下列【新】软件包将被安装：</span><br><span class=\"line\">  gdal-data libaec0 libarmadillo8 libarpack2 libcharls1 libdap25 libdapclient6v5 libepsilon1 libfreexl1 libfyba0 libgdal20 libgdcm2.8 libgeos-3.6.2 libgeos-c1v5 libgeotiff2 libgif7 libgl2ps1.4 libhdf4-0-alt libhdf5-100 libhdf5-openmpi-100</span><br><span class=\"line\">  libjsoncpp1 libkmlbase1 libkmldom1 libkmlengine1 liblept5 libminizip1 libnetcdf-c++4 libnetcdf13 libodbc1 libogdi3.2 libopencv-calib3d3.2 libopencv-contrib3.2 libopencv-core3.2 libopencv-features2d3.2 libopencv-flann3.2</span><br><span class=\"line\">  libopencv-highgui3.2 libopencv-imgcodecs3.2 libopencv-imgproc3.2 libopencv-ml3.2 libopencv-objdetect3.2 libopencv-photo3.2 libopencv-shape3.2 libopencv-stitching3.2 libopencv-superres3.2 libopencv-video3.2 libopencv-videoio3.2</span><br><span class=\"line\">  libopencv-videostab3.2 libopencv-viz3.2 libpq5 libproj12 libqhull7 libsocket++1 libspatialite7 libsuperlu5 libsz2 libtcl8.6 libtesseract4 libtk8.6 liburiparser1 libvtk6.3 libxerces-c3.2 odbcinst odbcinst1debian2 proj-bin proj-data</span><br><span class=\"line\">  python3-numpy python3-opencv</span><br><span class=\"line\">升级了 0 个软件包，新安装了 67 个软件包，要卸载 0 个软件包，有 315 个软件包未被升级。</span><br><span class=\"line\">需要下载 55.8 MB 的归档。</span><br><span class=\"line\">解压缩后会消耗 265 MB 的额外空间。</span><br><span class=\"line\">您希望继续执行吗？ [Y/n] y</span><br></pre></td></tr></table></figure></p>\n<p>测试下看看<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:~# python3</span><br><span class=\"line\">Python 3.6.7 (default, Oct 22 2018, 11:32:17) </span><br><span class=\"line\">[GCC 8.2.0] on linux</span><br><span class=\"line\">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span><br><span class=\"line\">&gt;&gt;&gt; import cv2</span><br><span class=\"line\">&gt;&gt;&gt; print(cv2.__version__)</span><br><span class=\"line\">3.2.0</span><br><span class=\"line\">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></p>\n<p>默认3.2版本，和系统本身自带的不统一;<br>python2.7版本自带的opencv<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:~# python</span><br><span class=\"line\">Python 2.7.15rc1 (default, Nov 12 2018, 14:31:15) </span><br><span class=\"line\">[GCC 7.3.0] on linux2</span><br><span class=\"line\">Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.</span><br><span class=\"line\">&gt;&gt;&gt; import cv2</span><br><span class=\"line\">&gt;&gt;&gt;  print(cv2.__version__)</span><br><span class=\"line\">  File &quot;&lt;stdin&gt;&quot;, line 1</span><br><span class=\"line\">    print(cv2.__version__)</span><br><span class=\"line\">    ^</span><br><span class=\"line\">IndentationError: unexpected indent</span><br><span class=\"line\">&gt;&gt;&gt; print(cv2.__version__)</span><br><span class=\"line\">3.3.1</span><br><span class=\"line\">&gt;&gt;&gt;</span><br></pre></td></tr></table></figure></p>\n<p>python3能安装的OpenCV的版本太低;稍后再解决;<br>4，更新系统</p>\n<p>执行命令<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">apt-get update &amp;&amp; apt-get upgrade -y</span><br></pre></td></tr></table></figure></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">效果片段如下：下载内容较多，可能时间会很长。</span><br><span class=\"line\">升级了 305 个软件包，新安装了 0 个软件包，要卸载 0 个软件包，有 10 个软件包未被升级。</span><br><span class=\"line\">需要下载 396 MB/396 MB 的归档。</span><br><span class=\"line\">解压缩后会消耗 69.5 MB 的额外空间。</span><br><span class=\"line\">命中:13 http://ports.ubuntu.com/ubuntu-ports bionic InRelease                                             </span><br><span class=\"line\">获取:1 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 login arm64 1:4.5-1ubuntu2 [301 kB]</span><br><span class=\"line\">命中:14 http://ports.ubuntu.com/ubuntu-ports bionic-updates InRelease                                     </span><br><span class=\"line\">命中:15 http://ports.ubuntu.com/ubuntu-ports bionic-backports InRelease                                   </span><br><span class=\"line\">命中:16 http://ports.ubuntu.com/ubuntu-ports bionic-security InRelease                                    </span><br><span class=\"line\">正在读取软件包列表... 完成 20%]                                              80.2 kB/s 1小时 22分 13秒    </span><br><span class=\"line\">获取:2 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libgomp1 arm64 8.3.0-6ubuntu1~18.04 [69.6 kB]                                                                                                                             </span><br><span class=\"line\">获取:3 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libitm1 arm64 8.3.0-6ubuntu1~18.04 [24.3 kB]                                                                                                                              </span><br><span class=\"line\">获取:4 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 gcc-8-base arm64 8.3.0-6ubuntu1~18.04 [18.7 kB]                                                                                                                           </span><br><span class=\"line\">获取:5 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libgcc1 arm64 1:8.3.0-6ubuntu1~18.04 [34.4 kB]                                                                                                                            </span><br><span class=\"line\">获取:6 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 liblsan0 arm64 8.3.0-6ubuntu1~18.04 [121 kB]                                                                                                                              </span><br><span class=\"line\">获取:7 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libtsan0 arm64 8.3.0-6ubuntu1~18.04 [269 kB]                                                                                                                              </span><br><span class=\"line\">获取:8 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libcc1-0 arm64 8.3.0-6ubuntu1~18.04 [46.4 kB]                                                                                                                             </span><br><span class=\"line\">获取:9 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libatomic1 arm64 8.3.0-6ubuntu1~18.04 [9,164 B]                                                                                                                           </span><br><span class=\"line\">获取:10 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libstdc++6 arm64 8.3.0-6ubuntu1~18.04 [372 kB]                                                                                                                           </span><br><span class=\"line\">获取:11 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libnss-systemd arm64 237-3ubuntu10.21 [90.1 kB]                                                                                                                          </span><br><span class=\"line\">获取:12 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libudev1 arm64 237-3ubuntu10.21 [45.2 kB]                                                                                                                                </span><br><span class=\"line\">获取:13 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 udev arm64 237-3ubuntu10.21 [1,050 kB]                                                                                                                                   </span><br><span class=\"line\">获取:14 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libnss-myhostname arm64 237-3ubuntu10.21 [30.2 kB]                                                                                                                       </span><br><span class=\"line\">获取:15 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libpam-systemd arm64 237-3ubuntu10.21 [92.8 kB]                                                                                                                          </span><br><span class=\"line\">获取:17 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libsystemd0 arm64 237-3ubuntu10.21 [171 kB]                                                                                                                              </span><br><span class=\"line\">获取:18 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libpam0g arm64 1.1.8-3.6ubuntu2.18.04.1 [51.1 kB]                                                                                                                        </span><br><span class=\"line\">获取:16 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 systemd arm64 237-3ubuntu10.21 [2,551 kB]                                                                                                                                </span><br><span class=\"line\">获取:19 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libpam-modules-bin arm64 1.1.8-3.6ubuntu2.18.04.1 [32.7 kB]</span><br></pre></td></tr></table></figure>\n<p>默认的更新源国内访问实在太慢了。<br>/etc/apt/sources.list文件<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">gudit /etc/apt/sources.list</span><br></pre></td></tr></table></figure></p>\n<p>里面的链接全部替换成清华的源<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main multiverse restricted universe</span><br><span class=\"line\">deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main multiverse restricted universe</span><br><span class=\"line\">deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main multiverse restricted universe</span><br><span class=\"line\">deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main multiverse restricted universe</span><br><span class=\"line\">deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main multiverse restricted universe</span><br><span class=\"line\">deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main multiverse restricted universe</span><br><span class=\"line\">deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main multiverse restricted universe</span><br><span class=\"line\">deb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main multiverse restricted universe</span><br><span class=\"line\"></span><br><span class=\"line\">然后重新执行;</span><br><span class=\"line\">获取:84 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/main arm64 Packages [1,024 B]                                                                                                                                         </span><br><span class=\"line\">获取:85 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/main Translation-en [448 B]                                                                                                                                           </span><br><span class=\"line\">获取:86 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/universe arm64 Packages [3,468 B]                                                                                                                                     </span><br><span class=\"line\">获取:87 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/universe Translation-en [1,604 B]                                                                                                                                     </span><br><span class=\"line\">获取:88 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/universe arm64 DEP-11 Metadata [7,156 B]                                                                                                                              </span><br><span class=\"line\">获取:89 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/universe DEP-11 48x48 Icons [29 B]                                                                                                                                    </span><br><span class=\"line\">获取:90 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/universe DEP-11 64x64 Icons [29 B]                                                                                                                                    </span><br><span class=\"line\">已下载 45.5 MB，耗时 16秒 (2,900 kB/s)</span><br></pre></td></tr></table></figure></p>\n<p>速度超快！<br>5，关闭桌面系统<br>先看下内存<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:~# free</span><br><span class=\"line\">              total        used        free      shared  buff/cache   available</span><br><span class=\"line\">Mem:        4059712      572136     2529292       19044      958284     3304544</span><br><span class=\"line\">Swap:             0           0           0</span><br><span class=\"line\">root@jetson-desktop:~#</span><br></pre></td></tr></table></figure></p>\n<p>关闭桌面<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:~# sudo systemctl set-default multi-user.target</span><br><span class=\"line\">Removed /etc/systemd/system/default.target.</span><br><span class=\"line\">Created symlink /etc/systemd/system/default.target → /lib/systemd/system/multi-user.target.</span><br><span class=\"line\">root@jetson-desktop:~# reboot</span><br></pre></td></tr></table></figure></p>\n<p>再看内存<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">root@jetson-desktop:~# free</span><br><span class=\"line\">              total        used        free      shared  buff/cache   available</span><br><span class=\"line\">Mem:        4059712      321340     3511972       17616      226400     3573020</span><br><span class=\"line\">Swap:             0           0           0</span><br><span class=\"line\">root@jetson-desktop:~#</span><br></pre></td></tr></table></figure></p>\n<p>参考链接：<a href=\"https://www.jianshu.com/p/1fac6cdedd0d\" target=\"_blank\" rel=\"noopener\">https://www.jianshu.com/p/1fac6cdedd0d</a></p>\n"},{"title":"The size of tensor a (5) must match the size of tensor b (3) at non-singleton dimension 3","date":"2018-12-24T19:38:57.000Z","categoies":["框架","pytorch","爬坑"],"_content":"\n******\n打印所有操作的张量形状，然后您将更好地了解Tensor形状如何随每个操作而变化。之后，可以找出要更改的行以使尺寸匹配。\n\n*********\n主要在你的输入尺寸  输出尺寸  模型结构方面考虑 \n*******\n用.size（）排错\n","source":"_posts/The-size-of-tensor-a-(5)-must-match-the-size-of-tensor-b-(3)-at-non-singleton-dimension-3.md","raw":"---\ntitle: The size of tensor a (5) must match the size of tensor b (3) at non-singleton dimension 3\ndate: 2018-12-25 03:38:57\ntags:\n    - 爬坑\ncategoies:\n    - 框架\n    - pytorch\n    - 爬坑\n---\n\n******\n打印所有操作的张量形状，然后您将更好地了解Tensor形状如何随每个操作而变化。之后，可以找出要更改的行以使尺寸匹配。\n\n*********\n主要在你的输入尺寸  输出尺寸  模型结构方面考虑 \n*******\n用.size（）排错\n","slug":"The-size-of-tensor-a-(5)-must-match-the-size-of-tensor-b-(3)-at-non-singleton-dimension-3","published":1,"updated":"2021-07-26T09:58:02.569Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m1b000figtarwp3x27n","content":"<hr>\n<p>打印所有操作的张量形状，然后您将更好地了解Tensor形状如何随每个操作而变化。之后，可以找出要更改的行以使尺寸匹配。</p>\n<hr>\n<p>主要在你的输入尺寸  输出尺寸  模型结构方面考虑 </p>\n<hr>\n<p>用.size（）排错</p>\n","site":{"data":{}},"excerpt":"","more":"<hr>\n<p>打印所有操作的张量形状，然后您将更好地了解Tensor形状如何随每个操作而变化。之后，可以找出要更改的行以使尺寸匹配。</p>\n<hr>\n<p>主要在你的输入尺寸  输出尺寸  模型结构方面考虑 </p>\n<hr>\n<p>用.size（）排错</p>\n"},{"title":"fastai-安装","date":"2018-12-15T07:31:15.000Z","_content":"\n\n*** 来自官方文档!!!!***\n************\n***********\n#### 前提:\n**注意:Python:需要python3.6及其以上**\n\n**fastai需要pytorch1.0以上**\n********\n\n*******\n#### pytorch1.0可直接安装:\n|平台|\t|GPU|\t|cpu|\n|-|-|-|\n|Linux|\t|直接安装|\t|直接安装|\n|Mac|  |源码安装|\t|直接安装|\n|Windows||直接安装|\t|直接安装|\n<font color=red> 具体更新,请看官方:https://pytorch.org/</font>\n***********\n\n# cpu安装:\n\n**`conda` 安装：**\n```\n conda install -c pytorch pytorch-cpu torchvision\n conda install -c fastai fastai\n ```\n **`pip` 安装：**\n ```\n pip install http://download.pytorch.org/whl/cpu/torch-1.0.0-cp36-cp36m-linux_x86_64.whl\n pip install fastai\n```\n*********\n\n# Gpu安装:\n<font color=red> 注意对应cuda版本,以下以9.2为例</font>\n**`conda` 安装：**\n\n```\nconda install -c pytorch pytorch-nightly cuda92\nconda install -c fastai fastai\n ```\n **`pip` 安装：**\n ```\n pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu90/torch_nightly.html\n pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org\n pip install fastai\n```\n***********\n\n\n<font color=red>下图给liunx用户安装cuda提醒:</font>\n\n| CUDA工具包 || NVIDIA（Linux x86_64）显卡驱动 |\n|-|-|\n| CUDA 10.0 || > = 410.00 |\n| CUDA 9.0|\t|> = 384.81|\n| CUDA 8.0| |> = 367.48|\n\n\n","source":"_posts/fastai-安装.md","raw":"---\ntitle:  fastai-安装\ndate: 2018-12-15 15:31:15\ntags:\n    - fastai\ncategories: \n    - 框架\n    - pytorch\n    - fastai\n   \n---\n\n\n*** 来自官方文档!!!!***\n************\n***********\n#### 前提:\n**注意:Python:需要python3.6及其以上**\n\n**fastai需要pytorch1.0以上**\n********\n\n*******\n#### pytorch1.0可直接安装:\n|平台|\t|GPU|\t|cpu|\n|-|-|-|\n|Linux|\t|直接安装|\t|直接安装|\n|Mac|  |源码安装|\t|直接安装|\n|Windows||直接安装|\t|直接安装|\n<font color=red> 具体更新,请看官方:https://pytorch.org/</font>\n***********\n\n# cpu安装:\n\n**`conda` 安装：**\n```\n conda install -c pytorch pytorch-cpu torchvision\n conda install -c fastai fastai\n ```\n **`pip` 安装：**\n ```\n pip install http://download.pytorch.org/whl/cpu/torch-1.0.0-cp36-cp36m-linux_x86_64.whl\n pip install fastai\n```\n*********\n\n# Gpu安装:\n<font color=red> 注意对应cuda版本,以下以9.2为例</font>\n**`conda` 安装：**\n\n```\nconda install -c pytorch pytorch-nightly cuda92\nconda install -c fastai fastai\n ```\n **`pip` 安装：**\n ```\n pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu90/torch_nightly.html\n pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org\n pip install fastai\n```\n***********\n\n\n<font color=red>下图给liunx用户安装cuda提醒:</font>\n\n| CUDA工具包 || NVIDIA（Linux x86_64）显卡驱动 |\n|-|-|\n| CUDA 10.0 || > = 410.00 |\n| CUDA 9.0|\t|> = 384.81|\n| CUDA 8.0| |> = 367.48|\n\n\n","slug":"fastai-安装","published":1,"updated":"2021-07-26T09:58:02.513Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m1d000higta0d8fsc9z","content":"<p><strong><em> 来自官方文档!!!!</em></strong></p>\n<hr>\n<hr>\n<h4 id=\"前提\"><a href=\"#前提\" class=\"headerlink\" title=\"前提:\"></a>前提:</h4><p><strong>注意:Python:需要python3.6及其以上</strong></p>\n<p><strong>fastai需要pytorch1.0以上</strong></p>\n<hr>\n<hr>\n<h4 id=\"pytorch1-0可直接安装\"><a href=\"#pytorch1-0可直接安装\" class=\"headerlink\" title=\"pytorch1.0可直接安装:\"></a>pytorch1.0可直接安装:</h4><table>\n<thead>\n<tr>\n<th>平台</th>\n<th></th>\n<th>GPU</th>\n<th></th>\n<th>cpu</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Linux</td>\n<td></td>\n<td>直接安装</td>\n<td></td>\n<td>直接安装</td>\n</tr>\n<tr>\n<td>Mac</td>\n<td></td>\n<td>源码安装</td>\n<td></td>\n<td>直接安装</td>\n</tr>\n<tr>\n<td>Windows</td>\n<td></td>\n<td>直接安装</td>\n<td></td>\n<td>直接安装</td>\n</tr>\n</tbody>\n</table>\n<font color=\"red\"> 具体更新,请看官方:<a href=\"https://pytorch.org/\" target=\"_blank\" rel=\"noopener\">https://pytorch.org/</a></font><br><strong><strong>***</strong></strong><br><br># cpu安装:<br><br><strong><code>conda</code> 安装：</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda install -c pytorch pytorch-cpu torchvision</span><br><span class=\"line\">conda install -c fastai fastai</span><br></pre></td></tr></table></figure><br><br> <strong><code>pip</code> 安装：</strong><br> <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install http://download.pytorch.org/whl/cpu/torch-1.0.0-cp36-cp36m-linux_x86_64.whl</span><br><span class=\"line\">pip install fastai</span><br></pre></td></tr></table></figure><br><br><strong><strong>*</strong></strong><br><br># Gpu安装:<br><font color=\"red\"> 注意对应cuda版本,以下以9.2为例</font><br><strong><code>conda</code> 安装：</strong><br><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda install -c pytorch pytorch-nightly cuda92</span><br><span class=\"line\">conda install -c fastai fastai</span><br></pre></td></tr></table></figure><br><br> <strong><code>pip</code> 安装：</strong><br> <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu90/torch_nightly.html</span><br><span class=\"line\">pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org</span><br><span class=\"line\">pip install fastai</span><br></pre></td></tr></table></figure><br><br><strong><strong>***</strong></strong><br><br><br><font color=\"red\">下图给liunx用户安装cuda提醒:</font>\n\n<table>\n<thead>\n<tr>\n<th>CUDA工具包</th>\n<th></th>\n<th>NVIDIA（Linux x86_64）显卡驱动</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CUDA 10.0</td>\n<td></td>\n<td>&gt; = 410.00</td>\n</tr>\n<tr>\n<td>CUDA 9.0</td>\n<td></td>\n<td>&gt; = 384.81</td>\n</tr>\n<tr>\n<td>CUDA 8.0</td>\n<td></td>\n<td>&gt; = 367.48</td>\n</tr>\n</tbody>\n</table>\n","site":{"data":{}},"excerpt":"","more":"<p><strong><em> 来自官方文档!!!!</em></strong></p>\n<hr>\n<hr>\n<h4 id=\"前提\"><a href=\"#前提\" class=\"headerlink\" title=\"前提:\"></a>前提:</h4><p><strong>注意:Python:需要python3.6及其以上</strong></p>\n<p><strong>fastai需要pytorch1.0以上</strong></p>\n<hr>\n<hr>\n<h4 id=\"pytorch1-0可直接安装\"><a href=\"#pytorch1-0可直接安装\" class=\"headerlink\" title=\"pytorch1.0可直接安装:\"></a>pytorch1.0可直接安装:</h4><table>\n<thead>\n<tr>\n<th>平台</th>\n<th></th>\n<th>GPU</th>\n<th></th>\n<th>cpu</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Linux</td>\n<td></td>\n<td>直接安装</td>\n<td></td>\n<td>直接安装</td>\n</tr>\n<tr>\n<td>Mac</td>\n<td></td>\n<td>源码安装</td>\n<td></td>\n<td>直接安装</td>\n</tr>\n<tr>\n<td>Windows</td>\n<td></td>\n<td>直接安装</td>\n<td></td>\n<td>直接安装</td>\n</tr>\n</tbody>\n</table>\n<font color=\"red\"> 具体更新,请看官方:<a href=\"https://pytorch.org/\" target=\"_blank\" rel=\"noopener\">https://pytorch.org/</a></font><br><strong><strong>***</strong></strong><br><br># cpu安装:<br><br><strong><code>conda</code> 安装：</strong><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda install -c pytorch pytorch-cpu torchvision</span><br><span class=\"line\">conda install -c fastai fastai</span><br></pre></td></tr></table></figure><br><br> <strong><code>pip</code> 安装：</strong><br> <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install http://download.pytorch.org/whl/cpu/torch-1.0.0-cp36-cp36m-linux_x86_64.whl</span><br><span class=\"line\">pip install fastai</span><br></pre></td></tr></table></figure><br><br><strong><strong>*</strong></strong><br><br># Gpu安装:<br><font color=\"red\"> 注意对应cuda版本,以下以9.2为例</font><br><strong><code>conda</code> 安装：</strong><br><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">conda install -c pytorch pytorch-nightly cuda92</span><br><span class=\"line\">conda install -c fastai fastai</span><br></pre></td></tr></table></figure><br><br> <strong><code>pip</code> 安装：</strong><br> <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu90/torch_nightly.html</span><br><span class=\"line\">pip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.org</span><br><span class=\"line\">pip install fastai</span><br></pre></td></tr></table></figure><br><br><strong><strong>***</strong></strong><br><br><br><font color=\"red\">下图给liunx用户安装cuda提醒:</font>\n\n<table>\n<thead>\n<tr>\n<th>CUDA工具包</th>\n<th></th>\n<th>NVIDIA（Linux x86_64）显卡驱动</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>CUDA 10.0</td>\n<td></td>\n<td>&gt; = 410.00</td>\n</tr>\n<tr>\n<td>CUDA 9.0</td>\n<td></td>\n<td>&gt; = 384.81</td>\n</tr>\n<tr>\n<td>CUDA 8.0</td>\n<td></td>\n<td>&gt; = 367.48</td>\n</tr>\n</tbody>\n</table>\n"},{"title":"fastai-入门视觉","date":"2018-12-15T08:04:01.000Z","_content":"\n<font color=red> 来自官方文档!!</font>\n\n## 视觉库概览:\n1.visionfastai库的模块包含定义数据集和训练计算机视觉任务模型的所有必要功能。它包含四个不同的子模块来实现该目标：\n*************\n2.vision.image包含Image对象的基本定义以及在后台使用的所有函数，以将转换应用于此类对象。\n******\n3.vision.transform 包含我们可用于数据扩充的所有变换。\n********\n4.vision.data包含定义ImageClassificationDataset以及实用功能，以轻松构建DataBunch计算机视觉问题。\n**********\n5.vision.learner 允许您使用预训练的CNN骨干构建和微调模型，或从头开始训练随机​​初始化的模型。\n*********\n\n```python\n\n#首先，从fastai库导入您需要的所有内容。\nfrom fastai.vision import*  #导入计算机视觉库\nfrom fastai  import *        #导入常用库\n\n#\n# 首先，创建一个包含MNIST子集的数据文件夹\n# ，data/mnist_sample使用这个小帮助程序，为您下载它：\n\n\npath=untar_data(URLs.MNIST_SAMPLE)\n#print(path)\n\n#由于下载文件家包含标准文件夹train和valid文件夹，并且每个文件夹包含一个文件夹\n# ，因此您可以DataBunch在一行中创建：\n\ndata=ImageDataBunch.from_folder(path)\n\n# 复习：\n# from_folder：从imagenet风格数据集创建\n# path与train，valid，test子文件夹\n# （或提供valid_pct）\n# “ Imagenet风格 ”数据集看起来像这样（请注意，测试文件夹是可选的）：\n# path\\\n#   train\\\n#     clas1\\\n#     clas2\\\n#     ...\n#   valid\\\n#     clas1\\\n#     clas2\\\n#     ...\n#   test\\\n\n\n\n#加载一个预训练模型（从vision.models）准备进行微调：\n\nlearn=create_cnn(data,models.resnet18,metrics=accuracy)\n\n\n#完成所有工作 开始训练\nlearn.fit(1)\n```\n****************\n*** ok  就这么暴力,完了!!!\n让我想起了sklearn!***\n***************\n\n### 下面来回头看下:\n\n```python\n\n#######################################\n######回   顾###############\n##########################\n#首先来看最重要数据长什么样\n#print(data)\n\n#可以通过获取相应的属性来访问该训练集和验证集\nds = data.train_ds\n# print(ds)\n#\n```\n\n```python\n# 我们顺便看看vision.image，它定义了Image类。\n# 我们的数据集将在索引时返回Image对象。\nfrom fastai.vision import Image\nimport matplotlib.pyplot as plt\nimg,label=ds[0]\n#print(img)\n\n#换种方式显示图片\n\nimg.show(figsize=(2, 1), title='Little ')\n\n#同时 你还可以改变它\n#如旋转\nimg.rotate(35)\n```\n\n```python\n#下面来看看数据增强方式\n# vision.transform让我们进行数据扩充。\n# 最简单的方法是从一组标准变换中进行选择，\n# 其中默认值是为图片设计的\n\n#print(help(get_transforms))\n#创建你想要的列表\n\ntfms=[rotate(degrees=(-20,20)),symmetric_warp(magnitude=(-0.3,0.3))]\n\nprint(tfms)\n\n#可以使用apply tfms方法将这些变换应用于图像\n\nfig,axes=plt.subplots(1,4,figsize=(8,2))\nprint(fig,axes)\nfor ax in axes:\n    ds[0][0].apply_tfms(tfms).show(ax=ax)\n\n\n# 您可以使用转换后的训练和验证数据加载器在单个步骤中\n# 创建一个数据库，并传入一个元组（train_TFMS，valid_TFMS）\n\ndata=ImageDataBunch.from_folder(path,ds_tfms=(tfms,[]))\nprint(data)\n```\n\n```python\n##############################################3\n#下面来看训练过程\n# 现在你已准备好训练一个模型。要创建模型，\n# 只需将您的DataBunch和模型创建函数\n# （例如vision.models或torchvision.models提供的函数）\n# 传递给create_cnn，并调用fit：\n\nlearn=create_cnn(data,models.resnet18,metrics=accuracy,callback_fns = ShowGraph)\n\nlearn.fit(100)\n\n#接下来我们看一下最不正确的图像，以及分类矩阵。\n\n\ninterp=ClassificationInterpretation.from_learner(learn)\ninterp.plot_top_losses(9,figsize=(6,6))\n\n\ninterp.plot_confusion_matrix()\n\n# 要简单地预测新图像的结果（类型为image，\n# 例如用open image打开），\n# 只需使用learn.predict。它返回类，它的索引\n# 和每个类的概率。\nimg=learn.data.train_ds[0][0]\nprint(learn.predict(img))\n```\n\n** <font color=blue>要显示图像记得添加(我是在最后直接显示:</font>\n```\nplt.show()\n```\n\n\n\n\n\n\n\n\n","source":"_posts/fastai-入门视觉.md","raw":"---\ntitle: fastai-入门视觉\ndate: 2018-12-15 16:04:01\ntags:\n    - fastai\ncategories: \n    - 框架\n    - pytorch\n    - fastai\n    \n---\n\n<font color=red> 来自官方文档!!</font>\n\n## 视觉库概览:\n1.visionfastai库的模块包含定义数据集和训练计算机视觉任务模型的所有必要功能。它包含四个不同的子模块来实现该目标：\n*************\n2.vision.image包含Image对象的基本定义以及在后台使用的所有函数，以将转换应用于此类对象。\n******\n3.vision.transform 包含我们可用于数据扩充的所有变换。\n********\n4.vision.data包含定义ImageClassificationDataset以及实用功能，以轻松构建DataBunch计算机视觉问题。\n**********\n5.vision.learner 允许您使用预训练的CNN骨干构建和微调模型，或从头开始训练随机​​初始化的模型。\n*********\n\n```python\n\n#首先，从fastai库导入您需要的所有内容。\nfrom fastai.vision import*  #导入计算机视觉库\nfrom fastai  import *        #导入常用库\n\n#\n# 首先，创建一个包含MNIST子集的数据文件夹\n# ，data/mnist_sample使用这个小帮助程序，为您下载它：\n\n\npath=untar_data(URLs.MNIST_SAMPLE)\n#print(path)\n\n#由于下载文件家包含标准文件夹train和valid文件夹，并且每个文件夹包含一个文件夹\n# ，因此您可以DataBunch在一行中创建：\n\ndata=ImageDataBunch.from_folder(path)\n\n# 复习：\n# from_folder：从imagenet风格数据集创建\n# path与train，valid，test子文件夹\n# （或提供valid_pct）\n# “ Imagenet风格 ”数据集看起来像这样（请注意，测试文件夹是可选的）：\n# path\\\n#   train\\\n#     clas1\\\n#     clas2\\\n#     ...\n#   valid\\\n#     clas1\\\n#     clas2\\\n#     ...\n#   test\\\n\n\n\n#加载一个预训练模型（从vision.models）准备进行微调：\n\nlearn=create_cnn(data,models.resnet18,metrics=accuracy)\n\n\n#完成所有工作 开始训练\nlearn.fit(1)\n```\n****************\n*** ok  就这么暴力,完了!!!\n让我想起了sklearn!***\n***************\n\n### 下面来回头看下:\n\n```python\n\n#######################################\n######回   顾###############\n##########################\n#首先来看最重要数据长什么样\n#print(data)\n\n#可以通过获取相应的属性来访问该训练集和验证集\nds = data.train_ds\n# print(ds)\n#\n```\n\n```python\n# 我们顺便看看vision.image，它定义了Image类。\n# 我们的数据集将在索引时返回Image对象。\nfrom fastai.vision import Image\nimport matplotlib.pyplot as plt\nimg,label=ds[0]\n#print(img)\n\n#换种方式显示图片\n\nimg.show(figsize=(2, 1), title='Little ')\n\n#同时 你还可以改变它\n#如旋转\nimg.rotate(35)\n```\n\n```python\n#下面来看看数据增强方式\n# vision.transform让我们进行数据扩充。\n# 最简单的方法是从一组标准变换中进行选择，\n# 其中默认值是为图片设计的\n\n#print(help(get_transforms))\n#创建你想要的列表\n\ntfms=[rotate(degrees=(-20,20)),symmetric_warp(magnitude=(-0.3,0.3))]\n\nprint(tfms)\n\n#可以使用apply tfms方法将这些变换应用于图像\n\nfig,axes=plt.subplots(1,4,figsize=(8,2))\nprint(fig,axes)\nfor ax in axes:\n    ds[0][0].apply_tfms(tfms).show(ax=ax)\n\n\n# 您可以使用转换后的训练和验证数据加载器在单个步骤中\n# 创建一个数据库，并传入一个元组（train_TFMS，valid_TFMS）\n\ndata=ImageDataBunch.from_folder(path,ds_tfms=(tfms,[]))\nprint(data)\n```\n\n```python\n##############################################3\n#下面来看训练过程\n# 现在你已准备好训练一个模型。要创建模型，\n# 只需将您的DataBunch和模型创建函数\n# （例如vision.models或torchvision.models提供的函数）\n# 传递给create_cnn，并调用fit：\n\nlearn=create_cnn(data,models.resnet18,metrics=accuracy,callback_fns = ShowGraph)\n\nlearn.fit(100)\n\n#接下来我们看一下最不正确的图像，以及分类矩阵。\n\n\ninterp=ClassificationInterpretation.from_learner(learn)\ninterp.plot_top_losses(9,figsize=(6,6))\n\n\ninterp.plot_confusion_matrix()\n\n# 要简单地预测新图像的结果（类型为image，\n# 例如用open image打开），\n# 只需使用learn.predict。它返回类，它的索引\n# 和每个类的概率。\nimg=learn.data.train_ds[0][0]\nprint(learn.predict(img))\n```\n\n** <font color=blue>要显示图像记得添加(我是在最后直接显示:</font>\n```\nplt.show()\n```\n\n\n\n\n\n\n\n\n","slug":"fastai-入门视觉","published":1,"updated":"2021-07-26T09:58:02.514Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m1e000kigtak0uehcto","content":"<font color=\"red\"> 来自官方文档!!</font>\n\n<h2 id=\"视觉库概览\"><a href=\"#视觉库概览\" class=\"headerlink\" title=\"视觉库概览:\"></a>视觉库概览:</h2><p>1.visionfastai库的模块包含定义数据集和训练计算机视觉任务模型的所有必要功能。它包含四个不同的子模块来实现该目标：</p>\n<hr>\n<p>2.vision.image包含Image对象的基本定义以及在后台使用的所有函数，以将转换应用于此类对象。</p>\n<hr>\n<p>3.vision.transform 包含我们可用于数据扩充的所有变换。</p>\n<hr>\n<p>4.vision.data包含定义ImageClassificationDataset以及实用功能，以轻松构建DataBunch计算机视觉问题。</p>\n<hr>\n<p>5.vision.learner 允许您使用预训练的CNN骨干构建和微调模型，或从头开始训练随机​​初始化的模型。</p>\n<hr>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#首先，从fastai库导入您需要的所有内容。</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> fastai.vision <span class=\"keyword\">import</span>*  <span class=\"comment\">#导入计算机视觉库</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> fastai  <span class=\"keyword\">import</span> *        <span class=\"comment\">#导入常用库</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># 首先，创建一个包含MNIST子集的数据文件夹</span></span><br><span class=\"line\"><span class=\"comment\"># ，data/mnist_sample使用这个小帮助程序，为您下载它：</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">path=untar_data(URLs.MNIST_SAMPLE)</span><br><span class=\"line\"><span class=\"comment\">#print(path)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#由于下载文件家包含标准文件夹train和valid文件夹，并且每个文件夹包含一个文件夹</span></span><br><span class=\"line\"><span class=\"comment\"># ，因此您可以DataBunch在一行中创建：</span></span><br><span class=\"line\"></span><br><span class=\"line\">data=ImageDataBunch.from_folder(path)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 复习：</span></span><br><span class=\"line\"><span class=\"comment\"># from_folder：从imagenet风格数据集创建</span></span><br><span class=\"line\"><span class=\"comment\"># path与train，valid，test子文件夹</span></span><br><span class=\"line\"><span class=\"comment\"># （或提供valid_pct）</span></span><br><span class=\"line\"><span class=\"comment\"># “ Imagenet风格 ”数据集看起来像这样（请注意，测试文件夹是可选的）：</span></span><br><span class=\"line\"><span class=\"comment\"># path\\</span></span><br><span class=\"line\"><span class=\"comment\">#   train\\</span></span><br><span class=\"line\"><span class=\"comment\">#     clas1\\</span></span><br><span class=\"line\"><span class=\"comment\">#     clas2\\</span></span><br><span class=\"line\"><span class=\"comment\">#     ...</span></span><br><span class=\"line\"><span class=\"comment\">#   valid\\</span></span><br><span class=\"line\"><span class=\"comment\">#     clas1\\</span></span><br><span class=\"line\"><span class=\"comment\">#     clas2\\</span></span><br><span class=\"line\"><span class=\"comment\">#     ...</span></span><br><span class=\"line\"><span class=\"comment\">#   test\\</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#加载一个预训练模型（从vision.models）准备进行微调：</span></span><br><span class=\"line\"></span><br><span class=\"line\">learn=create_cnn(data,models.resnet18,metrics=accuracy)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#完成所有工作 开始训练</span></span><br><span class=\"line\">learn.fit(<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n<hr>\n<p><strong><em> ok  就这么暴力,完了!!!<br>让我想起了sklearn!</em></strong></p>\n<hr>\n<h3 id=\"下面来回头看下\"><a href=\"#下面来回头看下\" class=\"headerlink\" title=\"下面来回头看下:\"></a>下面来回头看下:</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#######################################</span></span><br><span class=\"line\"><span class=\"comment\">######回   顾###############</span></span><br><span class=\"line\"><span class=\"comment\">##########################</span></span><br><span class=\"line\"><span class=\"comment\">#首先来看最重要数据长什么样</span></span><br><span class=\"line\"><span class=\"comment\">#print(data)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#可以通过获取相应的属性来访问该训练集和验证集</span></span><br><span class=\"line\">ds = data.train_ds</span><br><span class=\"line\"><span class=\"comment\"># print(ds)</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 我们顺便看看vision.image，它定义了Image类。</span></span><br><span class=\"line\"><span class=\"comment\"># 我们的数据集将在索引时返回Image对象。</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> fastai.vision <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\">img,label=ds[<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"comment\">#print(img)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#换种方式显示图片</span></span><br><span class=\"line\"></span><br><span class=\"line\">img.show(figsize=(<span class=\"number\">2</span>, <span class=\"number\">1</span>), title=<span class=\"string\">'Little '</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#同时 你还可以改变它</span></span><br><span class=\"line\"><span class=\"comment\">#如旋转</span></span><br><span class=\"line\">img.rotate(<span class=\"number\">35</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#下面来看看数据增强方式</span></span><br><span class=\"line\"><span class=\"comment\"># vision.transform让我们进行数据扩充。</span></span><br><span class=\"line\"><span class=\"comment\"># 最简单的方法是从一组标准变换中进行选择，</span></span><br><span class=\"line\"><span class=\"comment\"># 其中默认值是为图片设计的</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#print(help(get_transforms))</span></span><br><span class=\"line\"><span class=\"comment\">#创建你想要的列表</span></span><br><span class=\"line\"></span><br><span class=\"line\">tfms=[rotate(degrees=(<span class=\"number\">-20</span>,<span class=\"number\">20</span>)),symmetric_warp(magnitude=(<span class=\"number\">-0.3</span>,<span class=\"number\">0.3</span>))]</span><br><span class=\"line\"></span><br><span class=\"line\">print(tfms)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#可以使用apply tfms方法将这些变换应用于图像</span></span><br><span class=\"line\"></span><br><span class=\"line\">fig,axes=plt.subplots(<span class=\"number\">1</span>,<span class=\"number\">4</span>,figsize=(<span class=\"number\">8</span>,<span class=\"number\">2</span>))</span><br><span class=\"line\">print(fig,axes)</span><br><span class=\"line\"><span class=\"keyword\">for</span> ax <span class=\"keyword\">in</span> axes:</span><br><span class=\"line\">    ds[<span class=\"number\">0</span>][<span class=\"number\">0</span>].apply_tfms(tfms).show(ax=ax)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 您可以使用转换后的训练和验证数据加载器在单个步骤中</span></span><br><span class=\"line\"><span class=\"comment\"># 创建一个数据库，并传入一个元组（train_TFMS，valid_TFMS）</span></span><br><span class=\"line\"></span><br><span class=\"line\">data=ImageDataBunch.from_folder(path,ds_tfms=(tfms,[]))</span><br><span class=\"line\">print(data)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">##############################################3</span></span><br><span class=\"line\"><span class=\"comment\">#下面来看训练过程</span></span><br><span class=\"line\"><span class=\"comment\"># 现在你已准备好训练一个模型。要创建模型，</span></span><br><span class=\"line\"><span class=\"comment\"># 只需将您的DataBunch和模型创建函数</span></span><br><span class=\"line\"><span class=\"comment\"># （例如vision.models或torchvision.models提供的函数）</span></span><br><span class=\"line\"><span class=\"comment\"># 传递给create_cnn，并调用fit：</span></span><br><span class=\"line\"></span><br><span class=\"line\">learn=create_cnn(data,models.resnet18,metrics=accuracy,callback_fns = ShowGraph)</span><br><span class=\"line\"></span><br><span class=\"line\">learn.fit(<span class=\"number\">100</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#接下来我们看一下最不正确的图像，以及分类矩阵。</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">interp=ClassificationInterpretation.from_learner(learn)</span><br><span class=\"line\">interp.plot_top_losses(<span class=\"number\">9</span>,figsize=(<span class=\"number\">6</span>,<span class=\"number\">6</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">interp.plot_confusion_matrix()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 要简单地预测新图像的结果（类型为image，</span></span><br><span class=\"line\"><span class=\"comment\"># 例如用open image打开），</span></span><br><span class=\"line\"><span class=\"comment\"># 只需使用learn.predict。它返回类，它的索引</span></span><br><span class=\"line\"><span class=\"comment\"># 和每个类的概率。</span></span><br><span class=\"line\">img=learn.data.train_ds[<span class=\"number\">0</span>][<span class=\"number\">0</span>]</span><br><span class=\"line\">print(learn.predict(img))</span><br></pre></td></tr></table></figure>\n<p>** <font color=\"blue\">要显示图像记得添加(我是在最后直接显示:</font><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure></p>\n","site":{"data":{}},"excerpt":"","more":"<font color=\"red\"> 来自官方文档!!</font>\n\n<h2 id=\"视觉库概览\"><a href=\"#视觉库概览\" class=\"headerlink\" title=\"视觉库概览:\"></a>视觉库概览:</h2><p>1.visionfastai库的模块包含定义数据集和训练计算机视觉任务模型的所有必要功能。它包含四个不同的子模块来实现该目标：</p>\n<hr>\n<p>2.vision.image包含Image对象的基本定义以及在后台使用的所有函数，以将转换应用于此类对象。</p>\n<hr>\n<p>3.vision.transform 包含我们可用于数据扩充的所有变换。</p>\n<hr>\n<p>4.vision.data包含定义ImageClassificationDataset以及实用功能，以轻松构建DataBunch计算机视觉问题。</p>\n<hr>\n<p>5.vision.learner 允许您使用预训练的CNN骨干构建和微调模型，或从头开始训练随机​​初始化的模型。</p>\n<hr>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#首先，从fastai库导入您需要的所有内容。</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> fastai.vision <span class=\"keyword\">import</span>*  <span class=\"comment\">#导入计算机视觉库</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> fastai  <span class=\"keyword\">import</span> *        <span class=\"comment\">#导入常用库</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br><span class=\"line\"><span class=\"comment\"># 首先，创建一个包含MNIST子集的数据文件夹</span></span><br><span class=\"line\"><span class=\"comment\"># ，data/mnist_sample使用这个小帮助程序，为您下载它：</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">path=untar_data(URLs.MNIST_SAMPLE)</span><br><span class=\"line\"><span class=\"comment\">#print(path)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#由于下载文件家包含标准文件夹train和valid文件夹，并且每个文件夹包含一个文件夹</span></span><br><span class=\"line\"><span class=\"comment\"># ，因此您可以DataBunch在一行中创建：</span></span><br><span class=\"line\"></span><br><span class=\"line\">data=ImageDataBunch.from_folder(path)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 复习：</span></span><br><span class=\"line\"><span class=\"comment\"># from_folder：从imagenet风格数据集创建</span></span><br><span class=\"line\"><span class=\"comment\"># path与train，valid，test子文件夹</span></span><br><span class=\"line\"><span class=\"comment\"># （或提供valid_pct）</span></span><br><span class=\"line\"><span class=\"comment\"># “ Imagenet风格 ”数据集看起来像这样（请注意，测试文件夹是可选的）：</span></span><br><span class=\"line\"><span class=\"comment\"># path\\</span></span><br><span class=\"line\"><span class=\"comment\">#   train\\</span></span><br><span class=\"line\"><span class=\"comment\">#     clas1\\</span></span><br><span class=\"line\"><span class=\"comment\">#     clas2\\</span></span><br><span class=\"line\"><span class=\"comment\">#     ...</span></span><br><span class=\"line\"><span class=\"comment\">#   valid\\</span></span><br><span class=\"line\"><span class=\"comment\">#     clas1\\</span></span><br><span class=\"line\"><span class=\"comment\">#     clas2\\</span></span><br><span class=\"line\"><span class=\"comment\">#     ...</span></span><br><span class=\"line\"><span class=\"comment\">#   test\\</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#加载一个预训练模型（从vision.models）准备进行微调：</span></span><br><span class=\"line\"></span><br><span class=\"line\">learn=create_cnn(data,models.resnet18,metrics=accuracy)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#完成所有工作 开始训练</span></span><br><span class=\"line\">learn.fit(<span class=\"number\">1</span>)</span><br></pre></td></tr></table></figure>\n<hr>\n<p><strong><em> ok  就这么暴力,完了!!!<br>让我想起了sklearn!</em></strong></p>\n<hr>\n<h3 id=\"下面来回头看下\"><a href=\"#下面来回头看下\" class=\"headerlink\" title=\"下面来回头看下:\"></a>下面来回头看下:</h3><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#######################################</span></span><br><span class=\"line\"><span class=\"comment\">######回   顾###############</span></span><br><span class=\"line\"><span class=\"comment\">##########################</span></span><br><span class=\"line\"><span class=\"comment\">#首先来看最重要数据长什么样</span></span><br><span class=\"line\"><span class=\"comment\">#print(data)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#可以通过获取相应的属性来访问该训练集和验证集</span></span><br><span class=\"line\">ds = data.train_ds</span><br><span class=\"line\"><span class=\"comment\"># print(ds)</span></span><br><span class=\"line\"><span class=\"comment\">#</span></span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 我们顺便看看vision.image，它定义了Image类。</span></span><br><span class=\"line\"><span class=\"comment\"># 我们的数据集将在索引时返回Image对象。</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> fastai.vision <span class=\"keyword\">import</span> Image</span><br><span class=\"line\"><span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\">img,label=ds[<span class=\"number\">0</span>]</span><br><span class=\"line\"><span class=\"comment\">#print(img)</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#换种方式显示图片</span></span><br><span class=\"line\"></span><br><span class=\"line\">img.show(figsize=(<span class=\"number\">2</span>, <span class=\"number\">1</span>), title=<span class=\"string\">'Little '</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#同时 你还可以改变它</span></span><br><span class=\"line\"><span class=\"comment\">#如旋转</span></span><br><span class=\"line\">img.rotate(<span class=\"number\">35</span>)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#下面来看看数据增强方式</span></span><br><span class=\"line\"><span class=\"comment\"># vision.transform让我们进行数据扩充。</span></span><br><span class=\"line\"><span class=\"comment\"># 最简单的方法是从一组标准变换中进行选择，</span></span><br><span class=\"line\"><span class=\"comment\"># 其中默认值是为图片设计的</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#print(help(get_transforms))</span></span><br><span class=\"line\"><span class=\"comment\">#创建你想要的列表</span></span><br><span class=\"line\"></span><br><span class=\"line\">tfms=[rotate(degrees=(<span class=\"number\">-20</span>,<span class=\"number\">20</span>)),symmetric_warp(magnitude=(<span class=\"number\">-0.3</span>,<span class=\"number\">0.3</span>))]</span><br><span class=\"line\"></span><br><span class=\"line\">print(tfms)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#可以使用apply tfms方法将这些变换应用于图像</span></span><br><span class=\"line\"></span><br><span class=\"line\">fig,axes=plt.subplots(<span class=\"number\">1</span>,<span class=\"number\">4</span>,figsize=(<span class=\"number\">8</span>,<span class=\"number\">2</span>))</span><br><span class=\"line\">print(fig,axes)</span><br><span class=\"line\"><span class=\"keyword\">for</span> ax <span class=\"keyword\">in</span> axes:</span><br><span class=\"line\">    ds[<span class=\"number\">0</span>][<span class=\"number\">0</span>].apply_tfms(tfms).show(ax=ax)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 您可以使用转换后的训练和验证数据加载器在单个步骤中</span></span><br><span class=\"line\"><span class=\"comment\"># 创建一个数据库，并传入一个元组（train_TFMS，valid_TFMS）</span></span><br><span class=\"line\"></span><br><span class=\"line\">data=ImageDataBunch.from_folder(path,ds_tfms=(tfms,[]))</span><br><span class=\"line\">print(data)</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">##############################################3</span></span><br><span class=\"line\"><span class=\"comment\">#下面来看训练过程</span></span><br><span class=\"line\"><span class=\"comment\"># 现在你已准备好训练一个模型。要创建模型，</span></span><br><span class=\"line\"><span class=\"comment\"># 只需将您的DataBunch和模型创建函数</span></span><br><span class=\"line\"><span class=\"comment\"># （例如vision.models或torchvision.models提供的函数）</span></span><br><span class=\"line\"><span class=\"comment\"># 传递给create_cnn，并调用fit：</span></span><br><span class=\"line\"></span><br><span class=\"line\">learn=create_cnn(data,models.resnet18,metrics=accuracy,callback_fns = ShowGraph)</span><br><span class=\"line\"></span><br><span class=\"line\">learn.fit(<span class=\"number\">100</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#接下来我们看一下最不正确的图像，以及分类矩阵。</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">interp=ClassificationInterpretation.from_learner(learn)</span><br><span class=\"line\">interp.plot_top_losses(<span class=\"number\">9</span>,figsize=(<span class=\"number\">6</span>,<span class=\"number\">6</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">interp.plot_confusion_matrix()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 要简单地预测新图像的结果（类型为image，</span></span><br><span class=\"line\"><span class=\"comment\"># 例如用open image打开），</span></span><br><span class=\"line\"><span class=\"comment\"># 只需使用learn.predict。它返回类，它的索引</span></span><br><span class=\"line\"><span class=\"comment\"># 和每个类的概率。</span></span><br><span class=\"line\">img=learn.data.train_ds[<span class=\"number\">0</span>][<span class=\"number\">0</span>]</span><br><span class=\"line\">print(learn.predict(img))</span><br></pre></td></tr></table></figure>\n<p>** <font color=\"blue\">要显示图像记得添加(我是在最后直接显示:</font><br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">plt.show()</span><br></pre></td></tr></table></figure></p>\n"},{"title":"回顾-instaGAN","date":"2019-02-21T05:40:56.000Z","_content":"\n# 1.InstaGAN简介：\n[InstaGAN](https://openreview.net/forum?id=ryxwJhC9YX)这种 GAN 结合了实例信息（如目标分割掩码），提高了多实例转换的能力。在保持实例置换不变性的同时，该 GAN 对图像和相应的实例属性集进行转换。为此，研究人员引入了一个语境保留损失函数，鼓励网络学习目标实例之外的恒等函数。此外，他们还提出了一种序列 mini-batch 推理/训练技术，这种技术借助有限的 GPU 内存处理多个实例，增强了该网络在多实例任务中的泛化能力。\n*********\n是Cycle GAN的改进版本。虽然Cycle GAN替换不能改变形状，但它可以改变形状。但老实说，这种印象是准确度和分辨率仍然很低\n***********\n\n# 2. instaGANGAN网络结构:\n如图:\n![](https://blog.mviai.com/images/instaGAN/network.png)\n\n* 首先看图（左边）\n\t* 这是全局图，可以看到依然是cycleGAN模式，最大特点就是原图与mask进行合并（cat）输入和输出\n*（右边）\n\t* 大体上我们可以把G看做![](https://blog.mviai.com/images/instaGAN/g.png)，d看做![](https://blog.mviai.com/images/instaGAN/d.png)\n\t* 看到原图与mask合并后，还加了一个add模块 ，即为了获得属性，我们对所有集合元素的不变性求和，然后将其与等方差的恒等映射连接起来。\n\t* 中间f，表示用通过f函数提取特征。\n# 3.instaGAN损失函数\n其实就是把加一个约束，保证masks之外的信息保持不变（下式中的L_{ctx}项）。整个loss如下：\n![](https://blog.mviai.com/images/instaGAN/loss.png)\n\n对比下cycleGAN的损失函数\n![](https://blog.mviai.com/images/instaGAN/closs.png)\n\n然后在分开看下instaGAN的loss：\n![](https://blog.mviai.com/images/instaGAN/inloss.png)\n\n* 解释下：\n\t* LSGAN损失函数时最基本的GAN网络损失函数\n    * cycle-consistency loss cyclegan网络的损失函数，为保证图像翻译过程中映射关系一一对应\n    * identity mapping loss 也是内容损失函数保证图像翻译前后内容不变\n    * context preserving loss ，也是保证在实例翻译时图像的背景内容不发生变化。\n\t\n# 4 创新点\n1、提出了一个多属性图像翻译的网络结构，且属性之间的顺序是任意的\n2、提出了context preserving loss来鼓励网络去学习一个目标示例的之外的一个恒等映射\n3、提出一种sequential mini-batch的方法顺序生成mini-batchs的属性，而不是在整个数据集上做一次。\n\t* sequential mini-batch其实就是渐进迭代的方法把mask分开，一个个生成就好了。但是这里要注意，通常小的mask放到后面效果会更好。因为迭代进行的话，每次生成的图片都会被改变，后面如果是大mask，很容易把前面生成的小mask跟淹没掉。\n所以，使用这种办法，一定程度上破坏了object mask之间的时序不变性，如果GPU显存足够，就不要用这种方法了。\n\n\n\n\n","source":"_posts/instagan-pytorch1.1实现.md","raw":"---\ntitle: 回顾-instaGAN\ndate: 2019-2-21 13:40:56\ntags:\n    - instaGAN\n\ncategories: \n    - 框架\n    - pytorch\n    - GAN\n---\n\n# 1.InstaGAN简介：\n[InstaGAN](https://openreview.net/forum?id=ryxwJhC9YX)这种 GAN 结合了实例信息（如目标分割掩码），提高了多实例转换的能力。在保持实例置换不变性的同时，该 GAN 对图像和相应的实例属性集进行转换。为此，研究人员引入了一个语境保留损失函数，鼓励网络学习目标实例之外的恒等函数。此外，他们还提出了一种序列 mini-batch 推理/训练技术，这种技术借助有限的 GPU 内存处理多个实例，增强了该网络在多实例任务中的泛化能力。\n*********\n是Cycle GAN的改进版本。虽然Cycle GAN替换不能改变形状，但它可以改变形状。但老实说，这种印象是准确度和分辨率仍然很低\n***********\n\n# 2. instaGANGAN网络结构:\n如图:\n![](https://blog.mviai.com/images/instaGAN/network.png)\n\n* 首先看图（左边）\n\t* 这是全局图，可以看到依然是cycleGAN模式，最大特点就是原图与mask进行合并（cat）输入和输出\n*（右边）\n\t* 大体上我们可以把G看做![](https://blog.mviai.com/images/instaGAN/g.png)，d看做![](https://blog.mviai.com/images/instaGAN/d.png)\n\t* 看到原图与mask合并后，还加了一个add模块 ，即为了获得属性，我们对所有集合元素的不变性求和，然后将其与等方差的恒等映射连接起来。\n\t* 中间f，表示用通过f函数提取特征。\n# 3.instaGAN损失函数\n其实就是把加一个约束，保证masks之外的信息保持不变（下式中的L_{ctx}项）。整个loss如下：\n![](https://blog.mviai.com/images/instaGAN/loss.png)\n\n对比下cycleGAN的损失函数\n![](https://blog.mviai.com/images/instaGAN/closs.png)\n\n然后在分开看下instaGAN的loss：\n![](https://blog.mviai.com/images/instaGAN/inloss.png)\n\n* 解释下：\n\t* LSGAN损失函数时最基本的GAN网络损失函数\n    * cycle-consistency loss cyclegan网络的损失函数，为保证图像翻译过程中映射关系一一对应\n    * identity mapping loss 也是内容损失函数保证图像翻译前后内容不变\n    * context preserving loss ，也是保证在实例翻译时图像的背景内容不发生变化。\n\t\n# 4 创新点\n1、提出了一个多属性图像翻译的网络结构，且属性之间的顺序是任意的\n2、提出了context preserving loss来鼓励网络去学习一个目标示例的之外的一个恒等映射\n3、提出一种sequential mini-batch的方法顺序生成mini-batchs的属性，而不是在整个数据集上做一次。\n\t* sequential mini-batch其实就是渐进迭代的方法把mask分开，一个个生成就好了。但是这里要注意，通常小的mask放到后面效果会更好。因为迭代进行的话，每次生成的图片都会被改变，后面如果是大mask，很容易把前面生成的小mask跟淹没掉。\n所以，使用这种办法，一定程度上破坏了object mask之间的时序不变性，如果GPU显存足够，就不要用这种方法了。\n\n\n\n\n","slug":"instagan-pytorch1.1实现","published":1,"updated":"2021-07-26T09:58:02.514Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m1g000migtax17ipfwu","content":"<h1 id=\"1-InstaGAN简介：\"><a href=\"#1-InstaGAN简介：\" class=\"headerlink\" title=\"1.InstaGAN简介：\"></a>1.InstaGAN简介：</h1><p><a href=\"https://openreview.net/forum?id=ryxwJhC9YX\" target=\"_blank\" rel=\"noopener\">InstaGAN</a>这种 GAN 结合了实例信息（如目标分割掩码），提高了多实例转换的能力。在保持实例置换不变性的同时，该 GAN 对图像和相应的实例属性集进行转换。为此，研究人员引入了一个语境保留损失函数，鼓励网络学习目标实例之外的恒等函数。此外，他们还提出了一种序列 mini-batch 推理/训练技术，这种技术借助有限的 GPU 内存处理多个实例，增强了该网络在多实例任务中的泛化能力。</p>\n<hr>\n<p>是Cycle GAN的改进版本。虽然Cycle GAN替换不能改变形状，但它可以改变形状。但老实说，这种印象是准确度和分辨率仍然很低</p>\n<hr>\n<h1 id=\"2-instaGANGAN网络结构\"><a href=\"#2-instaGANGAN网络结构\" class=\"headerlink\" title=\"2. instaGANGAN网络结构:\"></a>2. instaGANGAN网络结构:</h1><p>如图:<br><img src=\"https://blog.mviai.com/images/instaGAN/network.png\" alt></p>\n<ul>\n<li>首先看图（左边）<ul>\n<li>这是全局图，可以看到依然是cycleGAN模式，最大特点就是原图与mask进行合并（cat）输入和输出<br>*（右边）</li>\n<li>大体上我们可以把G看做<img src=\"https://blog.mviai.com/images/instaGAN/g.png\" alt>，d看做<img src=\"https://blog.mviai.com/images/instaGAN/d.png\" alt></li>\n<li>看到原图与mask合并后，还加了一个add模块 ，即为了获得属性，我们对所有集合元素的不变性求和，然后将其与等方差的恒等映射连接起来。</li>\n<li>中间f，表示用通过f函数提取特征。<h1 id=\"3-instaGAN损失函数\"><a href=\"#3-instaGAN损失函数\" class=\"headerlink\" title=\"3.instaGAN损失函数\"></a>3.instaGAN损失函数</h1>其实就是把加一个约束，保证masks之外的信息保持不变（下式中的L_{ctx}项）。整个loss如下：<br><img src=\"https://blog.mviai.com/images/instaGAN/loss.png\" alt></li>\n</ul>\n</li>\n</ul>\n<p>对比下cycleGAN的损失函数<br><img src=\"https://blog.mviai.com/images/instaGAN/closs.png\" alt></p>\n<p>然后在分开看下instaGAN的loss：<br><img src=\"https://blog.mviai.com/images/instaGAN/inloss.png\" alt></p>\n<ul>\n<li>解释下：<ul>\n<li>LSGAN损失函数时最基本的GAN网络损失函数</li>\n<li>cycle-consistency loss cyclegan网络的损失函数，为保证图像翻译过程中映射关系一一对应</li>\n<li>identity mapping loss 也是内容损失函数保证图像翻译前后内容不变</li>\n<li>context preserving loss ，也是保证在实例翻译时图像的背景内容不发生变化。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"4-创新点\"><a href=\"#4-创新点\" class=\"headerlink\" title=\"4 创新点\"></a>4 创新点</h1><p>1、提出了一个多属性图像翻译的网络结构，且属性之间的顺序是任意的<br>2、提出了context preserving loss来鼓励网络去学习一个目标示例的之外的一个恒等映射<br>3、提出一种sequential mini-batch的方法顺序生成mini-batchs的属性，而不是在整个数据集上做一次。</p>\n<pre><code>* sequential mini-batch其实就是渐进迭代的方法把mask分开，一个个生成就好了。但是这里要注意，通常小的mask放到后面效果会更好。因为迭代进行的话，每次生成的图片都会被改变，后面如果是大mask，很容易把前面生成的小mask跟淹没掉。\n</code></pre><p>所以，使用这种办法，一定程度上破坏了object mask之间的时序不变性，如果GPU显存足够，就不要用这种方法了。</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"1-InstaGAN简介：\"><a href=\"#1-InstaGAN简介：\" class=\"headerlink\" title=\"1.InstaGAN简介：\"></a>1.InstaGAN简介：</h1><p><a href=\"https://openreview.net/forum?id=ryxwJhC9YX\" target=\"_blank\" rel=\"noopener\">InstaGAN</a>这种 GAN 结合了实例信息（如目标分割掩码），提高了多实例转换的能力。在保持实例置换不变性的同时，该 GAN 对图像和相应的实例属性集进行转换。为此，研究人员引入了一个语境保留损失函数，鼓励网络学习目标实例之外的恒等函数。此外，他们还提出了一种序列 mini-batch 推理/训练技术，这种技术借助有限的 GPU 内存处理多个实例，增强了该网络在多实例任务中的泛化能力。</p>\n<hr>\n<p>是Cycle GAN的改进版本。虽然Cycle GAN替换不能改变形状，但它可以改变形状。但老实说，这种印象是准确度和分辨率仍然很低</p>\n<hr>\n<h1 id=\"2-instaGANGAN网络结构\"><a href=\"#2-instaGANGAN网络结构\" class=\"headerlink\" title=\"2. instaGANGAN网络结构:\"></a>2. instaGANGAN网络结构:</h1><p>如图:<br><img src=\"https://blog.mviai.com/images/instaGAN/network.png\" alt></p>\n<ul>\n<li>首先看图（左边）<ul>\n<li>这是全局图，可以看到依然是cycleGAN模式，最大特点就是原图与mask进行合并（cat）输入和输出<br>*（右边）</li>\n<li>大体上我们可以把G看做<img src=\"https://blog.mviai.com/images/instaGAN/g.png\" alt>，d看做<img src=\"https://blog.mviai.com/images/instaGAN/d.png\" alt></li>\n<li>看到原图与mask合并后，还加了一个add模块 ，即为了获得属性，我们对所有集合元素的不变性求和，然后将其与等方差的恒等映射连接起来。</li>\n<li>中间f，表示用通过f函数提取特征。<h1 id=\"3-instaGAN损失函数\"><a href=\"#3-instaGAN损失函数\" class=\"headerlink\" title=\"3.instaGAN损失函数\"></a>3.instaGAN损失函数</h1>其实就是把加一个约束，保证masks之外的信息保持不变（下式中的L_{ctx}项）。整个loss如下：<br><img src=\"https://blog.mviai.com/images/instaGAN/loss.png\" alt></li>\n</ul>\n</li>\n</ul>\n<p>对比下cycleGAN的损失函数<br><img src=\"https://blog.mviai.com/images/instaGAN/closs.png\" alt></p>\n<p>然后在分开看下instaGAN的loss：<br><img src=\"https://blog.mviai.com/images/instaGAN/inloss.png\" alt></p>\n<ul>\n<li>解释下：<ul>\n<li>LSGAN损失函数时最基本的GAN网络损失函数</li>\n<li>cycle-consistency loss cyclegan网络的损失函数，为保证图像翻译过程中映射关系一一对应</li>\n<li>identity mapping loss 也是内容损失函数保证图像翻译前后内容不变</li>\n<li>context preserving loss ，也是保证在实例翻译时图像的背景内容不发生变化。</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"4-创新点\"><a href=\"#4-创新点\" class=\"headerlink\" title=\"4 创新点\"></a>4 创新点</h1><p>1、提出了一个多属性图像翻译的网络结构，且属性之间的顺序是任意的<br>2、提出了context preserving loss来鼓励网络去学习一个目标示例的之外的一个恒等映射<br>3、提出一种sequential mini-batch的方法顺序生成mini-batchs的属性，而不是在整个数据集上做一次。</p>\n<pre><code>* sequential mini-batch其实就是渐进迭代的方法把mask分开，一个个生成就好了。但是这里要注意，通常小的mask放到后面效果会更好。因为迭代进行的话，每次生成的图片都会被改变，后面如果是大mask，很容易把前面生成的小mask跟淹没掉。\n</code></pre><p>所以，使用这种办法，一定程度上破坏了object mask之间的时序不变性，如果GPU显存足够，就不要用这种方法了。</p>\n"},{"title":"php中添加html中的css，js，图片，视频等外部文件方法","url":"129.html","id":"129","date":"2018-04-08T08:15:10.000Z","_content":"\nphp中添加html中的css，js，图片，视频等外部文件方法\n-------------------------------\n\n**方法一：**\n--------\n\n1、将 xx.html 修改为 page-xx.php 上传到你当前使用的主题目录中； 2、在WordPress后台创建别名为 xx 的页面后发布，大功告成。 **注意：创建的页面别名一定要与page-后面一样。或者在步骤1中将xx改为你的页面ID。**\n\n**方法二：**\n--------\n\n1、将 xx.html 修改为page-template-xx.php 然后再该文件头部添加：\n\n    <?php\n    /*\n    Template Name: xx 页面模板\n    */\n    ?>\n    \n\n然后上传到你当前使用的主题目录中； 2、在WordPress后台创建别名为 xx 的页面并选择页面模板为第一步中创建的 xx页面模板，然后发布，大功告成。 **如果你添加的页面是首页，可以在 设置 > 阅读 \\> 首页显示 中设置将此页面设置为首页。**\n\n**关于CSS、JS、图片等外部文件**\n--------------------\n\n如果你的页面有引用CSS、JS以及图片，例如：sample.css、sample.js、sample.jpg，可以将这些文件一并复制到主题目录下，然后引用地址改为：\n\n    <link href=\"<?php echo get_theme_file_uri( 'sample.css' ); ?>\" rel=\"stylesheet\" type=\"text/css\" />\n    <script src=\"<?php echo get_theme_file_uri( 'sample.js' ); ?>\" type=\"text/javascript\"></script>\n    <img src=\"<?php echo get_theme_file_uri( 'sample.jpg' ); ?>\" />\n    \n\n如果有视频等，同上面方法。\n\n* * *\n\n**如果你想了解更多：**\n-------------\n\n2017.11.04 新增： 上面介绍了将WordPress转换为Page（页面）的方法，下面介绍转换为首页、分类、标签、文章等页面的方法：\n\n1.  front-page.php**：这个文件是首页，**如果没有则使用上面方法二中在后台设置为首页的页面；\n2.  home.php：文档归档页面，通常1中都没有使用这个显示首页；\n3.  index.php：1、2都没有使用这个显示首页；\n4.  single.php：文章模板文件；\n5.  404.php：404页面文件；\n6.  page.php：页面模板文件，支持 page-$id （即页面 ID）或 page-$slug （即页面别名）；\n7.  category.php：分类归档模板文件，支持 category-$id 或category-$slug ；\n8.  tag.php：标签归档模板文件，支持 category-$id 或category-$slug ；\n9.  author.php：作者归档模板文件，支持 category-$id 或 category-$slug；\n10.  date.php：日期归档模板文件；\n11.  archive.php：如果主题没有7-10之中的任一文件，那么都会用此模板文件显示对应内容，当此模板文件也不存在时，则使用index.php显示，支持 archive-$id 或archive-$slug。\n\nheader.php、footer.php、sidebar.php等文件一般都是“页面部分”模板文件，即：页眉、页脚、边栏。 如果你能看懂英文，详细可参考官方文档： [WordPress模板文件等级介绍（官方）](https://link.zhihu.com/?target=https%3A//developer.wordpress.org/themes/basics/template-hierarchy/) [WordPress获取主题目录里的文件和目录](https://link.zhihu.com/?target=https%3A//developer.wordpress.org/themes/basics/linking-theme-files-directories/)\n\n[@马向阳](https://www.zhihu.com/question/20129430/answer/40653740)\n","source":"_posts/php中添加html中的css，js，图片，视频等外部文件方法.md","raw":"---\ntitle: php中添加html中的css，js，图片，视频等外部文件方法\ntags:\n  - wordpress\nurl: 129.html\nid: 129\ncategories:\n  - 网站\n  - wordpress\ndate: 2018-04-08 16:15:10\n---\n\nphp中添加html中的css，js，图片，视频等外部文件方法\n-------------------------------\n\n**方法一：**\n--------\n\n1、将 xx.html 修改为 page-xx.php 上传到你当前使用的主题目录中； 2、在WordPress后台创建别名为 xx 的页面后发布，大功告成。 **注意：创建的页面别名一定要与page-后面一样。或者在步骤1中将xx改为你的页面ID。**\n\n**方法二：**\n--------\n\n1、将 xx.html 修改为page-template-xx.php 然后再该文件头部添加：\n\n    <?php\n    /*\n    Template Name: xx 页面模板\n    */\n    ?>\n    \n\n然后上传到你当前使用的主题目录中； 2、在WordPress后台创建别名为 xx 的页面并选择页面模板为第一步中创建的 xx页面模板，然后发布，大功告成。 **如果你添加的页面是首页，可以在 设置 > 阅读 \\> 首页显示 中设置将此页面设置为首页。**\n\n**关于CSS、JS、图片等外部文件**\n--------------------\n\n如果你的页面有引用CSS、JS以及图片，例如：sample.css、sample.js、sample.jpg，可以将这些文件一并复制到主题目录下，然后引用地址改为：\n\n    <link href=\"<?php echo get_theme_file_uri( 'sample.css' ); ?>\" rel=\"stylesheet\" type=\"text/css\" />\n    <script src=\"<?php echo get_theme_file_uri( 'sample.js' ); ?>\" type=\"text/javascript\"></script>\n    <img src=\"<?php echo get_theme_file_uri( 'sample.jpg' ); ?>\" />\n    \n\n如果有视频等，同上面方法。\n\n* * *\n\n**如果你想了解更多：**\n-------------\n\n2017.11.04 新增： 上面介绍了将WordPress转换为Page（页面）的方法，下面介绍转换为首页、分类、标签、文章等页面的方法：\n\n1.  front-page.php**：这个文件是首页，**如果没有则使用上面方法二中在后台设置为首页的页面；\n2.  home.php：文档归档页面，通常1中都没有使用这个显示首页；\n3.  index.php：1、2都没有使用这个显示首页；\n4.  single.php：文章模板文件；\n5.  404.php：404页面文件；\n6.  page.php：页面模板文件，支持 page-$id （即页面 ID）或 page-$slug （即页面别名）；\n7.  category.php：分类归档模板文件，支持 category-$id 或category-$slug ；\n8.  tag.php：标签归档模板文件，支持 category-$id 或category-$slug ；\n9.  author.php：作者归档模板文件，支持 category-$id 或 category-$slug；\n10.  date.php：日期归档模板文件；\n11.  archive.php：如果主题没有7-10之中的任一文件，那么都会用此模板文件显示对应内容，当此模板文件也不存在时，则使用index.php显示，支持 archive-$id 或archive-$slug。\n\nheader.php、footer.php、sidebar.php等文件一般都是“页面部分”模板文件，即：页眉、页脚、边栏。 如果你能看懂英文，详细可参考官方文档： [WordPress模板文件等级介绍（官方）](https://link.zhihu.com/?target=https%3A//developer.wordpress.org/themes/basics/template-hierarchy/) [WordPress获取主题目录里的文件和目录](https://link.zhihu.com/?target=https%3A//developer.wordpress.org/themes/basics/linking-theme-files-directories/)\n\n[@马向阳](https://www.zhihu.com/question/20129430/answer/40653740)\n","slug":"php中添加html中的css，js，图片，视频等外部文件方法","published":1,"updated":"2021-07-26T09:58:02.516Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m1k000pigtaq1qbcu2a","content":"<h2 id=\"php中添加html中的css，js，图片，视频等外部文件方法\"><a href=\"#php中添加html中的css，js，图片，视频等外部文件方法\" class=\"headerlink\" title=\"php中添加html中的css，js，图片，视频等外部文件方法\"></a>php中添加html中的css，js，图片，视频等外部文件方法</h2><h2 id=\"方法一：\"><a href=\"#方法一：\" class=\"headerlink\" title=\"方法一：\"></a><strong>方法一：</strong></h2><p>1、将 xx.html 修改为 page-xx.php 上传到你当前使用的主题目录中； 2、在WordPress后台创建别名为 xx 的页面后发布，大功告成。 <strong>注意：创建的页面别名一定要与page-后面一样。或者在步骤1中将xx改为你的页面ID。</strong></p>\n<h2 id=\"方法二：\"><a href=\"#方法二：\" class=\"headerlink\" title=\"方法二：\"></a><strong>方法二：</strong></h2><p>1、将 xx.html 修改为page-template-xx.php 然后再该文件头部添加：</p>\n<pre><code>&lt;?php\n/*\nTemplate Name: xx 页面模板\n*/\n?&gt;\n</code></pre><p>然后上传到你当前使用的主题目录中； 2、在WordPress后台创建别名为 xx 的页面并选择页面模板为第一步中创建的 xx页面模板，然后发布，大功告成。 <strong>如果你添加的页面是首页，可以在 设置 &gt; 阅读 > 首页显示 中设置将此页面设置为首页。</strong></p>\n<h2 id=\"关于CSS、JS、图片等外部文件\"><a href=\"#关于CSS、JS、图片等外部文件\" class=\"headerlink\" title=\"关于CSS、JS、图片等外部文件\"></a><strong>关于CSS、JS、图片等外部文件</strong></h2><p>如果你的页面有引用CSS、JS以及图片，例如：sample.css、sample.js、sample.jpg，可以将这些文件一并复制到主题目录下，然后引用地址改为：</p>\n<pre><code>&lt;link href=&quot;&lt;?php echo get_theme_file_uri( &apos;sample.css&apos; ); ?&gt;&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot; /&gt;\n&lt;script src=&quot;&lt;?php echo get_theme_file_uri( &apos;sample.js&apos; ); ?&gt;&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;\n&lt;img src=&quot;&lt;?php echo get_theme_file_uri( &apos;sample.jpg&apos; ); ?&gt;&quot; /&gt;\n</code></pre><p>如果有视频等，同上面方法。</p>\n<hr>\n<h2 id=\"如果你想了解更多：\"><a href=\"#如果你想了解更多：\" class=\"headerlink\" title=\"如果你想了解更多：\"></a><strong>如果你想了解更多：</strong></h2><p>2017.11.04 新增： 上面介绍了将WordPress转换为Page（页面）的方法，下面介绍转换为首页、分类、标签、文章等页面的方法：</p>\n<ol>\n<li>front-page.php<strong>：这个文件是首页，</strong>如果没有则使用上面方法二中在后台设置为首页的页面；</li>\n<li>home.php：文档归档页面，通常1中都没有使用这个显示首页；</li>\n<li>index.php：1、2都没有使用这个显示首页；</li>\n<li>single.php：文章模板文件；</li>\n<li>404.php：404页面文件；</li>\n<li>page.php：页面模板文件，支持 page-$id （即页面 ID）或 page-$slug （即页面别名）；</li>\n<li>category.php：分类归档模板文件，支持 category-$id 或category-$slug ；</li>\n<li>tag.php：标签归档模板文件，支持 category-$id 或category-$slug ；</li>\n<li>author.php：作者归档模板文件，支持 category-$id 或 category-$slug；</li>\n<li>date.php：日期归档模板文件；</li>\n<li>archive.php：如果主题没有7-10之中的任一文件，那么都会用此模板文件显示对应内容，当此模板文件也不存在时，则使用index.php显示，支持 archive-$id 或archive-$slug。</li>\n</ol>\n<p>header.php、footer.php、sidebar.php等文件一般都是“页面部分”模板文件，即：页眉、页脚、边栏。 如果你能看懂英文，详细可参考官方文档： <a href=\"https://link.zhihu.com/?target=https%3A//developer.wordpress.org/themes/basics/template-hierarchy/\" target=\"_blank\" rel=\"noopener\">WordPress模板文件等级介绍（官方）</a> <a href=\"https://link.zhihu.com/?target=https%3A//developer.wordpress.org/themes/basics/linking-theme-files-directories/\" target=\"_blank\" rel=\"noopener\">WordPress获取主题目录里的文件和目录</a></p>\n<p><a href=\"https://www.zhihu.com/question/20129430/answer/40653740\" target=\"_blank\" rel=\"noopener\">@马向阳</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"php中添加html中的css，js，图片，视频等外部文件方法\"><a href=\"#php中添加html中的css，js，图片，视频等外部文件方法\" class=\"headerlink\" title=\"php中添加html中的css，js，图片，视频等外部文件方法\"></a>php中添加html中的css，js，图片，视频等外部文件方法</h2><h2 id=\"方法一：\"><a href=\"#方法一：\" class=\"headerlink\" title=\"方法一：\"></a><strong>方法一：</strong></h2><p>1、将 xx.html 修改为 page-xx.php 上传到你当前使用的主题目录中； 2、在WordPress后台创建别名为 xx 的页面后发布，大功告成。 <strong>注意：创建的页面别名一定要与page-后面一样。或者在步骤1中将xx改为你的页面ID。</strong></p>\n<h2 id=\"方法二：\"><a href=\"#方法二：\" class=\"headerlink\" title=\"方法二：\"></a><strong>方法二：</strong></h2><p>1、将 xx.html 修改为page-template-xx.php 然后再该文件头部添加：</p>\n<pre><code>&lt;?php\n/*\nTemplate Name: xx 页面模板\n*/\n?&gt;\n</code></pre><p>然后上传到你当前使用的主题目录中； 2、在WordPress后台创建别名为 xx 的页面并选择页面模板为第一步中创建的 xx页面模板，然后发布，大功告成。 <strong>如果你添加的页面是首页，可以在 设置 &gt; 阅读 > 首页显示 中设置将此页面设置为首页。</strong></p>\n<h2 id=\"关于CSS、JS、图片等外部文件\"><a href=\"#关于CSS、JS、图片等外部文件\" class=\"headerlink\" title=\"关于CSS、JS、图片等外部文件\"></a><strong>关于CSS、JS、图片等外部文件</strong></h2><p>如果你的页面有引用CSS、JS以及图片，例如：sample.css、sample.js、sample.jpg，可以将这些文件一并复制到主题目录下，然后引用地址改为：</p>\n<pre><code>&lt;link href=&quot;&lt;?php echo get_theme_file_uri( &apos;sample.css&apos; ); ?&gt;&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot; /&gt;\n&lt;script src=&quot;&lt;?php echo get_theme_file_uri( &apos;sample.js&apos; ); ?&gt;&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt;\n&lt;img src=&quot;&lt;?php echo get_theme_file_uri( &apos;sample.jpg&apos; ); ?&gt;&quot; /&gt;\n</code></pre><p>如果有视频等，同上面方法。</p>\n<hr>\n<h2 id=\"如果你想了解更多：\"><a href=\"#如果你想了解更多：\" class=\"headerlink\" title=\"如果你想了解更多：\"></a><strong>如果你想了解更多：</strong></h2><p>2017.11.04 新增： 上面介绍了将WordPress转换为Page（页面）的方法，下面介绍转换为首页、分类、标签、文章等页面的方法：</p>\n<ol>\n<li>front-page.php<strong>：这个文件是首页，</strong>如果没有则使用上面方法二中在后台设置为首页的页面；</li>\n<li>home.php：文档归档页面，通常1中都没有使用这个显示首页；</li>\n<li>index.php：1、2都没有使用这个显示首页；</li>\n<li>single.php：文章模板文件；</li>\n<li>404.php：404页面文件；</li>\n<li>page.php：页面模板文件，支持 page-$id （即页面 ID）或 page-$slug （即页面别名）；</li>\n<li>category.php：分类归档模板文件，支持 category-$id 或category-$slug ；</li>\n<li>tag.php：标签归档模板文件，支持 category-$id 或category-$slug ；</li>\n<li>author.php：作者归档模板文件，支持 category-$id 或 category-$slug；</li>\n<li>date.php：日期归档模板文件；</li>\n<li>archive.php：如果主题没有7-10之中的任一文件，那么都会用此模板文件显示对应内容，当此模板文件也不存在时，则使用index.php显示，支持 archive-$id 或archive-$slug。</li>\n</ol>\n<p>header.php、footer.php、sidebar.php等文件一般都是“页面部分”模板文件，即：页眉、页脚、边栏。 如果你能看懂英文，详细可参考官方文档： <a href=\"https://link.zhihu.com/?target=https%3A//developer.wordpress.org/themes/basics/template-hierarchy/\" target=\"_blank\" rel=\"noopener\">WordPress模板文件等级介绍（官方）</a> <a href=\"https://link.zhihu.com/?target=https%3A//developer.wordpress.org/themes/basics/linking-theme-files-directories/\" target=\"_blank\" rel=\"noopener\">WordPress获取主题目录里的文件和目录</a></p>\n<p><a href=\"https://www.zhihu.com/question/20129430/answer/40653740\" target=\"_blank\" rel=\"noopener\">@马向阳</a></p>\n"},{"title":"pytorch  expected backend CPU and dtype Double but got backend CPU and dtype Float","date":"2019-01-24T19:38:57.000Z","categoies":["框架","pytorch","爬坑"],"_content":"\n### 用pytorch搭建网络测试时，代码报错如下：\nRuntimeError: expected backend CPU and dtype Double but got backend CPU and dtype Float\n\n***\n报错在transform.ToTensor ()：\n***\n如图：\n![](https://blog.mviai.com/images/爬坑/totensor.png)\n\n报类型错误，默认x类型为float64，加上那句运行正确。\n\n\n****\n尝试过其他方法：\n\n\n1：\n如A fix would be to call .double() on your model (or .float() on the input)\nhttps://github.com/pytorch/pytorch/issues/2138\n\n2：\n\nfrom_numpy().float()\n\n3:\nastype('float')\n\n4:\n您的输入和目标张量是DoubleTensors，但您的模型参数是FloatTensors。您必须转换输入或参数。\n\n要将输入转换为float（推荐）：\n\ninputs, labels = data\ninputs = inputs.float()\nlabels = labels.float()\ninputs, labels = Variable(inputs), Variable(labels)\n要将模型转换为double：\n\nmodel = ColorizerNet()\nmodel.double()\n我建议使用浮动而不是双打。它是PyTorch中的默认张量类型。在GPU上，浮点计算比双重计算快得多。\nhttps://discuss.pytorch.org/t/problems-with-weight-array-of-floattensor-type-in-loss-function/381\n\n\n\n\n","source":"_posts/pytorch搭建网络测试时报错RuntimeError-expected-backend-CPU-and-dtype-Double-but-got-backend-CPU-and-dtype-Float.md","raw":"---\ntitle: pytorch  expected backend CPU and dtype Double but got backend CPU and dtype Float\n\ndate: 2019-01-25 03:38:57\ntags:\n    - 爬坑\ncategoies:\n    - 框架\n    - pytorch\n    - 爬坑\n---\n\n### 用pytorch搭建网络测试时，代码报错如下：\nRuntimeError: expected backend CPU and dtype Double but got backend CPU and dtype Float\n\n***\n报错在transform.ToTensor ()：\n***\n如图：\n![](https://blog.mviai.com/images/爬坑/totensor.png)\n\n报类型错误，默认x类型为float64，加上那句运行正确。\n\n\n****\n尝试过其他方法：\n\n\n1：\n如A fix would be to call .double() on your model (or .float() on the input)\nhttps://github.com/pytorch/pytorch/issues/2138\n\n2：\n\nfrom_numpy().float()\n\n3:\nastype('float')\n\n4:\n您的输入和目标张量是DoubleTensors，但您的模型参数是FloatTensors。您必须转换输入或参数。\n\n要将输入转换为float（推荐）：\n\ninputs, labels = data\ninputs = inputs.float()\nlabels = labels.float()\ninputs, labels = Variable(inputs), Variable(labels)\n要将模型转换为double：\n\nmodel = ColorizerNet()\nmodel.double()\n我建议使用浮动而不是双打。它是PyTorch中的默认张量类型。在GPU上，浮点计算比双重计算快得多。\nhttps://discuss.pytorch.org/t/problems-with-weight-array-of-floattensor-type-in-loss-function/381\n\n\n\n\n","slug":"pytorch搭建网络测试时报错RuntimeError-expected-backend-CPU-and-dtype-Double-but-got-backend-CPU-and-dtype-Float","published":1,"updated":"2021-07-26T09:58:02.516Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m1m000rigta7baisx83","content":"<h3 id=\"用pytorch搭建网络测试时，代码报错如下：\"><a href=\"#用pytorch搭建网络测试时，代码报错如下：\" class=\"headerlink\" title=\"用pytorch搭建网络测试时，代码报错如下：\"></a>用pytorch搭建网络测试时，代码报错如下：</h3><p>RuntimeError: expected backend CPU and dtype Double but got backend CPU and dtype Float</p>\n<hr>\n<p>报错在transform.ToTensor ()：</p>\n<hr>\n<p>如图：<br><img src=\"https://blog.mviai.com/images/爬坑/totensor.png\" alt></p>\n<p>报类型错误，默认x类型为float64，加上那句运行正确。</p>\n<hr>\n<p>尝试过其他方法：</p>\n<p>1：<br>如A fix would be to call .double() on your model (or .float() on the input)<br><a href=\"https://github.com/pytorch/pytorch/issues/2138\" target=\"_blank\" rel=\"noopener\">https://github.com/pytorch/pytorch/issues/2138</a></p>\n<p>2：</p>\n<p>from_numpy().float()</p>\n<p>3:<br>astype(‘float’)</p>\n<p>4:<br>您的输入和目标张量是DoubleTensors，但您的模型参数是FloatTensors。您必须转换输入或参数。</p>\n<p>要将输入转换为float（推荐）：</p>\n<p>inputs, labels = data<br>inputs = inputs.float()<br>labels = labels.float()<br>inputs, labels = Variable(inputs), Variable(labels)<br>要将模型转换为double：</p>\n<p>model = ColorizerNet()<br>model.double()<br>我建议使用浮动而不是双打。它是PyTorch中的默认张量类型。在GPU上，浮点计算比双重计算快得多。<br><a href=\"https://discuss.pytorch.org/t/problems-with-weight-array-of-floattensor-type-in-loss-function/381\" target=\"_blank\" rel=\"noopener\">https://discuss.pytorch.org/t/problems-with-weight-array-of-floattensor-type-in-loss-function/381</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"用pytorch搭建网络测试时，代码报错如下：\"><a href=\"#用pytorch搭建网络测试时，代码报错如下：\" class=\"headerlink\" title=\"用pytorch搭建网络测试时，代码报错如下：\"></a>用pytorch搭建网络测试时，代码报错如下：</h3><p>RuntimeError: expected backend CPU and dtype Double but got backend CPU and dtype Float</p>\n<hr>\n<p>报错在transform.ToTensor ()：</p>\n<hr>\n<p>如图：<br><img src=\"https://blog.mviai.com/images/爬坑/totensor.png\" alt></p>\n<p>报类型错误，默认x类型为float64，加上那句运行正确。</p>\n<hr>\n<p>尝试过其他方法：</p>\n<p>1：<br>如A fix would be to call .double() on your model (or .float() on the input)<br><a href=\"https://github.com/pytorch/pytorch/issues/2138\" target=\"_blank\" rel=\"noopener\">https://github.com/pytorch/pytorch/issues/2138</a></p>\n<p>2：</p>\n<p>from_numpy().float()</p>\n<p>3:<br>astype(‘float’)</p>\n<p>4:<br>您的输入和目标张量是DoubleTensors，但您的模型参数是FloatTensors。您必须转换输入或参数。</p>\n<p>要将输入转换为float（推荐）：</p>\n<p>inputs, labels = data<br>inputs = inputs.float()<br>labels = labels.float()<br>inputs, labels = Variable(inputs), Variable(labels)<br>要将模型转换为double：</p>\n<p>model = ColorizerNet()<br>model.double()<br>我建议使用浮动而不是双打。它是PyTorch中的默认张量类型。在GPU上，浮点计算比双重计算快得多。<br><a href=\"https://discuss.pytorch.org/t/problems-with-weight-array-of-floattensor-type-in-loss-function/381\" target=\"_blank\" rel=\"noopener\">https://discuss.pytorch.org/t/problems-with-weight-array-of-floattensor-type-in-loss-function/381</a></p>\n"},{"title":"一些系统软件","date":"2019-03-27T09:36:05.000Z","_content":"\n***           下载链接在最后        ***\n__________\n# 系统类：\n### 系统激活：（针对2015长期维护版 win10）\n在联网的前提下\n打开命令行：\n'''\nslmgr /ipk WNMTR-4C88C-JK8YV-HQ7T2-76DF9\nslmgr /skms zh.us.to\nslmgr /ato\n直接运行这个命令就行了\n\n'''\n\n### office2016 破解版(三合一：\n直接下载<font color=red> Microsoft Office 2016 X64 20170323</font>后安装（请勿开启微软自带和其他杀毒软件）\n\n### 内存测试：\n<font color=red> MemTest_Pro</font>\nMemTest验证RAM的可靠性。正确运行的计算机应该能够以100％的准确度将数据存储在内存中。\n\n### 硬盘测试（固态）：\n获取详细信息（如通电次数，硬盘健康状态）\n<font color=red>CrystalDiskInfo</font>\n\n测试速度：\n<font color=red>CrystalDiskMark </font>\n\n### 任务栏透明美化（win最底下）：\n<font color=red>StartIsBack v2.8.2_P（破解版）</font>\n\n### 雷克沙固态检测（专用）\n<font color=red>Lexar_SSD_Dash</font>\n\n\n### uefi启动管理器（破解版）：\n<font color=red>EasyUEFI</font>\n* 如果是mbr 启动 用Easybcd\n\n\n-------\n\n\n# 软件类：\n### 冰点文库：\n* 可以下载百度文库等各大文库文章。（采用截图方式生成pdf文件）\n\n### 蓝色鼠标：\n<font color=red> 解压后将文件打开AutoSetup.inf右键安装</font>\n\n### Git （github）：\n<font color=red>Git-2.20.1-64-bit</font>\n\n### vpn （谷歌浏览器 火狐浏览器）：\n商店可以直接下，速度只适合浏览网页\n<font color=red>SetupVPN</font>\n\n\n### VS 精简版（快速安装）\n<font color=red>Visual Studio 2017 Enterprise</font>\n\n* 会在最后报错 点击忽略,完成后打开软件帮助选项激活（激活码百度输入Visual Studio 2017 激活码）\n\n### windows获取Linux命令插件：\n <font color=red>MinGW</font> \n * 将文件夹路径添加进环境变量（path）\n\n\n# win10 小坑：\n### 优化清理软件：\n\n<font color=red>Dism++ (几kb，但是什么都能做）</font>\n\n\n### 有些电脑显卡驱动老是安装失败，只能用官方驱动\n<font color=red>显卡驱动卸载神器（ddu）</font>\n* 卸载完后，就可以安装最新驱动。性能最大化\n\n\n\n### 微软商店连不上网\n<font color=red>打开设置-->选择网络和internet-->代理-->所有开启的全部关闭</font>\n\n### 换硬盘卡死 进不去系统\n<font color=red>强制关机重启（重复几次） --》选择启动--》安全启动--》只要进去就可以重启！（来源于驱动问题） 否则进pe引导系统或者重装</font>\n\n### 远程控制Teamvier\n\n<font color=red>可以实现远程辅助，比qq好用 强大</font>\n\n# 下载地址（百度云）\n* 下载地址：<font color=red>链接：https://pan.yangxin.com/s/10Xbd6X8JbimC8dnxdKANVw \n*  提取码：vdrv \n</font> \n","source":"_posts/一些系统的工具.md","raw":"---\ntitle: 一些系统软件\ndate: 2019-03-27 17:36:05\ntags:\n    - 系统软件\ncategories:\n    - 工具\n    - 日常工具\n    - 系统软件\n---\n\n***           下载链接在最后        ***\n__________\n# 系统类：\n### 系统激活：（针对2015长期维护版 win10）\n在联网的前提下\n打开命令行：\n'''\nslmgr /ipk WNMTR-4C88C-JK8YV-HQ7T2-76DF9\nslmgr /skms zh.us.to\nslmgr /ato\n直接运行这个命令就行了\n\n'''\n\n### office2016 破解版(三合一：\n直接下载<font color=red> Microsoft Office 2016 X64 20170323</font>后安装（请勿开启微软自带和其他杀毒软件）\n\n### 内存测试：\n<font color=red> MemTest_Pro</font>\nMemTest验证RAM的可靠性。正确运行的计算机应该能够以100％的准确度将数据存储在内存中。\n\n### 硬盘测试（固态）：\n获取详细信息（如通电次数，硬盘健康状态）\n<font color=red>CrystalDiskInfo</font>\n\n测试速度：\n<font color=red>CrystalDiskMark </font>\n\n### 任务栏透明美化（win最底下）：\n<font color=red>StartIsBack v2.8.2_P（破解版）</font>\n\n### 雷克沙固态检测（专用）\n<font color=red>Lexar_SSD_Dash</font>\n\n\n### uefi启动管理器（破解版）：\n<font color=red>EasyUEFI</font>\n* 如果是mbr 启动 用Easybcd\n\n\n-------\n\n\n# 软件类：\n### 冰点文库：\n* 可以下载百度文库等各大文库文章。（采用截图方式生成pdf文件）\n\n### 蓝色鼠标：\n<font color=red> 解压后将文件打开AutoSetup.inf右键安装</font>\n\n### Git （github）：\n<font color=red>Git-2.20.1-64-bit</font>\n\n### vpn （谷歌浏览器 火狐浏览器）：\n商店可以直接下，速度只适合浏览网页\n<font color=red>SetupVPN</font>\n\n\n### VS 精简版（快速安装）\n<font color=red>Visual Studio 2017 Enterprise</font>\n\n* 会在最后报错 点击忽略,完成后打开软件帮助选项激活（激活码百度输入Visual Studio 2017 激活码）\n\n### windows获取Linux命令插件：\n <font color=red>MinGW</font> \n * 将文件夹路径添加进环境变量（path）\n\n\n# win10 小坑：\n### 优化清理软件：\n\n<font color=red>Dism++ (几kb，但是什么都能做）</font>\n\n\n### 有些电脑显卡驱动老是安装失败，只能用官方驱动\n<font color=red>显卡驱动卸载神器（ddu）</font>\n* 卸载完后，就可以安装最新驱动。性能最大化\n\n\n\n### 微软商店连不上网\n<font color=red>打开设置-->选择网络和internet-->代理-->所有开启的全部关闭</font>\n\n### 换硬盘卡死 进不去系统\n<font color=red>强制关机重启（重复几次） --》选择启动--》安全启动--》只要进去就可以重启！（来源于驱动问题） 否则进pe引导系统或者重装</font>\n\n### 远程控制Teamvier\n\n<font color=red>可以实现远程辅助，比qq好用 强大</font>\n\n# 下载地址（百度云）\n* 下载地址：<font color=red>链接：https://pan.yangxin.com/s/10Xbd6X8JbimC8dnxdKANVw \n*  提取码：vdrv \n</font> \n","slug":"一些系统的工具","published":1,"updated":"2021-07-26T09:58:02.584Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m1n000uigta605du5ob","content":"<p><strong><em>           下载链接在最后        </em></strong></p>\n<hr>\n<h1 id=\"系统类：\"><a href=\"#系统类：\" class=\"headerlink\" title=\"系统类：\"></a>系统类：</h1><h3 id=\"系统激活：（针对2015长期维护版-win10）\"><a href=\"#系统激活：（针对2015长期维护版-win10）\" class=\"headerlink\" title=\"系统激活：（针对2015长期维护版 win10）\"></a>系统激活：（针对2015长期维护版 win10）</h3><p>在联网的前提下<br>打开命令行：<br>‘’’<br>slmgr /ipk WNMTR-4C88C-JK8YV-HQ7T2-76DF9<br>slmgr /skms zh.us.to<br>slmgr /ato<br>直接运行这个命令就行了</p>\n<p>‘’’</p>\n<h3 id=\"office2016-破解版-三合一：\"><a href=\"#office2016-破解版-三合一：\" class=\"headerlink\" title=\"office2016 破解版(三合一：\"></a>office2016 破解版(三合一：</h3><p>直接下载<font color=\"red\"> Microsoft Office 2016 X64 20170323</font>后安装（请勿开启微软自带和其他杀毒软件）</p>\n<h3 id=\"内存测试：\"><a href=\"#内存测试：\" class=\"headerlink\" title=\"内存测试：\"></a>内存测试：</h3><font color=\"red\"> MemTest_Pro</font><br>MemTest验证RAM的可靠性。正确运行的计算机应该能够以100％的准确度将数据存储在内存中。<br><br>### 硬盘测试（固态）：<br>获取详细信息（如通电次数，硬盘健康状态）<br><font color=\"red\">CrystalDiskInfo</font>\n\n<p>测试速度：</p>\n<font color=\"red\">CrystalDiskMark </font>\n\n<h3 id=\"任务栏透明美化（win最底下）：\"><a href=\"#任务栏透明美化（win最底下）：\" class=\"headerlink\" title=\"任务栏透明美化（win最底下）：\"></a>任务栏透明美化（win最底下）：</h3><font color=\"red\">StartIsBack v2.8.2_P（破解版）</font>\n\n<h3 id=\"雷克沙固态检测（专用）\"><a href=\"#雷克沙固态检测（专用）\" class=\"headerlink\" title=\"雷克沙固态检测（专用）\"></a>雷克沙固态检测（专用）</h3><font color=\"red\">Lexar_SSD_Dash</font>\n\n\n<h3 id=\"uefi启动管理器（破解版）：\"><a href=\"#uefi启动管理器（破解版）：\" class=\"headerlink\" title=\"uefi启动管理器（破解版）：\"></a>uefi启动管理器（破解版）：</h3><font color=\"red\">EasyUEFI</font><br><em> 如果是mbr 启动 用Easybcd<br><br><br>——-<br><br><br># 软件类：<br>### 冰点文库：\n</em> 可以下载百度文库等各大文库文章。（采用截图方式生成pdf文件）<br><br>### 蓝色鼠标：<br><font color=\"red\"> 解压后将文件打开AutoSetup.inf右键安装</font>\n\n<h3 id=\"Git-（github）：\"><a href=\"#Git-（github）：\" class=\"headerlink\" title=\"Git （github）：\"></a>Git （github）：</h3><font color=\"red\">Git-2.20.1-64-bit</font>\n\n<h3 id=\"vpn-（谷歌浏览器-火狐浏览器）：\"><a href=\"#vpn-（谷歌浏览器-火狐浏览器）：\" class=\"headerlink\" title=\"vpn （谷歌浏览器 火狐浏览器）：\"></a>vpn （谷歌浏览器 火狐浏览器）：</h3><p>商店可以直接下，速度只适合浏览网页</p>\n<font color=\"red\">SetupVPN</font>\n\n\n<h3 id=\"VS-精简版（快速安装）\"><a href=\"#VS-精简版（快速安装）\" class=\"headerlink\" title=\"VS 精简版（快速安装）\"></a>VS 精简版（快速安装）</h3><font color=\"red\">Visual Studio 2017 Enterprise</font>\n\n<ul>\n<li>会在最后报错 点击忽略,完成后打开软件帮助选项激活（激活码百度输入Visual Studio 2017 激活码）</li>\n</ul>\n<h3 id=\"windows获取Linux命令插件：\"><a href=\"#windows获取Linux命令插件：\" class=\"headerlink\" title=\"windows获取Linux命令插件：\"></a>windows获取Linux命令插件：</h3> <font color=\"red\">MinGW</font><br> * 将文件夹路径添加进环境变量（path）<br><br><br># win10 小坑：<br>### 优化清理软件：<br><br><font color=\"red\">Dism++ (几kb，但是什么都能做）</font>\n\n\n<h3 id=\"有些电脑显卡驱动老是安装失败，只能用官方驱动\"><a href=\"#有些电脑显卡驱动老是安装失败，只能用官方驱动\" class=\"headerlink\" title=\"有些电脑显卡驱动老是安装失败，只能用官方驱动\"></a>有些电脑显卡驱动老是安装失败，只能用官方驱动</h3><font color=\"red\">显卡驱动卸载神器（ddu）</font><br>* 卸载完后，就可以安装最新驱动。性能最大化<br><br><br><br>### 微软商店连不上网<br><font color=\"red\">打开设置–&gt;选择网络和internet–&gt;代理–&gt;所有开启的全部关闭</font>\n\n<h3 id=\"换硬盘卡死-进不去系统\"><a href=\"#换硬盘卡死-进不去系统\" class=\"headerlink\" title=\"换硬盘卡死 进不去系统\"></a>换硬盘卡死 进不去系统</h3><font color=\"red\">强制关机重启（重复几次） –》选择启动–》安全启动–》只要进去就可以重启！（来源于驱动问题） 否则进pe引导系统或者重装</font>\n\n<h3 id=\"远程控制Teamvier\"><a href=\"#远程控制Teamvier\" class=\"headerlink\" title=\"远程控制Teamvier\"></a>远程控制Teamvier</h3><font color=\"red\">可以实现远程辅助，比qq好用 强大</font>\n\n<h1 id=\"下载地址（百度云）\"><a href=\"#下载地址（百度云）\" class=\"headerlink\" title=\"下载地址（百度云）\"></a>下载地址（百度云）</h1><ul>\n<li>下载地址：<font color=\"red\">链接：<a href=\"https://pan.yangxin.com/s/10Xbd6X8JbimC8dnxdKANVw\" target=\"_blank\" rel=\"noopener\">https://pan.yangxin.com/s/10Xbd6X8JbimC8dnxdKANVw</a> </font></li>\n<li>提取码：vdrv<br> </li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p><strong><em>           下载链接在最后        </em></strong></p>\n<hr>\n<h1 id=\"系统类：\"><a href=\"#系统类：\" class=\"headerlink\" title=\"系统类：\"></a>系统类：</h1><h3 id=\"系统激活：（针对2015长期维护版-win10）\"><a href=\"#系统激活：（针对2015长期维护版-win10）\" class=\"headerlink\" title=\"系统激活：（针对2015长期维护版 win10）\"></a>系统激活：（针对2015长期维护版 win10）</h3><p>在联网的前提下<br>打开命令行：<br>‘’’<br>slmgr /ipk WNMTR-4C88C-JK8YV-HQ7T2-76DF9<br>slmgr /skms zh.us.to<br>slmgr /ato<br>直接运行这个命令就行了</p>\n<p>‘’’</p>\n<h3 id=\"office2016-破解版-三合一：\"><a href=\"#office2016-破解版-三合一：\" class=\"headerlink\" title=\"office2016 破解版(三合一：\"></a>office2016 破解版(三合一：</h3><p>直接下载<font color=\"red\"> Microsoft Office 2016 X64 20170323</font>后安装（请勿开启微软自带和其他杀毒软件）</p>\n<h3 id=\"内存测试：\"><a href=\"#内存测试：\" class=\"headerlink\" title=\"内存测试：\"></a>内存测试：</h3><font color=\"red\"> MemTest_Pro</font><br>MemTest验证RAM的可靠性。正确运行的计算机应该能够以100％的准确度将数据存储在内存中。<br><br>### 硬盘测试（固态）：<br>获取详细信息（如通电次数，硬盘健康状态）<br><font color=\"red\">CrystalDiskInfo</font>\n\n<p>测试速度：</p>\n<font color=\"red\">CrystalDiskMark </font>\n\n<h3 id=\"任务栏透明美化（win最底下）：\"><a href=\"#任务栏透明美化（win最底下）：\" class=\"headerlink\" title=\"任务栏透明美化（win最底下）：\"></a>任务栏透明美化（win最底下）：</h3><font color=\"red\">StartIsBack v2.8.2_P（破解版）</font>\n\n<h3 id=\"雷克沙固态检测（专用）\"><a href=\"#雷克沙固态检测（专用）\" class=\"headerlink\" title=\"雷克沙固态检测（专用）\"></a>雷克沙固态检测（专用）</h3><font color=\"red\">Lexar_SSD_Dash</font>\n\n\n<h3 id=\"uefi启动管理器（破解版）：\"><a href=\"#uefi启动管理器（破解版）：\" class=\"headerlink\" title=\"uefi启动管理器（破解版）：\"></a>uefi启动管理器（破解版）：</h3><font color=\"red\">EasyUEFI</font><br><em> 如果是mbr 启动 用Easybcd<br><br><br>——-<br><br><br># 软件类：<br>### 冰点文库：\n</em> 可以下载百度文库等各大文库文章。（采用截图方式生成pdf文件）<br><br>### 蓝色鼠标：<br><font color=\"red\"> 解压后将文件打开AutoSetup.inf右键安装</font>\n\n<h3 id=\"Git-（github）：\"><a href=\"#Git-（github）：\" class=\"headerlink\" title=\"Git （github）：\"></a>Git （github）：</h3><font color=\"red\">Git-2.20.1-64-bit</font>\n\n<h3 id=\"vpn-（谷歌浏览器-火狐浏览器）：\"><a href=\"#vpn-（谷歌浏览器-火狐浏览器）：\" class=\"headerlink\" title=\"vpn （谷歌浏览器 火狐浏览器）：\"></a>vpn （谷歌浏览器 火狐浏览器）：</h3><p>商店可以直接下，速度只适合浏览网页</p>\n<font color=\"red\">SetupVPN</font>\n\n\n<h3 id=\"VS-精简版（快速安装）\"><a href=\"#VS-精简版（快速安装）\" class=\"headerlink\" title=\"VS 精简版（快速安装）\"></a>VS 精简版（快速安装）</h3><font color=\"red\">Visual Studio 2017 Enterprise</font>\n\n<ul>\n<li>会在最后报错 点击忽略,完成后打开软件帮助选项激活（激活码百度输入Visual Studio 2017 激活码）</li>\n</ul>\n<h3 id=\"windows获取Linux命令插件：\"><a href=\"#windows获取Linux命令插件：\" class=\"headerlink\" title=\"windows获取Linux命令插件：\"></a>windows获取Linux命令插件：</h3> <font color=\"red\">MinGW</font><br> * 将文件夹路径添加进环境变量（path）<br><br><br># win10 小坑：<br>### 优化清理软件：<br><br><font color=\"red\">Dism++ (几kb，但是什么都能做）</font>\n\n\n<h3 id=\"有些电脑显卡驱动老是安装失败，只能用官方驱动\"><a href=\"#有些电脑显卡驱动老是安装失败，只能用官方驱动\" class=\"headerlink\" title=\"有些电脑显卡驱动老是安装失败，只能用官方驱动\"></a>有些电脑显卡驱动老是安装失败，只能用官方驱动</h3><font color=\"red\">显卡驱动卸载神器（ddu）</font><br>* 卸载完后，就可以安装最新驱动。性能最大化<br><br><br><br>### 微软商店连不上网<br><font color=\"red\">打开设置–&gt;选择网络和internet–&gt;代理–&gt;所有开启的全部关闭</font>\n\n<h3 id=\"换硬盘卡死-进不去系统\"><a href=\"#换硬盘卡死-进不去系统\" class=\"headerlink\" title=\"换硬盘卡死 进不去系统\"></a>换硬盘卡死 进不去系统</h3><font color=\"red\">强制关机重启（重复几次） –》选择启动–》安全启动–》只要进去就可以重启！（来源于驱动问题） 否则进pe引导系统或者重装</font>\n\n<h3 id=\"远程控制Teamvier\"><a href=\"#远程控制Teamvier\" class=\"headerlink\" title=\"远程控制Teamvier\"></a>远程控制Teamvier</h3><font color=\"red\">可以实现远程辅助，比qq好用 强大</font>\n\n<h1 id=\"下载地址（百度云）\"><a href=\"#下载地址（百度云）\" class=\"headerlink\" title=\"下载地址（百度云）\"></a>下载地址（百度云）</h1><ul>\n<li>下载地址：<font color=\"red\">链接：<a href=\"https://pan.yangxin.com/s/10Xbd6X8JbimC8dnxdKANVw\" target=\"_blank\" rel=\"noopener\">https://pan.yangxin.com/s/10Xbd6X8JbimC8dnxdKANVw</a> </font></li>\n<li>提取码：vdrv<br> </li>\n</ul>\n"},{"title":"pytorch expected backend CPU and dtype Double but got backend CPU and dtype Float","date":"2019-01-24T19:38:57.000Z","categoies":["框架","pytorch","爬坑"],"_content":"\n### 用pytorch搭建网络测试时，代码报错如下：\nRuntimeError: expected backend CPU and dtype Double but got backend CPU and dtype Float\n\n***\n报错在transform.ToTensor ()：\n***\n如图：\n![](http:/images.yx1024.top/爬坑/totensor.png)\n\n报类型错误，默认x类型为float64，加上那句运行正确。\n\n\n****\n尝试过其他方法：\n\n\n1：\n如A fix would be to call .double() on your model (or .float() on the input)\nhttps://github.com/pytorch/pytorch/issues/2138\n\n2：\n\nfrom_numpy().float()\n\n3:\nastype('float')\n\n4:\n您的输入和目标张量是DoubleTensors，但您的模型参数是FloatTensors。您必须转换输入或参数。\n\n要将输入转换为float（推荐）：\n\ninputs, labels = data\ninputs = inputs.float()\nlabels = labels.float()\ninputs, labels = Variable(inputs), Variable(labels)\n要将模型转换为double：\n\nmodel = ColorizerNet()\nmodel.double()\n我建议使用浮动而不是双打。它是PyTorch中的默认张量类型。在GPU上，浮点计算比双重计算快得多。\nhttps://discuss.pytorch.org/t/problems-with-weight-array-of-floattensor-type-in-loss-function/381\n\n\n\n\n","source":"_posts/pytorch RuntimeError-expected-backend-CPU-and-dtype-Double-but-got-backend-CPU-and-dtype-Float.md","raw":"---\ntitle: pytorch expected backend CPU and dtype Double but got backend CPU and dtype Float\ndate: 2019-01-25 03:38:57\ntags:\n    - 爬坑\ncategoies:\n    - 框架\n    - pytorch\n    - 爬坑\n---\n\n### 用pytorch搭建网络测试时，代码报错如下：\nRuntimeError: expected backend CPU and dtype Double but got backend CPU and dtype Float\n\n***\n报错在transform.ToTensor ()：\n***\n如图：\n![](http:/images.yx1024.top/爬坑/totensor.png)\n\n报类型错误，默认x类型为float64，加上那句运行正确。\n\n\n****\n尝试过其他方法：\n\n\n1：\n如A fix would be to call .double() on your model (or .float() on the input)\nhttps://github.com/pytorch/pytorch/issues/2138\n\n2：\n\nfrom_numpy().float()\n\n3:\nastype('float')\n\n4:\n您的输入和目标张量是DoubleTensors，但您的模型参数是FloatTensors。您必须转换输入或参数。\n\n要将输入转换为float（推荐）：\n\ninputs, labels = data\ninputs = inputs.float()\nlabels = labels.float()\ninputs, labels = Variable(inputs), Variable(labels)\n要将模型转换为double：\n\nmodel = ColorizerNet()\nmodel.double()\n我建议使用浮动而不是双打。它是PyTorch中的默认张量类型。在GPU上，浮点计算比双重计算快得多。\nhttps://discuss.pytorch.org/t/problems-with-weight-array-of-floattensor-type-in-loss-function/381\n\n\n\n\n","slug":"pytorch RuntimeError-expected-backend-CPU-and-dtype-Double-but-got-backend-CPU-and-dtype-Float","published":1,"updated":"2021-07-26T09:47:11.132Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m1o000wigtackjw33d9","content":"<h3 id=\"用pytorch搭建网络测试时，代码报错如下：\"><a href=\"#用pytorch搭建网络测试时，代码报错如下：\" class=\"headerlink\" title=\"用pytorch搭建网络测试时，代码报错如下：\"></a>用pytorch搭建网络测试时，代码报错如下：</h3><p>RuntimeError: expected backend CPU and dtype Double but got backend CPU and dtype Float</p>\n<hr>\n<p>报错在transform.ToTensor ()：</p>\n<hr>\n<p>如图：<br><img src=\"http:/images.yx1024.top/爬坑/totensor.png\" alt></p>\n<p>报类型错误，默认x类型为float64，加上那句运行正确。</p>\n<hr>\n<p>尝试过其他方法：</p>\n<p>1：<br>如A fix would be to call .double() on your model (or .float() on the input)<br><a href=\"https://github.com/pytorch/pytorch/issues/2138\" target=\"_blank\" rel=\"noopener\">https://github.com/pytorch/pytorch/issues/2138</a></p>\n<p>2：</p>\n<p>from_numpy().float()</p>\n<p>3:<br>astype(‘float’)</p>\n<p>4:<br>您的输入和目标张量是DoubleTensors，但您的模型参数是FloatTensors。您必须转换输入或参数。</p>\n<p>要将输入转换为float（推荐）：</p>\n<p>inputs, labels = data<br>inputs = inputs.float()<br>labels = labels.float()<br>inputs, labels = Variable(inputs), Variable(labels)<br>要将模型转换为double：</p>\n<p>model = ColorizerNet()<br>model.double()<br>我建议使用浮动而不是双打。它是PyTorch中的默认张量类型。在GPU上，浮点计算比双重计算快得多。<br><a href=\"https://discuss.pytorch.org/t/problems-with-weight-array-of-floattensor-type-in-loss-function/381\" target=\"_blank\" rel=\"noopener\">https://discuss.pytorch.org/t/problems-with-weight-array-of-floattensor-type-in-loss-function/381</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"用pytorch搭建网络测试时，代码报错如下：\"><a href=\"#用pytorch搭建网络测试时，代码报错如下：\" class=\"headerlink\" title=\"用pytorch搭建网络测试时，代码报错如下：\"></a>用pytorch搭建网络测试时，代码报错如下：</h3><p>RuntimeError: expected backend CPU and dtype Double but got backend CPU and dtype Float</p>\n<hr>\n<p>报错在transform.ToTensor ()：</p>\n<hr>\n<p>如图：<br><img src=\"http:/images.yx1024.top/爬坑/totensor.png\" alt></p>\n<p>报类型错误，默认x类型为float64，加上那句运行正确。</p>\n<hr>\n<p>尝试过其他方法：</p>\n<p>1：<br>如A fix would be to call .double() on your model (or .float() on the input)<br><a href=\"https://github.com/pytorch/pytorch/issues/2138\" target=\"_blank\" rel=\"noopener\">https://github.com/pytorch/pytorch/issues/2138</a></p>\n<p>2：</p>\n<p>from_numpy().float()</p>\n<p>3:<br>astype(‘float’)</p>\n<p>4:<br>您的输入和目标张量是DoubleTensors，但您的模型参数是FloatTensors。您必须转换输入或参数。</p>\n<p>要将输入转换为float（推荐）：</p>\n<p>inputs, labels = data<br>inputs = inputs.float()<br>labels = labels.float()<br>inputs, labels = Variable(inputs), Variable(labels)<br>要将模型转换为double：</p>\n<p>model = ColorizerNet()<br>model.double()<br>我建议使用浮动而不是双打。它是PyTorch中的默认张量类型。在GPU上，浮点计算比双重计算快得多。<br><a href=\"https://discuss.pytorch.org/t/problems-with-weight-array-of-floattensor-type-in-loss-function/381\" target=\"_blank\" rel=\"noopener\">https://discuss.pytorch.org/t/problems-with-weight-array-of-floattensor-type-in-loss-function/381</a></p>\n"},{"title":"RuntimeError output with shape [1,x,x] doesn't match the broadcast shape [3, x, x]","date":"2019-05-15T05:40:56.000Z","_content":"在用pytorch导入图片数据时出现了上述错误，\n报错程序：\n```python\ntransform = transforms.Compose([\n\ttransforms.ToTensor(), \n\ttransforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])]) \n```\n报错原因：这是因图片里面有是灰度图像，只有一个通道，而上面的transforms.Normalize 却对三个通道都归一化了，这肯定会报错，所以只要像下面修改即可：\n```python\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))# 第一个是均值，第二个是标准差，\n\t\n    ])\n```\n参考：https://blog.csdn.net/qq_31829611/article/details/90200694 \n","source":"_posts/pytorch维度报错.md","raw":"\n---\ntitle: RuntimeError output with shape [1,x,x] doesn't match the broadcast shape [3, x, x]\ndate: 2019-5-15 13:40:56\ntags:\n    - 爬坑\n\ncategories:\n     - 框架\n     - pytorch\n\n\n---\n在用pytorch导入图片数据时出现了上述错误，\n报错程序：\n```python\ntransform = transforms.Compose([\n\ttransforms.ToTensor(), \n\ttransforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])]) \n```\n报错原因：这是因图片里面有是灰度图像，只有一个通道，而上面的transforms.Normalize 却对三个通道都归一化了，这肯定会报错，所以只要像下面修改即可：\n```python\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))# 第一个是均值，第二个是标准差，\n\t\n    ])\n```\n参考：https://blog.csdn.net/qq_31829611/article/details/90200694 \n","slug":"pytorch维度报错","published":1,"updated":"2021-07-26T09:58:02.568Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m1q0010igta9xzsbukb","content":"<p>在用pytorch导入图片数据时出现了上述错误，<br>报错程序：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">transform = transforms.Compose([</span><br><span class=\"line\">\ttransforms.ToTensor(), </span><br><span class=\"line\">\ttransforms.Normalize(mean=[<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>], std=[<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>])])</span><br></pre></td></tr></table></figure></p>\n<p>报错原因：这是因图片里面有是灰度图像，只有一个通道，而上面的transforms.Normalize 却对三个通道都归一化了，这肯定会报错，所以只要像下面修改即可：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">transform = transforms.Compose([</span><br><span class=\"line\">    transforms.ToTensor(),</span><br><span class=\"line\">    transforms.Normalize((<span class=\"number\">0.1307</span>,), (<span class=\"number\">0.3081</span>,))<span class=\"comment\"># 第一个是均值，第二个是标准差，</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">    ])</span><br></pre></td></tr></table></figure></p>\n<p>参考：<a href=\"https://blog.csdn.net/qq_31829611/article/details/90200694\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_31829611/article/details/90200694</a> </p>\n","site":{"data":{}},"excerpt":"","more":"<p>在用pytorch导入图片数据时出现了上述错误，<br>报错程序：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">transform = transforms.Compose([</span><br><span class=\"line\">\ttransforms.ToTensor(), </span><br><span class=\"line\">\ttransforms.Normalize(mean=[<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>], std=[<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>])])</span><br></pre></td></tr></table></figure></p>\n<p>报错原因：这是因图片里面有是灰度图像，只有一个通道，而上面的transforms.Normalize 却对三个通道都归一化了，这肯定会报错，所以只要像下面修改即可：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">transform = transforms.Compose([</span><br><span class=\"line\">    transforms.ToTensor(),</span><br><span class=\"line\">    transforms.Normalize((<span class=\"number\">0.1307</span>,), (<span class=\"number\">0.3081</span>,))<span class=\"comment\"># 第一个是均值，第二个是标准差，</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">    ])</span><br></pre></td></tr></table></figure></p>\n<p>参考：<a href=\"https://blog.csdn.net/qq_31829611/article/details/90200694\" target=\"_blank\" rel=\"noopener\">https://blog.csdn.net/qq_31829611/article/details/90200694</a> </p>\n"},{"title":"回顾-AlexNet","date":"2018-12-18T12:49:57.000Z","_content":"# 1. AlexNet 简介:\nAlexNet由Alex Krizhevsky于2012年提出，夺得2012年ILSVRC比赛的冠军，top5预测的错误率为16.4%，远超第一名。\n******************\n# 2. AlexNet 网络结构:\nAlexNet采用8层的神经网络，5个卷积层和3个全连接层(3个卷积层后面加了最大池化层)，包含6亿3000万个链接，6000万个 参数和65万个神经元。\n* 如图:\n\n* ![](https://blog.mviai.com/images/alexnet.png)\n**********\n*******************\n* 官方图:\n* ![](https://blog.mviai.com/images/a2.png)\n************\n# 3. AlexNet 改进点:\n* 1.使用ReLU作为CNN的激活函数，验证了其效果在较深的网络中超过了Sigmoid.解决了Sigmoid在网络较深时的梯度弥散问题。\n* 2.使用最大池化可以避免平均池化的模糊效果。同时重叠效果可以提升特征的丰富性。\n* 3.提出LRN（Local Response Normalization，即局部响应归一化）层，对局部神经元的活动创建竞争机制，使得其中响应比较大的值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力。\n* 4.数据增强，随机的从256` *`256的图片中截取224` *`224大小的区域（以及水平翻转的镜像），相当于增加了（256-224)\\*(2^2)=2048 倍的数据量，如果没有数据增强，模型会陷入过拟合中，使用数据增强可以增大模型的泛化能力。\n*  5.使用CUDA加速神经网络的训练，利用了GPU强大的计算能力。\n*  6.训练时使用Dropout随机忽略一部分神经元，以避免模型过拟合，一般在全连接层使用，在预测的时候是不使用Dropout的，即Dropout为1.\n*****************\n# 4.PyTorch实现:\n* 网络架构:AlexNet.py文件:\n```python\nimport torch\n\n#跟着第一幅图走\nclass AlexNet(torch.nn.Module):\n    def __init__(self):\n        super(AlexNet, self).__init__()\n        # 输入图片大小 227*227*3\n\t\t#第一层\n        self.conv1 = torch.nn.Sequential(\n\t\t\t#卷积\n            torch.nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=0),\n            # (227-11)/4+1=55,  输出图片大小:55*55*96\n            torch.nn.ReLU(),#激活层\n            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n            # (55-3)/2+1=27, 输出图片大小: 27*27*96\n        )\n\n        # 从上面获得图片大小27*27*96\n        self.conv2 = torch.nn.Sequential(\n            torch.nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2),\n            # （27-5 + 2*2）/ 1 + 1 = 27, 输出图片大小:27*27*256\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n            # (27 - 3 )/2 + 1 = 13, 输出图片大小:13*13*256\n        )\n\n        # 从上面获得图片大小13*13*256\n        self.conv3 = torch.nn.Sequential(\n            torch.nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1),\n            # (13 - 3 +1*2)/1 + 1 = 13 , 输出图片大小:13*13*384\n            torch.nn.ReLU()\n        )\n\n        # 从上面获得图片大小13*13*384\n        self.conv4 = torch.nn.Sequential(\n            torch.nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1),\n            # (13 - 3 + 1*2)/1 +1 = 13, 输出图片大小:13*13*384\n            torch.nn.ReLU()\n        )\n\n        # 从上面获得图片大小13*13*384\n        self.conv5 = torch.nn.Sequential(\n            torch.nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1),\n            # (13 - 3 + 1*2) +1 = 13, 13*13*256\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n            # (13 - 3 )/2 +1 =6, 6*6*256\n        )\n\n        # 从上面获得图片大小 6*6*256 = 9216 共9216输出特征\n        self.lostlayer = torch.nn.Sequential(\n\t\t\t#第六层\n            torch.nn.Linear(9216, 4096),#全连接\n            torch.nn.ReLU(),#激活层\n            torch.nn.Dropout(0.5),#以0.5&几率随机忽略一部分神经元\n\t\t\t\n\t\t\t#第七层\n            torch.nn.Linear(4096, 4096),\n            torch.nn.ReLU(),\n            torch.nn.Dropout(0.5),\n\t\t\t\n\t\t\t#第八层\n            torch.nn.Linear(4096, 2)\n            # 最后输出2 ,因为只分猫狗两类\n        )\n\n\t#前向传播\n    def forward(self, x):\n        conv1_out = self.conv1(x)\n        conv2_out = self.conv2(conv1_out)\n        conv3_out = self.conv3(conv2_out)\n        conv4_out = self.conv4(conv3_out)\n        conv5_out = self.conv5(conv4_out)\n        res = conv5_out.view(conv5_out.size(0), -1)#展平多维的卷积图成 一维(batch_size, 4096)\n        out = self.lostlayer(res)\n        return out\n```\n\n*********************\n******************\n* 训练架构:train.py文件 猫狗10张图:\n```python\nimport torch\nimport torch.nn as nn\nimport torchvision.datasets as datasets\nimport torchvision.transforms as  transforms\nfrom torch.autograd import Variable\n\n# 工具包\nimport argparse\n# 载入网络\nfrom AlexNet import   AlexNet\n\n#############参数设置#############\n####命令行设置########\nparser = argparse.ArgumentParser (description='CNN')  # 导入命令行模块\n# 对于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明\nparser.add_argument ('--batch-size', type=int, default=32, metavar='N',\n\t\t\t\t\t help='训练batch-size大小 (default: 32)')\nparser.add_argument ('--epochs', type=int, default=10, metavar='N',\n\t\t\t\t\t help='训练epochs大小 (default: 10)')\nparser.add_argument ('--lr', type=float, default=0.001, metavar='LR',\n\t\t\t\t\t help='学习率 (default: 0.001)')\nparser.add_argument ('--no-cuda', action='store_true', default=False,\n\t\t\t\t\t help='不开启cuda训练')\nparser.add_argument ('--seed', type=int, default=1, metavar='S',\n\t\t\t\t\t help='随机种子 (default: 1)')\nparser.add_argument ('--log-interval', type=int, default=1, metavar='N',\n\t\t\t\t\t help='记录等待n批次 (default: 1)')\nargs = parser.parse_args ()  # 相当于激活命令\n\nargs.cuda = not args.no_cuda and torch.cuda.is_available ()  # 判断gpu\n\ntorch.manual_seed (args.seed)\nif args.cuda:\n\ttorch.cuda.manual_seed (args.seed)  # 为CPU设置种子用于生成随机数，以使得结果是确定的\n\n\n##########数据转换#####################\ndata_transforms = transforms.Compose([transforms.Scale(227),#通过调整比例调整大小,会报警\n    \t\t\t\t\t\t\t\ttransforms.CenterCrop(227),#在中心裁剪给指定大小方形PIL图像\n\t\t\t\t\t\t\t\t\ttransforms.ToTensor ()])#转换成pytorch 变量tensor\n###############数据载入################\ntrain_dataset = datasets.ImageFolder(root=\"./data/train/\",  # 保存目录\n\t\t\t\t\t\t\t\t\ttransform=data_transforms) # 把数据转换成上面约束样子\n\ntest_dataset = datasets.ImageFolder (root='./data/test/',\n\t\t\t\t\t\t\t\t\ttransform=data_transforms)\n\n\n##########数据如下####\n# # root/dog/xxx.png\n# # root/dog/xxy.png\n# # root/dog/xxz.png\n# #\n# # root/cat/123.png\n# # root/cat/nsdf3.png\n# # root/cat/asd932_.png\n######################\n\n##############数据装载###############\ntrain_loader = torch.utils.data.DataLoader (dataset=train_dataset,  # 装载数据\n\t\t\t\t\t\t\t\t\t\t\tbatch_size=args.batch_size,  # 设置批大小\n\t\t\t\t\t\t\t\t\t\t\tshuffle=True)  # 是否随机打乱\ntest_loader = torch.utils.data.DataLoader (dataset=test_dataset,\n\t\t\t\t\t\t\t\t\t\t   batch_size=args.batch_size,\n\t\t\t\t\t\t\t\t\t\t   shuffle=True)\n\n#############模型载入#################\nAlexNet = AlexNet ()\nif not args.no_cuda:\n\tprint ('正在使用gpu')\n\tAlexNet.cuda ()\nprint (AlexNet)\n\n###############损失函数##################\ncriterion = nn.CrossEntropyLoss ()  # 内置标准损失\noptimizer = torch.optim.Adam (AlexNet.parameters (), lr=args.lr)  # Adam优化器\n#############训练过程#####################\nfor epoch in range (args.epochs):\n\tfor i, (images, labels) in enumerate (train_loader):  # 枚举出来\n\t\tif not args.no_cuda:  # 数据处理是否用gpu\n\t\t\timages = images.cuda ()\n\t\t\tlabels = labels.cuda ()\n\t\t\n\t\timages = Variable (images)  # 装箱\n\t\tlabels = Variable (labels)\n\t\t\n\t\t##前向传播\n\t\toptimizer.zero_grad ()\n\t\toutputs = AlexNet(images)\n\t\t# 损失\n\t\tloss = criterion (outputs, labels)\n\t\t# 反向传播\n\t\tloss.backward ()\n\t\toptimizer.step ()\n\t\t##打印记录\n\t\t\n\t\tif (i + 1) % args.log_interval == 0:\n\t\t\tprint ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'\n\t\t\t\t   % (epoch + 1, args.epochs, i + 1, len (train_dataset) // args.batch_size, loss.item ()))\n\t\t\n\t\t# 保存模型\n\t\ttorch.save (AlexNet.state_dict (), 'AlexNet.pkl')\n```\n************\n* 效果如图:\n![](https://blog.mviai.com/images/回顾-AlexNet/20181218112800405.png)\n","source":"_posts/回顾-AlexNet.md","raw":"---\ntitle: 回顾-AlexNet\ndate: 2018-12-18 20:49:57\ntags:\n    - AlexNet\ncategories:\n    - 框架\n    - pytorch\n    - AlexNet\n---\n# 1. AlexNet 简介:\nAlexNet由Alex Krizhevsky于2012年提出，夺得2012年ILSVRC比赛的冠军，top5预测的错误率为16.4%，远超第一名。\n******************\n# 2. AlexNet 网络结构:\nAlexNet采用8层的神经网络，5个卷积层和3个全连接层(3个卷积层后面加了最大池化层)，包含6亿3000万个链接，6000万个 参数和65万个神经元。\n* 如图:\n\n* ![](https://blog.mviai.com/images/alexnet.png)\n**********\n*******************\n* 官方图:\n* ![](https://blog.mviai.com/images/a2.png)\n************\n# 3. AlexNet 改进点:\n* 1.使用ReLU作为CNN的激活函数，验证了其效果在较深的网络中超过了Sigmoid.解决了Sigmoid在网络较深时的梯度弥散问题。\n* 2.使用最大池化可以避免平均池化的模糊效果。同时重叠效果可以提升特征的丰富性。\n* 3.提出LRN（Local Response Normalization，即局部响应归一化）层，对局部神经元的活动创建竞争机制，使得其中响应比较大的值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力。\n* 4.数据增强，随机的从256` *`256的图片中截取224` *`224大小的区域（以及水平翻转的镜像），相当于增加了（256-224)\\*(2^2)=2048 倍的数据量，如果没有数据增强，模型会陷入过拟合中，使用数据增强可以增大模型的泛化能力。\n*  5.使用CUDA加速神经网络的训练，利用了GPU强大的计算能力。\n*  6.训练时使用Dropout随机忽略一部分神经元，以避免模型过拟合，一般在全连接层使用，在预测的时候是不使用Dropout的，即Dropout为1.\n*****************\n# 4.PyTorch实现:\n* 网络架构:AlexNet.py文件:\n```python\nimport torch\n\n#跟着第一幅图走\nclass AlexNet(torch.nn.Module):\n    def __init__(self):\n        super(AlexNet, self).__init__()\n        # 输入图片大小 227*227*3\n\t\t#第一层\n        self.conv1 = torch.nn.Sequential(\n\t\t\t#卷积\n            torch.nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=0),\n            # (227-11)/4+1=55,  输出图片大小:55*55*96\n            torch.nn.ReLU(),#激活层\n            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n            # (55-3)/2+1=27, 输出图片大小: 27*27*96\n        )\n\n        # 从上面获得图片大小27*27*96\n        self.conv2 = torch.nn.Sequential(\n            torch.nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2),\n            # （27-5 + 2*2）/ 1 + 1 = 27, 输出图片大小:27*27*256\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n            # (27 - 3 )/2 + 1 = 13, 输出图片大小:13*13*256\n        )\n\n        # 从上面获得图片大小13*13*256\n        self.conv3 = torch.nn.Sequential(\n            torch.nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1),\n            # (13 - 3 +1*2)/1 + 1 = 13 , 输出图片大小:13*13*384\n            torch.nn.ReLU()\n        )\n\n        # 从上面获得图片大小13*13*384\n        self.conv4 = torch.nn.Sequential(\n            torch.nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1),\n            # (13 - 3 + 1*2)/1 +1 = 13, 输出图片大小:13*13*384\n            torch.nn.ReLU()\n        )\n\n        # 从上面获得图片大小13*13*384\n        self.conv5 = torch.nn.Sequential(\n            torch.nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1),\n            # (13 - 3 + 1*2) +1 = 13, 13*13*256\n            torch.nn.ReLU(),\n            torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0)\n            # (13 - 3 )/2 +1 =6, 6*6*256\n        )\n\n        # 从上面获得图片大小 6*6*256 = 9216 共9216输出特征\n        self.lostlayer = torch.nn.Sequential(\n\t\t\t#第六层\n            torch.nn.Linear(9216, 4096),#全连接\n            torch.nn.ReLU(),#激活层\n            torch.nn.Dropout(0.5),#以0.5&几率随机忽略一部分神经元\n\t\t\t\n\t\t\t#第七层\n            torch.nn.Linear(4096, 4096),\n            torch.nn.ReLU(),\n            torch.nn.Dropout(0.5),\n\t\t\t\n\t\t\t#第八层\n            torch.nn.Linear(4096, 2)\n            # 最后输出2 ,因为只分猫狗两类\n        )\n\n\t#前向传播\n    def forward(self, x):\n        conv1_out = self.conv1(x)\n        conv2_out = self.conv2(conv1_out)\n        conv3_out = self.conv3(conv2_out)\n        conv4_out = self.conv4(conv3_out)\n        conv5_out = self.conv5(conv4_out)\n        res = conv5_out.view(conv5_out.size(0), -1)#展平多维的卷积图成 一维(batch_size, 4096)\n        out = self.lostlayer(res)\n        return out\n```\n\n*********************\n******************\n* 训练架构:train.py文件 猫狗10张图:\n```python\nimport torch\nimport torch.nn as nn\nimport torchvision.datasets as datasets\nimport torchvision.transforms as  transforms\nfrom torch.autograd import Variable\n\n# 工具包\nimport argparse\n# 载入网络\nfrom AlexNet import   AlexNet\n\n#############参数设置#############\n####命令行设置########\nparser = argparse.ArgumentParser (description='CNN')  # 导入命令行模块\n# 对于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明\nparser.add_argument ('--batch-size', type=int, default=32, metavar='N',\n\t\t\t\t\t help='训练batch-size大小 (default: 32)')\nparser.add_argument ('--epochs', type=int, default=10, metavar='N',\n\t\t\t\t\t help='训练epochs大小 (default: 10)')\nparser.add_argument ('--lr', type=float, default=0.001, metavar='LR',\n\t\t\t\t\t help='学习率 (default: 0.001)')\nparser.add_argument ('--no-cuda', action='store_true', default=False,\n\t\t\t\t\t help='不开启cuda训练')\nparser.add_argument ('--seed', type=int, default=1, metavar='S',\n\t\t\t\t\t help='随机种子 (default: 1)')\nparser.add_argument ('--log-interval', type=int, default=1, metavar='N',\n\t\t\t\t\t help='记录等待n批次 (default: 1)')\nargs = parser.parse_args ()  # 相当于激活命令\n\nargs.cuda = not args.no_cuda and torch.cuda.is_available ()  # 判断gpu\n\ntorch.manual_seed (args.seed)\nif args.cuda:\n\ttorch.cuda.manual_seed (args.seed)  # 为CPU设置种子用于生成随机数，以使得结果是确定的\n\n\n##########数据转换#####################\ndata_transforms = transforms.Compose([transforms.Scale(227),#通过调整比例调整大小,会报警\n    \t\t\t\t\t\t\t\ttransforms.CenterCrop(227),#在中心裁剪给指定大小方形PIL图像\n\t\t\t\t\t\t\t\t\ttransforms.ToTensor ()])#转换成pytorch 变量tensor\n###############数据载入################\ntrain_dataset = datasets.ImageFolder(root=\"./data/train/\",  # 保存目录\n\t\t\t\t\t\t\t\t\ttransform=data_transforms) # 把数据转换成上面约束样子\n\ntest_dataset = datasets.ImageFolder (root='./data/test/',\n\t\t\t\t\t\t\t\t\ttransform=data_transforms)\n\n\n##########数据如下####\n# # root/dog/xxx.png\n# # root/dog/xxy.png\n# # root/dog/xxz.png\n# #\n# # root/cat/123.png\n# # root/cat/nsdf3.png\n# # root/cat/asd932_.png\n######################\n\n##############数据装载###############\ntrain_loader = torch.utils.data.DataLoader (dataset=train_dataset,  # 装载数据\n\t\t\t\t\t\t\t\t\t\t\tbatch_size=args.batch_size,  # 设置批大小\n\t\t\t\t\t\t\t\t\t\t\tshuffle=True)  # 是否随机打乱\ntest_loader = torch.utils.data.DataLoader (dataset=test_dataset,\n\t\t\t\t\t\t\t\t\t\t   batch_size=args.batch_size,\n\t\t\t\t\t\t\t\t\t\t   shuffle=True)\n\n#############模型载入#################\nAlexNet = AlexNet ()\nif not args.no_cuda:\n\tprint ('正在使用gpu')\n\tAlexNet.cuda ()\nprint (AlexNet)\n\n###############损失函数##################\ncriterion = nn.CrossEntropyLoss ()  # 内置标准损失\noptimizer = torch.optim.Adam (AlexNet.parameters (), lr=args.lr)  # Adam优化器\n#############训练过程#####################\nfor epoch in range (args.epochs):\n\tfor i, (images, labels) in enumerate (train_loader):  # 枚举出来\n\t\tif not args.no_cuda:  # 数据处理是否用gpu\n\t\t\timages = images.cuda ()\n\t\t\tlabels = labels.cuda ()\n\t\t\n\t\timages = Variable (images)  # 装箱\n\t\tlabels = Variable (labels)\n\t\t\n\t\t##前向传播\n\t\toptimizer.zero_grad ()\n\t\toutputs = AlexNet(images)\n\t\t# 损失\n\t\tloss = criterion (outputs, labels)\n\t\t# 反向传播\n\t\tloss.backward ()\n\t\toptimizer.step ()\n\t\t##打印记录\n\t\t\n\t\tif (i + 1) % args.log_interval == 0:\n\t\t\tprint ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'\n\t\t\t\t   % (epoch + 1, args.epochs, i + 1, len (train_dataset) // args.batch_size, loss.item ()))\n\t\t\n\t\t# 保存模型\n\t\ttorch.save (AlexNet.state_dict (), 'AlexNet.pkl')\n```\n************\n* 效果如图:\n![](https://blog.mviai.com/images/回顾-AlexNet/20181218112800405.png)\n","slug":"回顾-AlexNet","published":1,"updated":"2021-07-26T09:58:02.575Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m1r0011igta8i7ruxxl","content":"<h1 id=\"1-AlexNet-简介\"><a href=\"#1-AlexNet-简介\" class=\"headerlink\" title=\"1. AlexNet 简介:\"></a>1. AlexNet 简介:</h1><p>AlexNet由Alex Krizhevsky于2012年提出，夺得2012年ILSVRC比赛的冠军，top5预测的错误率为16.4%，远超第一名。</p>\n<hr>\n<h1 id=\"2-AlexNet-网络结构\"><a href=\"#2-AlexNet-网络结构\" class=\"headerlink\" title=\"2. AlexNet 网络结构:\"></a>2. AlexNet 网络结构:</h1><p>AlexNet采用8层的神经网络，5个卷积层和3个全连接层(3个卷积层后面加了最大池化层)，包含6亿3000万个链接，6000万个 参数和65万个神经元。</p>\n<ul>\n<li><p>如图:</p>\n</li>\n<li><p><img src=\"https://blog.mviai.com/images/alexnet.png\" alt></p>\n</li>\n</ul>\n<hr>\n<hr>\n<ul>\n<li>官方图:</li>\n<li><img src=\"https://blog.mviai.com/images/a2.png\" alt></li>\n</ul>\n<hr>\n<h1 id=\"3-AlexNet-改进点\"><a href=\"#3-AlexNet-改进点\" class=\"headerlink\" title=\"3. AlexNet 改进点:\"></a>3. AlexNet 改进点:</h1><ul>\n<li>1.使用ReLU作为CNN的激活函数，验证了其效果在较深的网络中超过了Sigmoid.解决了Sigmoid在网络较深时的梯度弥散问题。</li>\n<li>2.使用最大池化可以避免平均池化的模糊效果。同时重叠效果可以提升特征的丰富性。</li>\n<li>3.提出LRN（Local Response Normalization，即局部响应归一化）层，对局部神经元的活动创建竞争机制，使得其中响应比较大的值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力。</li>\n<li>4.数据增强，随机的从256<code>*</code>256的图片中截取224<code>*</code>224大小的区域（以及水平翻转的镜像），相当于增加了（256-224)*(2^2)=2048 倍的数据量，如果没有数据增强，模型会陷入过拟合中，使用数据增强可以增大模型的泛化能力。</li>\n<li>5.使用CUDA加速神经网络的训练，利用了GPU强大的计算能力。</li>\n<li>6.训练时使用Dropout随机忽略一部分神经元，以避免模型过拟合，一般在全连接层使用，在预测的时候是不使用Dropout的，即Dropout为1.</li>\n</ul>\n<hr>\n<h1 id=\"4-PyTorch实现\"><a href=\"#4-PyTorch实现\" class=\"headerlink\" title=\"4.PyTorch实现:\"></a>4.PyTorch实现:</h1><ul>\n<li>网络架构:AlexNet.py文件:<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#跟着第一幅图走</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">AlexNet</span><span class=\"params\">(torch.nn.Module)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        super(AlexNet, self).__init__()</span><br><span class=\"line\">        <span class=\"comment\"># 输入图片大小 227*227*3</span></span><br><span class=\"line\">\t\t<span class=\"comment\">#第一层</span></span><br><span class=\"line\">        self.conv1 = torch.nn.Sequential(</span><br><span class=\"line\">\t\t\t<span class=\"comment\">#卷积</span></span><br><span class=\"line\">            torch.nn.Conv2d(in_channels=<span class=\"number\">3</span>, out_channels=<span class=\"number\">96</span>, kernel_size=<span class=\"number\">11</span>, stride=<span class=\"number\">4</span>, padding=<span class=\"number\">0</span>),</span><br><span class=\"line\">            <span class=\"comment\"># (227-11)/4+1=55,  输出图片大小:55*55*96</span></span><br><span class=\"line\">            torch.nn.ReLU(),<span class=\"comment\">#激活层</span></span><br><span class=\"line\">            torch.nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">0</span>)</span><br><span class=\"line\">            <span class=\"comment\"># (55-3)/2+1=27, 输出图片大小: 27*27*96</span></span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 从上面获得图片大小27*27*96</span></span><br><span class=\"line\">        self.conv2 = torch.nn.Sequential(</span><br><span class=\"line\">            torch.nn.Conv2d(in_channels=<span class=\"number\">96</span>, out_channels=<span class=\"number\">256</span>, kernel_size=<span class=\"number\">5</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">2</span>),</span><br><span class=\"line\">            <span class=\"comment\"># （27-5 + 2*2）/ 1 + 1 = 27, 输出图片大小:27*27*256</span></span><br><span class=\"line\">            torch.nn.ReLU(),</span><br><span class=\"line\">            torch.nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">0</span>)</span><br><span class=\"line\">            <span class=\"comment\"># (27 - 3 )/2 + 1 = 13, 输出图片大小:13*13*256</span></span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 从上面获得图片大小13*13*256</span></span><br><span class=\"line\">        self.conv3 = torch.nn.Sequential(</span><br><span class=\"line\">            torch.nn.Conv2d(in_channels=<span class=\"number\">256</span>, out_channels=<span class=\"number\">384</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>),</span><br><span class=\"line\">            <span class=\"comment\"># (13 - 3 +1*2)/1 + 1 = 13 , 输出图片大小:13*13*384</span></span><br><span class=\"line\">            torch.nn.ReLU()</span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 从上面获得图片大小13*13*384</span></span><br><span class=\"line\">        self.conv4 = torch.nn.Sequential(</span><br><span class=\"line\">            torch.nn.Conv2d(in_channels=<span class=\"number\">384</span>, out_channels=<span class=\"number\">384</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>),</span><br><span class=\"line\">            <span class=\"comment\"># (13 - 3 + 1*2)/1 +1 = 13, 输出图片大小:13*13*384</span></span><br><span class=\"line\">            torch.nn.ReLU()</span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 从上面获得图片大小13*13*384</span></span><br><span class=\"line\">        self.conv5 = torch.nn.Sequential(</span><br><span class=\"line\">            torch.nn.Conv2d(in_channels=<span class=\"number\">384</span>, out_channels=<span class=\"number\">256</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>),</span><br><span class=\"line\">            <span class=\"comment\"># (13 - 3 + 1*2) +1 = 13, 13*13*256</span></span><br><span class=\"line\">            torch.nn.ReLU(),</span><br><span class=\"line\">            torch.nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">0</span>)</span><br><span class=\"line\">            <span class=\"comment\"># (13 - 3 )/2 +1 =6, 6*6*256</span></span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 从上面获得图片大小 6*6*256 = 9216 共9216输出特征</span></span><br><span class=\"line\">        self.lostlayer = torch.nn.Sequential(</span><br><span class=\"line\">\t\t\t<span class=\"comment\">#第六层</span></span><br><span class=\"line\">            torch.nn.Linear(<span class=\"number\">9216</span>, <span class=\"number\">4096</span>),<span class=\"comment\">#全连接</span></span><br><span class=\"line\">            torch.nn.ReLU(),<span class=\"comment\">#激活层</span></span><br><span class=\"line\">            torch.nn.Dropout(<span class=\"number\">0.5</span>),<span class=\"comment\">#以0.5&amp;几率随机忽略一部分神经元</span></span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\t<span class=\"comment\">#第七层</span></span><br><span class=\"line\">            torch.nn.Linear(<span class=\"number\">4096</span>, <span class=\"number\">4096</span>),</span><br><span class=\"line\">            torch.nn.ReLU(),</span><br><span class=\"line\">            torch.nn.Dropout(<span class=\"number\">0.5</span>),</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\t<span class=\"comment\">#第八层</span></span><br><span class=\"line\">            torch.nn.Linear(<span class=\"number\">4096</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">            <span class=\"comment\"># 最后输出2 ,因为只分猫狗两类</span></span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">#前向传播</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></span><br><span class=\"line\">        conv1_out = self.conv1(x)</span><br><span class=\"line\">        conv2_out = self.conv2(conv1_out)</span><br><span class=\"line\">        conv3_out = self.conv3(conv2_out)</span><br><span class=\"line\">        conv4_out = self.conv4(conv3_out)</span><br><span class=\"line\">        conv5_out = self.conv5(conv4_out)</span><br><span class=\"line\">        res = conv5_out.view(conv5_out.size(<span class=\"number\">0</span>), <span class=\"number\">-1</span>)<span class=\"comment\">#展平多维的卷积图成 一维(batch_size, 4096)</span></span><br><span class=\"line\">        out = self.lostlayer(res)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<hr>\n<hr>\n<ul>\n<li>训练架构:train.py文件 猫狗10张图:<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision.datasets <span class=\"keyword\">as</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision.transforms <span class=\"keyword\">as</span>  transforms</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 工具包</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> argparse</span><br><span class=\"line\"><span class=\"comment\"># 载入网络</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> AlexNet <span class=\"keyword\">import</span>   AlexNet</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############参数设置#############</span></span><br><span class=\"line\"><span class=\"comment\">####命令行设置########</span></span><br><span class=\"line\">parser = argparse.ArgumentParser (description=<span class=\"string\">'CNN'</span>)  <span class=\"comment\"># 导入命令行模块</span></span><br><span class=\"line\"><span class=\"comment\"># 对于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--batch-size'</span>, type=int, default=<span class=\"number\">32</span>, metavar=<span class=\"string\">'N'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'训练batch-size大小 (default: 32)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--epochs'</span>, type=int, default=<span class=\"number\">10</span>, metavar=<span class=\"string\">'N'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'训练epochs大小 (default: 10)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--lr'</span>, type=float, default=<span class=\"number\">0.001</span>, metavar=<span class=\"string\">'LR'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'学习率 (default: 0.001)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--no-cuda'</span>, action=<span class=\"string\">'store_true'</span>, default=<span class=\"literal\">False</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'不开启cuda训练'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--seed'</span>, type=int, default=<span class=\"number\">1</span>, metavar=<span class=\"string\">'S'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'随机种子 (default: 1)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--log-interval'</span>, type=int, default=<span class=\"number\">1</span>, metavar=<span class=\"string\">'N'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'记录等待n批次 (default: 1)'</span>)</span><br><span class=\"line\">args = parser.parse_args ()  <span class=\"comment\"># 相当于激活命令</span></span><br><span class=\"line\"></span><br><span class=\"line\">args.cuda = <span class=\"keyword\">not</span> args.no_cuda <span class=\"keyword\">and</span> torch.cuda.is_available ()  <span class=\"comment\"># 判断gpu</span></span><br><span class=\"line\"></span><br><span class=\"line\">torch.manual_seed (args.seed)</span><br><span class=\"line\"><span class=\"keyword\">if</span> args.cuda:</span><br><span class=\"line\">\ttorch.cuda.manual_seed (args.seed)  <span class=\"comment\"># 为CPU设置种子用于生成随机数，以使得结果是确定的</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##########数据转换#####################</span></span><br><span class=\"line\">data_transforms = transforms.Compose([transforms.Scale(<span class=\"number\">227</span>),<span class=\"comment\">#通过调整比例调整大小,会报警</span></span><br><span class=\"line\">    \t\t\t\t\t\t\t\ttransforms.CenterCrop(<span class=\"number\">227</span>),<span class=\"comment\">#在中心裁剪给指定大小方形PIL图像</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\ttransforms.ToTensor ()])<span class=\"comment\">#转换成pytorch 变量tensor</span></span><br><span class=\"line\"><span class=\"comment\">###############数据载入################</span></span><br><span class=\"line\">train_dataset = datasets.ImageFolder(root=<span class=\"string\">\"./data/train/\"</span>,  <span class=\"comment\"># 保存目录</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\ttransform=data_transforms) <span class=\"comment\"># 把数据转换成上面约束样子</span></span><br><span class=\"line\"></span><br><span class=\"line\">test_dataset = datasets.ImageFolder (root=<span class=\"string\">'./data/test/'</span>,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\ttransform=data_transforms)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##########数据如下####</span></span><br><span class=\"line\"><span class=\"comment\"># # root/dog/xxx.png</span></span><br><span class=\"line\"><span class=\"comment\"># # root/dog/xxy.png</span></span><br><span class=\"line\"><span class=\"comment\"># # root/dog/xxz.png</span></span><br><span class=\"line\"><span class=\"comment\"># #</span></span><br><span class=\"line\"><span class=\"comment\"># # root/cat/123.png</span></span><br><span class=\"line\"><span class=\"comment\"># # root/cat/nsdf3.png</span></span><br><span class=\"line\"><span class=\"comment\"># # root/cat/asd932_.png</span></span><br><span class=\"line\"><span class=\"comment\">######################</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##############数据装载###############</span></span><br><span class=\"line\">train_loader = torch.utils.data.DataLoader (dataset=train_dataset,  <span class=\"comment\"># 装载数据</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\tbatch_size=args.batch_size,  <span class=\"comment\"># 设置批大小</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\tshuffle=<span class=\"literal\">True</span>)  <span class=\"comment\"># 是否随机打乱</span></span><br><span class=\"line\">test_loader = torch.utils.data.DataLoader (dataset=test_dataset,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   batch_size=args.batch_size,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   shuffle=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############模型载入#################</span></span><br><span class=\"line\">AlexNet = AlexNet ()</span><br><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"keyword\">not</span> args.no_cuda:</span><br><span class=\"line\">\t<span class=\"keyword\">print</span> (<span class=\"string\">'正在使用gpu'</span>)</span><br><span class=\"line\">\tAlexNet.cuda ()</span><br><span class=\"line\"><span class=\"keyword\">print</span> (AlexNet)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###############损失函数##################</span></span><br><span class=\"line\">criterion = nn.CrossEntropyLoss ()  <span class=\"comment\"># 内置标准损失</span></span><br><span class=\"line\">optimizer = torch.optim.Adam (AlexNet.parameters (), lr=args.lr)  <span class=\"comment\"># Adam优化器</span></span><br><span class=\"line\"><span class=\"comment\">#############训练过程#####################</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range (args.epochs):</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i, (images, labels) <span class=\"keyword\">in</span> enumerate (train_loader):  <span class=\"comment\"># 枚举出来</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> <span class=\"keyword\">not</span> args.no_cuda:  <span class=\"comment\"># 数据处理是否用gpu</span></span><br><span class=\"line\">\t\t\timages = images.cuda ()</span><br><span class=\"line\">\t\t\tlabels = labels.cuda ()</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\timages = Variable (images)  <span class=\"comment\"># 装箱</span></span><br><span class=\"line\">\t\tlabels = Variable (labels)</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\">##前向传播</span></span><br><span class=\"line\">\t\toptimizer.zero_grad ()</span><br><span class=\"line\">\t\toutputs = AlexNet(images)</span><br><span class=\"line\">\t\t<span class=\"comment\"># 损失</span></span><br><span class=\"line\">\t\tloss = criterion (outputs, labels)</span><br><span class=\"line\">\t\t<span class=\"comment\"># 反向传播</span></span><br><span class=\"line\">\t\tloss.backward ()</span><br><span class=\"line\">\t\toptimizer.step ()</span><br><span class=\"line\">\t\t<span class=\"comment\">##打印记录</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (i + <span class=\"number\">1</span>) % args.log_interval == <span class=\"number\">0</span>:</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">print</span> (<span class=\"string\">'Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'</span></span><br><span class=\"line\">\t\t\t\t   % (epoch + <span class=\"number\">1</span>, args.epochs, i + <span class=\"number\">1</span>, len (train_dataset) // args.batch_size, loss.item ()))</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 保存模型</span></span><br><span class=\"line\">\t\ttorch.save (AlexNet.state_dict (), <span class=\"string\">'AlexNet.pkl'</span>)</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<hr>\n<ul>\n<li>效果如图:<br><img src=\"https://blog.mviai.com/images/回顾-AlexNet/20181218112800405.png\" alt></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"1-AlexNet-简介\"><a href=\"#1-AlexNet-简介\" class=\"headerlink\" title=\"1. AlexNet 简介:\"></a>1. AlexNet 简介:</h1><p>AlexNet由Alex Krizhevsky于2012年提出，夺得2012年ILSVRC比赛的冠军，top5预测的错误率为16.4%，远超第一名。</p>\n<hr>\n<h1 id=\"2-AlexNet-网络结构\"><a href=\"#2-AlexNet-网络结构\" class=\"headerlink\" title=\"2. AlexNet 网络结构:\"></a>2. AlexNet 网络结构:</h1><p>AlexNet采用8层的神经网络，5个卷积层和3个全连接层(3个卷积层后面加了最大池化层)，包含6亿3000万个链接，6000万个 参数和65万个神经元。</p>\n<ul>\n<li><p>如图:</p>\n</li>\n<li><p><img src=\"https://blog.mviai.com/images/alexnet.png\" alt></p>\n</li>\n</ul>\n<hr>\n<hr>\n<ul>\n<li>官方图:</li>\n<li><img src=\"https://blog.mviai.com/images/a2.png\" alt></li>\n</ul>\n<hr>\n<h1 id=\"3-AlexNet-改进点\"><a href=\"#3-AlexNet-改进点\" class=\"headerlink\" title=\"3. AlexNet 改进点:\"></a>3. AlexNet 改进点:</h1><ul>\n<li>1.使用ReLU作为CNN的激活函数，验证了其效果在较深的网络中超过了Sigmoid.解决了Sigmoid在网络较深时的梯度弥散问题。</li>\n<li>2.使用最大池化可以避免平均池化的模糊效果。同时重叠效果可以提升特征的丰富性。</li>\n<li>3.提出LRN（Local Response Normalization，即局部响应归一化）层，对局部神经元的活动创建竞争机制，使得其中响应比较大的值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力。</li>\n<li>4.数据增强，随机的从256<code>*</code>256的图片中截取224<code>*</code>224大小的区域（以及水平翻转的镜像），相当于增加了（256-224)*(2^2)=2048 倍的数据量，如果没有数据增强，模型会陷入过拟合中，使用数据增强可以增大模型的泛化能力。</li>\n<li>5.使用CUDA加速神经网络的训练，利用了GPU强大的计算能力。</li>\n<li>6.训练时使用Dropout随机忽略一部分神经元，以避免模型过拟合，一般在全连接层使用，在预测的时候是不使用Dropout的，即Dropout为1.</li>\n</ul>\n<hr>\n<h1 id=\"4-PyTorch实现\"><a href=\"#4-PyTorch实现\" class=\"headerlink\" title=\"4.PyTorch实现:\"></a>4.PyTorch实现:</h1><ul>\n<li>网络架构:AlexNet.py文件:<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#跟着第一幅图走</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">AlexNet</span><span class=\"params\">(torch.nn.Module)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        super(AlexNet, self).__init__()</span><br><span class=\"line\">        <span class=\"comment\"># 输入图片大小 227*227*3</span></span><br><span class=\"line\">\t\t<span class=\"comment\">#第一层</span></span><br><span class=\"line\">        self.conv1 = torch.nn.Sequential(</span><br><span class=\"line\">\t\t\t<span class=\"comment\">#卷积</span></span><br><span class=\"line\">            torch.nn.Conv2d(in_channels=<span class=\"number\">3</span>, out_channels=<span class=\"number\">96</span>, kernel_size=<span class=\"number\">11</span>, stride=<span class=\"number\">4</span>, padding=<span class=\"number\">0</span>),</span><br><span class=\"line\">            <span class=\"comment\"># (227-11)/4+1=55,  输出图片大小:55*55*96</span></span><br><span class=\"line\">            torch.nn.ReLU(),<span class=\"comment\">#激活层</span></span><br><span class=\"line\">            torch.nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">0</span>)</span><br><span class=\"line\">            <span class=\"comment\"># (55-3)/2+1=27, 输出图片大小: 27*27*96</span></span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 从上面获得图片大小27*27*96</span></span><br><span class=\"line\">        self.conv2 = torch.nn.Sequential(</span><br><span class=\"line\">            torch.nn.Conv2d(in_channels=<span class=\"number\">96</span>, out_channels=<span class=\"number\">256</span>, kernel_size=<span class=\"number\">5</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">2</span>),</span><br><span class=\"line\">            <span class=\"comment\"># （27-5 + 2*2）/ 1 + 1 = 27, 输出图片大小:27*27*256</span></span><br><span class=\"line\">            torch.nn.ReLU(),</span><br><span class=\"line\">            torch.nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">0</span>)</span><br><span class=\"line\">            <span class=\"comment\"># (27 - 3 )/2 + 1 = 13, 输出图片大小:13*13*256</span></span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 从上面获得图片大小13*13*256</span></span><br><span class=\"line\">        self.conv3 = torch.nn.Sequential(</span><br><span class=\"line\">            torch.nn.Conv2d(in_channels=<span class=\"number\">256</span>, out_channels=<span class=\"number\">384</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>),</span><br><span class=\"line\">            <span class=\"comment\"># (13 - 3 +1*2)/1 + 1 = 13 , 输出图片大小:13*13*384</span></span><br><span class=\"line\">            torch.nn.ReLU()</span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 从上面获得图片大小13*13*384</span></span><br><span class=\"line\">        self.conv4 = torch.nn.Sequential(</span><br><span class=\"line\">            torch.nn.Conv2d(in_channels=<span class=\"number\">384</span>, out_channels=<span class=\"number\">384</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>),</span><br><span class=\"line\">            <span class=\"comment\"># (13 - 3 + 1*2)/1 +1 = 13, 输出图片大小:13*13*384</span></span><br><span class=\"line\">            torch.nn.ReLU()</span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 从上面获得图片大小13*13*384</span></span><br><span class=\"line\">        self.conv5 = torch.nn.Sequential(</span><br><span class=\"line\">            torch.nn.Conv2d(in_channels=<span class=\"number\">384</span>, out_channels=<span class=\"number\">256</span>, kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">1</span>, padding=<span class=\"number\">1</span>),</span><br><span class=\"line\">            <span class=\"comment\"># (13 - 3 + 1*2) +1 = 13, 13*13*256</span></span><br><span class=\"line\">            torch.nn.ReLU(),</span><br><span class=\"line\">            torch.nn.MaxPool2d(kernel_size=<span class=\"number\">3</span>, stride=<span class=\"number\">2</span>, padding=<span class=\"number\">0</span>)</span><br><span class=\"line\">            <span class=\"comment\"># (13 - 3 )/2 +1 =6, 6*6*256</span></span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 从上面获得图片大小 6*6*256 = 9216 共9216输出特征</span></span><br><span class=\"line\">        self.lostlayer = torch.nn.Sequential(</span><br><span class=\"line\">\t\t\t<span class=\"comment\">#第六层</span></span><br><span class=\"line\">            torch.nn.Linear(<span class=\"number\">9216</span>, <span class=\"number\">4096</span>),<span class=\"comment\">#全连接</span></span><br><span class=\"line\">            torch.nn.ReLU(),<span class=\"comment\">#激活层</span></span><br><span class=\"line\">            torch.nn.Dropout(<span class=\"number\">0.5</span>),<span class=\"comment\">#以0.5&amp;几率随机忽略一部分神经元</span></span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\t<span class=\"comment\">#第七层</span></span><br><span class=\"line\">            torch.nn.Linear(<span class=\"number\">4096</span>, <span class=\"number\">4096</span>),</span><br><span class=\"line\">            torch.nn.ReLU(),</span><br><span class=\"line\">            torch.nn.Dropout(<span class=\"number\">0.5</span>),</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\t<span class=\"comment\">#第八层</span></span><br><span class=\"line\">            torch.nn.Linear(<span class=\"number\">4096</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">            <span class=\"comment\"># 最后输出2 ,因为只分猫狗两类</span></span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">#前向传播</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></span><br><span class=\"line\">        conv1_out = self.conv1(x)</span><br><span class=\"line\">        conv2_out = self.conv2(conv1_out)</span><br><span class=\"line\">        conv3_out = self.conv3(conv2_out)</span><br><span class=\"line\">        conv4_out = self.conv4(conv3_out)</span><br><span class=\"line\">        conv5_out = self.conv5(conv4_out)</span><br><span class=\"line\">        res = conv5_out.view(conv5_out.size(<span class=\"number\">0</span>), <span class=\"number\">-1</span>)<span class=\"comment\">#展平多维的卷积图成 一维(batch_size, 4096)</span></span><br><span class=\"line\">        out = self.lostlayer(res)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<hr>\n<hr>\n<ul>\n<li>训练架构:train.py文件 猫狗10张图:<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision.datasets <span class=\"keyword\">as</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision.transforms <span class=\"keyword\">as</span>  transforms</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 工具包</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> argparse</span><br><span class=\"line\"><span class=\"comment\"># 载入网络</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> AlexNet <span class=\"keyword\">import</span>   AlexNet</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############参数设置#############</span></span><br><span class=\"line\"><span class=\"comment\">####命令行设置########</span></span><br><span class=\"line\">parser = argparse.ArgumentParser (description=<span class=\"string\">'CNN'</span>)  <span class=\"comment\"># 导入命令行模块</span></span><br><span class=\"line\"><span class=\"comment\"># 对于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--batch-size'</span>, type=int, default=<span class=\"number\">32</span>, metavar=<span class=\"string\">'N'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'训练batch-size大小 (default: 32)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--epochs'</span>, type=int, default=<span class=\"number\">10</span>, metavar=<span class=\"string\">'N'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'训练epochs大小 (default: 10)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--lr'</span>, type=float, default=<span class=\"number\">0.001</span>, metavar=<span class=\"string\">'LR'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'学习率 (default: 0.001)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--no-cuda'</span>, action=<span class=\"string\">'store_true'</span>, default=<span class=\"literal\">False</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'不开启cuda训练'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--seed'</span>, type=int, default=<span class=\"number\">1</span>, metavar=<span class=\"string\">'S'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'随机种子 (default: 1)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--log-interval'</span>, type=int, default=<span class=\"number\">1</span>, metavar=<span class=\"string\">'N'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'记录等待n批次 (default: 1)'</span>)</span><br><span class=\"line\">args = parser.parse_args ()  <span class=\"comment\"># 相当于激活命令</span></span><br><span class=\"line\"></span><br><span class=\"line\">args.cuda = <span class=\"keyword\">not</span> args.no_cuda <span class=\"keyword\">and</span> torch.cuda.is_available ()  <span class=\"comment\"># 判断gpu</span></span><br><span class=\"line\"></span><br><span class=\"line\">torch.manual_seed (args.seed)</span><br><span class=\"line\"><span class=\"keyword\">if</span> args.cuda:</span><br><span class=\"line\">\ttorch.cuda.manual_seed (args.seed)  <span class=\"comment\"># 为CPU设置种子用于生成随机数，以使得结果是确定的</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##########数据转换#####################</span></span><br><span class=\"line\">data_transforms = transforms.Compose([transforms.Scale(<span class=\"number\">227</span>),<span class=\"comment\">#通过调整比例调整大小,会报警</span></span><br><span class=\"line\">    \t\t\t\t\t\t\t\ttransforms.CenterCrop(<span class=\"number\">227</span>),<span class=\"comment\">#在中心裁剪给指定大小方形PIL图像</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\ttransforms.ToTensor ()])<span class=\"comment\">#转换成pytorch 变量tensor</span></span><br><span class=\"line\"><span class=\"comment\">###############数据载入################</span></span><br><span class=\"line\">train_dataset = datasets.ImageFolder(root=<span class=\"string\">\"./data/train/\"</span>,  <span class=\"comment\"># 保存目录</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\ttransform=data_transforms) <span class=\"comment\"># 把数据转换成上面约束样子</span></span><br><span class=\"line\"></span><br><span class=\"line\">test_dataset = datasets.ImageFolder (root=<span class=\"string\">'./data/test/'</span>,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\ttransform=data_transforms)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##########数据如下####</span></span><br><span class=\"line\"><span class=\"comment\"># # root/dog/xxx.png</span></span><br><span class=\"line\"><span class=\"comment\"># # root/dog/xxy.png</span></span><br><span class=\"line\"><span class=\"comment\"># # root/dog/xxz.png</span></span><br><span class=\"line\"><span class=\"comment\"># #</span></span><br><span class=\"line\"><span class=\"comment\"># # root/cat/123.png</span></span><br><span class=\"line\"><span class=\"comment\"># # root/cat/nsdf3.png</span></span><br><span class=\"line\"><span class=\"comment\"># # root/cat/asd932_.png</span></span><br><span class=\"line\"><span class=\"comment\">######################</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##############数据装载###############</span></span><br><span class=\"line\">train_loader = torch.utils.data.DataLoader (dataset=train_dataset,  <span class=\"comment\"># 装载数据</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\tbatch_size=args.batch_size,  <span class=\"comment\"># 设置批大小</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\tshuffle=<span class=\"literal\">True</span>)  <span class=\"comment\"># 是否随机打乱</span></span><br><span class=\"line\">test_loader = torch.utils.data.DataLoader (dataset=test_dataset,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   batch_size=args.batch_size,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   shuffle=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############模型载入#################</span></span><br><span class=\"line\">AlexNet = AlexNet ()</span><br><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"keyword\">not</span> args.no_cuda:</span><br><span class=\"line\">\t<span class=\"keyword\">print</span> (<span class=\"string\">'正在使用gpu'</span>)</span><br><span class=\"line\">\tAlexNet.cuda ()</span><br><span class=\"line\"><span class=\"keyword\">print</span> (AlexNet)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###############损失函数##################</span></span><br><span class=\"line\">criterion = nn.CrossEntropyLoss ()  <span class=\"comment\"># 内置标准损失</span></span><br><span class=\"line\">optimizer = torch.optim.Adam (AlexNet.parameters (), lr=args.lr)  <span class=\"comment\"># Adam优化器</span></span><br><span class=\"line\"><span class=\"comment\">#############训练过程#####################</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range (args.epochs):</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i, (images, labels) <span class=\"keyword\">in</span> enumerate (train_loader):  <span class=\"comment\"># 枚举出来</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> <span class=\"keyword\">not</span> args.no_cuda:  <span class=\"comment\"># 数据处理是否用gpu</span></span><br><span class=\"line\">\t\t\timages = images.cuda ()</span><br><span class=\"line\">\t\t\tlabels = labels.cuda ()</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\timages = Variable (images)  <span class=\"comment\"># 装箱</span></span><br><span class=\"line\">\t\tlabels = Variable (labels)</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\">##前向传播</span></span><br><span class=\"line\">\t\toptimizer.zero_grad ()</span><br><span class=\"line\">\t\toutputs = AlexNet(images)</span><br><span class=\"line\">\t\t<span class=\"comment\"># 损失</span></span><br><span class=\"line\">\t\tloss = criterion (outputs, labels)</span><br><span class=\"line\">\t\t<span class=\"comment\"># 反向传播</span></span><br><span class=\"line\">\t\tloss.backward ()</span><br><span class=\"line\">\t\toptimizer.step ()</span><br><span class=\"line\">\t\t<span class=\"comment\">##打印记录</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (i + <span class=\"number\">1</span>) % args.log_interval == <span class=\"number\">0</span>:</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">print</span> (<span class=\"string\">'Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'</span></span><br><span class=\"line\">\t\t\t\t   % (epoch + <span class=\"number\">1</span>, args.epochs, i + <span class=\"number\">1</span>, len (train_dataset) // args.batch_size, loss.item ()))</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 保存模型</span></span><br><span class=\"line\">\t\ttorch.save (AlexNet.state_dict (), <span class=\"string\">'AlexNet.pkl'</span>)</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<hr>\n<ul>\n<li>效果如图:<br><img src=\"https://blog.mviai.com/images/回顾-AlexNet/20181218112800405.png\" alt></li>\n</ul>\n"},{"title":"为什么我要写博客！","toc":false,"date":"2018-04-05T13:03:38.000Z","_content":"\n**一 不想写博客的原因：**\n---------------\n\n1.  **想写，但不知道写什么**\n2.  **没有深厚底蕴，害怕没有意义**\n3.  **害怕浪费宝贵时间**\n4.  **生活繁忙，没有时间整理写作**\n5.  **觉得自己能记住**\n6.  **有度粮，Google等可以查阅**\n7.  **偷懒，不想整理思绪**\n\n二 想写博客的原因；\n----------\n\n1.  ** 怕自己日后会用到**\n2.  **网络信息繁杂，只有自己实践过的才是真理**\n3.  **提高自己思维整理能力**\n4.  **为自己人生留下些许痕迹**\n5.  **能让他人获得些许帮助**\n6.  **养成良好习惯**\n7.  **汇中式再次学习**\n8.  **记录学习历程**\n\n三 为何自建网站写博客:\n------------\n\n1.  ** 自己做的比较了解和维护**\n2.  **没有庸俗繁杂广告**\n3.  **可以逼迫自己再次学习相关知识**\n4.  **比较好看，简洁**\n5.  **价格低廉，平均每年约为30元**\n\n四 总结；\n-----\n\n**对于一个技术人员来讲 ，写博客是对自己能力，思维，技能，知识的提升和挑战，写博客虽然非常花费时间，但是当网络信息拥堵的年代，这时间花费性价比最高，是最值得的。博客不需要太复杂，简简单单就好。给自己一份勇气，大胆去想，勇敢去写** \n-----\n五 博客结构:\n-----\n框架\n- \tpytorch\n- \ttensorflow\n\n-----\t\n编程\n- \tC++\n- \tpython\n-----\n界面\n- \tPyQT\n- \tQT\n-----\n\n网站\n- \thexo\n- \twordpress\n- \thtml\n-----\n学习\n- \t教学\n- \t计算机网络\n- \t算法\n-----\n工具\n- \t日常工具\n- \t嵌入式\n\n\n-----\n感悟\n\n\n-----","source":"_posts/为什么我要写博客！.md","raw":"---\ntitle: 为什么我要写博客！\ntags:\n  - 心理\ncategories:\n  - 感悟\ntoc: false\ndate: 2018-04-05 21:03:38\n---\n\n**一 不想写博客的原因：**\n---------------\n\n1.  **想写，但不知道写什么**\n2.  **没有深厚底蕴，害怕没有意义**\n3.  **害怕浪费宝贵时间**\n4.  **生活繁忙，没有时间整理写作**\n5.  **觉得自己能记住**\n6.  **有度粮，Google等可以查阅**\n7.  **偷懒，不想整理思绪**\n\n二 想写博客的原因；\n----------\n\n1.  ** 怕自己日后会用到**\n2.  **网络信息繁杂，只有自己实践过的才是真理**\n3.  **提高自己思维整理能力**\n4.  **为自己人生留下些许痕迹**\n5.  **能让他人获得些许帮助**\n6.  **养成良好习惯**\n7.  **汇中式再次学习**\n8.  **记录学习历程**\n\n三 为何自建网站写博客:\n------------\n\n1.  ** 自己做的比较了解和维护**\n2.  **没有庸俗繁杂广告**\n3.  **可以逼迫自己再次学习相关知识**\n4.  **比较好看，简洁**\n5.  **价格低廉，平均每年约为30元**\n\n四 总结；\n-----\n\n**对于一个技术人员来讲 ，写博客是对自己能力，思维，技能，知识的提升和挑战，写博客虽然非常花费时间，但是当网络信息拥堵的年代，这时间花费性价比最高，是最值得的。博客不需要太复杂，简简单单就好。给自己一份勇气，大胆去想，勇敢去写** \n-----\n五 博客结构:\n-----\n框架\n- \tpytorch\n- \ttensorflow\n\n-----\t\n编程\n- \tC++\n- \tpython\n-----\n界面\n- \tPyQT\n- \tQT\n-----\n\n网站\n- \thexo\n- \twordpress\n- \thtml\n-----\n学习\n- \t教学\n- \t计算机网络\n- \t算法\n-----\n工具\n- \t日常工具\n- \t嵌入式\n\n\n-----\n感悟\n\n\n-----","slug":"为什么我要写博客！","published":1,"updated":"2021-07-26T09:58:02.582Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m1t0014igta3r3abjy5","content":"<h2 id=\"一-不想写博客的原因：\"><a href=\"#一-不想写博客的原因：\" class=\"headerlink\" title=\"一 不想写博客的原因：\"></a><strong>一 不想写博客的原因：</strong></h2><ol>\n<li><strong>想写，但不知道写什么</strong></li>\n<li><strong>没有深厚底蕴，害怕没有意义</strong></li>\n<li><strong>害怕浪费宝贵时间</strong></li>\n<li><strong>生活繁忙，没有时间整理写作</strong></li>\n<li><strong>觉得自己能记住</strong></li>\n<li><strong>有度粮，Google等可以查阅</strong></li>\n<li><strong>偷懒，不想整理思绪</strong></li>\n</ol>\n<h2 id=\"二-想写博客的原因；\"><a href=\"#二-想写博客的原因；\" class=\"headerlink\" title=\"二 想写博客的原因；\"></a>二 想写博客的原因；</h2><ol>\n<li><strong> 怕自己日后会用到</strong></li>\n<li><strong>网络信息繁杂，只有自己实践过的才是真理</strong></li>\n<li><strong>提高自己思维整理能力</strong></li>\n<li><strong>为自己人生留下些许痕迹</strong></li>\n<li><strong>能让他人获得些许帮助</strong></li>\n<li><strong>养成良好习惯</strong></li>\n<li><strong>汇中式再次学习</strong></li>\n<li><strong>记录学习历程</strong></li>\n</ol>\n<h2 id=\"三-为何自建网站写博客\"><a href=\"#三-为何自建网站写博客\" class=\"headerlink\" title=\"三 为何自建网站写博客:\"></a>三 为何自建网站写博客:</h2><ol>\n<li><strong> 自己做的比较了解和维护</strong></li>\n<li><strong>没有庸俗繁杂广告</strong></li>\n<li><strong>可以逼迫自己再次学习相关知识</strong></li>\n<li><strong>比较好看，简洁</strong></li>\n<li><strong>价格低廉，平均每年约为30元</strong></li>\n</ol>\n<h2 id=\"四-总结；\"><a href=\"#四-总结；\" class=\"headerlink\" title=\"四 总结；\"></a>四 总结；</h2><h2 id=\"对于一个技术人员来讲-，写博客是对自己能力，思维，技能，知识的提升和挑战，写博客虽然非常花费时间，但是当网络信息拥堵的年代，这时间花费性价比最高，是最值得的。博客不需要太复杂，简简单单就好。给自己一份勇气，大胆去想，勇敢去写\"><a href=\"#对于一个技术人员来讲-，写博客是对自己能力，思维，技能，知识的提升和挑战，写博客虽然非常花费时间，但是当网络信息拥堵的年代，这时间花费性价比最高，是最值得的。博客不需要太复杂，简简单单就好。给自己一份勇气，大胆去想，勇敢去写\" class=\"headerlink\" title=\"对于一个技术人员来讲 ，写博客是对自己能力，思维，技能，知识的提升和挑战，写博客虽然非常花费时间，但是当网络信息拥堵的年代，这时间花费性价比最高，是最值得的。博客不需要太复杂，简简单单就好。给自己一份勇气，大胆去想，勇敢去写 \"></a><strong>对于一个技术人员来讲 ，写博客是对自己能力，思维，技能，知识的提升和挑战，写博客虽然非常花费时间，但是当网络信息拥堵的年代，这时间花费性价比最高，是最值得的。博客不需要太复杂，简简单单就好。给自己一份勇气，大胆去想，勇敢去写</strong> </h2><h2 id=\"五-博客结构\"><a href=\"#五-博客结构\" class=\"headerlink\" title=\"五 博客结构:\"></a>五 博客结构:</h2><p>框架</p>\n<ul>\n<li>pytorch</li>\n<li>tensorflow</li>\n</ul>\n<hr>\n<p>编程</p>\n<ul>\n<li>C++</li>\n<li>python</li>\n</ul>\n<hr>\n<p>界面</p>\n<ul>\n<li>PyQT</li>\n<li>QT</li>\n</ul>\n<hr>\n<p>网站</p>\n<ul>\n<li>hexo</li>\n<li>wordpress</li>\n<li>html</li>\n</ul>\n<hr>\n<p>学习</p>\n<ul>\n<li>教学</li>\n<li>计算机网络</li>\n<li>算法</li>\n</ul>\n<hr>\n<p>工具</p>\n<ul>\n<li>日常工具</li>\n<li>嵌入式</li>\n</ul>\n<hr>\n<p>感悟</p>\n<hr>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"一-不想写博客的原因：\"><a href=\"#一-不想写博客的原因：\" class=\"headerlink\" title=\"一 不想写博客的原因：\"></a><strong>一 不想写博客的原因：</strong></h2><ol>\n<li><strong>想写，但不知道写什么</strong></li>\n<li><strong>没有深厚底蕴，害怕没有意义</strong></li>\n<li><strong>害怕浪费宝贵时间</strong></li>\n<li><strong>生活繁忙，没有时间整理写作</strong></li>\n<li><strong>觉得自己能记住</strong></li>\n<li><strong>有度粮，Google等可以查阅</strong></li>\n<li><strong>偷懒，不想整理思绪</strong></li>\n</ol>\n<h2 id=\"二-想写博客的原因；\"><a href=\"#二-想写博客的原因；\" class=\"headerlink\" title=\"二 想写博客的原因；\"></a>二 想写博客的原因；</h2><ol>\n<li><strong> 怕自己日后会用到</strong></li>\n<li><strong>网络信息繁杂，只有自己实践过的才是真理</strong></li>\n<li><strong>提高自己思维整理能力</strong></li>\n<li><strong>为自己人生留下些许痕迹</strong></li>\n<li><strong>能让他人获得些许帮助</strong></li>\n<li><strong>养成良好习惯</strong></li>\n<li><strong>汇中式再次学习</strong></li>\n<li><strong>记录学习历程</strong></li>\n</ol>\n<h2 id=\"三-为何自建网站写博客\"><a href=\"#三-为何自建网站写博客\" class=\"headerlink\" title=\"三 为何自建网站写博客:\"></a>三 为何自建网站写博客:</h2><ol>\n<li><strong> 自己做的比较了解和维护</strong></li>\n<li><strong>没有庸俗繁杂广告</strong></li>\n<li><strong>可以逼迫自己再次学习相关知识</strong></li>\n<li><strong>比较好看，简洁</strong></li>\n<li><strong>价格低廉，平均每年约为30元</strong></li>\n</ol>\n<h2 id=\"四-总结；\"><a href=\"#四-总结；\" class=\"headerlink\" title=\"四 总结；\"></a>四 总结；</h2><h2 id=\"对于一个技术人员来讲-，写博客是对自己能力，思维，技能，知识的提升和挑战，写博客虽然非常花费时间，但是当网络信息拥堵的年代，这时间花费性价比最高，是最值得的。博客不需要太复杂，简简单单就好。给自己一份勇气，大胆去想，勇敢去写\"><a href=\"#对于一个技术人员来讲-，写博客是对自己能力，思维，技能，知识的提升和挑战，写博客虽然非常花费时间，但是当网络信息拥堵的年代，这时间花费性价比最高，是最值得的。博客不需要太复杂，简简单单就好。给自己一份勇气，大胆去想，勇敢去写\" class=\"headerlink\" title=\"对于一个技术人员来讲 ，写博客是对自己能力，思维，技能，知识的提升和挑战，写博客虽然非常花费时间，但是当网络信息拥堵的年代，这时间花费性价比最高，是最值得的。博客不需要太复杂，简简单单就好。给自己一份勇气，大胆去想，勇敢去写 \"></a><strong>对于一个技术人员来讲 ，写博客是对自己能力，思维，技能，知识的提升和挑战，写博客虽然非常花费时间，但是当网络信息拥堵的年代，这时间花费性价比最高，是最值得的。博客不需要太复杂，简简单单就好。给自己一份勇气，大胆去想，勇敢去写</strong> </h2><h2 id=\"五-博客结构\"><a href=\"#五-博客结构\" class=\"headerlink\" title=\"五 博客结构:\"></a>五 博客结构:</h2><p>框架</p>\n<ul>\n<li>pytorch</li>\n<li>tensorflow</li>\n</ul>\n<hr>\n<p>编程</p>\n<ul>\n<li>C++</li>\n<li>python</li>\n</ul>\n<hr>\n<p>界面</p>\n<ul>\n<li>PyQT</li>\n<li>QT</li>\n</ul>\n<hr>\n<p>网站</p>\n<ul>\n<li>hexo</li>\n<li>wordpress</li>\n<li>html</li>\n</ul>\n<hr>\n<p>学习</p>\n<ul>\n<li>教学</li>\n<li>计算机网络</li>\n<li>算法</li>\n</ul>\n<hr>\n<p>工具</p>\n<ul>\n<li>日常工具</li>\n<li>嵌入式</li>\n</ul>\n<hr>\n<p>感悟</p>\n<hr>\n"},{"title":"回顾-CNN","date":"2018-12-17T12:49:57.000Z","_content":"### 卷积神经网络通常包含以下几种层：\n\n**1.卷积层（Convolutional layer）:**\n卷积神经网路中每层卷积层由若干卷积单元组成，每个卷积单元的参数都是通过反向传播算法优化得到的。卷积运算的目的是提取输入的不同特征，第一层卷积层可能只能提取一些低级的特征如边缘、线条和角等层级，更多层的网络能从低级特征中迭代提取更复杂的特征。\n**2.线性整流层（Rectified Linear Units layer, ReLU layer）:**\n这一层神经的激活函数（Activation function）使用线性整流（Rectified Linear Units, ReLU）。\n就像容器  不管你水怎样流  放进去都是容器形状(这叫容器整流)\n\n**3.池化层（Pooling layer）:**\n通常在卷积层之后会得到维度很大的特征，将特征切成几个区域，取其最大值或平均值，得到新的、维度较小的特征。\n**4.全连接层（ Fully-Connected layer）:**\n把所有局部特征结合变成全局特征，用来计算最后每一类的得分。\n\n#### 卷积层:\n**1.局部感知:**\n相当于看一副很大很大的图,你必须从图中一区域(感受野)开始挨个浏览(扫描),你就能知道这幅图到底是啥!\n有啥好处,一下看很大的图--身心疲惫,而且还不一定能看懂\n慢慢看,又优雅,又高尚,还能快速抓到要点(就像你看到有德玛西亚,你就可以知道跟lol有关)\n**2.权值共享(参数共享)**\n比说,刚花了一万的力气创造了猪八戒和孙悟空,猪八戒找的到吃的,孙悟空能打小怪兽,\n后面我遇到小怪兽就不用创造悟空了,直接拿过来打小怪兽就可以了!\n如果遇到肚子饿了,孙悟空就没用了,就可以用猪八戒找吃的!\n\n所以参数共享能节省不必要的重复消耗,加快计算\n#### 池化层:\n池化（pool）即下采样（downsamples），目的是为了减少特征图。池化操作对每个深度切片独立，规模一般为 2＊2，相对于卷积层进行卷积运算，池化层进行的运算一般有以下几种： \n* 最大池化（Max Pooling）。取4个点的最大值。这是最常用的池化方法。 \n* 均值池化（Mean Pooling）。取4个点的均值。 \n    * 注:\n        池化操作将保存深度大小不变。\n        如果池化层的输入单元大小不是二的整数倍，\n        一般采取边缘补零（zero-padding）的方式补成2的倍数，然后再池化。\n        \n#### 全连接层:\n**全连接层** <font color=red> **可相互转换** </font> **卷积层**\n\n#### 常见卷积网络架构:\n输入 -> [[卷积层(CONV) -> 激活层(RELU)]  * N -> 池化层(POOL)] *  M \n-> [全连接(fc) -> 激活层(RELU)]* K -> 全连接(fc)\n\n\n### PyTorch:\n##### 网络架构:**CNN.py文件:**\n\n```python\nimport  torch.nn as nn\n\nclass CNN(nn.Module):\n\tdef __init__(self):\n\t\tsuper(CNN, self).__init__()                                      # 输入MNIST 图片大小是(1,28,28)\n\t\tself.layer=nn.Sequential(nn.Conv2d(1,8,kernel_size=5,padding=2),#第一个参数,输入是1,表示输入图片通道为1 ,8表示输出,5卷积核大小,2补边大小\n\t\t\t\t\t\t\t\t nn.BatchNorm2d(8),#归一化\n\t\t\t\t\t\t\t\t nn.ReLU(),#激活层\n\t\t\t\t\t\t\t\t nn.MaxPool2d(2),#池化层 到这 (8,28,28)图片就被池化成(8,14,14)了\n\t\t\t\t\t\t\t\t )\n\t\tself.fc=nn.Linear(14*14*8,10)  #全连接层 第一个输入的特征数,第二个 输出的特征 (0-9) 共10特征\n\t\n\t#前向传播\t\n\tdef forward(self, x):\n\t\tout=self.layer(x)\n\t\tout=out.view(out.size(0),-1)#展平多维的卷积图成 (batch_size, 32 * 7 * 7)\n\t\tout=self.fc(out)\n\t\treturn out\n```\n\n**训练架构:train.py文件**\n```python\n#pytorch\nimport torch\nimport torch.nn as nn\nimport  torchvision.datasets as datasets\nimport  torchvision.transforms as  transforms\nfrom torch.autograd import Variable\n\n#工具包\nimport argparse\n#载入网络\nfrom CNN import CNN\n\n#############参数设置#############\n####命令行设置########\nparser = argparse.ArgumentParser(description='CNN') #导入命令行模块\n#对于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明\nparser.add_argument('--batch-size', type=int, default=64, metavar='N',\n                    help='训练batch-size大小 (default: 64)')\nparser.add_argument('--epochs', type=int, default=10, metavar='N',\n                    help='训练epochs大小 (default: 10)')\nparser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n                    help='学习率 (default: 0.001)')\nparser.add_argument('--no-cuda', action='store_true', default=False,\n                    help='不开启cuda训练')\nparser.add_argument('--seed', type=int, default=1, metavar='S',\n                    help='随机种子 (default: 1)')\nparser.add_argument('--log-interval', type=int, default=50, metavar='N',\n                    help='记录等待n批次 (default: 50)')\nargs = parser.parse_args()#相当于激活命令\n\n\nargs.cuda = not args.no_cuda and torch.cuda.is_available()#判断gpu\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)#为CPU设置种子用于生成随机数，以使得结果是确定的\n    \n    \n###############数据载入################\ntrain_dataset=datasets.MNIST(root=\"./data/\",#保存目录\n                             train=True,  #选择训练集\n                             transform=transforms.ToTensor(), #把数据转换成pytorch张量 Tensor\n                             download=True) #是否下载数据集\ntest_dataset=datasets.MNIST(root='./data/',\n                            train=False,#关闭 表示选择测试集\n                            transform=transforms.ToTensor(),\n                            download=True)\n\n##############数据装载###############\ntrain_loader=torch.utils.data.DataLoader(dataset=train_dataset,#装载数据\n                                         batch_size=args.batch_size,#设置批大小\n                                         shuffle=True)#是否随机打乱\ntest_loader=torch.utils.data.DataLoader(dataset=test_dataset,\n                                         batch_size=args.batch_size,\n                                         shuffle=True)\n\n#############模型载入#################\ncnn=CNN()\nif not args.no_cuda:\n    print('正在使用gpu')\n    cnn.cuda()\nprint(cnn)\n\n###############损失函数##################\ncriterion=nn.CrossEntropyLoss()#内置标准损失\noptimizer=torch.optim.Adam(cnn.parameters(),lr=args.lr)#Adam优化器\n\n#############训练过程#####################\nfor epoch in range (args.epochs):\n    for i, (images,labels) in enumerate(train_loader):#枚举出来\n        if not  args.no_cuda:#数据处理是否用gpu\n            images=images.cuda()\n            labels=labels.cuda()\n        \n        \n        images=Variable(images)#装箱\n        labels=Variable(labels)\n        \n        ##前向传播\n        optimizer.zero_grad()\n        outputs=cnn(images)\n        #损失\n        loss=criterion(outputs,labels)\n        #反向传播\n        loss.backward()\n        optimizer.step ()\n        ##打印记录\n        \n        if (i+1)% args.log_interval==0:\n            print('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'\n                   %(epoch+1, args.epochs, i+1, len(train_dataset)//args.batch_size, loss.item()))\n            \n            \n        #保存模型\n        torch.save(cnn.state_dict(), 'cnn.pkl')\n```\n* 注:\n* 数据集下载不下来,修改pytorch里面MNIST.py文件\n* 效果如图:\n* \n![](https://blog.mviai.com/images/回顾-CNN/20181218125050651.png)\n","source":"_posts/回顾-CNN.md","raw":"---\ntitle: 回顾-CNN\ndate: 2018-12-17 20:49:57\ntags:\n    - CNN\ncategories: \n    - 框架\n    - pytorch\n    - CNN\n---\n### 卷积神经网络通常包含以下几种层：\n\n**1.卷积层（Convolutional layer）:**\n卷积神经网路中每层卷积层由若干卷积单元组成，每个卷积单元的参数都是通过反向传播算法优化得到的。卷积运算的目的是提取输入的不同特征，第一层卷积层可能只能提取一些低级的特征如边缘、线条和角等层级，更多层的网络能从低级特征中迭代提取更复杂的特征。\n**2.线性整流层（Rectified Linear Units layer, ReLU layer）:**\n这一层神经的激活函数（Activation function）使用线性整流（Rectified Linear Units, ReLU）。\n就像容器  不管你水怎样流  放进去都是容器形状(这叫容器整流)\n\n**3.池化层（Pooling layer）:**\n通常在卷积层之后会得到维度很大的特征，将特征切成几个区域，取其最大值或平均值，得到新的、维度较小的特征。\n**4.全连接层（ Fully-Connected layer）:**\n把所有局部特征结合变成全局特征，用来计算最后每一类的得分。\n\n#### 卷积层:\n**1.局部感知:**\n相当于看一副很大很大的图,你必须从图中一区域(感受野)开始挨个浏览(扫描),你就能知道这幅图到底是啥!\n有啥好处,一下看很大的图--身心疲惫,而且还不一定能看懂\n慢慢看,又优雅,又高尚,还能快速抓到要点(就像你看到有德玛西亚,你就可以知道跟lol有关)\n**2.权值共享(参数共享)**\n比说,刚花了一万的力气创造了猪八戒和孙悟空,猪八戒找的到吃的,孙悟空能打小怪兽,\n后面我遇到小怪兽就不用创造悟空了,直接拿过来打小怪兽就可以了!\n如果遇到肚子饿了,孙悟空就没用了,就可以用猪八戒找吃的!\n\n所以参数共享能节省不必要的重复消耗,加快计算\n#### 池化层:\n池化（pool）即下采样（downsamples），目的是为了减少特征图。池化操作对每个深度切片独立，规模一般为 2＊2，相对于卷积层进行卷积运算，池化层进行的运算一般有以下几种： \n* 最大池化（Max Pooling）。取4个点的最大值。这是最常用的池化方法。 \n* 均值池化（Mean Pooling）。取4个点的均值。 \n    * 注:\n        池化操作将保存深度大小不变。\n        如果池化层的输入单元大小不是二的整数倍，\n        一般采取边缘补零（zero-padding）的方式补成2的倍数，然后再池化。\n        \n#### 全连接层:\n**全连接层** <font color=red> **可相互转换** </font> **卷积层**\n\n#### 常见卷积网络架构:\n输入 -> [[卷积层(CONV) -> 激活层(RELU)]  * N -> 池化层(POOL)] *  M \n-> [全连接(fc) -> 激活层(RELU)]* K -> 全连接(fc)\n\n\n### PyTorch:\n##### 网络架构:**CNN.py文件:**\n\n```python\nimport  torch.nn as nn\n\nclass CNN(nn.Module):\n\tdef __init__(self):\n\t\tsuper(CNN, self).__init__()                                      # 输入MNIST 图片大小是(1,28,28)\n\t\tself.layer=nn.Sequential(nn.Conv2d(1,8,kernel_size=5,padding=2),#第一个参数,输入是1,表示输入图片通道为1 ,8表示输出,5卷积核大小,2补边大小\n\t\t\t\t\t\t\t\t nn.BatchNorm2d(8),#归一化\n\t\t\t\t\t\t\t\t nn.ReLU(),#激活层\n\t\t\t\t\t\t\t\t nn.MaxPool2d(2),#池化层 到这 (8,28,28)图片就被池化成(8,14,14)了\n\t\t\t\t\t\t\t\t )\n\t\tself.fc=nn.Linear(14*14*8,10)  #全连接层 第一个输入的特征数,第二个 输出的特征 (0-9) 共10特征\n\t\n\t#前向传播\t\n\tdef forward(self, x):\n\t\tout=self.layer(x)\n\t\tout=out.view(out.size(0),-1)#展平多维的卷积图成 (batch_size, 32 * 7 * 7)\n\t\tout=self.fc(out)\n\t\treturn out\n```\n\n**训练架构:train.py文件**\n```python\n#pytorch\nimport torch\nimport torch.nn as nn\nimport  torchvision.datasets as datasets\nimport  torchvision.transforms as  transforms\nfrom torch.autograd import Variable\n\n#工具包\nimport argparse\n#载入网络\nfrom CNN import CNN\n\n#############参数设置#############\n####命令行设置########\nparser = argparse.ArgumentParser(description='CNN') #导入命令行模块\n#对于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明\nparser.add_argument('--batch-size', type=int, default=64, metavar='N',\n                    help='训练batch-size大小 (default: 64)')\nparser.add_argument('--epochs', type=int, default=10, metavar='N',\n                    help='训练epochs大小 (default: 10)')\nparser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n                    help='学习率 (default: 0.001)')\nparser.add_argument('--no-cuda', action='store_true', default=False,\n                    help='不开启cuda训练')\nparser.add_argument('--seed', type=int, default=1, metavar='S',\n                    help='随机种子 (default: 1)')\nparser.add_argument('--log-interval', type=int, default=50, metavar='N',\n                    help='记录等待n批次 (default: 50)')\nargs = parser.parse_args()#相当于激活命令\n\n\nargs.cuda = not args.no_cuda and torch.cuda.is_available()#判断gpu\n\ntorch.manual_seed(args.seed)\nif args.cuda:\n    torch.cuda.manual_seed(args.seed)#为CPU设置种子用于生成随机数，以使得结果是确定的\n    \n    \n###############数据载入################\ntrain_dataset=datasets.MNIST(root=\"./data/\",#保存目录\n                             train=True,  #选择训练集\n                             transform=transforms.ToTensor(), #把数据转换成pytorch张量 Tensor\n                             download=True) #是否下载数据集\ntest_dataset=datasets.MNIST(root='./data/',\n                            train=False,#关闭 表示选择测试集\n                            transform=transforms.ToTensor(),\n                            download=True)\n\n##############数据装载###############\ntrain_loader=torch.utils.data.DataLoader(dataset=train_dataset,#装载数据\n                                         batch_size=args.batch_size,#设置批大小\n                                         shuffle=True)#是否随机打乱\ntest_loader=torch.utils.data.DataLoader(dataset=test_dataset,\n                                         batch_size=args.batch_size,\n                                         shuffle=True)\n\n#############模型载入#################\ncnn=CNN()\nif not args.no_cuda:\n    print('正在使用gpu')\n    cnn.cuda()\nprint(cnn)\n\n###############损失函数##################\ncriterion=nn.CrossEntropyLoss()#内置标准损失\noptimizer=torch.optim.Adam(cnn.parameters(),lr=args.lr)#Adam优化器\n\n#############训练过程#####################\nfor epoch in range (args.epochs):\n    for i, (images,labels) in enumerate(train_loader):#枚举出来\n        if not  args.no_cuda:#数据处理是否用gpu\n            images=images.cuda()\n            labels=labels.cuda()\n        \n        \n        images=Variable(images)#装箱\n        labels=Variable(labels)\n        \n        ##前向传播\n        optimizer.zero_grad()\n        outputs=cnn(images)\n        #损失\n        loss=criterion(outputs,labels)\n        #反向传播\n        loss.backward()\n        optimizer.step ()\n        ##打印记录\n        \n        if (i+1)% args.log_interval==0:\n            print('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'\n                   %(epoch+1, args.epochs, i+1, len(train_dataset)//args.batch_size, loss.item()))\n            \n            \n        #保存模型\n        torch.save(cnn.state_dict(), 'cnn.pkl')\n```\n* 注:\n* 数据集下载不下来,修改pytorch里面MNIST.py文件\n* 效果如图:\n* \n![](https://blog.mviai.com/images/回顾-CNN/20181218125050651.png)\n","slug":"回顾-CNN","published":1,"updated":"2021-07-26T09:58:02.576Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m1u0016igtagiat4f4t","content":"<h3 id=\"卷积神经网络通常包含以下几种层：\"><a href=\"#卷积神经网络通常包含以下几种层：\" class=\"headerlink\" title=\"卷积神经网络通常包含以下几种层：\"></a>卷积神经网络通常包含以下几种层：</h3><p><strong>1.卷积层（Convolutional layer）:</strong><br>卷积神经网路中每层卷积层由若干卷积单元组成，每个卷积单元的参数都是通过反向传播算法优化得到的。卷积运算的目的是提取输入的不同特征，第一层卷积层可能只能提取一些低级的特征如边缘、线条和角等层级，更多层的网络能从低级特征中迭代提取更复杂的特征。<br><strong>2.线性整流层（Rectified Linear Units layer, ReLU layer）:</strong><br>这一层神经的激活函数（Activation function）使用线性整流（Rectified Linear Units, ReLU）。<br>就像容器  不管你水怎样流  放进去都是容器形状(这叫容器整流)</p>\n<p><strong>3.池化层（Pooling layer）:</strong><br>通常在卷积层之后会得到维度很大的特征，将特征切成几个区域，取其最大值或平均值，得到新的、维度较小的特征。<br><strong>4.全连接层（ Fully-Connected layer）:</strong><br>把所有局部特征结合变成全局特征，用来计算最后每一类的得分。</p>\n<h4 id=\"卷积层\"><a href=\"#卷积层\" class=\"headerlink\" title=\"卷积层:\"></a>卷积层:</h4><p><strong>1.局部感知:</strong><br>相当于看一副很大很大的图,你必须从图中一区域(感受野)开始挨个浏览(扫描),你就能知道这幅图到底是啥!<br>有啥好处,一下看很大的图–身心疲惫,而且还不一定能看懂<br>慢慢看,又优雅,又高尚,还能快速抓到要点(就像你看到有德玛西亚,你就可以知道跟lol有关)<br><strong>2.权值共享(参数共享)</strong><br>比说,刚花了一万的力气创造了猪八戒和孙悟空,猪八戒找的到吃的,孙悟空能打小怪兽,<br>后面我遇到小怪兽就不用创造悟空了,直接拿过来打小怪兽就可以了!<br>如果遇到肚子饿了,孙悟空就没用了,就可以用猪八戒找吃的!</p>\n<p>所以参数共享能节省不必要的重复消耗,加快计算</p>\n<h4 id=\"池化层\"><a href=\"#池化层\" class=\"headerlink\" title=\"池化层:\"></a>池化层:</h4><p>池化（pool）即下采样（downsamples），目的是为了减少特征图。池化操作对每个深度切片独立，规模一般为 2＊2，相对于卷积层进行卷积运算，池化层进行的运算一般有以下几种： </p>\n<ul>\n<li>最大池化（Max Pooling）。取4个点的最大值。这是最常用的池化方法。 </li>\n<li>均值池化（Mean Pooling）。取4个点的均值。 <ul>\n<li>注:<br>  池化操作将保存深度大小不变。<br>  如果池化层的输入单元大小不是二的整数倍，<br>  一般采取边缘补零（zero-padding）的方式补成2的倍数，然后再池化。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"全连接层\"><a href=\"#全连接层\" class=\"headerlink\" title=\"全连接层:\"></a>全连接层:</h4><p><strong>全连接层</strong> <font color=\"red\"> <strong>可相互转换</strong> </font> <strong>卷积层</strong></p>\n<h4 id=\"常见卷积网络架构\"><a href=\"#常见卷积网络架构\" class=\"headerlink\" title=\"常见卷积网络架构:\"></a>常见卷积网络架构:</h4><p>输入 -&gt; [[卷积层(CONV) -&gt; 激活层(RELU)]  <em> N -&gt; 池化层(POOL)] </em>  M<br>-&gt; [全连接(fc) -&gt; 激活层(RELU)]* K -&gt; 全连接(fc)</p>\n<h3 id=\"PyTorch\"><a href=\"#PyTorch\" class=\"headerlink\" title=\"PyTorch:\"></a>PyTorch:</h3><h5 id=\"网络架构-CNN-py文件\"><a href=\"#网络架构-CNN-py文件\" class=\"headerlink\" title=\"网络架构:CNN.py文件:\"></a>网络架构:<strong>CNN.py文件:</strong></h5><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span>  torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">CNN</span><span class=\"params\">(nn.Module)</span>:</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">\t\tsuper(CNN, self).__init__()                                      <span class=\"comment\"># 输入MNIST 图片大小是(1,28,28)</span></span><br><span class=\"line\">\t\tself.layer=nn.Sequential(nn.Conv2d(<span class=\"number\">1</span>,<span class=\"number\">8</span>,kernel_size=<span class=\"number\">5</span>,padding=<span class=\"number\">2</span>),<span class=\"comment\">#第一个参数,输入是1,表示输入图片通道为1 ,8表示输出,5卷积核大小,2补边大小</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t nn.BatchNorm2d(<span class=\"number\">8</span>),<span class=\"comment\">#归一化</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t nn.ReLU(),<span class=\"comment\">#激活层</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t nn.MaxPool2d(<span class=\"number\">2</span>),<span class=\"comment\">#池化层 到这 (8,28,28)图片就被池化成(8,14,14)了</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t )</span><br><span class=\"line\">\t\tself.fc=nn.Linear(<span class=\"number\">14</span>*<span class=\"number\">14</span>*<span class=\"number\">8</span>,<span class=\"number\">10</span>)  <span class=\"comment\">#全连接层 第一个输入的特征数,第二个 输出的特征 (0-9) 共10特征</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">#前向传播\t</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></span><br><span class=\"line\">\t\tout=self.layer(x)</span><br><span class=\"line\">\t\tout=out.view(out.size(<span class=\"number\">0</span>),<span class=\"number\">-1</span>)<span class=\"comment\">#展平多维的卷积图成 (batch_size, 32 * 7 * 7)</span></span><br><span class=\"line\">\t\tout=self.fc(out)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> out</span><br></pre></td></tr></table></figure>\n<p><strong>训练架构:train.py文件</strong><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#pytorch</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span>  torchvision.datasets <span class=\"keyword\">as</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">import</span>  torchvision.transforms <span class=\"keyword\">as</span>  transforms</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#工具包</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> argparse</span><br><span class=\"line\"><span class=\"comment\">#载入网络</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> CNN <span class=\"keyword\">import</span> CNN</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############参数设置#############</span></span><br><span class=\"line\"><span class=\"comment\">####命令行设置########</span></span><br><span class=\"line\">parser = argparse.ArgumentParser(description=<span class=\"string\">'CNN'</span>) <span class=\"comment\">#导入命令行模块</span></span><br><span class=\"line\"><span class=\"comment\">#对于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明</span></span><br><span class=\"line\">parser.add_argument(<span class=\"string\">'--batch-size'</span>, type=int, default=<span class=\"number\">64</span>, metavar=<span class=\"string\">'N'</span>,</span><br><span class=\"line\">                    help=<span class=\"string\">'训练batch-size大小 (default: 64)'</span>)</span><br><span class=\"line\">parser.add_argument(<span class=\"string\">'--epochs'</span>, type=int, default=<span class=\"number\">10</span>, metavar=<span class=\"string\">'N'</span>,</span><br><span class=\"line\">                    help=<span class=\"string\">'训练epochs大小 (default: 10)'</span>)</span><br><span class=\"line\">parser.add_argument(<span class=\"string\">'--lr'</span>, type=float, default=<span class=\"number\">0.001</span>, metavar=<span class=\"string\">'LR'</span>,</span><br><span class=\"line\">                    help=<span class=\"string\">'学习率 (default: 0.001)'</span>)</span><br><span class=\"line\">parser.add_argument(<span class=\"string\">'--no-cuda'</span>, action=<span class=\"string\">'store_true'</span>, default=<span class=\"literal\">False</span>,</span><br><span class=\"line\">                    help=<span class=\"string\">'不开启cuda训练'</span>)</span><br><span class=\"line\">parser.add_argument(<span class=\"string\">'--seed'</span>, type=int, default=<span class=\"number\">1</span>, metavar=<span class=\"string\">'S'</span>,</span><br><span class=\"line\">                    help=<span class=\"string\">'随机种子 (default: 1)'</span>)</span><br><span class=\"line\">parser.add_argument(<span class=\"string\">'--log-interval'</span>, type=int, default=<span class=\"number\">50</span>, metavar=<span class=\"string\">'N'</span>,</span><br><span class=\"line\">                    help=<span class=\"string\">'记录等待n批次 (default: 50)'</span>)</span><br><span class=\"line\">args = parser.parse_args()<span class=\"comment\">#相当于激活命令</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">args.cuda = <span class=\"keyword\">not</span> args.no_cuda <span class=\"keyword\">and</span> torch.cuda.is_available()<span class=\"comment\">#判断gpu</span></span><br><span class=\"line\"></span><br><span class=\"line\">torch.manual_seed(args.seed)</span><br><span class=\"line\"><span class=\"keyword\">if</span> args.cuda:</span><br><span class=\"line\">    torch.cuda.manual_seed(args.seed)<span class=\"comment\">#为CPU设置种子用于生成随机数，以使得结果是确定的</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\">###############数据载入################</span></span><br><span class=\"line\">train_dataset=datasets.MNIST(root=<span class=\"string\">\"./data/\"</span>,<span class=\"comment\">#保存目录</span></span><br><span class=\"line\">                             train=<span class=\"literal\">True</span>,  <span class=\"comment\">#选择训练集</span></span><br><span class=\"line\">                             transform=transforms.ToTensor(), <span class=\"comment\">#把数据转换成pytorch张量 Tensor</span></span><br><span class=\"line\">                             download=<span class=\"literal\">True</span>) <span class=\"comment\">#是否下载数据集</span></span><br><span class=\"line\">test_dataset=datasets.MNIST(root=<span class=\"string\">'./data/'</span>,</span><br><span class=\"line\">                            train=<span class=\"literal\">False</span>,<span class=\"comment\">#关闭 表示选择测试集</span></span><br><span class=\"line\">                            transform=transforms.ToTensor(),</span><br><span class=\"line\">                            download=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##############数据装载###############</span></span><br><span class=\"line\">train_loader=torch.utils.data.DataLoader(dataset=train_dataset,<span class=\"comment\">#装载数据</span></span><br><span class=\"line\">                                         batch_size=args.batch_size,<span class=\"comment\">#设置批大小</span></span><br><span class=\"line\">                                         shuffle=<span class=\"literal\">True</span>)<span class=\"comment\">#是否随机打乱</span></span><br><span class=\"line\">test_loader=torch.utils.data.DataLoader(dataset=test_dataset,</span><br><span class=\"line\">                                         batch_size=args.batch_size,</span><br><span class=\"line\">                                         shuffle=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############模型载入#################</span></span><br><span class=\"line\">cnn=CNN()</span><br><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"keyword\">not</span> args.no_cuda:</span><br><span class=\"line\">    print(<span class=\"string\">'正在使用gpu'</span>)</span><br><span class=\"line\">    cnn.cuda()</span><br><span class=\"line\">print(cnn)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###############损失函数##################</span></span><br><span class=\"line\">criterion=nn.CrossEntropyLoss()<span class=\"comment\">#内置标准损失</span></span><br><span class=\"line\">optimizer=torch.optim.Adam(cnn.parameters(),lr=args.lr)<span class=\"comment\">#Adam优化器</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############训练过程#####################</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range (args.epochs):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i, (images,labels) <span class=\"keyword\">in</span> enumerate(train_loader):<span class=\"comment\">#枚举出来</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span>  args.no_cuda:<span class=\"comment\">#数据处理是否用gpu</span></span><br><span class=\"line\">            images=images.cuda()</span><br><span class=\"line\">            labels=labels.cuda()</span><br><span class=\"line\">        </span><br><span class=\"line\">        </span><br><span class=\"line\">        images=Variable(images)<span class=\"comment\">#装箱</span></span><br><span class=\"line\">        labels=Variable(labels)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\">##前向传播</span></span><br><span class=\"line\">        optimizer.zero_grad()</span><br><span class=\"line\">        outputs=cnn(images)</span><br><span class=\"line\">        <span class=\"comment\">#损失</span></span><br><span class=\"line\">        loss=criterion(outputs,labels)</span><br><span class=\"line\">        <span class=\"comment\">#反向传播</span></span><br><span class=\"line\">        loss.backward()</span><br><span class=\"line\">        optimizer.step ()</span><br><span class=\"line\">        <span class=\"comment\">##打印记录</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">if</span> (i+<span class=\"number\">1</span>)% args.log_interval==<span class=\"number\">0</span>:</span><br><span class=\"line\">            print(<span class=\"string\">'Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'</span></span><br><span class=\"line\">                   %(epoch+<span class=\"number\">1</span>, args.epochs, i+<span class=\"number\">1</span>, len(train_dataset)//args.batch_size, loss.item()))</span><br><span class=\"line\">            </span><br><span class=\"line\">            </span><br><span class=\"line\">        <span class=\"comment\">#保存模型</span></span><br><span class=\"line\">        torch.save(cnn.state_dict(), <span class=\"string\">'cnn.pkl'</span>)</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>注:</li>\n<li>数据集下载不下来,修改pytorch里面MNIST.py文件</li>\n<li>效果如图:</li>\n<li><img src=\"https://blog.mviai.com/images/回顾-CNN/20181218125050651.png\" alt></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h3 id=\"卷积神经网络通常包含以下几种层：\"><a href=\"#卷积神经网络通常包含以下几种层：\" class=\"headerlink\" title=\"卷积神经网络通常包含以下几种层：\"></a>卷积神经网络通常包含以下几种层：</h3><p><strong>1.卷积层（Convolutional layer）:</strong><br>卷积神经网路中每层卷积层由若干卷积单元组成，每个卷积单元的参数都是通过反向传播算法优化得到的。卷积运算的目的是提取输入的不同特征，第一层卷积层可能只能提取一些低级的特征如边缘、线条和角等层级，更多层的网络能从低级特征中迭代提取更复杂的特征。<br><strong>2.线性整流层（Rectified Linear Units layer, ReLU layer）:</strong><br>这一层神经的激活函数（Activation function）使用线性整流（Rectified Linear Units, ReLU）。<br>就像容器  不管你水怎样流  放进去都是容器形状(这叫容器整流)</p>\n<p><strong>3.池化层（Pooling layer）:</strong><br>通常在卷积层之后会得到维度很大的特征，将特征切成几个区域，取其最大值或平均值，得到新的、维度较小的特征。<br><strong>4.全连接层（ Fully-Connected layer）:</strong><br>把所有局部特征结合变成全局特征，用来计算最后每一类的得分。</p>\n<h4 id=\"卷积层\"><a href=\"#卷积层\" class=\"headerlink\" title=\"卷积层:\"></a>卷积层:</h4><p><strong>1.局部感知:</strong><br>相当于看一副很大很大的图,你必须从图中一区域(感受野)开始挨个浏览(扫描),你就能知道这幅图到底是啥!<br>有啥好处,一下看很大的图–身心疲惫,而且还不一定能看懂<br>慢慢看,又优雅,又高尚,还能快速抓到要点(就像你看到有德玛西亚,你就可以知道跟lol有关)<br><strong>2.权值共享(参数共享)</strong><br>比说,刚花了一万的力气创造了猪八戒和孙悟空,猪八戒找的到吃的,孙悟空能打小怪兽,<br>后面我遇到小怪兽就不用创造悟空了,直接拿过来打小怪兽就可以了!<br>如果遇到肚子饿了,孙悟空就没用了,就可以用猪八戒找吃的!</p>\n<p>所以参数共享能节省不必要的重复消耗,加快计算</p>\n<h4 id=\"池化层\"><a href=\"#池化层\" class=\"headerlink\" title=\"池化层:\"></a>池化层:</h4><p>池化（pool）即下采样（downsamples），目的是为了减少特征图。池化操作对每个深度切片独立，规模一般为 2＊2，相对于卷积层进行卷积运算，池化层进行的运算一般有以下几种： </p>\n<ul>\n<li>最大池化（Max Pooling）。取4个点的最大值。这是最常用的池化方法。 </li>\n<li>均值池化（Mean Pooling）。取4个点的均值。 <ul>\n<li>注:<br>  池化操作将保存深度大小不变。<br>  如果池化层的输入单元大小不是二的整数倍，<br>  一般采取边缘补零（zero-padding）的方式补成2的倍数，然后再池化。</li>\n</ul>\n</li>\n</ul>\n<h4 id=\"全连接层\"><a href=\"#全连接层\" class=\"headerlink\" title=\"全连接层:\"></a>全连接层:</h4><p><strong>全连接层</strong> <font color=\"red\"> <strong>可相互转换</strong> </font> <strong>卷积层</strong></p>\n<h4 id=\"常见卷积网络架构\"><a href=\"#常见卷积网络架构\" class=\"headerlink\" title=\"常见卷积网络架构:\"></a>常见卷积网络架构:</h4><p>输入 -&gt; [[卷积层(CONV) -&gt; 激活层(RELU)]  <em> N -&gt; 池化层(POOL)] </em>  M<br>-&gt; [全连接(fc) -&gt; 激活层(RELU)]* K -&gt; 全连接(fc)</p>\n<h3 id=\"PyTorch\"><a href=\"#PyTorch\" class=\"headerlink\" title=\"PyTorch:\"></a>PyTorch:</h3><h5 id=\"网络架构-CNN-py文件\"><a href=\"#网络架构-CNN-py文件\" class=\"headerlink\" title=\"网络架构:CNN.py文件:\"></a>网络架构:<strong>CNN.py文件:</strong></h5><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span>  torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">CNN</span><span class=\"params\">(nn.Module)</span>:</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">\t\tsuper(CNN, self).__init__()                                      <span class=\"comment\"># 输入MNIST 图片大小是(1,28,28)</span></span><br><span class=\"line\">\t\tself.layer=nn.Sequential(nn.Conv2d(<span class=\"number\">1</span>,<span class=\"number\">8</span>,kernel_size=<span class=\"number\">5</span>,padding=<span class=\"number\">2</span>),<span class=\"comment\">#第一个参数,输入是1,表示输入图片通道为1 ,8表示输出,5卷积核大小,2补边大小</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t nn.BatchNorm2d(<span class=\"number\">8</span>),<span class=\"comment\">#归一化</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t nn.ReLU(),<span class=\"comment\">#激活层</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t nn.MaxPool2d(<span class=\"number\">2</span>),<span class=\"comment\">#池化层 到这 (8,28,28)图片就被池化成(8,14,14)了</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t )</span><br><span class=\"line\">\t\tself.fc=nn.Linear(<span class=\"number\">14</span>*<span class=\"number\">14</span>*<span class=\"number\">8</span>,<span class=\"number\">10</span>)  <span class=\"comment\">#全连接层 第一个输入的特征数,第二个 输出的特征 (0-9) 共10特征</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">#前向传播\t</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></span><br><span class=\"line\">\t\tout=self.layer(x)</span><br><span class=\"line\">\t\tout=out.view(out.size(<span class=\"number\">0</span>),<span class=\"number\">-1</span>)<span class=\"comment\">#展平多维的卷积图成 (batch_size, 32 * 7 * 7)</span></span><br><span class=\"line\">\t\tout=self.fc(out)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> out</span><br></pre></td></tr></table></figure>\n<p><strong>训练架构:train.py文件</strong><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#pytorch</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span>  torchvision.datasets <span class=\"keyword\">as</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">import</span>  torchvision.transforms <span class=\"keyword\">as</span>  transforms</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#工具包</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> argparse</span><br><span class=\"line\"><span class=\"comment\">#载入网络</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> CNN <span class=\"keyword\">import</span> CNN</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############参数设置#############</span></span><br><span class=\"line\"><span class=\"comment\">####命令行设置########</span></span><br><span class=\"line\">parser = argparse.ArgumentParser(description=<span class=\"string\">'CNN'</span>) <span class=\"comment\">#导入命令行模块</span></span><br><span class=\"line\"><span class=\"comment\">#对于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明</span></span><br><span class=\"line\">parser.add_argument(<span class=\"string\">'--batch-size'</span>, type=int, default=<span class=\"number\">64</span>, metavar=<span class=\"string\">'N'</span>,</span><br><span class=\"line\">                    help=<span class=\"string\">'训练batch-size大小 (default: 64)'</span>)</span><br><span class=\"line\">parser.add_argument(<span class=\"string\">'--epochs'</span>, type=int, default=<span class=\"number\">10</span>, metavar=<span class=\"string\">'N'</span>,</span><br><span class=\"line\">                    help=<span class=\"string\">'训练epochs大小 (default: 10)'</span>)</span><br><span class=\"line\">parser.add_argument(<span class=\"string\">'--lr'</span>, type=float, default=<span class=\"number\">0.001</span>, metavar=<span class=\"string\">'LR'</span>,</span><br><span class=\"line\">                    help=<span class=\"string\">'学习率 (default: 0.001)'</span>)</span><br><span class=\"line\">parser.add_argument(<span class=\"string\">'--no-cuda'</span>, action=<span class=\"string\">'store_true'</span>, default=<span class=\"literal\">False</span>,</span><br><span class=\"line\">                    help=<span class=\"string\">'不开启cuda训练'</span>)</span><br><span class=\"line\">parser.add_argument(<span class=\"string\">'--seed'</span>, type=int, default=<span class=\"number\">1</span>, metavar=<span class=\"string\">'S'</span>,</span><br><span class=\"line\">                    help=<span class=\"string\">'随机种子 (default: 1)'</span>)</span><br><span class=\"line\">parser.add_argument(<span class=\"string\">'--log-interval'</span>, type=int, default=<span class=\"number\">50</span>, metavar=<span class=\"string\">'N'</span>,</span><br><span class=\"line\">                    help=<span class=\"string\">'记录等待n批次 (default: 50)'</span>)</span><br><span class=\"line\">args = parser.parse_args()<span class=\"comment\">#相当于激活命令</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">args.cuda = <span class=\"keyword\">not</span> args.no_cuda <span class=\"keyword\">and</span> torch.cuda.is_available()<span class=\"comment\">#判断gpu</span></span><br><span class=\"line\"></span><br><span class=\"line\">torch.manual_seed(args.seed)</span><br><span class=\"line\"><span class=\"keyword\">if</span> args.cuda:</span><br><span class=\"line\">    torch.cuda.manual_seed(args.seed)<span class=\"comment\">#为CPU设置种子用于生成随机数，以使得结果是确定的</span></span><br><span class=\"line\">    </span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\">###############数据载入################</span></span><br><span class=\"line\">train_dataset=datasets.MNIST(root=<span class=\"string\">\"./data/\"</span>,<span class=\"comment\">#保存目录</span></span><br><span class=\"line\">                             train=<span class=\"literal\">True</span>,  <span class=\"comment\">#选择训练集</span></span><br><span class=\"line\">                             transform=transforms.ToTensor(), <span class=\"comment\">#把数据转换成pytorch张量 Tensor</span></span><br><span class=\"line\">                             download=<span class=\"literal\">True</span>) <span class=\"comment\">#是否下载数据集</span></span><br><span class=\"line\">test_dataset=datasets.MNIST(root=<span class=\"string\">'./data/'</span>,</span><br><span class=\"line\">                            train=<span class=\"literal\">False</span>,<span class=\"comment\">#关闭 表示选择测试集</span></span><br><span class=\"line\">                            transform=transforms.ToTensor(),</span><br><span class=\"line\">                            download=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##############数据装载###############</span></span><br><span class=\"line\">train_loader=torch.utils.data.DataLoader(dataset=train_dataset,<span class=\"comment\">#装载数据</span></span><br><span class=\"line\">                                         batch_size=args.batch_size,<span class=\"comment\">#设置批大小</span></span><br><span class=\"line\">                                         shuffle=<span class=\"literal\">True</span>)<span class=\"comment\">#是否随机打乱</span></span><br><span class=\"line\">test_loader=torch.utils.data.DataLoader(dataset=test_dataset,</span><br><span class=\"line\">                                         batch_size=args.batch_size,</span><br><span class=\"line\">                                         shuffle=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############模型载入#################</span></span><br><span class=\"line\">cnn=CNN()</span><br><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"keyword\">not</span> args.no_cuda:</span><br><span class=\"line\">    print(<span class=\"string\">'正在使用gpu'</span>)</span><br><span class=\"line\">    cnn.cuda()</span><br><span class=\"line\">print(cnn)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###############损失函数##################</span></span><br><span class=\"line\">criterion=nn.CrossEntropyLoss()<span class=\"comment\">#内置标准损失</span></span><br><span class=\"line\">optimizer=torch.optim.Adam(cnn.parameters(),lr=args.lr)<span class=\"comment\">#Adam优化器</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############训练过程#####################</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range (args.epochs):</span><br><span class=\"line\">    <span class=\"keyword\">for</span> i, (images,labels) <span class=\"keyword\">in</span> enumerate(train_loader):<span class=\"comment\">#枚举出来</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> <span class=\"keyword\">not</span>  args.no_cuda:<span class=\"comment\">#数据处理是否用gpu</span></span><br><span class=\"line\">            images=images.cuda()</span><br><span class=\"line\">            labels=labels.cuda()</span><br><span class=\"line\">        </span><br><span class=\"line\">        </span><br><span class=\"line\">        images=Variable(images)<span class=\"comment\">#装箱</span></span><br><span class=\"line\">        labels=Variable(labels)</span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"comment\">##前向传播</span></span><br><span class=\"line\">        optimizer.zero_grad()</span><br><span class=\"line\">        outputs=cnn(images)</span><br><span class=\"line\">        <span class=\"comment\">#损失</span></span><br><span class=\"line\">        loss=criterion(outputs,labels)</span><br><span class=\"line\">        <span class=\"comment\">#反向传播</span></span><br><span class=\"line\">        loss.backward()</span><br><span class=\"line\">        optimizer.step ()</span><br><span class=\"line\">        <span class=\"comment\">##打印记录</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        <span class=\"keyword\">if</span> (i+<span class=\"number\">1</span>)% args.log_interval==<span class=\"number\">0</span>:</span><br><span class=\"line\">            print(<span class=\"string\">'Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'</span></span><br><span class=\"line\">                   %(epoch+<span class=\"number\">1</span>, args.epochs, i+<span class=\"number\">1</span>, len(train_dataset)//args.batch_size, loss.item()))</span><br><span class=\"line\">            </span><br><span class=\"line\">            </span><br><span class=\"line\">        <span class=\"comment\">#保存模型</span></span><br><span class=\"line\">        torch.save(cnn.state_dict(), <span class=\"string\">'cnn.pkl'</span>)</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>注:</li>\n<li>数据集下载不下来,修改pytorch里面MNIST.py文件</li>\n<li>效果如图:</li>\n<li><img src=\"https://blog.mviai.com/images/回顾-CNN/20181218125050651.png\" alt></li>\n</ul>\n"},{"title":"回顾-BEGAN","date":"2018-12-25T19:38:57.000Z","_content":"","source":"_posts/回顾-BEGAN.md","raw":"---\ntitle: 回顾-BEGAN\ndate: 2018-12-26 03:38:57\ntags:\n    - BEGAN\ncategories: \n    - 框架\n    - pytorch\n    - GAN\n\n---\n","slug":"回顾-BEGAN","published":1,"updated":"2021-07-26T09:58:02.575Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m1v0018igtas9rtb31x","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"回顾-DiscoGAN","date":"2018-12-27T19:38:57.000Z","_content":"","source":"_posts/回顾-DiscoGAN.md","raw":"---\ntitle: 回顾-DiscoGAN\ndate: 2018-12-28 03:38:57\ntags:\n    - DiscoGAN\ncategories: \n    - 框架\n    - pytorch\n    - GAN\n---\n","slug":"回顾-DiscoGAN","published":1,"updated":"2021-07-26T09:58:02.577Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m1w001bigtasvyfvjx0","content":"","site":{"data":{}},"excerpt":"","more":""},{"title":"回顾-DCGAN","toc":false,"date":"2018-12-23T19:38:57.000Z","_content":"\n# 1. DCGAN 简介:\n如何把CNN与GAN结合？\nDCGAN是这方面最好的尝试之一，DCGAN的原理和GAN是一样的，这里就不在赘述。\n它只是把经典GAN中的G和D换成了两个卷积神经网络（CNN）。\n但是，并不是直接替换就可以了， DCGAN 对卷积神经网络的结构做了一些改变，以提高样本的质量和收敛的速度。用了哪些方法!我们简单了解下,原文地址:[点我](https://arxiv.org/pdf/1511.06434.pdf)\n*****************\n# 2. 网络结构：\n* 首先看图：\n![](https://blog.mviai.com/images/回顾-DCGAN/DCGAN.png)\n**网络改进点:**\n**<font color=blue>简单解释下:\nGAN 的第一层采用均匀噪声分布Z作为输入,因为它只是一个矩阵乘法操作所以可以称为全连接,但结果被重组为一个4维的张量,并作为卷积叠加（convolution stack）的开始。对于判别网络,最后卷积层是平滑的然后送入单个sigmoid输出。</font>**\n\n    * 1.使用步幅卷积替代确定性空间池化函数(比如最大池化)，允许网络学习自身的空间下采样的方法应用在生成网络当中，在判别网络中允许它学习自己的空间上采样。\n    * 2.在卷积层的中间地带直接分别连接到生成网络的输入和判别网络的输出系统也可以很好的工作。\n        * 其次一个趋势是在最顶层的卷积后面去除全连接层特点。<font color=red>发现全局平均池化虽然增加了模型的稳定性但却影响了收敛速度。</font>\n    * 3.最后是批量规范化:通过将输入的每个单元标准化为0均值与单位方差来稳定学习。<font color=red>有助于处理初始化不良导致的训练问题另外还有助于梯度流向更深的网络。</font>\n        * <font color=red>不要批量规范化（batchnorm）将应用到生成网络的输出层和判别网络输入层可以避免直接对所有的层采取批量归一化,导致采样的振荡和模型的不稳定问题</font>\n    * 4.使用有界激活可以让模型更快学习达到饱和并覆盖训练分布的颜色空间。在判别器中,发现LeakyReLU激活函数能够很好地工作,特别是对于更高分辨率的模型。\n\n**总结:**\n![](https://blog.mviai.com/images/回顾-DCGAN/work.png)\n\n***************\n\n### 训练细节上的改进:\n\n\n* 1.训练图像除了缩放到tanh激活函数的[-1,1]范围之外,没有经过其他的预处理。\n* 2.所有的模型都是通过小批量随机梯度下降法进行训练的(小批量的大小是 128)\n* 3.所有权重的初始化为均值为 0 和方差为 0.02的正态分布。\n* 4.在LeakyReLU, 所有模型的leak的斜率设置为0.2。\n* 5.DCGAN是使用Adam优化程序调整超参数。建议使用的学习率是0.001，太高的话使用0.0002代替。\n* 6.优化器参数beta1，在建议的0.9训练动荡且不稳定，但降低到0.5是有利于模型的稳定。\n\n# 3. pytorch 实现:\n** network.py**\n```python\n'''\n跟着图走\n\n'''\nimport torch.nn as nn\n\n#我们首先建立G\nclass G(nn.Module):\n    def __init__(self,args):\n        super(G,self).__init__()\n        ngf = args.ngf  #ndf 设置为128  卷积一般扩大两倍 参数为4,2,1\n        self.G_layer= nn.Sequential(\n            # 输入的相当于nz*1*1\n            nn.ConvTranspose2d (args.nz, ngf * 8, 4, 1, 0, bias=False),\n            nn.BatchNorm2d (ngf * 8),\n            nn.ReLU (True),\n            # (ngf*8) x 4 x 4\n            nn.ConvTranspose2d (ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d (ngf * 4),\n            nn.ReLU (True),\n            # (ngf*4) x 8 x 8\n            nn.ConvTranspose2d (ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d (ngf * 2),\n            nn.ReLU (True),\n            # (ngf*2) x 16 x 16\n            nn.ConvTranspose2d (ngf * 2, ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d (ngf),\n            nn.ReLU (True),\n            # (ngf) x 32 x 32\n            nn.ConvTranspose2d (ngf, 3, 4, 2, 1, bias=False),\n            nn.Tanh ())\n            # 3 x 64 x 64\n        \n        \n        \n    #前向传播\n    def forward(self,x):\n        out=self.G_layer(x)\n        return out\n\n#建立D\nclass D(nn.Module):\n    def __init__(self,args):\n        super(D,self).__init__()\n        ndf = args.ndf  # ndf 128\n        self.D_layer= nn.Sequential(\n                # 输入 3 x 64 x 64,\n                nn.Conv2d(3,ndf,4,2,1),\n                nn.BatchNorm2d (ndf),\n                nn.LeakyReLU (True),\n                #输出 (ndf)*32*32\n                nn.Conv2d(ndf,ndf*2,4,2,1),\n                nn.BatchNorm2d (ndf*2),\n                nn.LeakyReLU (True),\n                # 输出 (ndf*2)*16*16\n                nn.Conv2d (ndf*2, ndf*4, 4, 2, 1),\n                nn.BatchNorm2d (ndf*4),\n                nn.LeakyReLU (True),\n                # 输出 (ndf*4)*8*8\n                nn.Conv2d (ndf*4, ndf*8, 4, 2, 1),\n                nn.BatchNorm2d (ndf*8),\n                nn.LeakyReLU (True),\n                # 输出 (ndf*8)*4*4\n                nn.Conv2d (ndf * 8, 1, 4, 1, 0),\n                # 输出 1*0*0\n                nn.Sigmoid())#告诉D概率\n                \n    #前向传播\n    def forward(self,x):\n        out=self.D_layer(x)\n        return out\n\n\n```\n\n** train.py **\n```python\nimport torch\nimport torch.nn as nn\nimport torchvision.datasets as datasets\nimport torchvision.transforms as  transforms\nfrom torch.autograd import Variable\nimport torch.backends.cudnn as cudnn\n# 工具包\nimport argparse\n# 载入网络\nfrom network import G, D\n\n#############参数设置#############\n####命令行设置########\nparser = argparse.ArgumentParser (description='GANs')  # 导入命令行模块\n# 对关于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明\n#关于训练参数\nparser.add_argument ('--batch_size', type=int, default=64,\n\t\t\t\t\t help='训练batch-size大小 (default: 64)')\nparser.add_argument ('--imageSize', type=int, default=64,\n\t\t\t\t\t help='图片尺寸')\nparser.add_argument ('--max_epoch', type=int, default=20,\n\t\t\t\t\t help='最大迭代数 (default: 12)')\n#关于网络参数\nparser.add_argument ('--lr_g', type=float, default=2e-4,\n\t\t\t\t\t help='生成器学习率 (default: 2e-4)')\nparser.add_argument ('--lr_d', type=float, default=2e-4,\n\t\t\t\t\t help='判别器学习率 (default: 2e-4)')\nparser.add_argument ('--ngf', type=int, default=128,\n\t\t\t\t\t help='生成器feature map数')\nparser.add_argument ('--ndf', type=int, default=128,\n\t\t\t\t\t help='判别器feature map数')\nparser.add_argument ('--d_every', type=int, default=1,\n\t\t\t\t\t help='每几个batch训练一次判别器')\nparser.add_argument ('--g_every', type=int, default=4,\n\t\t\t\t\t help='每几个batch训练一次生成器')\nparser.add_argument ('--nz', type=int, default=100,\n\t\t\t\t\t help='噪声维度')\n\n#关于优化器参数\nparser.add_argument ('--beta1', type=int, default=0.5,\n\t\t\t\t\t help='Adam优化器的beta1参数')\n#路径\nparser.add_argument ('--dataset', default='data/',\n\t\t\t\t\t help='数据集路径')\n\nparser.add_argument ('--save_data',  default='save/',\n\t\t\t\t\t help='保存路径')\n\n#可视化\nparser.add_argument ('--vis', action='store_true',\n\t\t\t\t\t help='使用visdom可视化')\nparser.add_argument ('--plot_every', type=int, default=1,\n\t\t\t\t\t help='每间隔_batch，visdom画图一次')\n# 其他\n\nparser.add_argument ('--cuda', action='store_true',\n\t\t\t\t\t help='开启cuda训练')\nparser.add_argument ('--plt', action='store_true',\n\t\t\t\t\t help='开启画图')\nparser.add_argument ('--test', action='store_true',\n\t\t\t\t\t help='开启测试生成')\nparser.add_argument ('--save_every', type=int, default=5,\n\t\t\t\t\t help='几个epoch保存一次模型 (default: 2)')\nparser.add_argument ('--seed', type=int, default=1,\n\t\t\t\t\t help='随机种子 (default: 1)')\nargs = parser.parse_args ()  # 相当于激活命令\n\n\n#训练过程\ndef train():\n\t###############判断gpu#############\n\tdevice = torch.device ('cuda') if args.cuda else torch.device ('cpu')\n\t\n\t####### 为CPU设置种子用于生成随机数，以使得结果是确定的##########\n\ttorch.manual_seed (args.seed)\n\tif args.cuda:\n\t\ttorch.cuda.manual_seed (args.seed)\n\tcudnn.benchmark = True\n\t\n\t#################可视化###############\n\tif args.vis:\n\t\tvis = Visualizer ('GANs')\n\t##########数据转换#####################\n\tdata_transforms = transforms.Compose ([transforms.Scale (args.imageSize),  # 通过调整比例调整大小,会报警\n\t\t\t\t\t\t\t\t\t\t   transforms.CenterCrop (args.imageSize),  # 在中心裁剪给指定大小方形PIL图像\n\t\t\t\t\t\t\t\t\t\t   transforms.ToTensor (),# 转换成pytorch 变量tensor\n\t\t\t\t\t\t\t\t\t\t   transforms.Normalize ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\t###############数据载入################\n\t# train_dataset = datasets.ImageFolder (root=args.dataset,  # 数据路径目录\n\t# \t\t\t\t\t\t\t\t\t  transform=data_transforms)  # 把数据转换成上面约束样子\n\t\n\ttrain_dataset = datasets.CIFAR10(root=args.dataset,\n\t\t\t\t\t\t\t\t\t train=True,\n\t\t\t\t\t\t\t\t\t transform=data_transforms,\n\t\t\t\t\t\t\t\t\t download=False)\n\t# test_dataset = datasets.ImageFolder (root=args.dataset,\n\t# \t\t\t\t\t\t\t\t\t transform=data_transforms)\n\t\n\t##############数据装载###############\n\ttrain_loader = torch.utils.data.DataLoader (dataset=train_dataset,  # 装载数据\n\t\t\t\t\t\t\t\t\t\t\t\tbatch_size=args.batch_size,  # 设置批大小\n\t\t\t\t\t\t\t\t\t\t\t\tshuffle=True)  # 是否随机打乱\n\t# test_loader = torch.utils.data.DataLoader (dataset=test_dataset,\n\t# \t\t\t\t\t\t\t\t\t\t   batch_size=args.batch_size,\n\t# \t\t\t\t\t\t\t\t\t\t   shuffle=True)\n\t\n\t#############模型载入#################\n\tnetG ,netD= G (args),D (args)\n\tnetG.to (device)\n\tnetD.to (device)\n\tprint (netD, netG)\n\t\n\t###############损失函数##################\n\tcriterion = torch.nn.BCELoss ().to (device)\n\toptimizerD = torch.optim.Adam (netD.parameters (), lr=args.lr_d,betas=(0.5, 0.999))  # Adam优化器\n\toptimizerG = torch.optim.Adam (netG.parameters (), lr=args.lr_g,betas=(0.5, 0.999))  # Adam优化器\n\t###############画图参数保存##################\n\tG_losses = []\n\tD_losses = []\n\timg_list = []\n\t#############训练过程#####################\n\timport tqdm\n\t# Tqdm是一个快速，可扩展的Python进度条，可以在Python\n\t# 长循环中添加一个进度提示信息，用户只需要封装任意的迭代器\n\t# tqdm (iterator)。\n\tfor epoch in range (args.max_epoch):\n\t\tfor i, (images, labels) in tqdm.tqdm(enumerate (train_loader)):  # 枚举出来\n\t\t\t#数据处理\n\t\t\timages = images.to (device)\n\t\t\t# 装箱\n\t\t\timages = Variable (images)\n\t\t\tnoises=Variable(torch.randn(images.size(0), args.nz, 1, 1).to(device))\n\t\t\t\n\t\t\t#遍历每张图片,并且根据指定的训练机制训练\n\t\t\tif i % args.d_every==0:#满足此条件训练D\n\t\t\t\t#D前向传播\n\t\t\t\toptimizerD.zero_grad ()\n\t\t\t\t#D网络输出\n\t\t\t\toutput_r = netD (images).view(-1)\n\t\t\t\t#定义真张量\n\t\t\t\t#返回第一个参数为大小 第二参数为值 的张量\n\t\t\t\ttrue_label = torch.full ((images.size(0),), 1, device=device)\n\t\t\t\t#判别真的损失\n\t\t\t\td_real_loss = criterion(output_r, true_label)\n\t\t\t\t#反向传播\n\t\t\t\td_real_loss.backward()\n\t\t\t\t#G网络输出\n\t\t\t\tnoises.data.copy_ (torch.randn (images.size(0), args.nz, 1, 1))\n\t\t\t\tfake = netG (noises).detach ()  # 根据噪声生成假图\n\t\t\t\t#把假图给d\n\t\t\t\toutput_f = netD (fake).view(-1)\n\t\t\t\t#d假的损失\n\t\t\t\t#print(fake.size(),output_f.size(),output_r.size())\n\t\t\t\t# 返回第一个参数为大小 第二参数为值 的张量\n\t\t\t\tfake_label = torch.full ((images.size (0),), 0, device=device)\n\t\t\t\td_fake_loss= criterion(output_f,fake_label)\n\t\t\t\t#D假反向传播\n\t\t\t\td_fake_loss.backward ()\n\t\t\t\t# 总损失\n\t\t\t\tD_loss=d_fake_loss+d_real_loss\n\t\t\t\t#D更新参数\n\t\t\t\toptimizerD.step ()\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t# 度量\n\t\t\t\tD_x = output_r.mean ().item ()\n\t\t\t\tD_G_z1 = output_f.mean ().item ()\n\t\t\t\n\t\t\tif i % args.g_every==0:#满足此条件训练G\n\t\t\t\t#G前向传播\n\t\t\t\toptimizerG.zero_grad ()\n\t\t\t\t#G网络输出\n\t\t\t\tfake = netG (noises)  # 根据噪声生成假图\n\t\t\t\t#把假图给G\n\t\t\t\toutput_f = netD (fake).view(-1)\n\t\t\t\t#G的损失\n\t\t\t\ttrue_label = torch.full ((images.size (0),), 1, device=device)\n\t\t\t\tG_loss = criterion(output_f,true_label)\n\t\t\t\t#G反向传播\n\t\t\t\tG_loss.backward ()\n\t\t\t\t#度量\n\t\t\t\tD_G_z2 = output_f.mean ().item ()\n\t\t\t\t#D更新参数\n\t\t\t\toptimizerG.step ()\n\t\t\t\t\n\t\t\t###########################################\n\t\t\t##########可视化(可选)#####################\n\t\t\tif args.vis and i % args.plot_every == args.plot_every - 1:\n\t\t\t\tfake = netG (noises)\n\t\t\t\tvis.images (fake.detach ().cpu ().numpy () [:64] * 0.5 + 0.5, win='fixfake')\n\t\t\t\tvis.images (images.data.cpu ().numpy () [:64] * 0.5 + 0.5, win='real')\n\t\t\t\tvis.plot ('errord', D_loss.item ())\n\t\t\t\tvis.plot ('errorg', G_loss.item ())\n\t\t\t#######################################\n\t\t\t############打印记录###################\n\t\t\tif i % 1== 0:\n\t\t\t\tprint ('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n\t\t\t\t\t   % (epoch, args.max_epoch, i, len (train_loader),\n\t\t\t\t\t\t  D_loss.item (), G_loss.item (), D_x, D_G_z1, D_G_z2))\n\t\t\t\t########添加画图参数########\n\t\t\t\tG_losses.append (G_loss.item ())\n\t\t\t\tD_losses.append (D_loss.item ())\n\t\t\t\twith torch.no_grad ():\n\t\t\t\t\tnoises = torch.randn (args.batch_size, args.nz, 1, 1).to (device)\n\t\t\t\t\tfake = netG (noises).detach ().cpu ()\n\t\t\t\timport torchvision.utils as vutils\n\t\t\t\timg_list.append (vutils.make_grid (fake, padding=2, normalize=True))\n\t\n\n\n\t\t#######################################\n\t\t############保存模型###################\n\t\n\t\tif (epoch + 1) % args.save_every == 0:\n\t\t\timport torchvision as tv\n\t\t\t# 保存模型、图片\n\t\t\ttv.utils.save_image (fake.data [:64], '%s/%s.png' % (args.save_data, epoch), normalize=True,range=(-1, 1))\n\t\t\ttorch.save (netD.state_dict (), 'checkpoints/netd_%s.pth' % epoch)\n\t\t\ttorch.save (netG.state_dict (), 'checkpoints/netg_%s.pth' % epoch)\n\t\t\tprint('完成%s的模型保存'%epoch)\n\n\t#######################################\n\t############画图###################\n\t\n\tif args.plt:\n\t\timport matplotlib.pyplot as plt\n\t\timport numpy as np\n\t\timport torchvision.utils as vutils\n\t\t\n\t\tplt.figure (figsize=(10, 5))\n\t\tplt.title (\"GAN\")\n\t\tplt.plot (G_losses, label=\"G\")\n\t\tplt.plot (D_losses, label=\"D\")\n\t\tplt.xlabel (\"迭代次数\",fontproperties='SimHei')\n\t\tplt.ylabel (\"损失\",fontproperties='SimHei')\n\t\tplt.legend ()\n\t\tplt.show ()\n\t\t\n\t\t# 从数据集加载\n\t\treal_batch = next (iter (train_dataset))\n\t\t\n\t\t# 画出真图\n\t\tplt.figure (figsize=(15, 10))\n\t\tplt.subplot (1, 2, 1)\n\t\tplt.axis (\"off\")\n\t\tplt.title (\"真图\",fontproperties='SimHei')\n\t\tplt.imshow (np.transpose (\n\t\t\tvutils.make_grid (real_batch [0].to (device) [:64], padding=5, normalize=True).cpu (),\n\t\t\t(1, 2, 0)))\n\t\t\n\t\t# 画出假图\n\t\tplt.subplot (1, 2, 2)\n\t\tplt.axis (\"off\")\n\t\tplt.title (\"假图\",fontproperties='SimHei')\n\t\tplt.imshow (np.transpose (img_list [-1], (1, 2, 0)))\n\t\tplt.show ()\n\t\t\t\t\n\n\t\t\n\n\t\t\n\n@torch.no_grad()#禁用梯度计算\ndef test():\n\t#判断Gpu\n\tdevice = torch.device ('cuda') if args.cuda else torch.device ('cpu')\n\t#初始化网络\n\tnetg, netd = netG (args).eval (), netD (args).eval ()\n\t#定义噪声\n\tnoises = torch.randn (args.batch_size, args.nz, 1, 1).to (device)\n\t#载入网络\n\tnetd.load_state_dict (torch.load ('checkpoints/netd_%s.pth'%args.max_epoch))\n\tnetg.load_state_dict (torch.load ('checkpoints/netg_%s.pth'%args.max_epoch))\n\t#设备化\n\tnetd.to (device)\n\tnetg.to (device)\n\t# 生成图片，并计算图片在判别器的分数\n\tfake_img = netg (noises)\n\tscores = netd (fake_img).detach ()\n\t\n\t# 挑选最好的某几张\n\tindexs = scores.topk (5) [1]\n\tresult = []\n\tfor i in indexs:\n\t\tresult.append (fake_img.data [i])\n\t\n\t# 保存图片\n\timport torchvision as tv\n\ttv.utils.save_image (torch.stack (result), 5, normalize=True, range=(-1, 1))\n\n\n\n\n\n\n\n\n\n\n\n\t\n\t###################可视化类##################################\nimport visdom\nimport time\nimport torchvision as tv\nimport numpy as np\n\n\nclass Visualizer ():\n\t\"\"\"\n\t封装了visdom的基本操作，但是你仍然可以通过`self.vis.function`\n\t调用原生的visdom接口\n\t\"\"\"\n\t\n\tdef __init__ (self, env='default', **kwargs):\n\t\timport visdom\n\t\tself.vis = visdom.Visdom (env=env, use_incoming_socket=False, **kwargs)\n\t\t\n\t\t# 画的第几个数，相当于横座标\n\t\t# 保存（’loss',23） 即loss的第23个点\n\t\tself.index = {}\n\t\tself.log_text = ''\n\t\n\tdef reinit (self, env='default', **kwargs):\n\t\t\"\"\"\n\t\t修改visdom的配置\n\t\t\"\"\"\n\t\tself.vis = visdom.Visdom (env=env, use_incoming_socket=False, **kwargs)\n\t\treturn self\n\t\n\tdef plot_many (self, d):\n\t\t\"\"\"\n\t\t一次plot多个\n\t\t@params d: dict (name,value) i.e. ('loss',0.11)\n\t\t\"\"\"\n\t\tfor k, v in d.items ():\n\t\t\tself.plot (k, v)\n\t\n\tdef img_many (self, d):\n\t\tfor k, v in d.items ():\n\t\t\tself.img (k, v)\n\t\n\tdef plot (self, name, y):\n\t\t\"\"\"\n\t\tself.plot('loss',1.00)\n\t\t\"\"\"\n\t\tx = self.index.get (name, 0)\n\t\tself.vis.line (Y=np.array ([y]), X=np.array ([x]),\n\t\t\t\t\t   win=(name),\n\t\t\t\t\t   opts=dict (title=name),\n\t\t\t\t\t   update=None if x == 0 else 'append'\n\t\t\t\t\t   )\n\t\tself.index [name] = x + 1\n\t\n\tdef img (self, name, img_):\n\t\t\"\"\"\n\t\tself.img('input_img',t.Tensor(64,64))\n\t\t\"\"\"\n\t\t\n\t\tif len (img_.size ()) < 3:\n\t\t\timg_ = img_.cpu ().unsqueeze (0)\n\t\tself.vis.image (img_.cpu (),\n\t\t\t\t\t\twin=(name),\n\t\t\t\t\t\topts=dict (title=name)\n\t\t\t\t\t\t)\n\t\n\tdef img_grid_many (self, d):\n\t\tfor k, v in d.items ():\n\t\t\tself.img_grid (k, v)\n\t\n\tdef img_grid (self, name, input_3d):\n\t\t\"\"\"\n\t\t一个batch的图片转成一个网格图，i.e. input（36，64，64）\n\t\t会变成 6*6 的网格图，每个格子大小64*64\n\t\t\"\"\"\n\t\tself.img (name, tv.utils.make_grid (\n\t\t\tinput_3d.cpu () [0].unsqueeze (1).clamp (max=1, min=0)))\n\t\n\tdef log (self, info, win='log_text'):\n\t\t\"\"\"\n\t\tself.log({'loss':1,'lr':0.0001})\n\t\t\"\"\"\n\t\t\n\t\tself.log_text += ('[{time}] {info} <br>'.format (\n\t\t\ttime=time.strftime ('%m%d_%H%M%S'),\n\t\t\tinfo=info))\n\t\tself.vis.text (self.log_text, win=win)\n\t\n\tdef __getattr__ (self, name):\n\t\treturn getattr (self.vis, name)\n\t\n\t\n\t\nif __name__ == '__main__':\n\tif args.test:\n\t\ttest()\n\telse:\n\t\ttrain()\n```\n\n* 注 :数据集用的cifar-10-batches-py\n* 结果:\n* 迭代一次\n![](https://blog.mviai.com/images/回顾-DCGAN/0.png)\n* 迭代二次\n![](https://blog.mviai.com/images/回顾-DCGAN/1.png)","source":"_posts/回顾-DCGAN.md","raw":"---\ntitle: 回顾-DCGAN\ntags:\n  - DCGAN\ncategories:\n  - 框架\n  - pytorch\n  - GAN\ntoc: false\ndate: 2018-12-24 03:38:57\n---\n\n# 1. DCGAN 简介:\n如何把CNN与GAN结合？\nDCGAN是这方面最好的尝试之一，DCGAN的原理和GAN是一样的，这里就不在赘述。\n它只是把经典GAN中的G和D换成了两个卷积神经网络（CNN）。\n但是，并不是直接替换就可以了， DCGAN 对卷积神经网络的结构做了一些改变，以提高样本的质量和收敛的速度。用了哪些方法!我们简单了解下,原文地址:[点我](https://arxiv.org/pdf/1511.06434.pdf)\n*****************\n# 2. 网络结构：\n* 首先看图：\n![](https://blog.mviai.com/images/回顾-DCGAN/DCGAN.png)\n**网络改进点:**\n**<font color=blue>简单解释下:\nGAN 的第一层采用均匀噪声分布Z作为输入,因为它只是一个矩阵乘法操作所以可以称为全连接,但结果被重组为一个4维的张量,并作为卷积叠加（convolution stack）的开始。对于判别网络,最后卷积层是平滑的然后送入单个sigmoid输出。</font>**\n\n    * 1.使用步幅卷积替代确定性空间池化函数(比如最大池化)，允许网络学习自身的空间下采样的方法应用在生成网络当中，在判别网络中允许它学习自己的空间上采样。\n    * 2.在卷积层的中间地带直接分别连接到生成网络的输入和判别网络的输出系统也可以很好的工作。\n        * 其次一个趋势是在最顶层的卷积后面去除全连接层特点。<font color=red>发现全局平均池化虽然增加了模型的稳定性但却影响了收敛速度。</font>\n    * 3.最后是批量规范化:通过将输入的每个单元标准化为0均值与单位方差来稳定学习。<font color=red>有助于处理初始化不良导致的训练问题另外还有助于梯度流向更深的网络。</font>\n        * <font color=red>不要批量规范化（batchnorm）将应用到生成网络的输出层和判别网络输入层可以避免直接对所有的层采取批量归一化,导致采样的振荡和模型的不稳定问题</font>\n    * 4.使用有界激活可以让模型更快学习达到饱和并覆盖训练分布的颜色空间。在判别器中,发现LeakyReLU激活函数能够很好地工作,特别是对于更高分辨率的模型。\n\n**总结:**\n![](https://blog.mviai.com/images/回顾-DCGAN/work.png)\n\n***************\n\n### 训练细节上的改进:\n\n\n* 1.训练图像除了缩放到tanh激活函数的[-1,1]范围之外,没有经过其他的预处理。\n* 2.所有的模型都是通过小批量随机梯度下降法进行训练的(小批量的大小是 128)\n* 3.所有权重的初始化为均值为 0 和方差为 0.02的正态分布。\n* 4.在LeakyReLU, 所有模型的leak的斜率设置为0.2。\n* 5.DCGAN是使用Adam优化程序调整超参数。建议使用的学习率是0.001，太高的话使用0.0002代替。\n* 6.优化器参数beta1，在建议的0.9训练动荡且不稳定，但降低到0.5是有利于模型的稳定。\n\n# 3. pytorch 实现:\n** network.py**\n```python\n'''\n跟着图走\n\n'''\nimport torch.nn as nn\n\n#我们首先建立G\nclass G(nn.Module):\n    def __init__(self,args):\n        super(G,self).__init__()\n        ngf = args.ngf  #ndf 设置为128  卷积一般扩大两倍 参数为4,2,1\n        self.G_layer= nn.Sequential(\n            # 输入的相当于nz*1*1\n            nn.ConvTranspose2d (args.nz, ngf * 8, 4, 1, 0, bias=False),\n            nn.BatchNorm2d (ngf * 8),\n            nn.ReLU (True),\n            # (ngf*8) x 4 x 4\n            nn.ConvTranspose2d (ngf * 8, ngf * 4, 4, 2, 1, bias=False),\n            nn.BatchNorm2d (ngf * 4),\n            nn.ReLU (True),\n            # (ngf*4) x 8 x 8\n            nn.ConvTranspose2d (ngf * 4, ngf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d (ngf * 2),\n            nn.ReLU (True),\n            # (ngf*2) x 16 x 16\n            nn.ConvTranspose2d (ngf * 2, ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d (ngf),\n            nn.ReLU (True),\n            # (ngf) x 32 x 32\n            nn.ConvTranspose2d (ngf, 3, 4, 2, 1, bias=False),\n            nn.Tanh ())\n            # 3 x 64 x 64\n        \n        \n        \n    #前向传播\n    def forward(self,x):\n        out=self.G_layer(x)\n        return out\n\n#建立D\nclass D(nn.Module):\n    def __init__(self,args):\n        super(D,self).__init__()\n        ndf = args.ndf  # ndf 128\n        self.D_layer= nn.Sequential(\n                # 输入 3 x 64 x 64,\n                nn.Conv2d(3,ndf,4,2,1),\n                nn.BatchNorm2d (ndf),\n                nn.LeakyReLU (True),\n                #输出 (ndf)*32*32\n                nn.Conv2d(ndf,ndf*2,4,2,1),\n                nn.BatchNorm2d (ndf*2),\n                nn.LeakyReLU (True),\n                # 输出 (ndf*2)*16*16\n                nn.Conv2d (ndf*2, ndf*4, 4, 2, 1),\n                nn.BatchNorm2d (ndf*4),\n                nn.LeakyReLU (True),\n                # 输出 (ndf*4)*8*8\n                nn.Conv2d (ndf*4, ndf*8, 4, 2, 1),\n                nn.BatchNorm2d (ndf*8),\n                nn.LeakyReLU (True),\n                # 输出 (ndf*8)*4*4\n                nn.Conv2d (ndf * 8, 1, 4, 1, 0),\n                # 输出 1*0*0\n                nn.Sigmoid())#告诉D概率\n                \n    #前向传播\n    def forward(self,x):\n        out=self.D_layer(x)\n        return out\n\n\n```\n\n** train.py **\n```python\nimport torch\nimport torch.nn as nn\nimport torchvision.datasets as datasets\nimport torchvision.transforms as  transforms\nfrom torch.autograd import Variable\nimport torch.backends.cudnn as cudnn\n# 工具包\nimport argparse\n# 载入网络\nfrom network import G, D\n\n#############参数设置#############\n####命令行设置########\nparser = argparse.ArgumentParser (description='GANs')  # 导入命令行模块\n# 对关于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明\n#关于训练参数\nparser.add_argument ('--batch_size', type=int, default=64,\n\t\t\t\t\t help='训练batch-size大小 (default: 64)')\nparser.add_argument ('--imageSize', type=int, default=64,\n\t\t\t\t\t help='图片尺寸')\nparser.add_argument ('--max_epoch', type=int, default=20,\n\t\t\t\t\t help='最大迭代数 (default: 12)')\n#关于网络参数\nparser.add_argument ('--lr_g', type=float, default=2e-4,\n\t\t\t\t\t help='生成器学习率 (default: 2e-4)')\nparser.add_argument ('--lr_d', type=float, default=2e-4,\n\t\t\t\t\t help='判别器学习率 (default: 2e-4)')\nparser.add_argument ('--ngf', type=int, default=128,\n\t\t\t\t\t help='生成器feature map数')\nparser.add_argument ('--ndf', type=int, default=128,\n\t\t\t\t\t help='判别器feature map数')\nparser.add_argument ('--d_every', type=int, default=1,\n\t\t\t\t\t help='每几个batch训练一次判别器')\nparser.add_argument ('--g_every', type=int, default=4,\n\t\t\t\t\t help='每几个batch训练一次生成器')\nparser.add_argument ('--nz', type=int, default=100,\n\t\t\t\t\t help='噪声维度')\n\n#关于优化器参数\nparser.add_argument ('--beta1', type=int, default=0.5,\n\t\t\t\t\t help='Adam优化器的beta1参数')\n#路径\nparser.add_argument ('--dataset', default='data/',\n\t\t\t\t\t help='数据集路径')\n\nparser.add_argument ('--save_data',  default='save/',\n\t\t\t\t\t help='保存路径')\n\n#可视化\nparser.add_argument ('--vis', action='store_true',\n\t\t\t\t\t help='使用visdom可视化')\nparser.add_argument ('--plot_every', type=int, default=1,\n\t\t\t\t\t help='每间隔_batch，visdom画图一次')\n# 其他\n\nparser.add_argument ('--cuda', action='store_true',\n\t\t\t\t\t help='开启cuda训练')\nparser.add_argument ('--plt', action='store_true',\n\t\t\t\t\t help='开启画图')\nparser.add_argument ('--test', action='store_true',\n\t\t\t\t\t help='开启测试生成')\nparser.add_argument ('--save_every', type=int, default=5,\n\t\t\t\t\t help='几个epoch保存一次模型 (default: 2)')\nparser.add_argument ('--seed', type=int, default=1,\n\t\t\t\t\t help='随机种子 (default: 1)')\nargs = parser.parse_args ()  # 相当于激活命令\n\n\n#训练过程\ndef train():\n\t###############判断gpu#############\n\tdevice = torch.device ('cuda') if args.cuda else torch.device ('cpu')\n\t\n\t####### 为CPU设置种子用于生成随机数，以使得结果是确定的##########\n\ttorch.manual_seed (args.seed)\n\tif args.cuda:\n\t\ttorch.cuda.manual_seed (args.seed)\n\tcudnn.benchmark = True\n\t\n\t#################可视化###############\n\tif args.vis:\n\t\tvis = Visualizer ('GANs')\n\t##########数据转换#####################\n\tdata_transforms = transforms.Compose ([transforms.Scale (args.imageSize),  # 通过调整比例调整大小,会报警\n\t\t\t\t\t\t\t\t\t\t   transforms.CenterCrop (args.imageSize),  # 在中心裁剪给指定大小方形PIL图像\n\t\t\t\t\t\t\t\t\t\t   transforms.ToTensor (),# 转换成pytorch 变量tensor\n\t\t\t\t\t\t\t\t\t\t   transforms.Normalize ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\t###############数据载入################\n\t# train_dataset = datasets.ImageFolder (root=args.dataset,  # 数据路径目录\n\t# \t\t\t\t\t\t\t\t\t  transform=data_transforms)  # 把数据转换成上面约束样子\n\t\n\ttrain_dataset = datasets.CIFAR10(root=args.dataset,\n\t\t\t\t\t\t\t\t\t train=True,\n\t\t\t\t\t\t\t\t\t transform=data_transforms,\n\t\t\t\t\t\t\t\t\t download=False)\n\t# test_dataset = datasets.ImageFolder (root=args.dataset,\n\t# \t\t\t\t\t\t\t\t\t transform=data_transforms)\n\t\n\t##############数据装载###############\n\ttrain_loader = torch.utils.data.DataLoader (dataset=train_dataset,  # 装载数据\n\t\t\t\t\t\t\t\t\t\t\t\tbatch_size=args.batch_size,  # 设置批大小\n\t\t\t\t\t\t\t\t\t\t\t\tshuffle=True)  # 是否随机打乱\n\t# test_loader = torch.utils.data.DataLoader (dataset=test_dataset,\n\t# \t\t\t\t\t\t\t\t\t\t   batch_size=args.batch_size,\n\t# \t\t\t\t\t\t\t\t\t\t   shuffle=True)\n\t\n\t#############模型载入#################\n\tnetG ,netD= G (args),D (args)\n\tnetG.to (device)\n\tnetD.to (device)\n\tprint (netD, netG)\n\t\n\t###############损失函数##################\n\tcriterion = torch.nn.BCELoss ().to (device)\n\toptimizerD = torch.optim.Adam (netD.parameters (), lr=args.lr_d,betas=(0.5, 0.999))  # Adam优化器\n\toptimizerG = torch.optim.Adam (netG.parameters (), lr=args.lr_g,betas=(0.5, 0.999))  # Adam优化器\n\t###############画图参数保存##################\n\tG_losses = []\n\tD_losses = []\n\timg_list = []\n\t#############训练过程#####################\n\timport tqdm\n\t# Tqdm是一个快速，可扩展的Python进度条，可以在Python\n\t# 长循环中添加一个进度提示信息，用户只需要封装任意的迭代器\n\t# tqdm (iterator)。\n\tfor epoch in range (args.max_epoch):\n\t\tfor i, (images, labels) in tqdm.tqdm(enumerate (train_loader)):  # 枚举出来\n\t\t\t#数据处理\n\t\t\timages = images.to (device)\n\t\t\t# 装箱\n\t\t\timages = Variable (images)\n\t\t\tnoises=Variable(torch.randn(images.size(0), args.nz, 1, 1).to(device))\n\t\t\t\n\t\t\t#遍历每张图片,并且根据指定的训练机制训练\n\t\t\tif i % args.d_every==0:#满足此条件训练D\n\t\t\t\t#D前向传播\n\t\t\t\toptimizerD.zero_grad ()\n\t\t\t\t#D网络输出\n\t\t\t\toutput_r = netD (images).view(-1)\n\t\t\t\t#定义真张量\n\t\t\t\t#返回第一个参数为大小 第二参数为值 的张量\n\t\t\t\ttrue_label = torch.full ((images.size(0),), 1, device=device)\n\t\t\t\t#判别真的损失\n\t\t\t\td_real_loss = criterion(output_r, true_label)\n\t\t\t\t#反向传播\n\t\t\t\td_real_loss.backward()\n\t\t\t\t#G网络输出\n\t\t\t\tnoises.data.copy_ (torch.randn (images.size(0), args.nz, 1, 1))\n\t\t\t\tfake = netG (noises).detach ()  # 根据噪声生成假图\n\t\t\t\t#把假图给d\n\t\t\t\toutput_f = netD (fake).view(-1)\n\t\t\t\t#d假的损失\n\t\t\t\t#print(fake.size(),output_f.size(),output_r.size())\n\t\t\t\t# 返回第一个参数为大小 第二参数为值 的张量\n\t\t\t\tfake_label = torch.full ((images.size (0),), 0, device=device)\n\t\t\t\td_fake_loss= criterion(output_f,fake_label)\n\t\t\t\t#D假反向传播\n\t\t\t\td_fake_loss.backward ()\n\t\t\t\t# 总损失\n\t\t\t\tD_loss=d_fake_loss+d_real_loss\n\t\t\t\t#D更新参数\n\t\t\t\toptimizerD.step ()\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t# 度量\n\t\t\t\tD_x = output_r.mean ().item ()\n\t\t\t\tD_G_z1 = output_f.mean ().item ()\n\t\t\t\n\t\t\tif i % args.g_every==0:#满足此条件训练G\n\t\t\t\t#G前向传播\n\t\t\t\toptimizerG.zero_grad ()\n\t\t\t\t#G网络输出\n\t\t\t\tfake = netG (noises)  # 根据噪声生成假图\n\t\t\t\t#把假图给G\n\t\t\t\toutput_f = netD (fake).view(-1)\n\t\t\t\t#G的损失\n\t\t\t\ttrue_label = torch.full ((images.size (0),), 1, device=device)\n\t\t\t\tG_loss = criterion(output_f,true_label)\n\t\t\t\t#G反向传播\n\t\t\t\tG_loss.backward ()\n\t\t\t\t#度量\n\t\t\t\tD_G_z2 = output_f.mean ().item ()\n\t\t\t\t#D更新参数\n\t\t\t\toptimizerG.step ()\n\t\t\t\t\n\t\t\t###########################################\n\t\t\t##########可视化(可选)#####################\n\t\t\tif args.vis and i % args.plot_every == args.plot_every - 1:\n\t\t\t\tfake = netG (noises)\n\t\t\t\tvis.images (fake.detach ().cpu ().numpy () [:64] * 0.5 + 0.5, win='fixfake')\n\t\t\t\tvis.images (images.data.cpu ().numpy () [:64] * 0.5 + 0.5, win='real')\n\t\t\t\tvis.plot ('errord', D_loss.item ())\n\t\t\t\tvis.plot ('errorg', G_loss.item ())\n\t\t\t#######################################\n\t\t\t############打印记录###################\n\t\t\tif i % 1== 0:\n\t\t\t\tprint ('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n\t\t\t\t\t   % (epoch, args.max_epoch, i, len (train_loader),\n\t\t\t\t\t\t  D_loss.item (), G_loss.item (), D_x, D_G_z1, D_G_z2))\n\t\t\t\t########添加画图参数########\n\t\t\t\tG_losses.append (G_loss.item ())\n\t\t\t\tD_losses.append (D_loss.item ())\n\t\t\t\twith torch.no_grad ():\n\t\t\t\t\tnoises = torch.randn (args.batch_size, args.nz, 1, 1).to (device)\n\t\t\t\t\tfake = netG (noises).detach ().cpu ()\n\t\t\t\timport torchvision.utils as vutils\n\t\t\t\timg_list.append (vutils.make_grid (fake, padding=2, normalize=True))\n\t\n\n\n\t\t#######################################\n\t\t############保存模型###################\n\t\n\t\tif (epoch + 1) % args.save_every == 0:\n\t\t\timport torchvision as tv\n\t\t\t# 保存模型、图片\n\t\t\ttv.utils.save_image (fake.data [:64], '%s/%s.png' % (args.save_data, epoch), normalize=True,range=(-1, 1))\n\t\t\ttorch.save (netD.state_dict (), 'checkpoints/netd_%s.pth' % epoch)\n\t\t\ttorch.save (netG.state_dict (), 'checkpoints/netg_%s.pth' % epoch)\n\t\t\tprint('完成%s的模型保存'%epoch)\n\n\t#######################################\n\t############画图###################\n\t\n\tif args.plt:\n\t\timport matplotlib.pyplot as plt\n\t\timport numpy as np\n\t\timport torchvision.utils as vutils\n\t\t\n\t\tplt.figure (figsize=(10, 5))\n\t\tplt.title (\"GAN\")\n\t\tplt.plot (G_losses, label=\"G\")\n\t\tplt.plot (D_losses, label=\"D\")\n\t\tplt.xlabel (\"迭代次数\",fontproperties='SimHei')\n\t\tplt.ylabel (\"损失\",fontproperties='SimHei')\n\t\tplt.legend ()\n\t\tplt.show ()\n\t\t\n\t\t# 从数据集加载\n\t\treal_batch = next (iter (train_dataset))\n\t\t\n\t\t# 画出真图\n\t\tplt.figure (figsize=(15, 10))\n\t\tplt.subplot (1, 2, 1)\n\t\tplt.axis (\"off\")\n\t\tplt.title (\"真图\",fontproperties='SimHei')\n\t\tplt.imshow (np.transpose (\n\t\t\tvutils.make_grid (real_batch [0].to (device) [:64], padding=5, normalize=True).cpu (),\n\t\t\t(1, 2, 0)))\n\t\t\n\t\t# 画出假图\n\t\tplt.subplot (1, 2, 2)\n\t\tplt.axis (\"off\")\n\t\tplt.title (\"假图\",fontproperties='SimHei')\n\t\tplt.imshow (np.transpose (img_list [-1], (1, 2, 0)))\n\t\tplt.show ()\n\t\t\t\t\n\n\t\t\n\n\t\t\n\n@torch.no_grad()#禁用梯度计算\ndef test():\n\t#判断Gpu\n\tdevice = torch.device ('cuda') if args.cuda else torch.device ('cpu')\n\t#初始化网络\n\tnetg, netd = netG (args).eval (), netD (args).eval ()\n\t#定义噪声\n\tnoises = torch.randn (args.batch_size, args.nz, 1, 1).to (device)\n\t#载入网络\n\tnetd.load_state_dict (torch.load ('checkpoints/netd_%s.pth'%args.max_epoch))\n\tnetg.load_state_dict (torch.load ('checkpoints/netg_%s.pth'%args.max_epoch))\n\t#设备化\n\tnetd.to (device)\n\tnetg.to (device)\n\t# 生成图片，并计算图片在判别器的分数\n\tfake_img = netg (noises)\n\tscores = netd (fake_img).detach ()\n\t\n\t# 挑选最好的某几张\n\tindexs = scores.topk (5) [1]\n\tresult = []\n\tfor i in indexs:\n\t\tresult.append (fake_img.data [i])\n\t\n\t# 保存图片\n\timport torchvision as tv\n\ttv.utils.save_image (torch.stack (result), 5, normalize=True, range=(-1, 1))\n\n\n\n\n\n\n\n\n\n\n\n\t\n\t###################可视化类##################################\nimport visdom\nimport time\nimport torchvision as tv\nimport numpy as np\n\n\nclass Visualizer ():\n\t\"\"\"\n\t封装了visdom的基本操作，但是你仍然可以通过`self.vis.function`\n\t调用原生的visdom接口\n\t\"\"\"\n\t\n\tdef __init__ (self, env='default', **kwargs):\n\t\timport visdom\n\t\tself.vis = visdom.Visdom (env=env, use_incoming_socket=False, **kwargs)\n\t\t\n\t\t# 画的第几个数，相当于横座标\n\t\t# 保存（’loss',23） 即loss的第23个点\n\t\tself.index = {}\n\t\tself.log_text = ''\n\t\n\tdef reinit (self, env='default', **kwargs):\n\t\t\"\"\"\n\t\t修改visdom的配置\n\t\t\"\"\"\n\t\tself.vis = visdom.Visdom (env=env, use_incoming_socket=False, **kwargs)\n\t\treturn self\n\t\n\tdef plot_many (self, d):\n\t\t\"\"\"\n\t\t一次plot多个\n\t\t@params d: dict (name,value) i.e. ('loss',0.11)\n\t\t\"\"\"\n\t\tfor k, v in d.items ():\n\t\t\tself.plot (k, v)\n\t\n\tdef img_many (self, d):\n\t\tfor k, v in d.items ():\n\t\t\tself.img (k, v)\n\t\n\tdef plot (self, name, y):\n\t\t\"\"\"\n\t\tself.plot('loss',1.00)\n\t\t\"\"\"\n\t\tx = self.index.get (name, 0)\n\t\tself.vis.line (Y=np.array ([y]), X=np.array ([x]),\n\t\t\t\t\t   win=(name),\n\t\t\t\t\t   opts=dict (title=name),\n\t\t\t\t\t   update=None if x == 0 else 'append'\n\t\t\t\t\t   )\n\t\tself.index [name] = x + 1\n\t\n\tdef img (self, name, img_):\n\t\t\"\"\"\n\t\tself.img('input_img',t.Tensor(64,64))\n\t\t\"\"\"\n\t\t\n\t\tif len (img_.size ()) < 3:\n\t\t\timg_ = img_.cpu ().unsqueeze (0)\n\t\tself.vis.image (img_.cpu (),\n\t\t\t\t\t\twin=(name),\n\t\t\t\t\t\topts=dict (title=name)\n\t\t\t\t\t\t)\n\t\n\tdef img_grid_many (self, d):\n\t\tfor k, v in d.items ():\n\t\t\tself.img_grid (k, v)\n\t\n\tdef img_grid (self, name, input_3d):\n\t\t\"\"\"\n\t\t一个batch的图片转成一个网格图，i.e. input（36，64，64）\n\t\t会变成 6*6 的网格图，每个格子大小64*64\n\t\t\"\"\"\n\t\tself.img (name, tv.utils.make_grid (\n\t\t\tinput_3d.cpu () [0].unsqueeze (1).clamp (max=1, min=0)))\n\t\n\tdef log (self, info, win='log_text'):\n\t\t\"\"\"\n\t\tself.log({'loss':1,'lr':0.0001})\n\t\t\"\"\"\n\t\t\n\t\tself.log_text += ('[{time}] {info} <br>'.format (\n\t\t\ttime=time.strftime ('%m%d_%H%M%S'),\n\t\t\tinfo=info))\n\t\tself.vis.text (self.log_text, win=win)\n\t\n\tdef __getattr__ (self, name):\n\t\treturn getattr (self.vis, name)\n\t\n\t\n\t\nif __name__ == '__main__':\n\tif args.test:\n\t\ttest()\n\telse:\n\t\ttrain()\n```\n\n* 注 :数据集用的cifar-10-batches-py\n* 结果:\n* 迭代一次\n![](https://blog.mviai.com/images/回顾-DCGAN/0.png)\n* 迭代二次\n![](https://blog.mviai.com/images/回顾-DCGAN/1.png)","slug":"回顾-DCGAN","published":1,"updated":"2021-07-26T09:58:02.577Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m1x001digtab4cn33dc","content":"<h1 id=\"1-DCGAN-简介\"><a href=\"#1-DCGAN-简介\" class=\"headerlink\" title=\"1. DCGAN 简介:\"></a>1. DCGAN 简介:</h1><p>如何把CNN与GAN结合？<br>DCGAN是这方面最好的尝试之一，DCGAN的原理和GAN是一样的，这里就不在赘述。<br>它只是把经典GAN中的G和D换成了两个卷积神经网络（CNN）。<br>但是，并不是直接替换就可以了， DCGAN 对卷积神经网络的结构做了一些改变，以提高样本的质量和收敛的速度。用了哪些方法!我们简单了解下,原文地址:<a href=\"https://arxiv.org/pdf/1511.06434.pdf\" target=\"_blank\" rel=\"noopener\">点我</a></p>\n<hr>\n<h1 id=\"2-网络结构：\"><a href=\"#2-网络结构：\" class=\"headerlink\" title=\"2. 网络结构：\"></a>2. 网络结构：</h1><ul>\n<li><p>首先看图：<br><img src=\"https://blog.mviai.com/images/回顾-DCGAN/DCGAN.png\" alt><br><strong>网络改进点:</strong><br><strong><font color=\"blue\">简单解释下:<br>GAN 的第一层采用均匀噪声分布Z作为输入,因为它只是一个矩阵乘法操作所以可以称为全连接,但结果被重组为一个4维的张量,并作为卷积叠加（convolution stack）的开始。对于判别网络,最后卷积层是平滑的然后送入单个sigmoid输出。</font></strong></p>\n<ul>\n<li>1.使用步幅卷积替代确定性空间池化函数(比如最大池化)，允许网络学习自身的空间下采样的方法应用在生成网络当中，在判别网络中允许它学习自己的空间上采样。</li>\n<li>2.在卷积层的中间地带直接分别连接到生成网络的输入和判别网络的输出系统也可以很好的工作。<ul>\n<li>其次一个趋势是在最顶层的卷积后面去除全连接层特点。<font color=\"red\">发现全局平均池化虽然增加了模型的稳定性但却影响了收敛速度。</font></li>\n</ul>\n</li>\n<li>3.最后是批量规范化:通过将输入的每个单元标准化为0均值与单位方差来稳定学习。<font color=\"red\">有助于处理初始化不良导致的训练问题另外还有助于梯度流向更深的网络。</font><ul>\n<li><font color=\"red\">不要批量规范化（batchnorm）将应用到生成网络的输出层和判别网络输入层可以避免直接对所有的层采取批量归一化,导致采样的振荡和模型的不稳定问题</font></li>\n</ul>\n</li>\n<li>4.使用有界激活可以让模型更快学习达到饱和并覆盖训练分布的颜色空间。在判别器中,发现LeakyReLU激活函数能够很好地工作,特别是对于更高分辨率的模型。</li>\n</ul>\n</li>\n</ul>\n<p><strong>总结:</strong><br><img src=\"https://blog.mviai.com/images/回顾-DCGAN/work.png\" alt></p>\n<hr>\n<h3 id=\"训练细节上的改进\"><a href=\"#训练细节上的改进\" class=\"headerlink\" title=\"训练细节上的改进:\"></a>训练细节上的改进:</h3><ul>\n<li>1.训练图像除了缩放到tanh激活函数的[-1,1]范围之外,没有经过其他的预处理。</li>\n<li>2.所有的模型都是通过小批量随机梯度下降法进行训练的(小批量的大小是 128)</li>\n<li>3.所有权重的初始化为均值为 0 和方差为 0.02的正态分布。</li>\n<li>4.在LeakyReLU, 所有模型的leak的斜率设置为0.2。</li>\n<li>5.DCGAN是使用Adam优化程序调整超参数。建议使用的学习率是0.001，太高的话使用0.0002代替。</li>\n<li>6.优化器参数beta1，在建议的0.9训练动荡且不稳定，但降低到0.5是有利于模型的稳定。</li>\n</ul>\n<h1 id=\"3-pytorch-实现\"><a href=\"#3-pytorch-实现\" class=\"headerlink\" title=\"3. pytorch 实现:\"></a>3. pytorch 实现:</h1><p><strong> network.py</strong><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">跟着图走</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#我们首先建立G</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">G</span><span class=\"params\">(nn.Module)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self,args)</span>:</span></span><br><span class=\"line\">        super(G,self).__init__()</span><br><span class=\"line\">        ngf = args.ngf  <span class=\"comment\">#ndf 设置为128  卷积一般扩大两倍 参数为4,2,1</span></span><br><span class=\"line\">        self.G_layer= nn.Sequential(</span><br><span class=\"line\">            <span class=\"comment\"># 输入的相当于nz*1*1</span></span><br><span class=\"line\">            nn.ConvTranspose2d (args.nz, ngf * <span class=\"number\">8</span>, <span class=\"number\">4</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">            nn.BatchNorm2d (ngf * <span class=\"number\">8</span>),</span><br><span class=\"line\">            nn.ReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">            <span class=\"comment\"># (ngf*8) x 4 x 4</span></span><br><span class=\"line\">            nn.ConvTranspose2d (ngf * <span class=\"number\">8</span>, ngf * <span class=\"number\">4</span>, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">            nn.BatchNorm2d (ngf * <span class=\"number\">4</span>),</span><br><span class=\"line\">            nn.ReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">            <span class=\"comment\"># (ngf*4) x 8 x 8</span></span><br><span class=\"line\">            nn.ConvTranspose2d (ngf * <span class=\"number\">4</span>, ngf * <span class=\"number\">2</span>, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">            nn.BatchNorm2d (ngf * <span class=\"number\">2</span>),</span><br><span class=\"line\">            nn.ReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">            <span class=\"comment\"># (ngf*2) x 16 x 16</span></span><br><span class=\"line\">            nn.ConvTranspose2d (ngf * <span class=\"number\">2</span>, ngf, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">            nn.BatchNorm2d (ngf),</span><br><span class=\"line\">            nn.ReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">            <span class=\"comment\"># (ngf) x 32 x 32</span></span><br><span class=\"line\">            nn.ConvTranspose2d (ngf, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">            nn.Tanh ())</span><br><span class=\"line\">            <span class=\"comment\"># 3 x 64 x 64</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        </span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"comment\">#前向传播</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self,x)</span>:</span></span><br><span class=\"line\">        out=self.G_layer(x)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#建立D</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">D</span><span class=\"params\">(nn.Module)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self,args)</span>:</span></span><br><span class=\"line\">        super(D,self).__init__()</span><br><span class=\"line\">        ndf = args.ndf  <span class=\"comment\"># ndf 128</span></span><br><span class=\"line\">        self.D_layer= nn.Sequential(</span><br><span class=\"line\">                <span class=\"comment\"># 输入 3 x 64 x 64,</span></span><br><span class=\"line\">                nn.Conv2d(<span class=\"number\">3</span>,ndf,<span class=\"number\">4</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>),</span><br><span class=\"line\">                nn.BatchNorm2d (ndf),</span><br><span class=\"line\">                nn.LeakyReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">                <span class=\"comment\">#输出 (ndf)*32*32</span></span><br><span class=\"line\">                nn.Conv2d(ndf,ndf*<span class=\"number\">2</span>,<span class=\"number\">4</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>),</span><br><span class=\"line\">                nn.BatchNorm2d (ndf*<span class=\"number\">2</span>),</span><br><span class=\"line\">                nn.LeakyReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">                <span class=\"comment\"># 输出 (ndf*2)*16*16</span></span><br><span class=\"line\">                nn.Conv2d (ndf*<span class=\"number\">2</span>, ndf*<span class=\"number\">4</span>, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>),</span><br><span class=\"line\">                nn.BatchNorm2d (ndf*<span class=\"number\">4</span>),</span><br><span class=\"line\">                nn.LeakyReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">                <span class=\"comment\"># 输出 (ndf*4)*8*8</span></span><br><span class=\"line\">                nn.Conv2d (ndf*<span class=\"number\">4</span>, ndf*<span class=\"number\">8</span>, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>),</span><br><span class=\"line\">                nn.BatchNorm2d (ndf*<span class=\"number\">8</span>),</span><br><span class=\"line\">                nn.LeakyReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">                <span class=\"comment\"># 输出 (ndf*8)*4*4</span></span><br><span class=\"line\">                nn.Conv2d (ndf * <span class=\"number\">8</span>, <span class=\"number\">1</span>, <span class=\"number\">4</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>),</span><br><span class=\"line\">                <span class=\"comment\"># 输出 1*0*0</span></span><br><span class=\"line\">                nn.Sigmoid())<span class=\"comment\">#告诉D概率</span></span><br><span class=\"line\">                </span><br><span class=\"line\">    <span class=\"comment\">#前向传播</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self,x)</span>:</span></span><br><span class=\"line\">        out=self.D_layer(x)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br></pre></td></tr></table></figure></p>\n<p><strong> train.py </strong><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br><span class=\"line\">277</span><br><span class=\"line\">278</span><br><span class=\"line\">279</span><br><span class=\"line\">280</span><br><span class=\"line\">281</span><br><span class=\"line\">282</span><br><span class=\"line\">283</span><br><span class=\"line\">284</span><br><span class=\"line\">285</span><br><span class=\"line\">286</span><br><span class=\"line\">287</span><br><span class=\"line\">288</span><br><span class=\"line\">289</span><br><span class=\"line\">290</span><br><span class=\"line\">291</span><br><span class=\"line\">292</span><br><span class=\"line\">293</span><br><span class=\"line\">294</span><br><span class=\"line\">295</span><br><span class=\"line\">296</span><br><span class=\"line\">297</span><br><span class=\"line\">298</span><br><span class=\"line\">299</span><br><span class=\"line\">300</span><br><span class=\"line\">301</span><br><span class=\"line\">302</span><br><span class=\"line\">303</span><br><span class=\"line\">304</span><br><span class=\"line\">305</span><br><span class=\"line\">306</span><br><span class=\"line\">307</span><br><span class=\"line\">308</span><br><span class=\"line\">309</span><br><span class=\"line\">310</span><br><span class=\"line\">311</span><br><span class=\"line\">312</span><br><span class=\"line\">313</span><br><span class=\"line\">314</span><br><span class=\"line\">315</span><br><span class=\"line\">316</span><br><span class=\"line\">317</span><br><span class=\"line\">318</span><br><span class=\"line\">319</span><br><span class=\"line\">320</span><br><span class=\"line\">321</span><br><span class=\"line\">322</span><br><span class=\"line\">323</span><br><span class=\"line\">324</span><br><span class=\"line\">325</span><br><span class=\"line\">326</span><br><span class=\"line\">327</span><br><span class=\"line\">328</span><br><span class=\"line\">329</span><br><span class=\"line\">330</span><br><span class=\"line\">331</span><br><span class=\"line\">332</span><br><span class=\"line\">333</span><br><span class=\"line\">334</span><br><span class=\"line\">335</span><br><span class=\"line\">336</span><br><span class=\"line\">337</span><br><span class=\"line\">338</span><br><span class=\"line\">339</span><br><span class=\"line\">340</span><br><span class=\"line\">341</span><br><span class=\"line\">342</span><br><span class=\"line\">343</span><br><span class=\"line\">344</span><br><span class=\"line\">345</span><br><span class=\"line\">346</span><br><span class=\"line\">347</span><br><span class=\"line\">348</span><br><span class=\"line\">349</span><br><span class=\"line\">350</span><br><span class=\"line\">351</span><br><span class=\"line\">352</span><br><span class=\"line\">353</span><br><span class=\"line\">354</span><br><span class=\"line\">355</span><br><span class=\"line\">356</span><br><span class=\"line\">357</span><br><span class=\"line\">358</span><br><span class=\"line\">359</span><br><span class=\"line\">360</span><br><span class=\"line\">361</span><br><span class=\"line\">362</span><br><span class=\"line\">363</span><br><span class=\"line\">364</span><br><span class=\"line\">365</span><br><span class=\"line\">366</span><br><span class=\"line\">367</span><br><span class=\"line\">368</span><br><span class=\"line\">369</span><br><span class=\"line\">370</span><br><span class=\"line\">371</span><br><span class=\"line\">372</span><br><span class=\"line\">373</span><br><span class=\"line\">374</span><br><span class=\"line\">375</span><br><span class=\"line\">376</span><br><span class=\"line\">377</span><br><span class=\"line\">378</span><br><span class=\"line\">379</span><br><span class=\"line\">380</span><br><span class=\"line\">381</span><br><span class=\"line\">382</span><br><span class=\"line\">383</span><br><span class=\"line\">384</span><br><span class=\"line\">385</span><br><span class=\"line\">386</span><br><span class=\"line\">387</span><br><span class=\"line\">388</span><br><span class=\"line\">389</span><br><span class=\"line\">390</span><br><span class=\"line\">391</span><br><span class=\"line\">392</span><br><span class=\"line\">393</span><br><span class=\"line\">394</span><br><span class=\"line\">395</span><br><span class=\"line\">396</span><br><span class=\"line\">397</span><br><span class=\"line\">398</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision.datasets <span class=\"keyword\">as</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision.transforms <span class=\"keyword\">as</span>  transforms</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.backends.cudnn <span class=\"keyword\">as</span> cudnn</span><br><span class=\"line\"><span class=\"comment\"># 工具包</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> argparse</span><br><span class=\"line\"><span class=\"comment\"># 载入网络</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> network <span class=\"keyword\">import</span> G, D</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############参数设置#############</span></span><br><span class=\"line\"><span class=\"comment\">####命令行设置########</span></span><br><span class=\"line\">parser = argparse.ArgumentParser (description=<span class=\"string\">'GANs'</span>)  <span class=\"comment\"># 导入命令行模块</span></span><br><span class=\"line\"><span class=\"comment\"># 对关于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明</span></span><br><span class=\"line\"><span class=\"comment\">#关于训练参数</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--batch_size'</span>, type=int, default=<span class=\"number\">64</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'训练batch-size大小 (default: 64)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--imageSize'</span>, type=int, default=<span class=\"number\">64</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'图片尺寸'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--max_epoch'</span>, type=int, default=<span class=\"number\">20</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'最大迭代数 (default: 12)'</span>)</span><br><span class=\"line\"><span class=\"comment\">#关于网络参数</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--lr_g'</span>, type=float, default=<span class=\"number\">2e-4</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'生成器学习率 (default: 2e-4)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--lr_d'</span>, type=float, default=<span class=\"number\">2e-4</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'判别器学习率 (default: 2e-4)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--ngf'</span>, type=int, default=<span class=\"number\">128</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'生成器feature map数'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--ndf'</span>, type=int, default=<span class=\"number\">128</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'判别器feature map数'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--d_every'</span>, type=int, default=<span class=\"number\">1</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'每几个batch训练一次判别器'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--g_every'</span>, type=int, default=<span class=\"number\">4</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'每几个batch训练一次生成器'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--nz'</span>, type=int, default=<span class=\"number\">100</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'噪声维度'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#关于优化器参数</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--beta1'</span>, type=int, default=<span class=\"number\">0.5</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'Adam优化器的beta1参数'</span>)</span><br><span class=\"line\"><span class=\"comment\">#路径</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--dataset'</span>, default=<span class=\"string\">'data/'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'数据集路径'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--save_data'</span>,  default=<span class=\"string\">'save/'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'保存路径'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#可视化</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--vis'</span>, action=<span class=\"string\">'store_true'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'使用visdom可视化'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--plot_every'</span>, type=int, default=<span class=\"number\">1</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'每间隔_batch，visdom画图一次'</span>)</span><br><span class=\"line\"><span class=\"comment\"># 其他</span></span><br><span class=\"line\"></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--cuda'</span>, action=<span class=\"string\">'store_true'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'开启cuda训练'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--plt'</span>, action=<span class=\"string\">'store_true'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'开启画图'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--test'</span>, action=<span class=\"string\">'store_true'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'开启测试生成'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--save_every'</span>, type=int, default=<span class=\"number\">5</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'几个epoch保存一次模型 (default: 2)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--seed'</span>, type=int, default=<span class=\"number\">1</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'随机种子 (default: 1)'</span>)</span><br><span class=\"line\">args = parser.parse_args ()  <span class=\"comment\"># 相当于激活命令</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#训练过程</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">train</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">\t<span class=\"comment\">###############判断gpu#############</span></span><br><span class=\"line\">\tdevice = torch.device (<span class=\"string\">'cuda'</span>) <span class=\"keyword\">if</span> args.cuda <span class=\"keyword\">else</span> torch.device (<span class=\"string\">'cpu'</span>)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">####### 为CPU设置种子用于生成随机数，以使得结果是确定的##########</span></span><br><span class=\"line\">\ttorch.manual_seed (args.seed)</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> args.cuda:</span><br><span class=\"line\">\t\ttorch.cuda.manual_seed (args.seed)</span><br><span class=\"line\">\tcudnn.benchmark = <span class=\"literal\">True</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">#################可视化###############</span></span><br><span class=\"line\">\t<span class=\"keyword\">if</span> args.vis:</span><br><span class=\"line\">\t\tvis = Visualizer (<span class=\"string\">'GANs'</span>)</span><br><span class=\"line\">\t<span class=\"comment\">##########数据转换#####################</span></span><br><span class=\"line\">\tdata_transforms = transforms.Compose ([transforms.Scale (args.imageSize),  <span class=\"comment\"># 通过调整比例调整大小,会报警</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   transforms.CenterCrop (args.imageSize),  <span class=\"comment\"># 在中心裁剪给指定大小方形PIL图像</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   transforms.ToTensor (),<span class=\"comment\"># 转换成pytorch 变量tensor</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   transforms.Normalize ((<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>), (<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>))])</span><br><span class=\"line\">\t<span class=\"comment\">###############数据载入################</span></span><br><span class=\"line\">\t<span class=\"comment\"># train_dataset = datasets.ImageFolder (root=args.dataset,  # 数据路径目录</span></span><br><span class=\"line\">\t<span class=\"comment\"># \t\t\t\t\t\t\t\t\t  transform=data_transforms)  # 把数据转换成上面约束样子</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\ttrain_dataset = datasets.CIFAR10(root=args.dataset,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t train=<span class=\"literal\">True</span>,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t transform=data_transforms,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t download=<span class=\"literal\">False</span>)</span><br><span class=\"line\">\t<span class=\"comment\"># test_dataset = datasets.ImageFolder (root=args.dataset,</span></span><br><span class=\"line\">\t<span class=\"comment\"># \t\t\t\t\t\t\t\t\t transform=data_transforms)</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">##############数据装载###############</span></span><br><span class=\"line\">\ttrain_loader = torch.utils.data.DataLoader (dataset=train_dataset,  <span class=\"comment\"># 装载数据</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\t\tbatch_size=args.batch_size,  <span class=\"comment\"># 设置批大小</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\t\tshuffle=<span class=\"literal\">True</span>)  <span class=\"comment\"># 是否随机打乱</span></span><br><span class=\"line\">\t<span class=\"comment\"># test_loader = torch.utils.data.DataLoader (dataset=test_dataset,</span></span><br><span class=\"line\">\t<span class=\"comment\"># \t\t\t\t\t\t\t\t\t\t   batch_size=args.batch_size,</span></span><br><span class=\"line\">\t<span class=\"comment\"># \t\t\t\t\t\t\t\t\t\t   shuffle=True)</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">#############模型载入#################</span></span><br><span class=\"line\">\tnetG ,netD= G (args),D (args)</span><br><span class=\"line\">\tnetG.to (device)</span><br><span class=\"line\">\tnetD.to (device)</span><br><span class=\"line\">\t<span class=\"keyword\">print</span> (netD, netG)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">###############损失函数##################</span></span><br><span class=\"line\">\tcriterion = torch.nn.BCELoss ().to (device)</span><br><span class=\"line\">\toptimizerD = torch.optim.Adam (netD.parameters (), lr=args.lr_d,betas=(<span class=\"number\">0.5</span>, <span class=\"number\">0.999</span>))  <span class=\"comment\"># Adam优化器</span></span><br><span class=\"line\">\toptimizerG = torch.optim.Adam (netG.parameters (), lr=args.lr_g,betas=(<span class=\"number\">0.5</span>, <span class=\"number\">0.999</span>))  <span class=\"comment\"># Adam优化器</span></span><br><span class=\"line\">\t<span class=\"comment\">###############画图参数保存##################</span></span><br><span class=\"line\">\tG_losses = []</span><br><span class=\"line\">\tD_losses = []</span><br><span class=\"line\">\timg_list = []</span><br><span class=\"line\">\t<span class=\"comment\">#############训练过程#####################</span></span><br><span class=\"line\">\t<span class=\"keyword\">import</span> tqdm</span><br><span class=\"line\">\t<span class=\"comment\"># Tqdm是一个快速，可扩展的Python进度条，可以在Python</span></span><br><span class=\"line\">\t<span class=\"comment\"># 长循环中添加一个进度提示信息，用户只需要封装任意的迭代器</span></span><br><span class=\"line\">\t<span class=\"comment\"># tqdm (iterator)。</span></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range (args.max_epoch):</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> i, (images, labels) <span class=\"keyword\">in</span> tqdm.tqdm(enumerate (train_loader)):  <span class=\"comment\"># 枚举出来</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\">#数据处理</span></span><br><span class=\"line\">\t\t\timages = images.to (device)</span><br><span class=\"line\">\t\t\t<span class=\"comment\"># 装箱</span></span><br><span class=\"line\">\t\t\timages = Variable (images)</span><br><span class=\"line\">\t\t\tnoises=Variable(torch.randn(images.size(<span class=\"number\">0</span>), args.nz, <span class=\"number\">1</span>, <span class=\"number\">1</span>).to(device))</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\t<span class=\"comment\">#遍历每张图片,并且根据指定的训练机制训练</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> i % args.d_every==<span class=\"number\">0</span>:<span class=\"comment\">#满足此条件训练D</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D前向传播</span></span><br><span class=\"line\">\t\t\t\toptimizerD.zero_grad ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D网络输出</span></span><br><span class=\"line\">\t\t\t\toutput_r = netD (images).view(<span class=\"number\">-1</span>)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#定义真张量</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#返回第一个参数为大小 第二参数为值 的张量</span></span><br><span class=\"line\">\t\t\t\ttrue_label = torch.full ((images.size(<span class=\"number\">0</span>),), <span class=\"number\">1</span>, device=device)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#判别真的损失</span></span><br><span class=\"line\">\t\t\t\td_real_loss = criterion(output_r, true_label)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#反向传播</span></span><br><span class=\"line\">\t\t\t\td_real_loss.backward()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G网络输出</span></span><br><span class=\"line\">\t\t\t\tnoises.data.copy_ (torch.randn (images.size(<span class=\"number\">0</span>), args.nz, <span class=\"number\">1</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">\t\t\t\tfake = netG (noises).detach ()  <span class=\"comment\"># 根据噪声生成假图</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#把假图给d</span></span><br><span class=\"line\">\t\t\t\toutput_f = netD (fake).view(<span class=\"number\">-1</span>)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#d假的损失</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#print(fake.size(),output_f.size(),output_r.size())</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\"># 返回第一个参数为大小 第二参数为值 的张量</span></span><br><span class=\"line\">\t\t\t\tfake_label = torch.full ((images.size (<span class=\"number\">0</span>),), <span class=\"number\">0</span>, device=device)</span><br><span class=\"line\">\t\t\t\td_fake_loss= criterion(output_f,fake_label)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D假反向传播</span></span><br><span class=\"line\">\t\t\t\td_fake_loss.backward ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\"># 总损失</span></span><br><span class=\"line\">\t\t\t\tD_loss=d_fake_loss+d_real_loss</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D更新参数</span></span><br><span class=\"line\">\t\t\t\toptimizerD.step ()</span><br><span class=\"line\">\t\t\t\t</span><br><span class=\"line\">\t\t\t\t</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\"># 度量</span></span><br><span class=\"line\">\t\t\t\tD_x = output_r.mean ().item ()</span><br><span class=\"line\">\t\t\t\tD_G_z1 = output_f.mean ().item ()</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> i % args.g_every==<span class=\"number\">0</span>:<span class=\"comment\">#满足此条件训练G</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G前向传播</span></span><br><span class=\"line\">\t\t\t\toptimizerG.zero_grad ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G网络输出</span></span><br><span class=\"line\">\t\t\t\tfake = netG (noises)  <span class=\"comment\"># 根据噪声生成假图</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#把假图给G</span></span><br><span class=\"line\">\t\t\t\toutput_f = netD (fake).view(<span class=\"number\">-1</span>)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G的损失</span></span><br><span class=\"line\">\t\t\t\ttrue_label = torch.full ((images.size (<span class=\"number\">0</span>),), <span class=\"number\">1</span>, device=device)</span><br><span class=\"line\">\t\t\t\tG_loss = criterion(output_f,true_label)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G反向传播</span></span><br><span class=\"line\">\t\t\t\tG_loss.backward ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#度量</span></span><br><span class=\"line\">\t\t\t\tD_G_z2 = output_f.mean ().item ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D更新参数</span></span><br><span class=\"line\">\t\t\t\toptimizerG.step ()</span><br><span class=\"line\">\t\t\t\t</span><br><span class=\"line\">\t\t\t<span class=\"comment\">###########################################</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\">##########可视化(可选)#####################</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> args.vis <span class=\"keyword\">and</span> i % args.plot_every == args.plot_every - <span class=\"number\">1</span>:</span><br><span class=\"line\">\t\t\t\tfake = netG (noises)</span><br><span class=\"line\">\t\t\t\tvis.images (fake.detach ().cpu ().numpy () [:<span class=\"number\">64</span>] * <span class=\"number\">0.5</span> + <span class=\"number\">0.5</span>, win=<span class=\"string\">'fixfake'</span>)</span><br><span class=\"line\">\t\t\t\tvis.images (images.data.cpu ().numpy () [:<span class=\"number\">64</span>] * <span class=\"number\">0.5</span> + <span class=\"number\">0.5</span>, win=<span class=\"string\">'real'</span>)</span><br><span class=\"line\">\t\t\t\tvis.plot (<span class=\"string\">'errord'</span>, D_loss.item ())</span><br><span class=\"line\">\t\t\t\tvis.plot (<span class=\"string\">'errorg'</span>, G_loss.item ())</span><br><span class=\"line\">\t\t\t<span class=\"comment\">#######################################</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\">############打印记录###################</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> i % <span class=\"number\">1</span>== <span class=\"number\">0</span>:</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">print</span> (<span class=\"string\">'[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'</span></span><br><span class=\"line\">\t\t\t\t\t   % (epoch, args.max_epoch, i, len (train_loader),</span><br><span class=\"line\">\t\t\t\t\t\t  D_loss.item (), G_loss.item (), D_x, D_G_z1, D_G_z2))</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">########添加画图参数########</span></span><br><span class=\"line\">\t\t\t\tG_losses.append (G_loss.item ())</span><br><span class=\"line\">\t\t\t\tD_losses.append (D_loss.item ())</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">with</span> torch.no_grad ():</span><br><span class=\"line\">\t\t\t\t\tnoises = torch.randn (args.batch_size, args.nz, <span class=\"number\">1</span>, <span class=\"number\">1</span>).to (device)</span><br><span class=\"line\">\t\t\t\t\tfake = netG (noises).detach ().cpu ()</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">import</span> torchvision.utils <span class=\"keyword\">as</span> vutils</span><br><span class=\"line\">\t\t\t\timg_list.append (vutils.make_grid (fake, padding=<span class=\"number\">2</span>, normalize=<span class=\"literal\">True</span>))</span><br><span class=\"line\">\t</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">\t\t<span class=\"comment\">#######################################</span></span><br><span class=\"line\">\t\t<span class=\"comment\">############保存模型###################</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (epoch + <span class=\"number\">1</span>) % args.save_every == <span class=\"number\">0</span>:</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">import</span> torchvision <span class=\"keyword\">as</span> tv</span><br><span class=\"line\">\t\t\t<span class=\"comment\"># 保存模型、图片</span></span><br><span class=\"line\">\t\t\ttv.utils.save_image (fake.data [:<span class=\"number\">64</span>], <span class=\"string\">'%s/%s.png'</span> % (args.save_data, epoch), normalize=<span class=\"literal\">True</span>,range=(<span class=\"number\">-1</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">\t\t\ttorch.save (netD.state_dict (), <span class=\"string\">'checkpoints/netd_%s.pth'</span> % epoch)</span><br><span class=\"line\">\t\t\ttorch.save (netG.state_dict (), <span class=\"string\">'checkpoints/netg_%s.pth'</span> % epoch)</span><br><span class=\"line\">\t\t\tprint(<span class=\"string\">'完成%s的模型保存'</span>%epoch)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">#######################################</span></span><br><span class=\"line\">\t<span class=\"comment\">############画图###################</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> args.plt:</span><br><span class=\"line\">\t\t<span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\">\t\t<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\">\t\t<span class=\"keyword\">import</span> torchvision.utils <span class=\"keyword\">as</span> vutils</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\tplt.figure (figsize=(<span class=\"number\">10</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\">\t\tplt.title (<span class=\"string\">\"GAN\"</span>)</span><br><span class=\"line\">\t\tplt.plot (G_losses, label=<span class=\"string\">\"G\"</span>)</span><br><span class=\"line\">\t\tplt.plot (D_losses, label=<span class=\"string\">\"D\"</span>)</span><br><span class=\"line\">\t\tplt.xlabel (<span class=\"string\">\"迭代次数\"</span>,fontproperties=<span class=\"string\">'SimHei'</span>)</span><br><span class=\"line\">\t\tplt.ylabel (<span class=\"string\">\"损失\"</span>,fontproperties=<span class=\"string\">'SimHei'</span>)</span><br><span class=\"line\">\t\tplt.legend ()</span><br><span class=\"line\">\t\tplt.show ()</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 从数据集加载</span></span><br><span class=\"line\">\t\treal_batch = next (iter (train_dataset))</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 画出真图</span></span><br><span class=\"line\">\t\tplt.figure (figsize=(<span class=\"number\">15</span>, <span class=\"number\">10</span>))</span><br><span class=\"line\">\t\tplt.subplot (<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">\t\tplt.axis (<span class=\"string\">\"off\"</span>)</span><br><span class=\"line\">\t\tplt.title (<span class=\"string\">\"真图\"</span>,fontproperties=<span class=\"string\">'SimHei'</span>)</span><br><span class=\"line\">\t\tplt.imshow (np.transpose (</span><br><span class=\"line\">\t\t\tvutils.make_grid (real_batch [<span class=\"number\">0</span>].to (device) [:<span class=\"number\">64</span>], padding=<span class=\"number\">5</span>, normalize=<span class=\"literal\">True</span>).cpu (),</span><br><span class=\"line\">\t\t\t(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>)))</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 画出假图</span></span><br><span class=\"line\">\t\tplt.subplot (<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">\t\tplt.axis (<span class=\"string\">\"off\"</span>)</span><br><span class=\"line\">\t\tplt.title (<span class=\"string\">\"假图\"</span>,fontproperties=<span class=\"string\">'SimHei'</span>)</span><br><span class=\"line\">\t\tplt.imshow (np.transpose (img_list [<span class=\"number\">-1</span>], (<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>)))</span><br><span class=\"line\">\t\tplt.show ()</span><br><span class=\"line\">\t\t\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@torch.no_grad()#禁用梯度计算</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">test</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">\t<span class=\"comment\">#判断Gpu</span></span><br><span class=\"line\">\tdevice = torch.device (<span class=\"string\">'cuda'</span>) <span class=\"keyword\">if</span> args.cuda <span class=\"keyword\">else</span> torch.device (<span class=\"string\">'cpu'</span>)</span><br><span class=\"line\">\t<span class=\"comment\">#初始化网络</span></span><br><span class=\"line\">\tnetg, netd = netG (args).eval (), netD (args).eval ()</span><br><span class=\"line\">\t<span class=\"comment\">#定义噪声</span></span><br><span class=\"line\">\tnoises = torch.randn (args.batch_size, args.nz, <span class=\"number\">1</span>, <span class=\"number\">1</span>).to (device)</span><br><span class=\"line\">\t<span class=\"comment\">#载入网络</span></span><br><span class=\"line\">\tnetd.load_state_dict (torch.load (<span class=\"string\">'checkpoints/netd_%s.pth'</span>%args.max_epoch))</span><br><span class=\"line\">\tnetg.load_state_dict (torch.load (<span class=\"string\">'checkpoints/netg_%s.pth'</span>%args.max_epoch))</span><br><span class=\"line\">\t<span class=\"comment\">#设备化</span></span><br><span class=\"line\">\tnetd.to (device)</span><br><span class=\"line\">\tnetg.to (device)</span><br><span class=\"line\">\t<span class=\"comment\"># 生成图片，并计算图片在判别器的分数</span></span><br><span class=\"line\">\tfake_img = netg (noises)</span><br><span class=\"line\">\tscores = netd (fake_img).detach ()</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\"># 挑选最好的某几张</span></span><br><span class=\"line\">\tindexs = scores.topk (<span class=\"number\">5</span>) [<span class=\"number\">1</span>]</span><br><span class=\"line\">\tresult = []</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> indexs:</span><br><span class=\"line\">\t\tresult.append (fake_img.data [i])</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\"># 保存图片</span></span><br><span class=\"line\">\t<span class=\"keyword\">import</span> torchvision <span class=\"keyword\">as</span> tv</span><br><span class=\"line\">\ttv.utils.save_image (torch.stack (result), <span class=\"number\">5</span>, normalize=<span class=\"literal\">True</span>, range=(<span class=\"number\">-1</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">###################可视化类##################################</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> visdom</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision <span class=\"keyword\">as</span> tv</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Visualizer</span> <span class=\"params\">()</span>:</span></span><br><span class=\"line\">\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t封装了visdom的基本操作，但是你仍然可以通过`self.vis.function`</span></span><br><span class=\"line\"><span class=\"string\">\t调用原生的visdom接口</span></span><br><span class=\"line\"><span class=\"string\">\t\"\"\"</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span> <span class=\"params\">(self, env=<span class=\"string\">'default'</span>, **kwargs)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">import</span> visdom</span><br><span class=\"line\">\t\tself.vis = visdom.Visdom (env=env, use_incoming_socket=<span class=\"literal\">False</span>, **kwargs)</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 画的第几个数，相当于横座标</span></span><br><span class=\"line\">\t\t<span class=\"comment\"># 保存（’loss',23） 即loss的第23个点</span></span><br><span class=\"line\">\t\tself.index = &#123;&#125;</span><br><span class=\"line\">\t\tself.log_text = <span class=\"string\">''</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">reinit</span> <span class=\"params\">(self, env=<span class=\"string\">'default'</span>, **kwargs)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\t修改visdom的配置</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\tself.vis = visdom.Visdom (env=env, use_incoming_socket=<span class=\"literal\">False</span>, **kwargs)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> self</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">plot_many</span> <span class=\"params\">(self, d)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\t一次plot多个</span></span><br><span class=\"line\"><span class=\"string\">\t\t@params d: dict (name,value) i.e. ('loss',0.11)</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> d.items ():</span><br><span class=\"line\">\t\t\tself.plot (k, v)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">img_many</span> <span class=\"params\">(self, d)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> d.items ():</span><br><span class=\"line\">\t\t\tself.img (k, v)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">plot</span> <span class=\"params\">(self, name, y)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\tself.plot('loss',1.00)</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\tx = self.index.get (name, <span class=\"number\">0</span>)</span><br><span class=\"line\">\t\tself.vis.line (Y=np.array ([y]), X=np.array ([x]),</span><br><span class=\"line\">\t\t\t\t\t   win=(name),</span><br><span class=\"line\">\t\t\t\t\t   opts=dict (title=name),</span><br><span class=\"line\">\t\t\t\t\t   update=<span class=\"literal\">None</span> <span class=\"keyword\">if</span> x == <span class=\"number\">0</span> <span class=\"keyword\">else</span> <span class=\"string\">'append'</span></span><br><span class=\"line\">\t\t\t\t\t   )</span><br><span class=\"line\">\t\tself.index [name] = x + <span class=\"number\">1</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">img</span> <span class=\"params\">(self, name, img_)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\tself.img('input_img',t.Tensor(64,64))</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> len (img_.size ()) &lt; <span class=\"number\">3</span>:</span><br><span class=\"line\">\t\t\timg_ = img_.cpu ().unsqueeze (<span class=\"number\">0</span>)</span><br><span class=\"line\">\t\tself.vis.image (img_.cpu (),</span><br><span class=\"line\">\t\t\t\t\t\twin=(name),</span><br><span class=\"line\">\t\t\t\t\t\topts=dict (title=name)</span><br><span class=\"line\">\t\t\t\t\t\t)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">img_grid_many</span> <span class=\"params\">(self, d)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> d.items ():</span><br><span class=\"line\">\t\t\tself.img_grid (k, v)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">img_grid</span> <span class=\"params\">(self, name, input_3d)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\t一个batch的图片转成一个网格图，i.e. input（36，64，64）</span></span><br><span class=\"line\"><span class=\"string\">\t\t会变成 6*6 的网格图，每个格子大小64*64</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\tself.img (name, tv.utils.make_grid (</span><br><span class=\"line\">\t\t\tinput_3d.cpu () [<span class=\"number\">0</span>].unsqueeze (<span class=\"number\">1</span>).clamp (max=<span class=\"number\">1</span>, min=<span class=\"number\">0</span>)))</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">log</span> <span class=\"params\">(self, info, win=<span class=\"string\">'log_text'</span>)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\tself.log(&#123;'loss':1,'lr':0.0001&#125;)</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\tself.log_text += (<span class=\"string\">'[&#123;time&#125;] &#123;info&#125; &lt;br&gt;'</span>.format (</span><br><span class=\"line\">\t\t\ttime=time.strftime (<span class=\"string\">'%m%d_%H%M%S'</span>),</span><br><span class=\"line\">\t\t\tinfo=info))</span><br><span class=\"line\">\t\tself.vis.text (self.log_text, win=win)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__getattr__</span> <span class=\"params\">(self, name)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> getattr (self.vis, name)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t</span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> args.test:</span><br><span class=\"line\">\t\ttest()</span><br><span class=\"line\">\t<span class=\"keyword\">else</span>:</span><br><span class=\"line\">\t\ttrain()</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>注 :数据集用的cifar-10-batches-py</li>\n<li>结果:</li>\n<li>迭代一次<br><img src=\"https://blog.mviai.com/images/回顾-DCGAN/0.png\" alt></li>\n<li>迭代二次<br><img src=\"https://blog.mviai.com/images/回顾-DCGAN/1.png\" alt></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"1-DCGAN-简介\"><a href=\"#1-DCGAN-简介\" class=\"headerlink\" title=\"1. DCGAN 简介:\"></a>1. DCGAN 简介:</h1><p>如何把CNN与GAN结合？<br>DCGAN是这方面最好的尝试之一，DCGAN的原理和GAN是一样的，这里就不在赘述。<br>它只是把经典GAN中的G和D换成了两个卷积神经网络（CNN）。<br>但是，并不是直接替换就可以了， DCGAN 对卷积神经网络的结构做了一些改变，以提高样本的质量和收敛的速度。用了哪些方法!我们简单了解下,原文地址:<a href=\"https://arxiv.org/pdf/1511.06434.pdf\" target=\"_blank\" rel=\"noopener\">点我</a></p>\n<hr>\n<h1 id=\"2-网络结构：\"><a href=\"#2-网络结构：\" class=\"headerlink\" title=\"2. 网络结构：\"></a>2. 网络结构：</h1><ul>\n<li><p>首先看图：<br><img src=\"https://blog.mviai.com/images/回顾-DCGAN/DCGAN.png\" alt><br><strong>网络改进点:</strong><br><strong><font color=\"blue\">简单解释下:<br>GAN 的第一层采用均匀噪声分布Z作为输入,因为它只是一个矩阵乘法操作所以可以称为全连接,但结果被重组为一个4维的张量,并作为卷积叠加（convolution stack）的开始。对于判别网络,最后卷积层是平滑的然后送入单个sigmoid输出。</font></strong></p>\n<ul>\n<li>1.使用步幅卷积替代确定性空间池化函数(比如最大池化)，允许网络学习自身的空间下采样的方法应用在生成网络当中，在判别网络中允许它学习自己的空间上采样。</li>\n<li>2.在卷积层的中间地带直接分别连接到生成网络的输入和判别网络的输出系统也可以很好的工作。<ul>\n<li>其次一个趋势是在最顶层的卷积后面去除全连接层特点。<font color=\"red\">发现全局平均池化虽然增加了模型的稳定性但却影响了收敛速度。</font></li>\n</ul>\n</li>\n<li>3.最后是批量规范化:通过将输入的每个单元标准化为0均值与单位方差来稳定学习。<font color=\"red\">有助于处理初始化不良导致的训练问题另外还有助于梯度流向更深的网络。</font><ul>\n<li><font color=\"red\">不要批量规范化（batchnorm）将应用到生成网络的输出层和判别网络输入层可以避免直接对所有的层采取批量归一化,导致采样的振荡和模型的不稳定问题</font></li>\n</ul>\n</li>\n<li>4.使用有界激活可以让模型更快学习达到饱和并覆盖训练分布的颜色空间。在判别器中,发现LeakyReLU激活函数能够很好地工作,特别是对于更高分辨率的模型。</li>\n</ul>\n</li>\n</ul>\n<p><strong>总结:</strong><br><img src=\"https://blog.mviai.com/images/回顾-DCGAN/work.png\" alt></p>\n<hr>\n<h3 id=\"训练细节上的改进\"><a href=\"#训练细节上的改进\" class=\"headerlink\" title=\"训练细节上的改进:\"></a>训练细节上的改进:</h3><ul>\n<li>1.训练图像除了缩放到tanh激活函数的[-1,1]范围之外,没有经过其他的预处理。</li>\n<li>2.所有的模型都是通过小批量随机梯度下降法进行训练的(小批量的大小是 128)</li>\n<li>3.所有权重的初始化为均值为 0 和方差为 0.02的正态分布。</li>\n<li>4.在LeakyReLU, 所有模型的leak的斜率设置为0.2。</li>\n<li>5.DCGAN是使用Adam优化程序调整超参数。建议使用的学习率是0.001，太高的话使用0.0002代替。</li>\n<li>6.优化器参数beta1，在建议的0.9训练动荡且不稳定，但降低到0.5是有利于模型的稳定。</li>\n</ul>\n<h1 id=\"3-pytorch-实现\"><a href=\"#3-pytorch-实现\" class=\"headerlink\" title=\"3. pytorch 实现:\"></a>3. pytorch 实现:</h1><p><strong> network.py</strong><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">跟着图走</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#我们首先建立G</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">G</span><span class=\"params\">(nn.Module)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self,args)</span>:</span></span><br><span class=\"line\">        super(G,self).__init__()</span><br><span class=\"line\">        ngf = args.ngf  <span class=\"comment\">#ndf 设置为128  卷积一般扩大两倍 参数为4,2,1</span></span><br><span class=\"line\">        self.G_layer= nn.Sequential(</span><br><span class=\"line\">            <span class=\"comment\"># 输入的相当于nz*1*1</span></span><br><span class=\"line\">            nn.ConvTranspose2d (args.nz, ngf * <span class=\"number\">8</span>, <span class=\"number\">4</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">            nn.BatchNorm2d (ngf * <span class=\"number\">8</span>),</span><br><span class=\"line\">            nn.ReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">            <span class=\"comment\"># (ngf*8) x 4 x 4</span></span><br><span class=\"line\">            nn.ConvTranspose2d (ngf * <span class=\"number\">8</span>, ngf * <span class=\"number\">4</span>, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">            nn.BatchNorm2d (ngf * <span class=\"number\">4</span>),</span><br><span class=\"line\">            nn.ReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">            <span class=\"comment\"># (ngf*4) x 8 x 8</span></span><br><span class=\"line\">            nn.ConvTranspose2d (ngf * <span class=\"number\">4</span>, ngf * <span class=\"number\">2</span>, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">            nn.BatchNorm2d (ngf * <span class=\"number\">2</span>),</span><br><span class=\"line\">            nn.ReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">            <span class=\"comment\"># (ngf*2) x 16 x 16</span></span><br><span class=\"line\">            nn.ConvTranspose2d (ngf * <span class=\"number\">2</span>, ngf, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">            nn.BatchNorm2d (ngf),</span><br><span class=\"line\">            nn.ReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">            <span class=\"comment\"># (ngf) x 32 x 32</span></span><br><span class=\"line\">            nn.ConvTranspose2d (ngf, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">            nn.Tanh ())</span><br><span class=\"line\">            <span class=\"comment\"># 3 x 64 x 64</span></span><br><span class=\"line\">        </span><br><span class=\"line\">        </span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"comment\">#前向传播</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self,x)</span>:</span></span><br><span class=\"line\">        out=self.G_layer(x)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#建立D</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">D</span><span class=\"params\">(nn.Module)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self,args)</span>:</span></span><br><span class=\"line\">        super(D,self).__init__()</span><br><span class=\"line\">        ndf = args.ndf  <span class=\"comment\"># ndf 128</span></span><br><span class=\"line\">        self.D_layer= nn.Sequential(</span><br><span class=\"line\">                <span class=\"comment\"># 输入 3 x 64 x 64,</span></span><br><span class=\"line\">                nn.Conv2d(<span class=\"number\">3</span>,ndf,<span class=\"number\">4</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>),</span><br><span class=\"line\">                nn.BatchNorm2d (ndf),</span><br><span class=\"line\">                nn.LeakyReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">                <span class=\"comment\">#输出 (ndf)*32*32</span></span><br><span class=\"line\">                nn.Conv2d(ndf,ndf*<span class=\"number\">2</span>,<span class=\"number\">4</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>),</span><br><span class=\"line\">                nn.BatchNorm2d (ndf*<span class=\"number\">2</span>),</span><br><span class=\"line\">                nn.LeakyReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">                <span class=\"comment\"># 输出 (ndf*2)*16*16</span></span><br><span class=\"line\">                nn.Conv2d (ndf*<span class=\"number\">2</span>, ndf*<span class=\"number\">4</span>, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>),</span><br><span class=\"line\">                nn.BatchNorm2d (ndf*<span class=\"number\">4</span>),</span><br><span class=\"line\">                nn.LeakyReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">                <span class=\"comment\"># 输出 (ndf*4)*8*8</span></span><br><span class=\"line\">                nn.Conv2d (ndf*<span class=\"number\">4</span>, ndf*<span class=\"number\">8</span>, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>),</span><br><span class=\"line\">                nn.BatchNorm2d (ndf*<span class=\"number\">8</span>),</span><br><span class=\"line\">                nn.LeakyReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">                <span class=\"comment\"># 输出 (ndf*8)*4*4</span></span><br><span class=\"line\">                nn.Conv2d (ndf * <span class=\"number\">8</span>, <span class=\"number\">1</span>, <span class=\"number\">4</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>),</span><br><span class=\"line\">                <span class=\"comment\"># 输出 1*0*0</span></span><br><span class=\"line\">                nn.Sigmoid())<span class=\"comment\">#告诉D概率</span></span><br><span class=\"line\">                </span><br><span class=\"line\">    <span class=\"comment\">#前向传播</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self,x)</span>:</span></span><br><span class=\"line\">        out=self.D_layer(x)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br></pre></td></tr></table></figure></p>\n<p><strong> train.py </strong><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br><span class=\"line\">277</span><br><span class=\"line\">278</span><br><span class=\"line\">279</span><br><span class=\"line\">280</span><br><span class=\"line\">281</span><br><span class=\"line\">282</span><br><span class=\"line\">283</span><br><span class=\"line\">284</span><br><span class=\"line\">285</span><br><span class=\"line\">286</span><br><span class=\"line\">287</span><br><span class=\"line\">288</span><br><span class=\"line\">289</span><br><span class=\"line\">290</span><br><span class=\"line\">291</span><br><span class=\"line\">292</span><br><span class=\"line\">293</span><br><span class=\"line\">294</span><br><span class=\"line\">295</span><br><span class=\"line\">296</span><br><span class=\"line\">297</span><br><span class=\"line\">298</span><br><span class=\"line\">299</span><br><span class=\"line\">300</span><br><span class=\"line\">301</span><br><span class=\"line\">302</span><br><span class=\"line\">303</span><br><span class=\"line\">304</span><br><span class=\"line\">305</span><br><span class=\"line\">306</span><br><span class=\"line\">307</span><br><span class=\"line\">308</span><br><span class=\"line\">309</span><br><span class=\"line\">310</span><br><span class=\"line\">311</span><br><span class=\"line\">312</span><br><span class=\"line\">313</span><br><span class=\"line\">314</span><br><span class=\"line\">315</span><br><span class=\"line\">316</span><br><span class=\"line\">317</span><br><span class=\"line\">318</span><br><span class=\"line\">319</span><br><span class=\"line\">320</span><br><span class=\"line\">321</span><br><span class=\"line\">322</span><br><span class=\"line\">323</span><br><span class=\"line\">324</span><br><span class=\"line\">325</span><br><span class=\"line\">326</span><br><span class=\"line\">327</span><br><span class=\"line\">328</span><br><span class=\"line\">329</span><br><span class=\"line\">330</span><br><span class=\"line\">331</span><br><span class=\"line\">332</span><br><span class=\"line\">333</span><br><span class=\"line\">334</span><br><span class=\"line\">335</span><br><span class=\"line\">336</span><br><span class=\"line\">337</span><br><span class=\"line\">338</span><br><span class=\"line\">339</span><br><span class=\"line\">340</span><br><span class=\"line\">341</span><br><span class=\"line\">342</span><br><span class=\"line\">343</span><br><span class=\"line\">344</span><br><span class=\"line\">345</span><br><span class=\"line\">346</span><br><span class=\"line\">347</span><br><span class=\"line\">348</span><br><span class=\"line\">349</span><br><span class=\"line\">350</span><br><span class=\"line\">351</span><br><span class=\"line\">352</span><br><span class=\"line\">353</span><br><span class=\"line\">354</span><br><span class=\"line\">355</span><br><span class=\"line\">356</span><br><span class=\"line\">357</span><br><span class=\"line\">358</span><br><span class=\"line\">359</span><br><span class=\"line\">360</span><br><span class=\"line\">361</span><br><span class=\"line\">362</span><br><span class=\"line\">363</span><br><span class=\"line\">364</span><br><span class=\"line\">365</span><br><span class=\"line\">366</span><br><span class=\"line\">367</span><br><span class=\"line\">368</span><br><span class=\"line\">369</span><br><span class=\"line\">370</span><br><span class=\"line\">371</span><br><span class=\"line\">372</span><br><span class=\"line\">373</span><br><span class=\"line\">374</span><br><span class=\"line\">375</span><br><span class=\"line\">376</span><br><span class=\"line\">377</span><br><span class=\"line\">378</span><br><span class=\"line\">379</span><br><span class=\"line\">380</span><br><span class=\"line\">381</span><br><span class=\"line\">382</span><br><span class=\"line\">383</span><br><span class=\"line\">384</span><br><span class=\"line\">385</span><br><span class=\"line\">386</span><br><span class=\"line\">387</span><br><span class=\"line\">388</span><br><span class=\"line\">389</span><br><span class=\"line\">390</span><br><span class=\"line\">391</span><br><span class=\"line\">392</span><br><span class=\"line\">393</span><br><span class=\"line\">394</span><br><span class=\"line\">395</span><br><span class=\"line\">396</span><br><span class=\"line\">397</span><br><span class=\"line\">398</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision.datasets <span class=\"keyword\">as</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision.transforms <span class=\"keyword\">as</span>  transforms</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.backends.cudnn <span class=\"keyword\">as</span> cudnn</span><br><span class=\"line\"><span class=\"comment\"># 工具包</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> argparse</span><br><span class=\"line\"><span class=\"comment\"># 载入网络</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> network <span class=\"keyword\">import</span> G, D</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############参数设置#############</span></span><br><span class=\"line\"><span class=\"comment\">####命令行设置########</span></span><br><span class=\"line\">parser = argparse.ArgumentParser (description=<span class=\"string\">'GANs'</span>)  <span class=\"comment\"># 导入命令行模块</span></span><br><span class=\"line\"><span class=\"comment\"># 对关于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明</span></span><br><span class=\"line\"><span class=\"comment\">#关于训练参数</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--batch_size'</span>, type=int, default=<span class=\"number\">64</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'训练batch-size大小 (default: 64)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--imageSize'</span>, type=int, default=<span class=\"number\">64</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'图片尺寸'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--max_epoch'</span>, type=int, default=<span class=\"number\">20</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'最大迭代数 (default: 12)'</span>)</span><br><span class=\"line\"><span class=\"comment\">#关于网络参数</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--lr_g'</span>, type=float, default=<span class=\"number\">2e-4</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'生成器学习率 (default: 2e-4)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--lr_d'</span>, type=float, default=<span class=\"number\">2e-4</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'判别器学习率 (default: 2e-4)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--ngf'</span>, type=int, default=<span class=\"number\">128</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'生成器feature map数'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--ndf'</span>, type=int, default=<span class=\"number\">128</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'判别器feature map数'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--d_every'</span>, type=int, default=<span class=\"number\">1</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'每几个batch训练一次判别器'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--g_every'</span>, type=int, default=<span class=\"number\">4</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'每几个batch训练一次生成器'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--nz'</span>, type=int, default=<span class=\"number\">100</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'噪声维度'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#关于优化器参数</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--beta1'</span>, type=int, default=<span class=\"number\">0.5</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'Adam优化器的beta1参数'</span>)</span><br><span class=\"line\"><span class=\"comment\">#路径</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--dataset'</span>, default=<span class=\"string\">'data/'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'数据集路径'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--save_data'</span>,  default=<span class=\"string\">'save/'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'保存路径'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#可视化</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--vis'</span>, action=<span class=\"string\">'store_true'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'使用visdom可视化'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--plot_every'</span>, type=int, default=<span class=\"number\">1</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'每间隔_batch，visdom画图一次'</span>)</span><br><span class=\"line\"><span class=\"comment\"># 其他</span></span><br><span class=\"line\"></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--cuda'</span>, action=<span class=\"string\">'store_true'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'开启cuda训练'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--plt'</span>, action=<span class=\"string\">'store_true'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'开启画图'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--test'</span>, action=<span class=\"string\">'store_true'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'开启测试生成'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--save_every'</span>, type=int, default=<span class=\"number\">5</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'几个epoch保存一次模型 (default: 2)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--seed'</span>, type=int, default=<span class=\"number\">1</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'随机种子 (default: 1)'</span>)</span><br><span class=\"line\">args = parser.parse_args ()  <span class=\"comment\"># 相当于激活命令</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#训练过程</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">train</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">\t<span class=\"comment\">###############判断gpu#############</span></span><br><span class=\"line\">\tdevice = torch.device (<span class=\"string\">'cuda'</span>) <span class=\"keyword\">if</span> args.cuda <span class=\"keyword\">else</span> torch.device (<span class=\"string\">'cpu'</span>)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">####### 为CPU设置种子用于生成随机数，以使得结果是确定的##########</span></span><br><span class=\"line\">\ttorch.manual_seed (args.seed)</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> args.cuda:</span><br><span class=\"line\">\t\ttorch.cuda.manual_seed (args.seed)</span><br><span class=\"line\">\tcudnn.benchmark = <span class=\"literal\">True</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">#################可视化###############</span></span><br><span class=\"line\">\t<span class=\"keyword\">if</span> args.vis:</span><br><span class=\"line\">\t\tvis = Visualizer (<span class=\"string\">'GANs'</span>)</span><br><span class=\"line\">\t<span class=\"comment\">##########数据转换#####################</span></span><br><span class=\"line\">\tdata_transforms = transforms.Compose ([transforms.Scale (args.imageSize),  <span class=\"comment\"># 通过调整比例调整大小,会报警</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   transforms.CenterCrop (args.imageSize),  <span class=\"comment\"># 在中心裁剪给指定大小方形PIL图像</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   transforms.ToTensor (),<span class=\"comment\"># 转换成pytorch 变量tensor</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   transforms.Normalize ((<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>), (<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>))])</span><br><span class=\"line\">\t<span class=\"comment\">###############数据载入################</span></span><br><span class=\"line\">\t<span class=\"comment\"># train_dataset = datasets.ImageFolder (root=args.dataset,  # 数据路径目录</span></span><br><span class=\"line\">\t<span class=\"comment\"># \t\t\t\t\t\t\t\t\t  transform=data_transforms)  # 把数据转换成上面约束样子</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\ttrain_dataset = datasets.CIFAR10(root=args.dataset,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t train=<span class=\"literal\">True</span>,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t transform=data_transforms,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t download=<span class=\"literal\">False</span>)</span><br><span class=\"line\">\t<span class=\"comment\"># test_dataset = datasets.ImageFolder (root=args.dataset,</span></span><br><span class=\"line\">\t<span class=\"comment\"># \t\t\t\t\t\t\t\t\t transform=data_transforms)</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">##############数据装载###############</span></span><br><span class=\"line\">\ttrain_loader = torch.utils.data.DataLoader (dataset=train_dataset,  <span class=\"comment\"># 装载数据</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\t\tbatch_size=args.batch_size,  <span class=\"comment\"># 设置批大小</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\t\tshuffle=<span class=\"literal\">True</span>)  <span class=\"comment\"># 是否随机打乱</span></span><br><span class=\"line\">\t<span class=\"comment\"># test_loader = torch.utils.data.DataLoader (dataset=test_dataset,</span></span><br><span class=\"line\">\t<span class=\"comment\"># \t\t\t\t\t\t\t\t\t\t   batch_size=args.batch_size,</span></span><br><span class=\"line\">\t<span class=\"comment\"># \t\t\t\t\t\t\t\t\t\t   shuffle=True)</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">#############模型载入#################</span></span><br><span class=\"line\">\tnetG ,netD= G (args),D (args)</span><br><span class=\"line\">\tnetG.to (device)</span><br><span class=\"line\">\tnetD.to (device)</span><br><span class=\"line\">\t<span class=\"keyword\">print</span> (netD, netG)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">###############损失函数##################</span></span><br><span class=\"line\">\tcriterion = torch.nn.BCELoss ().to (device)</span><br><span class=\"line\">\toptimizerD = torch.optim.Adam (netD.parameters (), lr=args.lr_d,betas=(<span class=\"number\">0.5</span>, <span class=\"number\">0.999</span>))  <span class=\"comment\"># Adam优化器</span></span><br><span class=\"line\">\toptimizerG = torch.optim.Adam (netG.parameters (), lr=args.lr_g,betas=(<span class=\"number\">0.5</span>, <span class=\"number\">0.999</span>))  <span class=\"comment\"># Adam优化器</span></span><br><span class=\"line\">\t<span class=\"comment\">###############画图参数保存##################</span></span><br><span class=\"line\">\tG_losses = []</span><br><span class=\"line\">\tD_losses = []</span><br><span class=\"line\">\timg_list = []</span><br><span class=\"line\">\t<span class=\"comment\">#############训练过程#####################</span></span><br><span class=\"line\">\t<span class=\"keyword\">import</span> tqdm</span><br><span class=\"line\">\t<span class=\"comment\"># Tqdm是一个快速，可扩展的Python进度条，可以在Python</span></span><br><span class=\"line\">\t<span class=\"comment\"># 长循环中添加一个进度提示信息，用户只需要封装任意的迭代器</span></span><br><span class=\"line\">\t<span class=\"comment\"># tqdm (iterator)。</span></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range (args.max_epoch):</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> i, (images, labels) <span class=\"keyword\">in</span> tqdm.tqdm(enumerate (train_loader)):  <span class=\"comment\"># 枚举出来</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\">#数据处理</span></span><br><span class=\"line\">\t\t\timages = images.to (device)</span><br><span class=\"line\">\t\t\t<span class=\"comment\"># 装箱</span></span><br><span class=\"line\">\t\t\timages = Variable (images)</span><br><span class=\"line\">\t\t\tnoises=Variable(torch.randn(images.size(<span class=\"number\">0</span>), args.nz, <span class=\"number\">1</span>, <span class=\"number\">1</span>).to(device))</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\t<span class=\"comment\">#遍历每张图片,并且根据指定的训练机制训练</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> i % args.d_every==<span class=\"number\">0</span>:<span class=\"comment\">#满足此条件训练D</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D前向传播</span></span><br><span class=\"line\">\t\t\t\toptimizerD.zero_grad ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D网络输出</span></span><br><span class=\"line\">\t\t\t\toutput_r = netD (images).view(<span class=\"number\">-1</span>)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#定义真张量</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#返回第一个参数为大小 第二参数为值 的张量</span></span><br><span class=\"line\">\t\t\t\ttrue_label = torch.full ((images.size(<span class=\"number\">0</span>),), <span class=\"number\">1</span>, device=device)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#判别真的损失</span></span><br><span class=\"line\">\t\t\t\td_real_loss = criterion(output_r, true_label)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#反向传播</span></span><br><span class=\"line\">\t\t\t\td_real_loss.backward()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G网络输出</span></span><br><span class=\"line\">\t\t\t\tnoises.data.copy_ (torch.randn (images.size(<span class=\"number\">0</span>), args.nz, <span class=\"number\">1</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">\t\t\t\tfake = netG (noises).detach ()  <span class=\"comment\"># 根据噪声生成假图</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#把假图给d</span></span><br><span class=\"line\">\t\t\t\toutput_f = netD (fake).view(<span class=\"number\">-1</span>)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#d假的损失</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#print(fake.size(),output_f.size(),output_r.size())</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\"># 返回第一个参数为大小 第二参数为值 的张量</span></span><br><span class=\"line\">\t\t\t\tfake_label = torch.full ((images.size (<span class=\"number\">0</span>),), <span class=\"number\">0</span>, device=device)</span><br><span class=\"line\">\t\t\t\td_fake_loss= criterion(output_f,fake_label)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D假反向传播</span></span><br><span class=\"line\">\t\t\t\td_fake_loss.backward ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\"># 总损失</span></span><br><span class=\"line\">\t\t\t\tD_loss=d_fake_loss+d_real_loss</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D更新参数</span></span><br><span class=\"line\">\t\t\t\toptimizerD.step ()</span><br><span class=\"line\">\t\t\t\t</span><br><span class=\"line\">\t\t\t\t</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\"># 度量</span></span><br><span class=\"line\">\t\t\t\tD_x = output_r.mean ().item ()</span><br><span class=\"line\">\t\t\t\tD_G_z1 = output_f.mean ().item ()</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> i % args.g_every==<span class=\"number\">0</span>:<span class=\"comment\">#满足此条件训练G</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G前向传播</span></span><br><span class=\"line\">\t\t\t\toptimizerG.zero_grad ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G网络输出</span></span><br><span class=\"line\">\t\t\t\tfake = netG (noises)  <span class=\"comment\"># 根据噪声生成假图</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#把假图给G</span></span><br><span class=\"line\">\t\t\t\toutput_f = netD (fake).view(<span class=\"number\">-1</span>)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G的损失</span></span><br><span class=\"line\">\t\t\t\ttrue_label = torch.full ((images.size (<span class=\"number\">0</span>),), <span class=\"number\">1</span>, device=device)</span><br><span class=\"line\">\t\t\t\tG_loss = criterion(output_f,true_label)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G反向传播</span></span><br><span class=\"line\">\t\t\t\tG_loss.backward ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#度量</span></span><br><span class=\"line\">\t\t\t\tD_G_z2 = output_f.mean ().item ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D更新参数</span></span><br><span class=\"line\">\t\t\t\toptimizerG.step ()</span><br><span class=\"line\">\t\t\t\t</span><br><span class=\"line\">\t\t\t<span class=\"comment\">###########################################</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\">##########可视化(可选)#####################</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> args.vis <span class=\"keyword\">and</span> i % args.plot_every == args.plot_every - <span class=\"number\">1</span>:</span><br><span class=\"line\">\t\t\t\tfake = netG (noises)</span><br><span class=\"line\">\t\t\t\tvis.images (fake.detach ().cpu ().numpy () [:<span class=\"number\">64</span>] * <span class=\"number\">0.5</span> + <span class=\"number\">0.5</span>, win=<span class=\"string\">'fixfake'</span>)</span><br><span class=\"line\">\t\t\t\tvis.images (images.data.cpu ().numpy () [:<span class=\"number\">64</span>] * <span class=\"number\">0.5</span> + <span class=\"number\">0.5</span>, win=<span class=\"string\">'real'</span>)</span><br><span class=\"line\">\t\t\t\tvis.plot (<span class=\"string\">'errord'</span>, D_loss.item ())</span><br><span class=\"line\">\t\t\t\tvis.plot (<span class=\"string\">'errorg'</span>, G_loss.item ())</span><br><span class=\"line\">\t\t\t<span class=\"comment\">#######################################</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\">############打印记录###################</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> i % <span class=\"number\">1</span>== <span class=\"number\">0</span>:</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">print</span> (<span class=\"string\">'[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'</span></span><br><span class=\"line\">\t\t\t\t\t   % (epoch, args.max_epoch, i, len (train_loader),</span><br><span class=\"line\">\t\t\t\t\t\t  D_loss.item (), G_loss.item (), D_x, D_G_z1, D_G_z2))</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">########添加画图参数########</span></span><br><span class=\"line\">\t\t\t\tG_losses.append (G_loss.item ())</span><br><span class=\"line\">\t\t\t\tD_losses.append (D_loss.item ())</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">with</span> torch.no_grad ():</span><br><span class=\"line\">\t\t\t\t\tnoises = torch.randn (args.batch_size, args.nz, <span class=\"number\">1</span>, <span class=\"number\">1</span>).to (device)</span><br><span class=\"line\">\t\t\t\t\tfake = netG (noises).detach ().cpu ()</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">import</span> torchvision.utils <span class=\"keyword\">as</span> vutils</span><br><span class=\"line\">\t\t\t\timg_list.append (vutils.make_grid (fake, padding=<span class=\"number\">2</span>, normalize=<span class=\"literal\">True</span>))</span><br><span class=\"line\">\t</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">\t\t<span class=\"comment\">#######################################</span></span><br><span class=\"line\">\t\t<span class=\"comment\">############保存模型###################</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (epoch + <span class=\"number\">1</span>) % args.save_every == <span class=\"number\">0</span>:</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">import</span> torchvision <span class=\"keyword\">as</span> tv</span><br><span class=\"line\">\t\t\t<span class=\"comment\"># 保存模型、图片</span></span><br><span class=\"line\">\t\t\ttv.utils.save_image (fake.data [:<span class=\"number\">64</span>], <span class=\"string\">'%s/%s.png'</span> % (args.save_data, epoch), normalize=<span class=\"literal\">True</span>,range=(<span class=\"number\">-1</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">\t\t\ttorch.save (netD.state_dict (), <span class=\"string\">'checkpoints/netd_%s.pth'</span> % epoch)</span><br><span class=\"line\">\t\t\ttorch.save (netG.state_dict (), <span class=\"string\">'checkpoints/netg_%s.pth'</span> % epoch)</span><br><span class=\"line\">\t\t\tprint(<span class=\"string\">'完成%s的模型保存'</span>%epoch)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">#######################################</span></span><br><span class=\"line\">\t<span class=\"comment\">############画图###################</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> args.plt:</span><br><span class=\"line\">\t\t<span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\">\t\t<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\">\t\t<span class=\"keyword\">import</span> torchvision.utils <span class=\"keyword\">as</span> vutils</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\tplt.figure (figsize=(<span class=\"number\">10</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\">\t\tplt.title (<span class=\"string\">\"GAN\"</span>)</span><br><span class=\"line\">\t\tplt.plot (G_losses, label=<span class=\"string\">\"G\"</span>)</span><br><span class=\"line\">\t\tplt.plot (D_losses, label=<span class=\"string\">\"D\"</span>)</span><br><span class=\"line\">\t\tplt.xlabel (<span class=\"string\">\"迭代次数\"</span>,fontproperties=<span class=\"string\">'SimHei'</span>)</span><br><span class=\"line\">\t\tplt.ylabel (<span class=\"string\">\"损失\"</span>,fontproperties=<span class=\"string\">'SimHei'</span>)</span><br><span class=\"line\">\t\tplt.legend ()</span><br><span class=\"line\">\t\tplt.show ()</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 从数据集加载</span></span><br><span class=\"line\">\t\treal_batch = next (iter (train_dataset))</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 画出真图</span></span><br><span class=\"line\">\t\tplt.figure (figsize=(<span class=\"number\">15</span>, <span class=\"number\">10</span>))</span><br><span class=\"line\">\t\tplt.subplot (<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">\t\tplt.axis (<span class=\"string\">\"off\"</span>)</span><br><span class=\"line\">\t\tplt.title (<span class=\"string\">\"真图\"</span>,fontproperties=<span class=\"string\">'SimHei'</span>)</span><br><span class=\"line\">\t\tplt.imshow (np.transpose (</span><br><span class=\"line\">\t\t\tvutils.make_grid (real_batch [<span class=\"number\">0</span>].to (device) [:<span class=\"number\">64</span>], padding=<span class=\"number\">5</span>, normalize=<span class=\"literal\">True</span>).cpu (),</span><br><span class=\"line\">\t\t\t(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>)))</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 画出假图</span></span><br><span class=\"line\">\t\tplt.subplot (<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">\t\tplt.axis (<span class=\"string\">\"off\"</span>)</span><br><span class=\"line\">\t\tplt.title (<span class=\"string\">\"假图\"</span>,fontproperties=<span class=\"string\">'SimHei'</span>)</span><br><span class=\"line\">\t\tplt.imshow (np.transpose (img_list [<span class=\"number\">-1</span>], (<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>)))</span><br><span class=\"line\">\t\tplt.show ()</span><br><span class=\"line\">\t\t\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@torch.no_grad()#禁用梯度计算</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">test</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">\t<span class=\"comment\">#判断Gpu</span></span><br><span class=\"line\">\tdevice = torch.device (<span class=\"string\">'cuda'</span>) <span class=\"keyword\">if</span> args.cuda <span class=\"keyword\">else</span> torch.device (<span class=\"string\">'cpu'</span>)</span><br><span class=\"line\">\t<span class=\"comment\">#初始化网络</span></span><br><span class=\"line\">\tnetg, netd = netG (args).eval (), netD (args).eval ()</span><br><span class=\"line\">\t<span class=\"comment\">#定义噪声</span></span><br><span class=\"line\">\tnoises = torch.randn (args.batch_size, args.nz, <span class=\"number\">1</span>, <span class=\"number\">1</span>).to (device)</span><br><span class=\"line\">\t<span class=\"comment\">#载入网络</span></span><br><span class=\"line\">\tnetd.load_state_dict (torch.load (<span class=\"string\">'checkpoints/netd_%s.pth'</span>%args.max_epoch))</span><br><span class=\"line\">\tnetg.load_state_dict (torch.load (<span class=\"string\">'checkpoints/netg_%s.pth'</span>%args.max_epoch))</span><br><span class=\"line\">\t<span class=\"comment\">#设备化</span></span><br><span class=\"line\">\tnetd.to (device)</span><br><span class=\"line\">\tnetg.to (device)</span><br><span class=\"line\">\t<span class=\"comment\"># 生成图片，并计算图片在判别器的分数</span></span><br><span class=\"line\">\tfake_img = netg (noises)</span><br><span class=\"line\">\tscores = netd (fake_img).detach ()</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\"># 挑选最好的某几张</span></span><br><span class=\"line\">\tindexs = scores.topk (<span class=\"number\">5</span>) [<span class=\"number\">1</span>]</span><br><span class=\"line\">\tresult = []</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> indexs:</span><br><span class=\"line\">\t\tresult.append (fake_img.data [i])</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\"># 保存图片</span></span><br><span class=\"line\">\t<span class=\"keyword\">import</span> torchvision <span class=\"keyword\">as</span> tv</span><br><span class=\"line\">\ttv.utils.save_image (torch.stack (result), <span class=\"number\">5</span>, normalize=<span class=\"literal\">True</span>, range=(<span class=\"number\">-1</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">###################可视化类##################################</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> visdom</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision <span class=\"keyword\">as</span> tv</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Visualizer</span> <span class=\"params\">()</span>:</span></span><br><span class=\"line\">\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t封装了visdom的基本操作，但是你仍然可以通过`self.vis.function`</span></span><br><span class=\"line\"><span class=\"string\">\t调用原生的visdom接口</span></span><br><span class=\"line\"><span class=\"string\">\t\"\"\"</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span> <span class=\"params\">(self, env=<span class=\"string\">'default'</span>, **kwargs)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">import</span> visdom</span><br><span class=\"line\">\t\tself.vis = visdom.Visdom (env=env, use_incoming_socket=<span class=\"literal\">False</span>, **kwargs)</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 画的第几个数，相当于横座标</span></span><br><span class=\"line\">\t\t<span class=\"comment\"># 保存（’loss',23） 即loss的第23个点</span></span><br><span class=\"line\">\t\tself.index = &#123;&#125;</span><br><span class=\"line\">\t\tself.log_text = <span class=\"string\">''</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">reinit</span> <span class=\"params\">(self, env=<span class=\"string\">'default'</span>, **kwargs)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\t修改visdom的配置</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\tself.vis = visdom.Visdom (env=env, use_incoming_socket=<span class=\"literal\">False</span>, **kwargs)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> self</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">plot_many</span> <span class=\"params\">(self, d)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\t一次plot多个</span></span><br><span class=\"line\"><span class=\"string\">\t\t@params d: dict (name,value) i.e. ('loss',0.11)</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> d.items ():</span><br><span class=\"line\">\t\t\tself.plot (k, v)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">img_many</span> <span class=\"params\">(self, d)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> d.items ():</span><br><span class=\"line\">\t\t\tself.img (k, v)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">plot</span> <span class=\"params\">(self, name, y)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\tself.plot('loss',1.00)</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\tx = self.index.get (name, <span class=\"number\">0</span>)</span><br><span class=\"line\">\t\tself.vis.line (Y=np.array ([y]), X=np.array ([x]),</span><br><span class=\"line\">\t\t\t\t\t   win=(name),</span><br><span class=\"line\">\t\t\t\t\t   opts=dict (title=name),</span><br><span class=\"line\">\t\t\t\t\t   update=<span class=\"literal\">None</span> <span class=\"keyword\">if</span> x == <span class=\"number\">0</span> <span class=\"keyword\">else</span> <span class=\"string\">'append'</span></span><br><span class=\"line\">\t\t\t\t\t   )</span><br><span class=\"line\">\t\tself.index [name] = x + <span class=\"number\">1</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">img</span> <span class=\"params\">(self, name, img_)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\tself.img('input_img',t.Tensor(64,64))</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> len (img_.size ()) &lt; <span class=\"number\">3</span>:</span><br><span class=\"line\">\t\t\timg_ = img_.cpu ().unsqueeze (<span class=\"number\">0</span>)</span><br><span class=\"line\">\t\tself.vis.image (img_.cpu (),</span><br><span class=\"line\">\t\t\t\t\t\twin=(name),</span><br><span class=\"line\">\t\t\t\t\t\topts=dict (title=name)</span><br><span class=\"line\">\t\t\t\t\t\t)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">img_grid_many</span> <span class=\"params\">(self, d)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> d.items ():</span><br><span class=\"line\">\t\t\tself.img_grid (k, v)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">img_grid</span> <span class=\"params\">(self, name, input_3d)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\t一个batch的图片转成一个网格图，i.e. input（36，64，64）</span></span><br><span class=\"line\"><span class=\"string\">\t\t会变成 6*6 的网格图，每个格子大小64*64</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\tself.img (name, tv.utils.make_grid (</span><br><span class=\"line\">\t\t\tinput_3d.cpu () [<span class=\"number\">0</span>].unsqueeze (<span class=\"number\">1</span>).clamp (max=<span class=\"number\">1</span>, min=<span class=\"number\">0</span>)))</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">log</span> <span class=\"params\">(self, info, win=<span class=\"string\">'log_text'</span>)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\tself.log(&#123;'loss':1,'lr':0.0001&#125;)</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\tself.log_text += (<span class=\"string\">'[&#123;time&#125;] &#123;info&#125; &lt;br&gt;'</span>.format (</span><br><span class=\"line\">\t\t\ttime=time.strftime (<span class=\"string\">'%m%d_%H%M%S'</span>),</span><br><span class=\"line\">\t\t\tinfo=info))</span><br><span class=\"line\">\t\tself.vis.text (self.log_text, win=win)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__getattr__</span> <span class=\"params\">(self, name)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> getattr (self.vis, name)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t</span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> args.test:</span><br><span class=\"line\">\t\ttest()</span><br><span class=\"line\">\t<span class=\"keyword\">else</span>:</span><br><span class=\"line\">\t\ttrain()</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>注 :数据集用的cifar-10-batches-py</li>\n<li>结果:</li>\n<li>迭代一次<br><img src=\"https://blog.mviai.com/images/回顾-DCGAN/0.png\" alt></li>\n<li>迭代二次<br><img src=\"https://blog.mviai.com/images/回顾-DCGAN/1.png\" alt></li>\n</ul>\n"},{"title":"回顾-GAN","date":"2018-12-21T05:40:56.000Z","_content":"# 1.GAN 简介：\n[GAN](https://arxiv.org/abs/1406.2661)是2014年放出的一篇开山之作.LSTM作者认为GAN是其他模型的变种,因为他在92年提出PM（PredictabilityMinimization）模型,所以他一直认为GAN是goodfellow在自己PM模型上的改进!哈哈!!\n*********\nGAN的主要灵感来源于博弈论中零和博弈的思想,即一个网络与另一个网络对抗!从而互相提升自己,我以前曾想有没有互助网络!答案是肯定的,遇到在说!\n***********\n# 2. GAN网络结构:\n如图:\n![](https://blog.mviai.com/images/回顾-GAN/net.png)\n\n* 从这图告诉我什么呢?\n    * 首先看到是两个大字 G  D ,G表示生成网络,D表示判别网络!\n    * 然后我们看这类似电路的网络图,我们从左往右看!\n      * (主干线) 在变量空间构造Noise(噪声)→送给→G(生成网络)→生出→假东西\n      * （看G上面） 一堆真东西\n      * 真东西（上面），假东西（G生出来的）交给D（判别网络）给出两个的有多像真东西几率<font color=red>  （当然给出真东西（上面）几率为100%（因为本来就是真的），假东西（G生出来的）几率为0~100%）</font>\n          * 如果很差，就告诉D（生成网络）你不行啊！！，然后D借鉴上次失败重新生成假东西，去骗G！\n          * 就这样持续了。。。。。。世纪，最终达到平衡，这时候G肯定很强大了\n   \n   \n* 然后我们说下平衡核心：\n![](https://blog.mviai.com/images/回顾-GAN/g.jpg)\n    * 然后我们从右到左说下:\n        * 首先想解释E E就是期望(期望就是概率求和)\n还有有就是log,这是逻辑回归那取对数似然出来的\n        * 最右边,G(z):其中z表示噪声.G(z)就表示生成的假东西,D(G(z))就表示D是否要告诉G('你不行')的概率\n            * 下角的 z-Pz表示一个噪声到噪声数据集\n        * 然后是D(x)表示看模板(真东西)是不是真东西概率\n            * 下角的 x-Pdata 表示x到真实数据集(表示要慢慢来,慢慢学,不然容易崩溃哟)\n        * 最后 min max ,你肯定有点不解,不是应该maxG吗? 简单理解下,当G最失败(最小)时候,就是让D看假东西得出概率最大.   (最垃圾时候,D都说你行,那就别说G强大时候了)   即在局部最大中试图找出全局最大\n  \n  \n  \n**************\n# 3.GAN的创新点:\n* 1. 相比较传统的模型，他存在两个不同的网络，而不是单一的网络，并且训练方式采用的是对抗训练方式\n* 2. GAN中G的梯度更新信息自于判别模型D的一个反传梯度。，而不是来自数据样本\n***********\n# 4.GAN的优缺点:\n#### 优点:\n\n●   训练时不需要对隐变量做推断,而且G参数来源于D\n\n●   GAN是一种生成式模型，相比较其他生成模型（玻尔兹曼机和GSNs）只用到了反向传播,而不需要复杂的马尔科夫链\n\n●  相比其他所有模型, GAN可以产生更加清晰，真实的样本\n\n●  GAN采用的是一种无监督的学习方式训练，可以被广泛用在无监督学习和半监督学习领域\n\n●  相比于变分自编码器, GANs没有引入任何决定性偏置( deterministic bias),变分方法引入决定性偏置,因为他们优化对数似然的下界,而不是似然度本身,这看起来导致了VAEs生成的实例比GANs更模糊\n\n●  相比VAE, GANs没有变分下界,如果鉴别器训练良好,那么生成器可以完美的学习到训练样本的分布.换句话说,GANs是渐进一致的,但是VAE是有偏差的\n\n●  GAN应用到一些场景上，比如图片风格迁移，超分辨率，图像补全，去噪，避免了损失函数设计的困难，不管三七二十一，只要有一个的基准，直接上判别器，剩下的就交给对抗训练了。\n#### 缺点:\n●  很不好训练,一是DG的同仇敌忾问题(同步)\n\n●  G参数来源于D,所以很难解释G的模型分布\n\n●  训练GAN需要达到纳什均衡,有时候可以用梯度下降法做到,有时候做不到.我们还没有找到很好的达到纳什均衡的方法,所以训练GAN相比VAE或者PixelRNN是不稳定的,但我认为在实践中它还是比训练玻尔兹曼机稳定的多\n\n●  GAN不适合处理离散形式的数据，比如文本\n\n●  GAN存在训练不稳定、梯度消失、模式崩溃的问题（就是自我欺骗,最后谁也不行!解决在WGAN）\n\n\n# 5.GAN的训练建议:\n注:来自https://github.com/soumith/ganhacks#authors\n** 1.标准化输入**\n* 在-1和1之间标准化图像\n* Tanh作为发电机输出的最后一层\n\n** 2：修改的损失函数**\n在GAN论文中，优化G的损失函数是min (log 1-D)，但实际上人们实际使用max log D\n\n* 因为第一个损失在早期就已经消失了\n* Goodfellow et。al（2014）\n** 在实践中，运作良好：** \n* 训练生成器时调换标签：real = fake，fake = real\n\n\n** 3：使用球形**\n\n* 不要从统一分布中取样\n![](https://blog.mviai.com/images/回顾-GAN/cube.png)\n* 来自高斯分布的样本\n![](https://blog.mviai.com/images/回顾-GAN/sphere.png)\n\n* 进行插值时，通过大圆进行插值，而不是从A点到B点的直线\n* Tom White的采样生成网络参考代码https://github.com/dribnet/plat\n\n\n\n** 4：BatchNorm **\n* 构建真实和假的不同小批次，即每个小批量只需要包含所有真实图像或所有生成的图像。\n* 当batchnorm不是一个选项时，使用实例标准化（对于每个样本，减去平均值并除以标准偏差）。\n![](https://blog.mviai.com/images/回顾-GAN/batchmix.png)\n\n\n** 5：避免稀疏梯度：ReLU，MaxPool**\n* 如果你的梯度稀疏，GANs的稳定性就会受到影响\n* LeakyReLU =优良（G和D都有）\n* 对于Downsampling，使用：Average Pooling，Conv2d+ stride\n* 对于Upsampling，请使用：PixelShuffle,ConvTranspose2d + stride\n    * [PixelShuffle](https：//arxiv.org/abs/1609.05158)\n\n\n** 6：使用平滑和复杂的标签**\n* 标签平滑，即如果你有两个目标标签：Real = 1和Fake = 0，那么对于每个传入的样本，如果它是真的，那么用0.7到1.2之间的随机数替换标签，如果它是假的样本，将其替换为0.0和0.3\n* 使标签对于鉴别器来说是有噪声的：在训练鉴别器时偶尔会调换标签\n\n\n** 7：DCGAN /混合模型** \n* 尽可能使用DCGAN。有用！\n* 如果您无法使用DCGAN并且没有模型稳定，请使用混合型号：KL + GAN或VAE + GAN\n\n\n** 8：使用RL的稳定性技巧** \n* 重复性经验\n    * 保留过去几代的重复缓冲区并偶尔展示它们\n    * 保持G和D过去的检查点，并偶尔交换它们几次迭代\n* 所有稳定性技巧都适用于深层确定性策略梯度( policy gradient)\n* 见Pfau＆Vinyals（2016）\n\n\n** 9：使用Adam Optimizer**\n* optim.Adam规则！\n\n* 使用SGD作为鉴别器，使用Adam作为生成器\n\n\n** 10：尽早跟踪故障**\n* D损失为0：故障模式\n* 检查渐变的规范：如果他们超过100件事情搞砸了\n* 当事情正在发挥作用时，D损失的方差很小，并且随着时间的推移而下降，而且存在巨大的差异和尖峰\n* 如果生成器的损失稳定下降，那就是用垃圾愚弄D（马丁说）\n\n\n** 11：不要通过统计平衡损失（除非你有充分的理由）**\n* 不要试图找到一个（G的数量/ D的数量）计划来解开训练这很难，我们都尝试过。\n\n* 如果您确实尝试过，请采用原则性方法，而不是直觉\n * 例如\n    ```python\n    while lossD > A:\n      train D\n    while lossG > B:\n      train G\n     ```\n     \n     \n** 12：如果你有标签，请使用它们** \n* 如果您有可用的标签，则训练鉴别器以对样品进行分类：辅助GAN\n\n\n** 13：向输入添加噪声，随时间衰减**\n* 在D的输入上添加一些人为噪声（Arjovsky et.al.Huszar，2016）\n    * http://www.inference.vc/instance-noise-a-trick-for-stabilising-gan-training/\n    * https://openreview.net/forum?id=Hk4_qw5xe\n\n* 在生成器的每一层都加入高斯噪声（Zhao et al。EBGAN）\n    * 改进的GAN：OpenAI代码也有它（注释掉）\n\n\n** 14：[notsure]（有时）更多的训练鉴别器**\n* 特别是当你有噪音时\n* 很难找到D迭代次数与G次迭代的时间表\n\n\n** 15：[notsure]批量鉴别 ** \n* 结果喜忧参半\n\n\n** 16：条件GAN中的离散变量**\n* 使用嵌入层\n* 添加为图像的附加通道\n* 保持低维度嵌入和上采样以匹配图像通道大小\n\n\n** 17：在train和test阶段使用G中的Dropouts **\n* 以随机的形式提供噪音（50％）。\n* 在训练和测试时间应用于我们的发电机的几个层\n* https://arxiv.org/pdf/1611.07004v1.pdf\n\n** 18.其他小技巧 **\n* 输入规范化到（-1，1）之间，最后一层的激活函数使用tanh\n* 使用wassertein GAN的损失函数\n* 学习率不要设置太大，初始1e-4可以参考，另外可以随着训练进行不断缩小学习率\n* 给D的网络层增加高斯噪声，相当于是一种正则\n\n\n\n\n****************\n************\n# 6.GANs的发展:\n![](https://blog.mviai.com/images/回顾-GAN/2014.png)\n![](https://blog.mviai.com/images/回顾-GAN/2016.png)\n![](https://blog.mviai.com/images/回顾-GAN/2017.png)\n更多,可以浏览:https://github.com/hindupuravinash\n# 7. pytorch实现:\n** 目录结构:**\n![](https://blog.mviai.com/images/回顾-GAN/m.png)\n* 注:从上到下依次是模型保存文件夹->数据集文件夹->生成文件夹\n\n\n** 设计网络常用计算:**\n* 反卷积:\n![](https://blog.mviai.com/images/回顾-GAN/反conv.png)\n* 卷积:\n ![](https://blog.mviai.com/images/回顾-GAN/conv.png)\n \n \n\n** network.py文件:** \n```python\n'''\n为了简单明了,所以今天还是创最最简单的GAN\n\n首先 有两个网络 分别是G D\n\n'''\nimport torch.nn as nn\n\n#我们首先建立G\nclass G(nn.Module):\n    def __init__(self,args):\n        super(G,self).__init__()\n        ngf = args.ngf  # 生成器feature map数(该层卷积核的个数，有多少个卷积核，经过卷积就会产生多少个feature map)\n        self.G_layer= nn.Sequential(\n                #输入是一个nz维度的噪声，我们可以认为它是一个1 * 1 * nz的feature map\n                nn.ConvTranspose2d(args.nz, 3,5,1,0),# 反conv2d\n                nn.BatchNorm2d (3),\n                nn.LeakyReLU(True),)\n                # 输出大小为3*5*5\n\n    #前向传播\n    def forward(self,x):\n        out=self.G_layer(x)\n        return out\n\n#建立D\nclass D(nn.Module):\n    def __init__(self,args):\n        super(D,self).__init__()\n        ndf = args.ndf  # 生成器feature map数(该层卷积核的个数，有多少个卷积核，经过卷积就会产生多少个feature map)\n        self.D_layer= nn.Sequential(\n                # 输入 3 x 5 x 5,\n                nn.Conv2d(3,ndf, 3),\n                nn.BatchNorm2d (ndf),\n                nn.LeakyReLU (True),\n                #输出 (ndf)*1*1\n                nn.Conv2d (ndf,1,1),\n                # 输出 1*0*0\n                nn.Sigmoid())#告诉D概率\n                \n    #前向传播\n    def forward(self,x):\n        out=self.D_layer(x)\n        return out\n\n\n```\n\n** train.py文件:** \n```python\nimport torch\nimport torch.nn as nn\nimport torchvision.datasets as datasets\nimport torchvision.transforms as  transforms\nfrom torch.autograd import Variable\nimport torch.backends.cudnn as cudnn\n# 工具包\nimport argparse\n# 载入网络\nfrom network import G, D\n\n#############参数设置#############\n####命令行设置########\nparser = argparse.ArgumentParser (description='GAN')  # 导入命令行模块\n# 对关于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明\n#关于训练参数\nparser.add_argument ('--batch_size', type=int, default=12,\n\t\t\t\t\t help='训练batch-size大小 (default: 64)')\nparser.add_argument ('--imageSize', type=int, default=5,\n\t\t\t\t\t help='图片尺寸')\nparser.add_argument ('--max_epoch', type=int, default=5,\n\t\t\t\t\t help='最大迭代数 (default: 5)')\n#关于网络参数\nparser.add_argument ('--lr_g', type=float, default=2e-4,\n\t\t\t\t\t help='生成器学习率 (default: 2e-4)')\nparser.add_argument ('--lr_d', type=float, default=2e-4,\n\t\t\t\t\t help='判别器学习率 (default: 2e-4)')\nparser.add_argument ('--ngf', type=int, default=32,\n\t\t\t\t\t help='生成器feature map数')\nparser.add_argument ('--ndf', type=int, default=32,\n\t\t\t\t\t help='判别器feature map数')\nparser.add_argument ('--d_every', type=int, default=1,\n\t\t\t\t\t help='每几个batch训练一次判别器')\nparser.add_argument ('--g_every', type=int, default=2,\n\t\t\t\t\t help='每几个batch训练一次生成器')\nparser.add_argument ('--nz', type=int, default=5,\n\t\t\t\t\t help='噪声维度')\n\n#关于优化器参数\nparser.add_argument ('--beta1', type=int, default=0.5,\n\t\t\t\t\t help='Adam优化器的beta1参数')\n#路径\nparser.add_argument ('--dataset', default='data/',\n\t\t\t\t\t help='数据集路径')\n\nparser.add_argument ('--save_data',  default='save/',\n\t\t\t\t\t help='保存路径')\n\n#可视化\nparser.add_argument ('--vis', action='store_true',\n\t\t\t\t\t help='是否使用visdom可视化')\nparser.add_argument ('--plot_every', type=int, default=1,\n\t\t\t\t\t help='每间隔_batch，visdom画图一次')\n# 其他\n\nparser.add_argument ('--cuda', action='store_true',\n\t\t\t\t\t help='开启cuda训练')\nparser.add_argument ('--plt', action='store_true',\n\t\t\t\t\t help='开启画图')\nparser.add_argument ('--test', action='store_true',\n\t\t\t\t\t help='开启测试生成')\nparser.add_argument ('--save_every', type=int, default=3,\n\t\t\t\t\t help='几个epoch保存一次模型 (default: 3)')\nparser.add_argument ('--seed', type=int, default=1,\n\t\t\t\t\t help='随机种子 (default: 1)')\nargs = parser.parse_args ()  # 相当于激活命令\n\n\n#训练过程\ndef train():\n\t###############判断gpu#############\n\tdevice = torch.device ('cuda') if args.cuda else torch.device ('cpu')\n\t\n\t####### 为CPU设置种子用于生成随机数，以使得结果是确定的##########\n\ttorch.manual_seed (args.seed)\n\tif args.cuda:\n\t\ttorch.cuda.manual_seed (args.seed)\n\tcudnn.benchmark = True\n\t\n\t#################可视化###############\n\tif args.vis:\n\t\tvis = Visualizer ('GANs')\n\t##########数据转换#####################\n\tdata_transforms = transforms.Compose ([transforms.Scale (args.imageSize),  # 通过调整比例调整大小,会报警\n\t\t\t\t\t\t\t\t\t\t   transforms.CenterCrop (args.imageSize),  # 在中心裁剪给指定大小方形PIL图像\n\t\t\t\t\t\t\t\t\t\t   transforms.ToTensor (),# 转换成pytorch 变量tensor\n\t\t\t\t\t\t\t\t\t\t   transforms.Normalize ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\t###############数据载入################\n\ttrain_dataset = datasets.ImageFolder (root=args.dataset,  # 数据路径目录\n\t\t\t\t\t\t\t\t\t\t  transform=data_transforms)  # 把数据转换成上面约束样子\n\t\n\t# test_dataset = datasets.ImageFolder (root=args.dataset,\n\t# \t\t\t\t\t\t\t\t\t transform=data_transforms)\n\t\n\t##############数据装载###############\n\ttrain_loader = torch.utils.data.DataLoader (dataset=train_dataset,  # 装载数据\n\t\t\t\t\t\t\t\t\t\t\t\tbatch_size=args.batch_size,  # 设置批大小\n\t\t\t\t\t\t\t\t\t\t\t\tshuffle=True)  # 是否随机打乱\n\t# test_loader = torch.utils.data.DataLoader (dataset=test_dataset,\n\t# \t\t\t\t\t\t\t\t\t\t   batch_size=args.batch_size,\n\t# \t\t\t\t\t\t\t\t\t\t   shuffle=True)\n\t\n\t#############模型载入#################\n\tnetG ,netD= G (args),D (args)\n\tnetG.to (device)\n\tnetD.to (device)\n\tprint (netD, netG)\n\t\n\t###############损失函数##################\n\toptimizerD = torch.optim.Adam (netD.parameters (), lr=args.lr_d,betas=(0.5, 0.999))  # Adam优化器\n\toptimizerG = torch.optim.Adam (netG.parameters (), lr=args.lr_g,betas=(0.5, 0.999))  # Adam优化器\n\t###############画图参数保存##################\n\tG_losses = []\n\tD_losses = []\n\timg_list = []\n\t#############训练过程#####################\n\timport tqdm\n\t# Tqdm是一个快速，可扩展的Python进度条，可以在Python\n\t# 长循环中添加一个进度提示信息，用户只需要封装任意的迭代器\n\t# tqdm (iterator)。\n\tfor epoch in range (args.max_epoch):\n\t\tfor i, (images, labels) in tqdm.tqdm(enumerate (train_loader)):  # 枚举出来\n\t\t\t#数据处理\n\t\t\timages = images.to (device)\n\t\t\t# 装箱\n\t\t\timages = Variable (images)\n\t\t\tnoises=Variable(torch.randn(args.batch_size, args.nz, 1, 1).to(device))\n\t\t\t\n\t\t\t#遍历每张图片,并且根据指定的训练机制训练\n\t\t\tif i % args.d_every==0:#满足此条件训练D\n\t\t\t\t#D前向传播\n\t\t\t\toptimizerD.zero_grad ()\n\t\t\t\t#D网络输出\n\t\t\t\toutput_r = netD (images)\n\t\t\t\t#G网络输出\n\t\t\t\tnoises.data.copy_ (torch.randn (args.batch_size, args.nz, 1, 1))\n\t\t\t\tfake = netG (noises).detach ()  # 根据噪声生成假图\n\t\t\t\t#把假图给d\n\t\t\t\toutput_f = netD (fake)\n\t\t\t\t#D的损失\n\t\t\t\t#print(fake.size(),output_f.size(),output_r.size())\n\t\t\t\tD_loss = - torch.mean (torch.log (output_r) + torch.log (1. - output_f))\n\t\t\t\t#D反向传播\n\t\t\t\tD_loss.backward ()\n\t\t\t\t#度量\n\t\t\t\tD_x = output_r.mean ().item ()\n\t\t\t\tD_G_z1 = output_f.mean ().item ()\n\t\t\t\t#D更新参数\n\t\t\t\toptimizerD.step ()\n\t\t\t\t\n\t\t\t\n\t\t\tif i % args.g_every==0:#满足此条件训练G\n\t\t\t\t#G前向传播\n\t\t\t\toptimizerG.zero_grad ()\n\t\t\t\t#G网络输出\n\t\t\t\tfake = netG (noises)  # 根据噪声生成假图\n\t\t\t\t#把假图给G\n\t\t\t\toutput_f = netD (fake)\n\t\t\t\t#G的损失\n\t\t\t\tG_loss = torch.mean (torch.log (1. - output_f))\n\t\t\t\t#G反向传播\n\t\t\t\tG_loss.backward ()\n\t\t\t\t#度量\n\t\t\t\tD_G_z2 = output_f.mean ().item ()\n\t\t\t\t#D更新参数\n\t\t\t\toptimizerG.step ()\n\t\t\t\t\n\t\t\t###########################################\n\t\t\t##########可视化(可选)#####################\n\t\t\tif args.vis and i % args.plot_every == args.plot_every - 1:\n\t\t\t\tfake = netG (noises)\n\t\t\t\tvis.images (fake.detach ().cpu ().numpy () [:64] * 0.5 + 0.5, win='fixfake')\n\t\t\t\tvis.images (images.data.cpu ().numpy () [:64] * 0.5 + 0.5, win='real')\n\t\t\t\tvis.plot ('errord', D_loss.item ())\n\t\t\t\tvis.plot ('errorg', G_loss.item ())\n\t\t\t#######################################\n\t\t\t############打印记录###################\n\t\t\tif i % 1== 0:\n\t\t\t\tprint ('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n\t\t\t\t\t   % (epoch, args.max_epoch, i, len (train_loader),\n\t\t\t\t\t\t  D_loss.item (), G_loss.item (), D_x, D_G_z1, D_G_z2))\n\t\t\t\t########添加画图参数########\n\t\t\t\tG_losses.append (G_loss.item ())\n\t\t\t\tD_losses.append (D_loss.item ())\n\t\t\t\twith torch.no_grad ():\n\t\t\t\t\tnoises = torch.randn (args.batch_size, args.nz, 1, 1).to (device)\n\t\t\t\t\tfake = netG (noises).detach ().cpu ()\n\t\t\t\timport torchvision.utils as vutils\n\t\t\t\timg_list.append (vutils.make_grid (fake, padding=2, normalize=True))\n\t\n\n\n\t\t#######################################\n\t\t############保存模型###################\n\t\n\t\tif (epoch + 1) % args.save_every == 0:\n\t\t\timport torchvision as tv\n\t\t\t# 保存模型、图片\n\t\t\ttv.utils.save_image (fake.data [:64], '%s/%s.png' % (args.save_data, epoch), normalize=True,range=(-1, 1))\n\t\t\ttorch.save (netD.state_dict (), 'checkpoints/netd_%s.pth' % epoch)\n\t\t\ttorch.save (netG.state_dict (), 'checkpoints/netg_%s.pth' % epoch)\n\t\t\tprint('完成%s的模型保存'%epoch)\n\n\t#######################################\n\t############画图###################\n\t\n\tif args.plt:\n\t\timport matplotlib.pyplot as plt\n\t\timport numpy as np\n\t\timport torchvision.utils as vutils\n\t\t\n\t\tplt.figure (figsize=(10, 5))\n\t\tplt.title (\"GAN\")\n\t\tplt.plot (G_losses, label=\"G\")\n\t\tplt.plot (D_losses, label=\"D\")\n\t\tplt.xlabel (\"迭代次数\")\n\t\tplt.ylabel (\"损失\")\n\t\tplt.legend ()\n\t\tplt.show ()\n\t\t\n\t\t# 从数据集加载\n\t\treal_batch = next (iter (train_dataset))\n\t\t\n\t\t# 画出真图\n\t\tplt.figure (figsize=(15, 10))\n\t\tplt.subplot (1, 2, 1)\n\t\tplt.axis (\"off\")\n\t\tplt.title (\"真图\")\n\t\tplt.imshow (np.transpose (\n\t\t\tvutils.make_grid (real_batch [0].to (device) [:64], padding=5, normalize=True).cpu (),\n\t\t\t(1, 2, 0)))\n\t\t\n\t\t# 画出假图\n\t\tplt.subplot (1, 2, 2)\n\t\tplt.axis (\"off\")\n\t\tplt.title (\"假图\")\n\t\tplt.imshow (np.transpose (img_list [-1], (1, 2, 0)))\n\t\tplt.show ()\n\t\t\t\t\n\n\t\t\n\n\t\t\n\n@torch.no_grad()#禁用梯度计算\ndef test():\n\t#判断Gpu\n\tdevice = torch.device ('cuda') if args.cuda else torch.device ('cpu')\n\t#初始化网络\n\tnetg, netd = netG (args).eval (), netD (args).eval ()\n\t#定义噪声\n\tnoises = torch.randn (args.batch_size, args.nz, 1, 1).to (device)\n\t#载入网络\n\tnetd.load_state_dict (torch.load ('checkpoints/netd_%s.pth'%args.max_epoch))\n\tnetg.load_state_dict (torch.load ('checkpoints/netg_%s.pth'%args.max_epoch))\n\t#设备化\n\tnetd.to (device)\n\tnetg.to (device)\n\t# 生成图片，并计算图片在判别器的分数\n\tfake_img = netg (noises)\n\tscores = netd (fake_img).detach ()\n\t\n\t# 挑选最好的某几张\n\tindexs = scores.topk (5) [1]\n\tresult = []\n\tfor i in indexs:\n\t\tresult.append (fake_img.data [i])\n\t\n\t# 保存图片\n\timport torchvision as tv\n\ttv.utils.save_image (torch.stack (result), 5, normalize=True, range=(-1, 1))\n\n\n\n\n\n\n\n\n\n\n\n\t\n\t###################可视化类##################################\nimport visdom\nimport time\nimport torchvision as tv\nimport numpy as np\n\n\nclass Visualizer ():\n\t\"\"\"\n\t封装了visdom的基本操作，但是你仍然可以通过`self.vis.function`\n\t调用原生的visdom接口\n\t\"\"\"\n\t\n\tdef __init__ (self, env='default', **kwargs):\n\t\timport visdom\n\t\tself.vis = visdom.Visdom (env=env, use_incoming_socket=False, **kwargs)\n\t\t\n\t\t# 画的第几个数，相当于横座标\n\t\t# 保存（’loss',23） 即loss的第23个点\n\t\tself.index = {}\n\t\tself.log_text = ''\n\t\n\tdef reinit (self, env='default', **kwargs):\n\t\t\"\"\"\n\t\t修改visdom的配置\n\t\t\"\"\"\n\t\tself.vis = visdom.Visdom (env=env, use_incoming_socket=False, **kwargs)\n\t\treturn self\n\t\n\tdef plot_many (self, d):\n\t\t\"\"\"\n\t\t一次plot多个\n\t\t@params d: dict (name,value) i.e. ('loss',0.11)\n\t\t\"\"\"\n\t\tfor k, v in d.items ():\n\t\t\tself.plot (k, v)\n\t\n\tdef img_many (self, d):\n\t\tfor k, v in d.items ():\n\t\t\tself.img (k, v)\n\t\n\tdef plot (self, name, y):\n\t\t\"\"\"\n\t\tself.plot('loss',1.00)\n\t\t\"\"\"\n\t\tx = self.index.get (name, 0)\n\t\tself.vis.line (Y=np.array ([y]), X=np.array ([x]),\n\t\t\t\t\t   win=(name),\n\t\t\t\t\t   opts=dict (title=name),\n\t\t\t\t\t   update=None if x == 0 else 'append'\n\t\t\t\t\t   )\n\t\tself.index [name] = x + 1\n\t\n\tdef img (self, name, img_):\n\t\t\"\"\"\n\t\tself.img('input_img',t.Tensor(64,64))\n\t\t\"\"\"\n\t\t\n\t\tif len (img_.size ()) < 3:\n\t\t\timg_ = img_.cpu ().unsqueeze (0)\n\t\tself.vis.image (img_.cpu (),\n\t\t\t\t\t\twin=(name),\n\t\t\t\t\t\topts=dict (title=name)\n\t\t\t\t\t\t)\n\t\n\tdef img_grid_many (self, d):\n\t\tfor k, v in d.items ():\n\t\t\tself.img_grid (k, v)\n\t\n\tdef img_grid (self, name, input_3d):\n\t\t\"\"\"\n\t\t一个batch的图片转成一个网格图，i.e. input（36，64，64）\n\t\t会变成 6*6 的网格图，每个格子大小64*64\n\t\t\"\"\"\n\t\tself.img (name, tv.utils.make_grid (\n\t\t\tinput_3d.cpu () [0].unsqueeze (1).clamp (max=1, min=0)))\n\t\n\tdef log (self, info, win='log_text'):\n\t\t\"\"\"\n\t\tself.log({'loss':1,'lr':0.0001})\n\t\t\"\"\"\n\t\t\n\t\tself.log_text += ('[{time}] {info} <br>'.format (\n\t\t\ttime=time.strftime ('%m%d_%H%M%S'),\n\t\t\tinfo=info))\n\t\tself.vis.text (self.log_text, win=win)\n\t\n\tdef __getattr__ (self, name):\n\t\treturn getattr (self.vis, name)\n\t\n\t\n\t\nif __name__ == '__main__':\n\tif args.test:\n\t\ttest()\n\telse:\n\t\ttrain()\n```\n* 输入：\n* 训练:\n```python\npython train.py --cuda --plt\n```\n* 测试:\n```python\npython train.py --cuda --test\n```\n    * `--cuda`表示用GPU\n    *  `--plt`表示启动画图功能\n    *  `--vis` 表示使用visdom可视化\n    *  具体可看参数列表:\n    *  ![](/回顾-GAN/q.png)\n\n** 输出：**\n![](https://blog.mviai.com/images/回顾-GAN/r.png)\n![](https://blog.mviai.com/images/回顾-GAN/r1.png)\n![](https://blog.mviai.com/images/回顾-GAN/r2.png)\n\n** 注：为什么结果这样，为了迎合网络，简单我把图片改的不成样 具体可以看参数设置**\n","source":"_posts/回顾-GAN.md","raw":"---\ntitle: 回顾-GAN\ndate: 2018-12-21 13:40:56\ntags:\n    - GAN\n\ncategories: \n    - 框架\n    - pytorch\n    - GAN\n---\n# 1.GAN 简介：\n[GAN](https://arxiv.org/abs/1406.2661)是2014年放出的一篇开山之作.LSTM作者认为GAN是其他模型的变种,因为他在92年提出PM（PredictabilityMinimization）模型,所以他一直认为GAN是goodfellow在自己PM模型上的改进!哈哈!!\n*********\nGAN的主要灵感来源于博弈论中零和博弈的思想,即一个网络与另一个网络对抗!从而互相提升自己,我以前曾想有没有互助网络!答案是肯定的,遇到在说!\n***********\n# 2. GAN网络结构:\n如图:\n![](https://blog.mviai.com/images/回顾-GAN/net.png)\n\n* 从这图告诉我什么呢?\n    * 首先看到是两个大字 G  D ,G表示生成网络,D表示判别网络!\n    * 然后我们看这类似电路的网络图,我们从左往右看!\n      * (主干线) 在变量空间构造Noise(噪声)→送给→G(生成网络)→生出→假东西\n      * （看G上面） 一堆真东西\n      * 真东西（上面），假东西（G生出来的）交给D（判别网络）给出两个的有多像真东西几率<font color=red>  （当然给出真东西（上面）几率为100%（因为本来就是真的），假东西（G生出来的）几率为0~100%）</font>\n          * 如果很差，就告诉D（生成网络）你不行啊！！，然后D借鉴上次失败重新生成假东西，去骗G！\n          * 就这样持续了。。。。。。世纪，最终达到平衡，这时候G肯定很强大了\n   \n   \n* 然后我们说下平衡核心：\n![](https://blog.mviai.com/images/回顾-GAN/g.jpg)\n    * 然后我们从右到左说下:\n        * 首先想解释E E就是期望(期望就是概率求和)\n还有有就是log,这是逻辑回归那取对数似然出来的\n        * 最右边,G(z):其中z表示噪声.G(z)就表示生成的假东西,D(G(z))就表示D是否要告诉G('你不行')的概率\n            * 下角的 z-Pz表示一个噪声到噪声数据集\n        * 然后是D(x)表示看模板(真东西)是不是真东西概率\n            * 下角的 x-Pdata 表示x到真实数据集(表示要慢慢来,慢慢学,不然容易崩溃哟)\n        * 最后 min max ,你肯定有点不解,不是应该maxG吗? 简单理解下,当G最失败(最小)时候,就是让D看假东西得出概率最大.   (最垃圾时候,D都说你行,那就别说G强大时候了)   即在局部最大中试图找出全局最大\n  \n  \n  \n**************\n# 3.GAN的创新点:\n* 1. 相比较传统的模型，他存在两个不同的网络，而不是单一的网络，并且训练方式采用的是对抗训练方式\n* 2. GAN中G的梯度更新信息自于判别模型D的一个反传梯度。，而不是来自数据样本\n***********\n# 4.GAN的优缺点:\n#### 优点:\n\n●   训练时不需要对隐变量做推断,而且G参数来源于D\n\n●   GAN是一种生成式模型，相比较其他生成模型（玻尔兹曼机和GSNs）只用到了反向传播,而不需要复杂的马尔科夫链\n\n●  相比其他所有模型, GAN可以产生更加清晰，真实的样本\n\n●  GAN采用的是一种无监督的学习方式训练，可以被广泛用在无监督学习和半监督学习领域\n\n●  相比于变分自编码器, GANs没有引入任何决定性偏置( deterministic bias),变分方法引入决定性偏置,因为他们优化对数似然的下界,而不是似然度本身,这看起来导致了VAEs生成的实例比GANs更模糊\n\n●  相比VAE, GANs没有变分下界,如果鉴别器训练良好,那么生成器可以完美的学习到训练样本的分布.换句话说,GANs是渐进一致的,但是VAE是有偏差的\n\n●  GAN应用到一些场景上，比如图片风格迁移，超分辨率，图像补全，去噪，避免了损失函数设计的困难，不管三七二十一，只要有一个的基准，直接上判别器，剩下的就交给对抗训练了。\n#### 缺点:\n●  很不好训练,一是DG的同仇敌忾问题(同步)\n\n●  G参数来源于D,所以很难解释G的模型分布\n\n●  训练GAN需要达到纳什均衡,有时候可以用梯度下降法做到,有时候做不到.我们还没有找到很好的达到纳什均衡的方法,所以训练GAN相比VAE或者PixelRNN是不稳定的,但我认为在实践中它还是比训练玻尔兹曼机稳定的多\n\n●  GAN不适合处理离散形式的数据，比如文本\n\n●  GAN存在训练不稳定、梯度消失、模式崩溃的问题（就是自我欺骗,最后谁也不行!解决在WGAN）\n\n\n# 5.GAN的训练建议:\n注:来自https://github.com/soumith/ganhacks#authors\n** 1.标准化输入**\n* 在-1和1之间标准化图像\n* Tanh作为发电机输出的最后一层\n\n** 2：修改的损失函数**\n在GAN论文中，优化G的损失函数是min (log 1-D)，但实际上人们实际使用max log D\n\n* 因为第一个损失在早期就已经消失了\n* Goodfellow et。al（2014）\n** 在实践中，运作良好：** \n* 训练生成器时调换标签：real = fake，fake = real\n\n\n** 3：使用球形**\n\n* 不要从统一分布中取样\n![](https://blog.mviai.com/images/回顾-GAN/cube.png)\n* 来自高斯分布的样本\n![](https://blog.mviai.com/images/回顾-GAN/sphere.png)\n\n* 进行插值时，通过大圆进行插值，而不是从A点到B点的直线\n* Tom White的采样生成网络参考代码https://github.com/dribnet/plat\n\n\n\n** 4：BatchNorm **\n* 构建真实和假的不同小批次，即每个小批量只需要包含所有真实图像或所有生成的图像。\n* 当batchnorm不是一个选项时，使用实例标准化（对于每个样本，减去平均值并除以标准偏差）。\n![](https://blog.mviai.com/images/回顾-GAN/batchmix.png)\n\n\n** 5：避免稀疏梯度：ReLU，MaxPool**\n* 如果你的梯度稀疏，GANs的稳定性就会受到影响\n* LeakyReLU =优良（G和D都有）\n* 对于Downsampling，使用：Average Pooling，Conv2d+ stride\n* 对于Upsampling，请使用：PixelShuffle,ConvTranspose2d + stride\n    * [PixelShuffle](https：//arxiv.org/abs/1609.05158)\n\n\n** 6：使用平滑和复杂的标签**\n* 标签平滑，即如果你有两个目标标签：Real = 1和Fake = 0，那么对于每个传入的样本，如果它是真的，那么用0.7到1.2之间的随机数替换标签，如果它是假的样本，将其替换为0.0和0.3\n* 使标签对于鉴别器来说是有噪声的：在训练鉴别器时偶尔会调换标签\n\n\n** 7：DCGAN /混合模型** \n* 尽可能使用DCGAN。有用！\n* 如果您无法使用DCGAN并且没有模型稳定，请使用混合型号：KL + GAN或VAE + GAN\n\n\n** 8：使用RL的稳定性技巧** \n* 重复性经验\n    * 保留过去几代的重复缓冲区并偶尔展示它们\n    * 保持G和D过去的检查点，并偶尔交换它们几次迭代\n* 所有稳定性技巧都适用于深层确定性策略梯度( policy gradient)\n* 见Pfau＆Vinyals（2016）\n\n\n** 9：使用Adam Optimizer**\n* optim.Adam规则！\n\n* 使用SGD作为鉴别器，使用Adam作为生成器\n\n\n** 10：尽早跟踪故障**\n* D损失为0：故障模式\n* 检查渐变的规范：如果他们超过100件事情搞砸了\n* 当事情正在发挥作用时，D损失的方差很小，并且随着时间的推移而下降，而且存在巨大的差异和尖峰\n* 如果生成器的损失稳定下降，那就是用垃圾愚弄D（马丁说）\n\n\n** 11：不要通过统计平衡损失（除非你有充分的理由）**\n* 不要试图找到一个（G的数量/ D的数量）计划来解开训练这很难，我们都尝试过。\n\n* 如果您确实尝试过，请采用原则性方法，而不是直觉\n * 例如\n    ```python\n    while lossD > A:\n      train D\n    while lossG > B:\n      train G\n     ```\n     \n     \n** 12：如果你有标签，请使用它们** \n* 如果您有可用的标签，则训练鉴别器以对样品进行分类：辅助GAN\n\n\n** 13：向输入添加噪声，随时间衰减**\n* 在D的输入上添加一些人为噪声（Arjovsky et.al.Huszar，2016）\n    * http://www.inference.vc/instance-noise-a-trick-for-stabilising-gan-training/\n    * https://openreview.net/forum?id=Hk4_qw5xe\n\n* 在生成器的每一层都加入高斯噪声（Zhao et al。EBGAN）\n    * 改进的GAN：OpenAI代码也有它（注释掉）\n\n\n** 14：[notsure]（有时）更多的训练鉴别器**\n* 特别是当你有噪音时\n* 很难找到D迭代次数与G次迭代的时间表\n\n\n** 15：[notsure]批量鉴别 ** \n* 结果喜忧参半\n\n\n** 16：条件GAN中的离散变量**\n* 使用嵌入层\n* 添加为图像的附加通道\n* 保持低维度嵌入和上采样以匹配图像通道大小\n\n\n** 17：在train和test阶段使用G中的Dropouts **\n* 以随机的形式提供噪音（50％）。\n* 在训练和测试时间应用于我们的发电机的几个层\n* https://arxiv.org/pdf/1611.07004v1.pdf\n\n** 18.其他小技巧 **\n* 输入规范化到（-1，1）之间，最后一层的激活函数使用tanh\n* 使用wassertein GAN的损失函数\n* 学习率不要设置太大，初始1e-4可以参考，另外可以随着训练进行不断缩小学习率\n* 给D的网络层增加高斯噪声，相当于是一种正则\n\n\n\n\n****************\n************\n# 6.GANs的发展:\n![](https://blog.mviai.com/images/回顾-GAN/2014.png)\n![](https://blog.mviai.com/images/回顾-GAN/2016.png)\n![](https://blog.mviai.com/images/回顾-GAN/2017.png)\n更多,可以浏览:https://github.com/hindupuravinash\n# 7. pytorch实现:\n** 目录结构:**\n![](https://blog.mviai.com/images/回顾-GAN/m.png)\n* 注:从上到下依次是模型保存文件夹->数据集文件夹->生成文件夹\n\n\n** 设计网络常用计算:**\n* 反卷积:\n![](https://blog.mviai.com/images/回顾-GAN/反conv.png)\n* 卷积:\n ![](https://blog.mviai.com/images/回顾-GAN/conv.png)\n \n \n\n** network.py文件:** \n```python\n'''\n为了简单明了,所以今天还是创最最简单的GAN\n\n首先 有两个网络 分别是G D\n\n'''\nimport torch.nn as nn\n\n#我们首先建立G\nclass G(nn.Module):\n    def __init__(self,args):\n        super(G,self).__init__()\n        ngf = args.ngf  # 生成器feature map数(该层卷积核的个数，有多少个卷积核，经过卷积就会产生多少个feature map)\n        self.G_layer= nn.Sequential(\n                #输入是一个nz维度的噪声，我们可以认为它是一个1 * 1 * nz的feature map\n                nn.ConvTranspose2d(args.nz, 3,5,1,0),# 反conv2d\n                nn.BatchNorm2d (3),\n                nn.LeakyReLU(True),)\n                # 输出大小为3*5*5\n\n    #前向传播\n    def forward(self,x):\n        out=self.G_layer(x)\n        return out\n\n#建立D\nclass D(nn.Module):\n    def __init__(self,args):\n        super(D,self).__init__()\n        ndf = args.ndf  # 生成器feature map数(该层卷积核的个数，有多少个卷积核，经过卷积就会产生多少个feature map)\n        self.D_layer= nn.Sequential(\n                # 输入 3 x 5 x 5,\n                nn.Conv2d(3,ndf, 3),\n                nn.BatchNorm2d (ndf),\n                nn.LeakyReLU (True),\n                #输出 (ndf)*1*1\n                nn.Conv2d (ndf,1,1),\n                # 输出 1*0*0\n                nn.Sigmoid())#告诉D概率\n                \n    #前向传播\n    def forward(self,x):\n        out=self.D_layer(x)\n        return out\n\n\n```\n\n** train.py文件:** \n```python\nimport torch\nimport torch.nn as nn\nimport torchvision.datasets as datasets\nimport torchvision.transforms as  transforms\nfrom torch.autograd import Variable\nimport torch.backends.cudnn as cudnn\n# 工具包\nimport argparse\n# 载入网络\nfrom network import G, D\n\n#############参数设置#############\n####命令行设置########\nparser = argparse.ArgumentParser (description='GAN')  # 导入命令行模块\n# 对关于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明\n#关于训练参数\nparser.add_argument ('--batch_size', type=int, default=12,\n\t\t\t\t\t help='训练batch-size大小 (default: 64)')\nparser.add_argument ('--imageSize', type=int, default=5,\n\t\t\t\t\t help='图片尺寸')\nparser.add_argument ('--max_epoch', type=int, default=5,\n\t\t\t\t\t help='最大迭代数 (default: 5)')\n#关于网络参数\nparser.add_argument ('--lr_g', type=float, default=2e-4,\n\t\t\t\t\t help='生成器学习率 (default: 2e-4)')\nparser.add_argument ('--lr_d', type=float, default=2e-4,\n\t\t\t\t\t help='判别器学习率 (default: 2e-4)')\nparser.add_argument ('--ngf', type=int, default=32,\n\t\t\t\t\t help='生成器feature map数')\nparser.add_argument ('--ndf', type=int, default=32,\n\t\t\t\t\t help='判别器feature map数')\nparser.add_argument ('--d_every', type=int, default=1,\n\t\t\t\t\t help='每几个batch训练一次判别器')\nparser.add_argument ('--g_every', type=int, default=2,\n\t\t\t\t\t help='每几个batch训练一次生成器')\nparser.add_argument ('--nz', type=int, default=5,\n\t\t\t\t\t help='噪声维度')\n\n#关于优化器参数\nparser.add_argument ('--beta1', type=int, default=0.5,\n\t\t\t\t\t help='Adam优化器的beta1参数')\n#路径\nparser.add_argument ('--dataset', default='data/',\n\t\t\t\t\t help='数据集路径')\n\nparser.add_argument ('--save_data',  default='save/',\n\t\t\t\t\t help='保存路径')\n\n#可视化\nparser.add_argument ('--vis', action='store_true',\n\t\t\t\t\t help='是否使用visdom可视化')\nparser.add_argument ('--plot_every', type=int, default=1,\n\t\t\t\t\t help='每间隔_batch，visdom画图一次')\n# 其他\n\nparser.add_argument ('--cuda', action='store_true',\n\t\t\t\t\t help='开启cuda训练')\nparser.add_argument ('--plt', action='store_true',\n\t\t\t\t\t help='开启画图')\nparser.add_argument ('--test', action='store_true',\n\t\t\t\t\t help='开启测试生成')\nparser.add_argument ('--save_every', type=int, default=3,\n\t\t\t\t\t help='几个epoch保存一次模型 (default: 3)')\nparser.add_argument ('--seed', type=int, default=1,\n\t\t\t\t\t help='随机种子 (default: 1)')\nargs = parser.parse_args ()  # 相当于激活命令\n\n\n#训练过程\ndef train():\n\t###############判断gpu#############\n\tdevice = torch.device ('cuda') if args.cuda else torch.device ('cpu')\n\t\n\t####### 为CPU设置种子用于生成随机数，以使得结果是确定的##########\n\ttorch.manual_seed (args.seed)\n\tif args.cuda:\n\t\ttorch.cuda.manual_seed (args.seed)\n\tcudnn.benchmark = True\n\t\n\t#################可视化###############\n\tif args.vis:\n\t\tvis = Visualizer ('GANs')\n\t##########数据转换#####################\n\tdata_transforms = transforms.Compose ([transforms.Scale (args.imageSize),  # 通过调整比例调整大小,会报警\n\t\t\t\t\t\t\t\t\t\t   transforms.CenterCrop (args.imageSize),  # 在中心裁剪给指定大小方形PIL图像\n\t\t\t\t\t\t\t\t\t\t   transforms.ToTensor (),# 转换成pytorch 变量tensor\n\t\t\t\t\t\t\t\t\t\t   transforms.Normalize ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\t###############数据载入################\n\ttrain_dataset = datasets.ImageFolder (root=args.dataset,  # 数据路径目录\n\t\t\t\t\t\t\t\t\t\t  transform=data_transforms)  # 把数据转换成上面约束样子\n\t\n\t# test_dataset = datasets.ImageFolder (root=args.dataset,\n\t# \t\t\t\t\t\t\t\t\t transform=data_transforms)\n\t\n\t##############数据装载###############\n\ttrain_loader = torch.utils.data.DataLoader (dataset=train_dataset,  # 装载数据\n\t\t\t\t\t\t\t\t\t\t\t\tbatch_size=args.batch_size,  # 设置批大小\n\t\t\t\t\t\t\t\t\t\t\t\tshuffle=True)  # 是否随机打乱\n\t# test_loader = torch.utils.data.DataLoader (dataset=test_dataset,\n\t# \t\t\t\t\t\t\t\t\t\t   batch_size=args.batch_size,\n\t# \t\t\t\t\t\t\t\t\t\t   shuffle=True)\n\t\n\t#############模型载入#################\n\tnetG ,netD= G (args),D (args)\n\tnetG.to (device)\n\tnetD.to (device)\n\tprint (netD, netG)\n\t\n\t###############损失函数##################\n\toptimizerD = torch.optim.Adam (netD.parameters (), lr=args.lr_d,betas=(0.5, 0.999))  # Adam优化器\n\toptimizerG = torch.optim.Adam (netG.parameters (), lr=args.lr_g,betas=(0.5, 0.999))  # Adam优化器\n\t###############画图参数保存##################\n\tG_losses = []\n\tD_losses = []\n\timg_list = []\n\t#############训练过程#####################\n\timport tqdm\n\t# Tqdm是一个快速，可扩展的Python进度条，可以在Python\n\t# 长循环中添加一个进度提示信息，用户只需要封装任意的迭代器\n\t# tqdm (iterator)。\n\tfor epoch in range (args.max_epoch):\n\t\tfor i, (images, labels) in tqdm.tqdm(enumerate (train_loader)):  # 枚举出来\n\t\t\t#数据处理\n\t\t\timages = images.to (device)\n\t\t\t# 装箱\n\t\t\timages = Variable (images)\n\t\t\tnoises=Variable(torch.randn(args.batch_size, args.nz, 1, 1).to(device))\n\t\t\t\n\t\t\t#遍历每张图片,并且根据指定的训练机制训练\n\t\t\tif i % args.d_every==0:#满足此条件训练D\n\t\t\t\t#D前向传播\n\t\t\t\toptimizerD.zero_grad ()\n\t\t\t\t#D网络输出\n\t\t\t\toutput_r = netD (images)\n\t\t\t\t#G网络输出\n\t\t\t\tnoises.data.copy_ (torch.randn (args.batch_size, args.nz, 1, 1))\n\t\t\t\tfake = netG (noises).detach ()  # 根据噪声生成假图\n\t\t\t\t#把假图给d\n\t\t\t\toutput_f = netD (fake)\n\t\t\t\t#D的损失\n\t\t\t\t#print(fake.size(),output_f.size(),output_r.size())\n\t\t\t\tD_loss = - torch.mean (torch.log (output_r) + torch.log (1. - output_f))\n\t\t\t\t#D反向传播\n\t\t\t\tD_loss.backward ()\n\t\t\t\t#度量\n\t\t\t\tD_x = output_r.mean ().item ()\n\t\t\t\tD_G_z1 = output_f.mean ().item ()\n\t\t\t\t#D更新参数\n\t\t\t\toptimizerD.step ()\n\t\t\t\t\n\t\t\t\n\t\t\tif i % args.g_every==0:#满足此条件训练G\n\t\t\t\t#G前向传播\n\t\t\t\toptimizerG.zero_grad ()\n\t\t\t\t#G网络输出\n\t\t\t\tfake = netG (noises)  # 根据噪声生成假图\n\t\t\t\t#把假图给G\n\t\t\t\toutput_f = netD (fake)\n\t\t\t\t#G的损失\n\t\t\t\tG_loss = torch.mean (torch.log (1. - output_f))\n\t\t\t\t#G反向传播\n\t\t\t\tG_loss.backward ()\n\t\t\t\t#度量\n\t\t\t\tD_G_z2 = output_f.mean ().item ()\n\t\t\t\t#D更新参数\n\t\t\t\toptimizerG.step ()\n\t\t\t\t\n\t\t\t###########################################\n\t\t\t##########可视化(可选)#####################\n\t\t\tif args.vis and i % args.plot_every == args.plot_every - 1:\n\t\t\t\tfake = netG (noises)\n\t\t\t\tvis.images (fake.detach ().cpu ().numpy () [:64] * 0.5 + 0.5, win='fixfake')\n\t\t\t\tvis.images (images.data.cpu ().numpy () [:64] * 0.5 + 0.5, win='real')\n\t\t\t\tvis.plot ('errord', D_loss.item ())\n\t\t\t\tvis.plot ('errorg', G_loss.item ())\n\t\t\t#######################################\n\t\t\t############打印记录###################\n\t\t\tif i % 1== 0:\n\t\t\t\tprint ('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n\t\t\t\t\t   % (epoch, args.max_epoch, i, len (train_loader),\n\t\t\t\t\t\t  D_loss.item (), G_loss.item (), D_x, D_G_z1, D_G_z2))\n\t\t\t\t########添加画图参数########\n\t\t\t\tG_losses.append (G_loss.item ())\n\t\t\t\tD_losses.append (D_loss.item ())\n\t\t\t\twith torch.no_grad ():\n\t\t\t\t\tnoises = torch.randn (args.batch_size, args.nz, 1, 1).to (device)\n\t\t\t\t\tfake = netG (noises).detach ().cpu ()\n\t\t\t\timport torchvision.utils as vutils\n\t\t\t\timg_list.append (vutils.make_grid (fake, padding=2, normalize=True))\n\t\n\n\n\t\t#######################################\n\t\t############保存模型###################\n\t\n\t\tif (epoch + 1) % args.save_every == 0:\n\t\t\timport torchvision as tv\n\t\t\t# 保存模型、图片\n\t\t\ttv.utils.save_image (fake.data [:64], '%s/%s.png' % (args.save_data, epoch), normalize=True,range=(-1, 1))\n\t\t\ttorch.save (netD.state_dict (), 'checkpoints/netd_%s.pth' % epoch)\n\t\t\ttorch.save (netG.state_dict (), 'checkpoints/netg_%s.pth' % epoch)\n\t\t\tprint('完成%s的模型保存'%epoch)\n\n\t#######################################\n\t############画图###################\n\t\n\tif args.plt:\n\t\timport matplotlib.pyplot as plt\n\t\timport numpy as np\n\t\timport torchvision.utils as vutils\n\t\t\n\t\tplt.figure (figsize=(10, 5))\n\t\tplt.title (\"GAN\")\n\t\tplt.plot (G_losses, label=\"G\")\n\t\tplt.plot (D_losses, label=\"D\")\n\t\tplt.xlabel (\"迭代次数\")\n\t\tplt.ylabel (\"损失\")\n\t\tplt.legend ()\n\t\tplt.show ()\n\t\t\n\t\t# 从数据集加载\n\t\treal_batch = next (iter (train_dataset))\n\t\t\n\t\t# 画出真图\n\t\tplt.figure (figsize=(15, 10))\n\t\tplt.subplot (1, 2, 1)\n\t\tplt.axis (\"off\")\n\t\tplt.title (\"真图\")\n\t\tplt.imshow (np.transpose (\n\t\t\tvutils.make_grid (real_batch [0].to (device) [:64], padding=5, normalize=True).cpu (),\n\t\t\t(1, 2, 0)))\n\t\t\n\t\t# 画出假图\n\t\tplt.subplot (1, 2, 2)\n\t\tplt.axis (\"off\")\n\t\tplt.title (\"假图\")\n\t\tplt.imshow (np.transpose (img_list [-1], (1, 2, 0)))\n\t\tplt.show ()\n\t\t\t\t\n\n\t\t\n\n\t\t\n\n@torch.no_grad()#禁用梯度计算\ndef test():\n\t#判断Gpu\n\tdevice = torch.device ('cuda') if args.cuda else torch.device ('cpu')\n\t#初始化网络\n\tnetg, netd = netG (args).eval (), netD (args).eval ()\n\t#定义噪声\n\tnoises = torch.randn (args.batch_size, args.nz, 1, 1).to (device)\n\t#载入网络\n\tnetd.load_state_dict (torch.load ('checkpoints/netd_%s.pth'%args.max_epoch))\n\tnetg.load_state_dict (torch.load ('checkpoints/netg_%s.pth'%args.max_epoch))\n\t#设备化\n\tnetd.to (device)\n\tnetg.to (device)\n\t# 生成图片，并计算图片在判别器的分数\n\tfake_img = netg (noises)\n\tscores = netd (fake_img).detach ()\n\t\n\t# 挑选最好的某几张\n\tindexs = scores.topk (5) [1]\n\tresult = []\n\tfor i in indexs:\n\t\tresult.append (fake_img.data [i])\n\t\n\t# 保存图片\n\timport torchvision as tv\n\ttv.utils.save_image (torch.stack (result), 5, normalize=True, range=(-1, 1))\n\n\n\n\n\n\n\n\n\n\n\n\t\n\t###################可视化类##################################\nimport visdom\nimport time\nimport torchvision as tv\nimport numpy as np\n\n\nclass Visualizer ():\n\t\"\"\"\n\t封装了visdom的基本操作，但是你仍然可以通过`self.vis.function`\n\t调用原生的visdom接口\n\t\"\"\"\n\t\n\tdef __init__ (self, env='default', **kwargs):\n\t\timport visdom\n\t\tself.vis = visdom.Visdom (env=env, use_incoming_socket=False, **kwargs)\n\t\t\n\t\t# 画的第几个数，相当于横座标\n\t\t# 保存（’loss',23） 即loss的第23个点\n\t\tself.index = {}\n\t\tself.log_text = ''\n\t\n\tdef reinit (self, env='default', **kwargs):\n\t\t\"\"\"\n\t\t修改visdom的配置\n\t\t\"\"\"\n\t\tself.vis = visdom.Visdom (env=env, use_incoming_socket=False, **kwargs)\n\t\treturn self\n\t\n\tdef plot_many (self, d):\n\t\t\"\"\"\n\t\t一次plot多个\n\t\t@params d: dict (name,value) i.e. ('loss',0.11)\n\t\t\"\"\"\n\t\tfor k, v in d.items ():\n\t\t\tself.plot (k, v)\n\t\n\tdef img_many (self, d):\n\t\tfor k, v in d.items ():\n\t\t\tself.img (k, v)\n\t\n\tdef plot (self, name, y):\n\t\t\"\"\"\n\t\tself.plot('loss',1.00)\n\t\t\"\"\"\n\t\tx = self.index.get (name, 0)\n\t\tself.vis.line (Y=np.array ([y]), X=np.array ([x]),\n\t\t\t\t\t   win=(name),\n\t\t\t\t\t   opts=dict (title=name),\n\t\t\t\t\t   update=None if x == 0 else 'append'\n\t\t\t\t\t   )\n\t\tself.index [name] = x + 1\n\t\n\tdef img (self, name, img_):\n\t\t\"\"\"\n\t\tself.img('input_img',t.Tensor(64,64))\n\t\t\"\"\"\n\t\t\n\t\tif len (img_.size ()) < 3:\n\t\t\timg_ = img_.cpu ().unsqueeze (0)\n\t\tself.vis.image (img_.cpu (),\n\t\t\t\t\t\twin=(name),\n\t\t\t\t\t\topts=dict (title=name)\n\t\t\t\t\t\t)\n\t\n\tdef img_grid_many (self, d):\n\t\tfor k, v in d.items ():\n\t\t\tself.img_grid (k, v)\n\t\n\tdef img_grid (self, name, input_3d):\n\t\t\"\"\"\n\t\t一个batch的图片转成一个网格图，i.e. input（36，64，64）\n\t\t会变成 6*6 的网格图，每个格子大小64*64\n\t\t\"\"\"\n\t\tself.img (name, tv.utils.make_grid (\n\t\t\tinput_3d.cpu () [0].unsqueeze (1).clamp (max=1, min=0)))\n\t\n\tdef log (self, info, win='log_text'):\n\t\t\"\"\"\n\t\tself.log({'loss':1,'lr':0.0001})\n\t\t\"\"\"\n\t\t\n\t\tself.log_text += ('[{time}] {info} <br>'.format (\n\t\t\ttime=time.strftime ('%m%d_%H%M%S'),\n\t\t\tinfo=info))\n\t\tself.vis.text (self.log_text, win=win)\n\t\n\tdef __getattr__ (self, name):\n\t\treturn getattr (self.vis, name)\n\t\n\t\n\t\nif __name__ == '__main__':\n\tif args.test:\n\t\ttest()\n\telse:\n\t\ttrain()\n```\n* 输入：\n* 训练:\n```python\npython train.py --cuda --plt\n```\n* 测试:\n```python\npython train.py --cuda --test\n```\n    * `--cuda`表示用GPU\n    *  `--plt`表示启动画图功能\n    *  `--vis` 表示使用visdom可视化\n    *  具体可看参数列表:\n    *  ![](/回顾-GAN/q.png)\n\n** 输出：**\n![](https://blog.mviai.com/images/回顾-GAN/r.png)\n![](https://blog.mviai.com/images/回顾-GAN/r1.png)\n![](https://blog.mviai.com/images/回顾-GAN/r2.png)\n\n** 注：为什么结果这样，为了迎合网络，简单我把图片改的不成样 具体可以看参数设置**\n","slug":"回顾-GAN","published":1,"updated":"2021-07-26T09:58:02.578Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m1z001gigta4u7diq7b","content":"<h1 id=\"1-GAN-简介：\"><a href=\"#1-GAN-简介：\" class=\"headerlink\" title=\"1.GAN 简介：\"></a>1.GAN 简介：</h1><p><a href=\"https://arxiv.org/abs/1406.2661\" target=\"_blank\" rel=\"noopener\">GAN</a>是2014年放出的一篇开山之作.LSTM作者认为GAN是其他模型的变种,因为他在92年提出PM（PredictabilityMinimization）模型,所以他一直认为GAN是goodfellow在自己PM模型上的改进!哈哈!!</p>\n<hr>\n<p>GAN的主要灵感来源于博弈论中零和博弈的思想,即一个网络与另一个网络对抗!从而互相提升自己,我以前曾想有没有互助网络!答案是肯定的,遇到在说!</p>\n<hr>\n<h1 id=\"2-GAN网络结构\"><a href=\"#2-GAN网络结构\" class=\"headerlink\" title=\"2. GAN网络结构:\"></a>2. GAN网络结构:</h1><p>如图:<br><img src=\"https://blog.mviai.com/images/回顾-GAN/net.png\" alt></p>\n<ul>\n<li>从这图告诉我什么呢?<ul>\n<li>首先看到是两个大字 G  D ,G表示生成网络,D表示判别网络!</li>\n<li>然后我们看这类似电路的网络图,我们从左往右看!<ul>\n<li>(主干线) 在变量空间构造Noise(噪声)→送给→G(生成网络)→生出→假东西</li>\n<li>（看G上面） 一堆真东西</li>\n<li>真东西（上面），假东西（G生出来的）交给D（判别网络）给出两个的有多像真东西几率<font color=\"red\">  （当然给出真东西（上面）几率为100%（因为本来就是真的），假东西（G生出来的）几率为0~100%）</font><ul>\n<li>如果很差，就告诉D（生成网络）你不行啊！！，然后D借鉴上次失败重新生成假东西，去骗G！</li>\n<li>就这样持续了。。。。。。世纪，最终达到平衡，这时候G肯定很强大了</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>然后我们说下平衡核心：<br><img src=\"https://blog.mviai.com/images/回顾-GAN/g.jpg\" alt><ul>\n<li>然后我们从右到左说下:<ul>\n<li>首先想解释E E就是期望(期望就是概率求和)<br>还有有就是log,这是逻辑回归那取对数似然出来的</li>\n<li>最右边,G(z):其中z表示噪声.G(z)就表示生成的假东西,D(G(z))就表示D是否要告诉G(‘你不行’)的概率<ul>\n<li>下角的 z-Pz表示一个噪声到噪声数据集</li>\n</ul>\n</li>\n<li>然后是D(x)表示看模板(真东西)是不是真东西概率<ul>\n<li>下角的 x-Pdata 表示x到真实数据集(表示要慢慢来,慢慢学,不然容易崩溃哟)</li>\n</ul>\n</li>\n<li>最后 min max ,你肯定有点不解,不是应该maxG吗? 简单理解下,当G最失败(最小)时候,就是让D看假东西得出概率最大.   (最垃圾时候,D都说你行,那就别说G强大时候了)   即在局部最大中试图找出全局最大</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h1 id=\"3-GAN的创新点\"><a href=\"#3-GAN的创新点\" class=\"headerlink\" title=\"3.GAN的创新点:\"></a>3.GAN的创新点:</h1><ul>\n<li><ol>\n<li>相比较传统的模型，他存在两个不同的网络，而不是单一的网络，并且训练方式采用的是对抗训练方式</li>\n</ol>\n</li>\n<li><ol start=\"2\">\n<li>GAN中G的梯度更新信息自于判别模型D的一个反传梯度。，而不是来自数据样本</li>\n</ol>\n</li>\n</ul>\n<hr>\n<h1 id=\"4-GAN的优缺点\"><a href=\"#4-GAN的优缺点\" class=\"headerlink\" title=\"4.GAN的优缺点:\"></a>4.GAN的优缺点:</h1><h4 id=\"优点\"><a href=\"#优点\" class=\"headerlink\" title=\"优点:\"></a>优点:</h4><p>●   训练时不需要对隐变量做推断,而且G参数来源于D</p>\n<p>●   GAN是一种生成式模型，相比较其他生成模型（玻尔兹曼机和GSNs）只用到了反向传播,而不需要复杂的马尔科夫链</p>\n<p>●  相比其他所有模型, GAN可以产生更加清晰，真实的样本</p>\n<p>●  GAN采用的是一种无监督的学习方式训练，可以被广泛用在无监督学习和半监督学习领域</p>\n<p>●  相比于变分自编码器, GANs没有引入任何决定性偏置( deterministic bias),变分方法引入决定性偏置,因为他们优化对数似然的下界,而不是似然度本身,这看起来导致了VAEs生成的实例比GANs更模糊</p>\n<p>●  相比VAE, GANs没有变分下界,如果鉴别器训练良好,那么生成器可以完美的学习到训练样本的分布.换句话说,GANs是渐进一致的,但是VAE是有偏差的</p>\n<p>●  GAN应用到一些场景上，比如图片风格迁移，超分辨率，图像补全，去噪，避免了损失函数设计的困难，不管三七二十一，只要有一个的基准，直接上判别器，剩下的就交给对抗训练了。</p>\n<h4 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点:\"></a>缺点:</h4><p>●  很不好训练,一是DG的同仇敌忾问题(同步)</p>\n<p>●  G参数来源于D,所以很难解释G的模型分布</p>\n<p>●  训练GAN需要达到纳什均衡,有时候可以用梯度下降法做到,有时候做不到.我们还没有找到很好的达到纳什均衡的方法,所以训练GAN相比VAE或者PixelRNN是不稳定的,但我认为在实践中它还是比训练玻尔兹曼机稳定的多</p>\n<p>●  GAN不适合处理离散形式的数据，比如文本</p>\n<p>●  GAN存在训练不稳定、梯度消失、模式崩溃的问题（就是自我欺骗,最后谁也不行!解决在WGAN）</p>\n<h1 id=\"5-GAN的训练建议\"><a href=\"#5-GAN的训练建议\" class=\"headerlink\" title=\"5.GAN的训练建议:\"></a>5.GAN的训练建议:</h1><p>注:来自<a href=\"https://github.com/soumith/ganhacks#authors\" target=\"_blank\" rel=\"noopener\">https://github.com/soumith/ganhacks#authors</a><br><strong> 1.标准化输入</strong></p>\n<ul>\n<li>在-1和1之间标准化图像</li>\n<li>Tanh作为发电机输出的最后一层</li>\n</ul>\n<p><strong> 2：修改的损失函数</strong><br>在GAN论文中，优化G的损失函数是min (log 1-D)，但实际上人们实际使用max log D</p>\n<ul>\n<li>因为第一个损失在早期就已经消失了</li>\n<li>Goodfellow et。al（2014）<br><strong> 在实践中，运作良好：</strong> </li>\n<li>训练生成器时调换标签：real = fake，fake = real</li>\n</ul>\n<p><strong> 3：使用球形</strong></p>\n<ul>\n<li>不要从统一分布中取样<br><img src=\"https://blog.mviai.com/images/回顾-GAN/cube.png\" alt></li>\n<li><p>来自高斯分布的样本<br><img src=\"https://blog.mviai.com/images/回顾-GAN/sphere.png\" alt></p>\n</li>\n<li><p>进行插值时，通过大圆进行插值，而不是从A点到B点的直线</p>\n</li>\n<li>Tom White的采样生成网络参考代码<a href=\"https://github.com/dribnet/plat\" target=\"_blank\" rel=\"noopener\">https://github.com/dribnet/plat</a></li>\n</ul>\n<p><strong> 4：BatchNorm </strong></p>\n<ul>\n<li>构建真实和假的不同小批次，即每个小批量只需要包含所有真实图像或所有生成的图像。</li>\n<li>当batchnorm不是一个选项时，使用实例标准化（对于每个样本，减去平均值并除以标准偏差）。<br><img src=\"https://blog.mviai.com/images/回顾-GAN/batchmix.png\" alt></li>\n</ul>\n<p><strong> 5：避免稀疏梯度：ReLU，MaxPool</strong></p>\n<ul>\n<li>如果你的梯度稀疏，GANs的稳定性就会受到影响</li>\n<li>LeakyReLU =优良（G和D都有）</li>\n<li>对于Downsampling，使用：Average Pooling，Conv2d+ stride</li>\n<li>对于Upsampling，请使用：PixelShuffle,ConvTranspose2d + stride<ul>\n<li><a href=\"https：//arxiv.org/abs/1609.05158\">PixelShuffle</a></li>\n</ul>\n</li>\n</ul>\n<p><strong> 6：使用平滑和复杂的标签</strong></p>\n<ul>\n<li>标签平滑，即如果你有两个目标标签：Real = 1和Fake = 0，那么对于每个传入的样本，如果它是真的，那么用0.7到1.2之间的随机数替换标签，如果它是假的样本，将其替换为0.0和0.3</li>\n<li>使标签对于鉴别器来说是有噪声的：在训练鉴别器时偶尔会调换标签</li>\n</ul>\n<p><strong> 7：DCGAN /混合模型</strong> </p>\n<ul>\n<li>尽可能使用DCGAN。有用！</li>\n<li>如果您无法使用DCGAN并且没有模型稳定，请使用混合型号：KL + GAN或VAE + GAN</li>\n</ul>\n<p><strong> 8：使用RL的稳定性技巧</strong> </p>\n<ul>\n<li>重复性经验<ul>\n<li>保留过去几代的重复缓冲区并偶尔展示它们</li>\n<li>保持G和D过去的检查点，并偶尔交换它们几次迭代</li>\n</ul>\n</li>\n<li>所有稳定性技巧都适用于深层确定性策略梯度( policy gradient)</li>\n<li>见Pfau＆Vinyals（2016）</li>\n</ul>\n<p><strong> 9：使用Adam Optimizer</strong></p>\n<ul>\n<li><p>optim.Adam规则！</p>\n</li>\n<li><p>使用SGD作为鉴别器，使用Adam作为生成器</p>\n</li>\n</ul>\n<p><strong> 10：尽早跟踪故障</strong></p>\n<ul>\n<li>D损失为0：故障模式</li>\n<li>检查渐变的规范：如果他们超过100件事情搞砸了</li>\n<li>当事情正在发挥作用时，D损失的方差很小，并且随着时间的推移而下降，而且存在巨大的差异和尖峰</li>\n<li>如果生成器的损失稳定下降，那就是用垃圾愚弄D（马丁说）</li>\n</ul>\n<p><strong> 11：不要通过统计平衡损失（除非你有充分的理由）</strong></p>\n<ul>\n<li><p>不要试图找到一个（G的数量/ D的数量）计划来解开训练这很难，我们都尝试过。</p>\n</li>\n<li><p>如果您确实尝试过，请采用原则性方法，而不是直觉</p>\n<ul>\n<li>例如<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">while</span> lossD &gt; A:</span><br><span class=\"line\">  train D</span><br><span class=\"line\"><span class=\"keyword\">while</span> lossG &gt; B:</span><br><span class=\"line\">  train G</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<p><strong> 12：如果你有标签，请使用它们</strong> </p>\n<ul>\n<li>如果您有可用的标签，则训练鉴别器以对样品进行分类：辅助GAN</li>\n</ul>\n<p><strong> 13：向输入添加噪声，随时间衰减</strong></p>\n<ul>\n<li><p>在D的输入上添加一些人为噪声（Arjovsky et.al.Huszar，2016）</p>\n<ul>\n<li><a href=\"http://www.inference.vc/instance-noise-a-trick-for-stabilising-gan-training/\" target=\"_blank\" rel=\"noopener\">http://www.inference.vc/instance-noise-a-trick-for-stabilising-gan-training/</a></li>\n<li><a href=\"https://openreview.net/forum?id=Hk4_qw5xe\" target=\"_blank\" rel=\"noopener\">https://openreview.net/forum?id=Hk4_qw5xe</a></li>\n</ul>\n</li>\n<li><p>在生成器的每一层都加入高斯噪声（Zhao et al。EBGAN）</p>\n<ul>\n<li>改进的GAN：OpenAI代码也有它（注释掉）</li>\n</ul>\n</li>\n</ul>\n<p><strong> 14：[notsure]（有时）更多的训练鉴别器</strong></p>\n<ul>\n<li>特别是当你有噪音时</li>\n<li>很难找到D迭代次数与G次迭代的时间表</li>\n</ul>\n<p><strong> 15：[notsure]批量鉴别 </strong> </p>\n<ul>\n<li>结果喜忧参半</li>\n</ul>\n<p><strong> 16：条件GAN中的离散变量</strong></p>\n<ul>\n<li>使用嵌入层</li>\n<li>添加为图像的附加通道</li>\n<li>保持低维度嵌入和上采样以匹配图像通道大小</li>\n</ul>\n<p><strong> 17：在train和test阶段使用G中的Dropouts </strong></p>\n<ul>\n<li>以随机的形式提供噪音（50％）。</li>\n<li>在训练和测试时间应用于我们的发电机的几个层</li>\n<li><a href=\"https://arxiv.org/pdf/1611.07004v1.pdf\" target=\"_blank\" rel=\"noopener\">https://arxiv.org/pdf/1611.07004v1.pdf</a></li>\n</ul>\n<p><strong> 18.其他小技巧 </strong></p>\n<ul>\n<li>输入规范化到（-1，1）之间，最后一层的激活函数使用tanh</li>\n<li>使用wassertein GAN的损失函数</li>\n<li>学习率不要设置太大，初始1e-4可以参考，另外可以随着训练进行不断缩小学习率</li>\n<li>给D的网络层增加高斯噪声，相当于是一种正则</li>\n</ul>\n<hr>\n<hr>\n<h1 id=\"6-GANs的发展\"><a href=\"#6-GANs的发展\" class=\"headerlink\" title=\"6.GANs的发展:\"></a>6.GANs的发展:</h1><p><img src=\"https://blog.mviai.com/images/回顾-GAN/2014.png\" alt><br><img src=\"https://blog.mviai.com/images/回顾-GAN/2016.png\" alt><br><img src=\"https://blog.mviai.com/images/回顾-GAN/2017.png\" alt><br>更多,可以浏览:<a href=\"https://github.com/hindupuravinash\" target=\"_blank\" rel=\"noopener\">https://github.com/hindupuravinash</a></p>\n<h1 id=\"7-pytorch实现\"><a href=\"#7-pytorch实现\" class=\"headerlink\" title=\"7. pytorch实现:\"></a>7. pytorch实现:</h1><p><strong> 目录结构:</strong><br><img src=\"https://blog.mviai.com/images/回顾-GAN/m.png\" alt></p>\n<ul>\n<li>注:从上到下依次是模型保存文件夹-&gt;数据集文件夹-&gt;生成文件夹</li>\n</ul>\n<p><strong> 设计网络常用计算:</strong></p>\n<ul>\n<li>反卷积:<br><img src=\"https://blog.mviai.com/images/回顾-GAN/反conv.png\" alt></li>\n<li>卷积:<br><img src=\"https://blog.mviai.com/images/回顾-GAN/conv.png\" alt></li>\n</ul>\n<p><strong> network.py文件:</strong><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">为了简单明了,所以今天还是创最最简单的GAN</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">首先 有两个网络 分别是G D</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#我们首先建立G</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">G</span><span class=\"params\">(nn.Module)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self,args)</span>:</span></span><br><span class=\"line\">        super(G,self).__init__()</span><br><span class=\"line\">        ngf = args.ngf  <span class=\"comment\"># 生成器feature map数(该层卷积核的个数，有多少个卷积核，经过卷积就会产生多少个feature map)</span></span><br><span class=\"line\">        self.G_layer= nn.Sequential(</span><br><span class=\"line\">                <span class=\"comment\">#输入是一个nz维度的噪声，我们可以认为它是一个1 * 1 * nz的feature map</span></span><br><span class=\"line\">                nn.ConvTranspose2d(args.nz, <span class=\"number\">3</span>,<span class=\"number\">5</span>,<span class=\"number\">1</span>,<span class=\"number\">0</span>),<span class=\"comment\"># 反conv2d</span></span><br><span class=\"line\">                nn.BatchNorm2d (<span class=\"number\">3</span>),</span><br><span class=\"line\">                nn.LeakyReLU(<span class=\"literal\">True</span>),)</span><br><span class=\"line\">                <span class=\"comment\"># 输出大小为3*5*5</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">#前向传播</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self,x)</span>:</span></span><br><span class=\"line\">        out=self.G_layer(x)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#建立D</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">D</span><span class=\"params\">(nn.Module)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self,args)</span>:</span></span><br><span class=\"line\">        super(D,self).__init__()</span><br><span class=\"line\">        ndf = args.ndf  <span class=\"comment\"># 生成器feature map数(该层卷积核的个数，有多少个卷积核，经过卷积就会产生多少个feature map)</span></span><br><span class=\"line\">        self.D_layer= nn.Sequential(</span><br><span class=\"line\">                <span class=\"comment\"># 输入 3 x 5 x 5,</span></span><br><span class=\"line\">                nn.Conv2d(<span class=\"number\">3</span>,ndf, <span class=\"number\">3</span>),</span><br><span class=\"line\">                nn.BatchNorm2d (ndf),</span><br><span class=\"line\">                nn.LeakyReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">                <span class=\"comment\">#输出 (ndf)*1*1</span></span><br><span class=\"line\">                nn.Conv2d (ndf,<span class=\"number\">1</span>,<span class=\"number\">1</span>),</span><br><span class=\"line\">                <span class=\"comment\"># 输出 1*0*0</span></span><br><span class=\"line\">                nn.Sigmoid())<span class=\"comment\">#告诉D概率</span></span><br><span class=\"line\">                </span><br><span class=\"line\">    <span class=\"comment\">#前向传播</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self,x)</span>:</span></span><br><span class=\"line\">        out=self.D_layer(x)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br></pre></td></tr></table></figure></p>\n<p><strong> train.py文件:</strong><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br><span class=\"line\">277</span><br><span class=\"line\">278</span><br><span class=\"line\">279</span><br><span class=\"line\">280</span><br><span class=\"line\">281</span><br><span class=\"line\">282</span><br><span class=\"line\">283</span><br><span class=\"line\">284</span><br><span class=\"line\">285</span><br><span class=\"line\">286</span><br><span class=\"line\">287</span><br><span class=\"line\">288</span><br><span class=\"line\">289</span><br><span class=\"line\">290</span><br><span class=\"line\">291</span><br><span class=\"line\">292</span><br><span class=\"line\">293</span><br><span class=\"line\">294</span><br><span class=\"line\">295</span><br><span class=\"line\">296</span><br><span class=\"line\">297</span><br><span class=\"line\">298</span><br><span class=\"line\">299</span><br><span class=\"line\">300</span><br><span class=\"line\">301</span><br><span class=\"line\">302</span><br><span class=\"line\">303</span><br><span class=\"line\">304</span><br><span class=\"line\">305</span><br><span class=\"line\">306</span><br><span class=\"line\">307</span><br><span class=\"line\">308</span><br><span class=\"line\">309</span><br><span class=\"line\">310</span><br><span class=\"line\">311</span><br><span class=\"line\">312</span><br><span class=\"line\">313</span><br><span class=\"line\">314</span><br><span class=\"line\">315</span><br><span class=\"line\">316</span><br><span class=\"line\">317</span><br><span class=\"line\">318</span><br><span class=\"line\">319</span><br><span class=\"line\">320</span><br><span class=\"line\">321</span><br><span class=\"line\">322</span><br><span class=\"line\">323</span><br><span class=\"line\">324</span><br><span class=\"line\">325</span><br><span class=\"line\">326</span><br><span class=\"line\">327</span><br><span class=\"line\">328</span><br><span class=\"line\">329</span><br><span class=\"line\">330</span><br><span class=\"line\">331</span><br><span class=\"line\">332</span><br><span class=\"line\">333</span><br><span class=\"line\">334</span><br><span class=\"line\">335</span><br><span class=\"line\">336</span><br><span class=\"line\">337</span><br><span class=\"line\">338</span><br><span class=\"line\">339</span><br><span class=\"line\">340</span><br><span class=\"line\">341</span><br><span class=\"line\">342</span><br><span class=\"line\">343</span><br><span class=\"line\">344</span><br><span class=\"line\">345</span><br><span class=\"line\">346</span><br><span class=\"line\">347</span><br><span class=\"line\">348</span><br><span class=\"line\">349</span><br><span class=\"line\">350</span><br><span class=\"line\">351</span><br><span class=\"line\">352</span><br><span class=\"line\">353</span><br><span class=\"line\">354</span><br><span class=\"line\">355</span><br><span class=\"line\">356</span><br><span class=\"line\">357</span><br><span class=\"line\">358</span><br><span class=\"line\">359</span><br><span class=\"line\">360</span><br><span class=\"line\">361</span><br><span class=\"line\">362</span><br><span class=\"line\">363</span><br><span class=\"line\">364</span><br><span class=\"line\">365</span><br><span class=\"line\">366</span><br><span class=\"line\">367</span><br><span class=\"line\">368</span><br><span class=\"line\">369</span><br><span class=\"line\">370</span><br><span class=\"line\">371</span><br><span class=\"line\">372</span><br><span class=\"line\">373</span><br><span class=\"line\">374</span><br><span class=\"line\">375</span><br><span class=\"line\">376</span><br><span class=\"line\">377</span><br><span class=\"line\">378</span><br><span class=\"line\">379</span><br><span class=\"line\">380</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision.datasets <span class=\"keyword\">as</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision.transforms <span class=\"keyword\">as</span>  transforms</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.backends.cudnn <span class=\"keyword\">as</span> cudnn</span><br><span class=\"line\"><span class=\"comment\"># 工具包</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> argparse</span><br><span class=\"line\"><span class=\"comment\"># 载入网络</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> network <span class=\"keyword\">import</span> G, D</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############参数设置#############</span></span><br><span class=\"line\"><span class=\"comment\">####命令行设置########</span></span><br><span class=\"line\">parser = argparse.ArgumentParser (description=<span class=\"string\">'GAN'</span>)  <span class=\"comment\"># 导入命令行模块</span></span><br><span class=\"line\"><span class=\"comment\"># 对关于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明</span></span><br><span class=\"line\"><span class=\"comment\">#关于训练参数</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--batch_size'</span>, type=int, default=<span class=\"number\">12</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'训练batch-size大小 (default: 64)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--imageSize'</span>, type=int, default=<span class=\"number\">5</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'图片尺寸'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--max_epoch'</span>, type=int, default=<span class=\"number\">5</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'最大迭代数 (default: 5)'</span>)</span><br><span class=\"line\"><span class=\"comment\">#关于网络参数</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--lr_g'</span>, type=float, default=<span class=\"number\">2e-4</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'生成器学习率 (default: 2e-4)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--lr_d'</span>, type=float, default=<span class=\"number\">2e-4</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'判别器学习率 (default: 2e-4)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--ngf'</span>, type=int, default=<span class=\"number\">32</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'生成器feature map数'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--ndf'</span>, type=int, default=<span class=\"number\">32</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'判别器feature map数'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--d_every'</span>, type=int, default=<span class=\"number\">1</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'每几个batch训练一次判别器'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--g_every'</span>, type=int, default=<span class=\"number\">2</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'每几个batch训练一次生成器'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--nz'</span>, type=int, default=<span class=\"number\">5</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'噪声维度'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#关于优化器参数</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--beta1'</span>, type=int, default=<span class=\"number\">0.5</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'Adam优化器的beta1参数'</span>)</span><br><span class=\"line\"><span class=\"comment\">#路径</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--dataset'</span>, default=<span class=\"string\">'data/'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'数据集路径'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--save_data'</span>,  default=<span class=\"string\">'save/'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'保存路径'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#可视化</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--vis'</span>, action=<span class=\"string\">'store_true'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'是否使用visdom可视化'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--plot_every'</span>, type=int, default=<span class=\"number\">1</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'每间隔_batch，visdom画图一次'</span>)</span><br><span class=\"line\"><span class=\"comment\"># 其他</span></span><br><span class=\"line\"></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--cuda'</span>, action=<span class=\"string\">'store_true'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'开启cuda训练'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--plt'</span>, action=<span class=\"string\">'store_true'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'开启画图'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--test'</span>, action=<span class=\"string\">'store_true'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'开启测试生成'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--save_every'</span>, type=int, default=<span class=\"number\">3</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'几个epoch保存一次模型 (default: 3)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--seed'</span>, type=int, default=<span class=\"number\">1</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'随机种子 (default: 1)'</span>)</span><br><span class=\"line\">args = parser.parse_args ()  <span class=\"comment\"># 相当于激活命令</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#训练过程</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">train</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">\t<span class=\"comment\">###############判断gpu#############</span></span><br><span class=\"line\">\tdevice = torch.device (<span class=\"string\">'cuda'</span>) <span class=\"keyword\">if</span> args.cuda <span class=\"keyword\">else</span> torch.device (<span class=\"string\">'cpu'</span>)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">####### 为CPU设置种子用于生成随机数，以使得结果是确定的##########</span></span><br><span class=\"line\">\ttorch.manual_seed (args.seed)</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> args.cuda:</span><br><span class=\"line\">\t\ttorch.cuda.manual_seed (args.seed)</span><br><span class=\"line\">\tcudnn.benchmark = <span class=\"literal\">True</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">#################可视化###############</span></span><br><span class=\"line\">\t<span class=\"keyword\">if</span> args.vis:</span><br><span class=\"line\">\t\tvis = Visualizer (<span class=\"string\">'GANs'</span>)</span><br><span class=\"line\">\t<span class=\"comment\">##########数据转换#####################</span></span><br><span class=\"line\">\tdata_transforms = transforms.Compose ([transforms.Scale (args.imageSize),  <span class=\"comment\"># 通过调整比例调整大小,会报警</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   transforms.CenterCrop (args.imageSize),  <span class=\"comment\"># 在中心裁剪给指定大小方形PIL图像</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   transforms.ToTensor (),<span class=\"comment\"># 转换成pytorch 变量tensor</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   transforms.Normalize ((<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>), (<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>))])</span><br><span class=\"line\">\t<span class=\"comment\">###############数据载入################</span></span><br><span class=\"line\">\ttrain_dataset = datasets.ImageFolder (root=args.dataset,  <span class=\"comment\"># 数据路径目录</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t  transform=data_transforms)  <span class=\"comment\"># 把数据转换成上面约束样子</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\"># test_dataset = datasets.ImageFolder (root=args.dataset,</span></span><br><span class=\"line\">\t<span class=\"comment\"># \t\t\t\t\t\t\t\t\t transform=data_transforms)</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">##############数据装载###############</span></span><br><span class=\"line\">\ttrain_loader = torch.utils.data.DataLoader (dataset=train_dataset,  <span class=\"comment\"># 装载数据</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\t\tbatch_size=args.batch_size,  <span class=\"comment\"># 设置批大小</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\t\tshuffle=<span class=\"literal\">True</span>)  <span class=\"comment\"># 是否随机打乱</span></span><br><span class=\"line\">\t<span class=\"comment\"># test_loader = torch.utils.data.DataLoader (dataset=test_dataset,</span></span><br><span class=\"line\">\t<span class=\"comment\"># \t\t\t\t\t\t\t\t\t\t   batch_size=args.batch_size,</span></span><br><span class=\"line\">\t<span class=\"comment\"># \t\t\t\t\t\t\t\t\t\t   shuffle=True)</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">#############模型载入#################</span></span><br><span class=\"line\">\tnetG ,netD= G (args),D (args)</span><br><span class=\"line\">\tnetG.to (device)</span><br><span class=\"line\">\tnetD.to (device)</span><br><span class=\"line\">\t<span class=\"keyword\">print</span> (netD, netG)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">###############损失函数##################</span></span><br><span class=\"line\">\toptimizerD = torch.optim.Adam (netD.parameters (), lr=args.lr_d,betas=(<span class=\"number\">0.5</span>, <span class=\"number\">0.999</span>))  <span class=\"comment\"># Adam优化器</span></span><br><span class=\"line\">\toptimizerG = torch.optim.Adam (netG.parameters (), lr=args.lr_g,betas=(<span class=\"number\">0.5</span>, <span class=\"number\">0.999</span>))  <span class=\"comment\"># Adam优化器</span></span><br><span class=\"line\">\t<span class=\"comment\">###############画图参数保存##################</span></span><br><span class=\"line\">\tG_losses = []</span><br><span class=\"line\">\tD_losses = []</span><br><span class=\"line\">\timg_list = []</span><br><span class=\"line\">\t<span class=\"comment\">#############训练过程#####################</span></span><br><span class=\"line\">\t<span class=\"keyword\">import</span> tqdm</span><br><span class=\"line\">\t<span class=\"comment\"># Tqdm是一个快速，可扩展的Python进度条，可以在Python</span></span><br><span class=\"line\">\t<span class=\"comment\"># 长循环中添加一个进度提示信息，用户只需要封装任意的迭代器</span></span><br><span class=\"line\">\t<span class=\"comment\"># tqdm (iterator)。</span></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range (args.max_epoch):</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> i, (images, labels) <span class=\"keyword\">in</span> tqdm.tqdm(enumerate (train_loader)):  <span class=\"comment\"># 枚举出来</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\">#数据处理</span></span><br><span class=\"line\">\t\t\timages = images.to (device)</span><br><span class=\"line\">\t\t\t<span class=\"comment\"># 装箱</span></span><br><span class=\"line\">\t\t\timages = Variable (images)</span><br><span class=\"line\">\t\t\tnoises=Variable(torch.randn(args.batch_size, args.nz, <span class=\"number\">1</span>, <span class=\"number\">1</span>).to(device))</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\t<span class=\"comment\">#遍历每张图片,并且根据指定的训练机制训练</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> i % args.d_every==<span class=\"number\">0</span>:<span class=\"comment\">#满足此条件训练D</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D前向传播</span></span><br><span class=\"line\">\t\t\t\toptimizerD.zero_grad ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D网络输出</span></span><br><span class=\"line\">\t\t\t\toutput_r = netD (images)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G网络输出</span></span><br><span class=\"line\">\t\t\t\tnoises.data.copy_ (torch.randn (args.batch_size, args.nz, <span class=\"number\">1</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">\t\t\t\tfake = netG (noises).detach ()  <span class=\"comment\"># 根据噪声生成假图</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#把假图给d</span></span><br><span class=\"line\">\t\t\t\toutput_f = netD (fake)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D的损失</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#print(fake.size(),output_f.size(),output_r.size())</span></span><br><span class=\"line\">\t\t\t\tD_loss = - torch.mean (torch.log (output_r) + torch.log (<span class=\"number\">1.</span> - output_f))</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D反向传播</span></span><br><span class=\"line\">\t\t\t\tD_loss.backward ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#度量</span></span><br><span class=\"line\">\t\t\t\tD_x = output_r.mean ().item ()</span><br><span class=\"line\">\t\t\t\tD_G_z1 = output_f.mean ().item ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D更新参数</span></span><br><span class=\"line\">\t\t\t\toptimizerD.step ()</span><br><span class=\"line\">\t\t\t\t</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> i % args.g_every==<span class=\"number\">0</span>:<span class=\"comment\">#满足此条件训练G</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G前向传播</span></span><br><span class=\"line\">\t\t\t\toptimizerG.zero_grad ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G网络输出</span></span><br><span class=\"line\">\t\t\t\tfake = netG (noises)  <span class=\"comment\"># 根据噪声生成假图</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#把假图给G</span></span><br><span class=\"line\">\t\t\t\toutput_f = netD (fake)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G的损失</span></span><br><span class=\"line\">\t\t\t\tG_loss = torch.mean (torch.log (<span class=\"number\">1.</span> - output_f))</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G反向传播</span></span><br><span class=\"line\">\t\t\t\tG_loss.backward ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#度量</span></span><br><span class=\"line\">\t\t\t\tD_G_z2 = output_f.mean ().item ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D更新参数</span></span><br><span class=\"line\">\t\t\t\toptimizerG.step ()</span><br><span class=\"line\">\t\t\t\t</span><br><span class=\"line\">\t\t\t<span class=\"comment\">###########################################</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\">##########可视化(可选)#####################</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> args.vis <span class=\"keyword\">and</span> i % args.plot_every == args.plot_every - <span class=\"number\">1</span>:</span><br><span class=\"line\">\t\t\t\tfake = netG (noises)</span><br><span class=\"line\">\t\t\t\tvis.images (fake.detach ().cpu ().numpy () [:<span class=\"number\">64</span>] * <span class=\"number\">0.5</span> + <span class=\"number\">0.5</span>, win=<span class=\"string\">'fixfake'</span>)</span><br><span class=\"line\">\t\t\t\tvis.images (images.data.cpu ().numpy () [:<span class=\"number\">64</span>] * <span class=\"number\">0.5</span> + <span class=\"number\">0.5</span>, win=<span class=\"string\">'real'</span>)</span><br><span class=\"line\">\t\t\t\tvis.plot (<span class=\"string\">'errord'</span>, D_loss.item ())</span><br><span class=\"line\">\t\t\t\tvis.plot (<span class=\"string\">'errorg'</span>, G_loss.item ())</span><br><span class=\"line\">\t\t\t<span class=\"comment\">#######################################</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\">############打印记录###################</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> i % <span class=\"number\">1</span>== <span class=\"number\">0</span>:</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">print</span> (<span class=\"string\">'[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'</span></span><br><span class=\"line\">\t\t\t\t\t   % (epoch, args.max_epoch, i, len (train_loader),</span><br><span class=\"line\">\t\t\t\t\t\t  D_loss.item (), G_loss.item (), D_x, D_G_z1, D_G_z2))</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">########添加画图参数########</span></span><br><span class=\"line\">\t\t\t\tG_losses.append (G_loss.item ())</span><br><span class=\"line\">\t\t\t\tD_losses.append (D_loss.item ())</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">with</span> torch.no_grad ():</span><br><span class=\"line\">\t\t\t\t\tnoises = torch.randn (args.batch_size, args.nz, <span class=\"number\">1</span>, <span class=\"number\">1</span>).to (device)</span><br><span class=\"line\">\t\t\t\t\tfake = netG (noises).detach ().cpu ()</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">import</span> torchvision.utils <span class=\"keyword\">as</span> vutils</span><br><span class=\"line\">\t\t\t\timg_list.append (vutils.make_grid (fake, padding=<span class=\"number\">2</span>, normalize=<span class=\"literal\">True</span>))</span><br><span class=\"line\">\t</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">\t\t<span class=\"comment\">#######################################</span></span><br><span class=\"line\">\t\t<span class=\"comment\">############保存模型###################</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (epoch + <span class=\"number\">1</span>) % args.save_every == <span class=\"number\">0</span>:</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">import</span> torchvision <span class=\"keyword\">as</span> tv</span><br><span class=\"line\">\t\t\t<span class=\"comment\"># 保存模型、图片</span></span><br><span class=\"line\">\t\t\ttv.utils.save_image (fake.data [:<span class=\"number\">64</span>], <span class=\"string\">'%s/%s.png'</span> % (args.save_data, epoch), normalize=<span class=\"literal\">True</span>,range=(<span class=\"number\">-1</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">\t\t\ttorch.save (netD.state_dict (), <span class=\"string\">'checkpoints/netd_%s.pth'</span> % epoch)</span><br><span class=\"line\">\t\t\ttorch.save (netG.state_dict (), <span class=\"string\">'checkpoints/netg_%s.pth'</span> % epoch)</span><br><span class=\"line\">\t\t\tprint(<span class=\"string\">'完成%s的模型保存'</span>%epoch)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">#######################################</span></span><br><span class=\"line\">\t<span class=\"comment\">############画图###################</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> args.plt:</span><br><span class=\"line\">\t\t<span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\">\t\t<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\">\t\t<span class=\"keyword\">import</span> torchvision.utils <span class=\"keyword\">as</span> vutils</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\tplt.figure (figsize=(<span class=\"number\">10</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\">\t\tplt.title (<span class=\"string\">\"GAN\"</span>)</span><br><span class=\"line\">\t\tplt.plot (G_losses, label=<span class=\"string\">\"G\"</span>)</span><br><span class=\"line\">\t\tplt.plot (D_losses, label=<span class=\"string\">\"D\"</span>)</span><br><span class=\"line\">\t\tplt.xlabel (<span class=\"string\">\"迭代次数\"</span>)</span><br><span class=\"line\">\t\tplt.ylabel (<span class=\"string\">\"损失\"</span>)</span><br><span class=\"line\">\t\tplt.legend ()</span><br><span class=\"line\">\t\tplt.show ()</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 从数据集加载</span></span><br><span class=\"line\">\t\treal_batch = next (iter (train_dataset))</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 画出真图</span></span><br><span class=\"line\">\t\tplt.figure (figsize=(<span class=\"number\">15</span>, <span class=\"number\">10</span>))</span><br><span class=\"line\">\t\tplt.subplot (<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">\t\tplt.axis (<span class=\"string\">\"off\"</span>)</span><br><span class=\"line\">\t\tplt.title (<span class=\"string\">\"真图\"</span>)</span><br><span class=\"line\">\t\tplt.imshow (np.transpose (</span><br><span class=\"line\">\t\t\tvutils.make_grid (real_batch [<span class=\"number\">0</span>].to (device) [:<span class=\"number\">64</span>], padding=<span class=\"number\">5</span>, normalize=<span class=\"literal\">True</span>).cpu (),</span><br><span class=\"line\">\t\t\t(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>)))</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 画出假图</span></span><br><span class=\"line\">\t\tplt.subplot (<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">\t\tplt.axis (<span class=\"string\">\"off\"</span>)</span><br><span class=\"line\">\t\tplt.title (<span class=\"string\">\"假图\"</span>)</span><br><span class=\"line\">\t\tplt.imshow (np.transpose (img_list [<span class=\"number\">-1</span>], (<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>)))</span><br><span class=\"line\">\t\tplt.show ()</span><br><span class=\"line\">\t\t\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@torch.no_grad()#禁用梯度计算</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">test</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">\t<span class=\"comment\">#判断Gpu</span></span><br><span class=\"line\">\tdevice = torch.device (<span class=\"string\">'cuda'</span>) <span class=\"keyword\">if</span> args.cuda <span class=\"keyword\">else</span> torch.device (<span class=\"string\">'cpu'</span>)</span><br><span class=\"line\">\t<span class=\"comment\">#初始化网络</span></span><br><span class=\"line\">\tnetg, netd = netG (args).eval (), netD (args).eval ()</span><br><span class=\"line\">\t<span class=\"comment\">#定义噪声</span></span><br><span class=\"line\">\tnoises = torch.randn (args.batch_size, args.nz, <span class=\"number\">1</span>, <span class=\"number\">1</span>).to (device)</span><br><span class=\"line\">\t<span class=\"comment\">#载入网络</span></span><br><span class=\"line\">\tnetd.load_state_dict (torch.load (<span class=\"string\">'checkpoints/netd_%s.pth'</span>%args.max_epoch))</span><br><span class=\"line\">\tnetg.load_state_dict (torch.load (<span class=\"string\">'checkpoints/netg_%s.pth'</span>%args.max_epoch))</span><br><span class=\"line\">\t<span class=\"comment\">#设备化</span></span><br><span class=\"line\">\tnetd.to (device)</span><br><span class=\"line\">\tnetg.to (device)</span><br><span class=\"line\">\t<span class=\"comment\"># 生成图片，并计算图片在判别器的分数</span></span><br><span class=\"line\">\tfake_img = netg (noises)</span><br><span class=\"line\">\tscores = netd (fake_img).detach ()</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\"># 挑选最好的某几张</span></span><br><span class=\"line\">\tindexs = scores.topk (<span class=\"number\">5</span>) [<span class=\"number\">1</span>]</span><br><span class=\"line\">\tresult = []</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> indexs:</span><br><span class=\"line\">\t\tresult.append (fake_img.data [i])</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\"># 保存图片</span></span><br><span class=\"line\">\t<span class=\"keyword\">import</span> torchvision <span class=\"keyword\">as</span> tv</span><br><span class=\"line\">\ttv.utils.save_image (torch.stack (result), <span class=\"number\">5</span>, normalize=<span class=\"literal\">True</span>, range=(<span class=\"number\">-1</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">###################可视化类##################################</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> visdom</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision <span class=\"keyword\">as</span> tv</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Visualizer</span> <span class=\"params\">()</span>:</span></span><br><span class=\"line\">\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t封装了visdom的基本操作，但是你仍然可以通过`self.vis.function`</span></span><br><span class=\"line\"><span class=\"string\">\t调用原生的visdom接口</span></span><br><span class=\"line\"><span class=\"string\">\t\"\"\"</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span> <span class=\"params\">(self, env=<span class=\"string\">'default'</span>, **kwargs)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">import</span> visdom</span><br><span class=\"line\">\t\tself.vis = visdom.Visdom (env=env, use_incoming_socket=<span class=\"literal\">False</span>, **kwargs)</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 画的第几个数，相当于横座标</span></span><br><span class=\"line\">\t\t<span class=\"comment\"># 保存（’loss',23） 即loss的第23个点</span></span><br><span class=\"line\">\t\tself.index = &#123;&#125;</span><br><span class=\"line\">\t\tself.log_text = <span class=\"string\">''</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">reinit</span> <span class=\"params\">(self, env=<span class=\"string\">'default'</span>, **kwargs)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\t修改visdom的配置</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\tself.vis = visdom.Visdom (env=env, use_incoming_socket=<span class=\"literal\">False</span>, **kwargs)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> self</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">plot_many</span> <span class=\"params\">(self, d)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\t一次plot多个</span></span><br><span class=\"line\"><span class=\"string\">\t\t@params d: dict (name,value) i.e. ('loss',0.11)</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> d.items ():</span><br><span class=\"line\">\t\t\tself.plot (k, v)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">img_many</span> <span class=\"params\">(self, d)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> d.items ():</span><br><span class=\"line\">\t\t\tself.img (k, v)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">plot</span> <span class=\"params\">(self, name, y)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\tself.plot('loss',1.00)</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\tx = self.index.get (name, <span class=\"number\">0</span>)</span><br><span class=\"line\">\t\tself.vis.line (Y=np.array ([y]), X=np.array ([x]),</span><br><span class=\"line\">\t\t\t\t\t   win=(name),</span><br><span class=\"line\">\t\t\t\t\t   opts=dict (title=name),</span><br><span class=\"line\">\t\t\t\t\t   update=<span class=\"literal\">None</span> <span class=\"keyword\">if</span> x == <span class=\"number\">0</span> <span class=\"keyword\">else</span> <span class=\"string\">'append'</span></span><br><span class=\"line\">\t\t\t\t\t   )</span><br><span class=\"line\">\t\tself.index [name] = x + <span class=\"number\">1</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">img</span> <span class=\"params\">(self, name, img_)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\tself.img('input_img',t.Tensor(64,64))</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> len (img_.size ()) &lt; <span class=\"number\">3</span>:</span><br><span class=\"line\">\t\t\timg_ = img_.cpu ().unsqueeze (<span class=\"number\">0</span>)</span><br><span class=\"line\">\t\tself.vis.image (img_.cpu (),</span><br><span class=\"line\">\t\t\t\t\t\twin=(name),</span><br><span class=\"line\">\t\t\t\t\t\topts=dict (title=name)</span><br><span class=\"line\">\t\t\t\t\t\t)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">img_grid_many</span> <span class=\"params\">(self, d)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> d.items ():</span><br><span class=\"line\">\t\t\tself.img_grid (k, v)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">img_grid</span> <span class=\"params\">(self, name, input_3d)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\t一个batch的图片转成一个网格图，i.e. input（36，64，64）</span></span><br><span class=\"line\"><span class=\"string\">\t\t会变成 6*6 的网格图，每个格子大小64*64</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\tself.img (name, tv.utils.make_grid (</span><br><span class=\"line\">\t\t\tinput_3d.cpu () [<span class=\"number\">0</span>].unsqueeze (<span class=\"number\">1</span>).clamp (max=<span class=\"number\">1</span>, min=<span class=\"number\">0</span>)))</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">log</span> <span class=\"params\">(self, info, win=<span class=\"string\">'log_text'</span>)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\tself.log(&#123;'loss':1,'lr':0.0001&#125;)</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\tself.log_text += (<span class=\"string\">'[&#123;time&#125;] &#123;info&#125; &lt;br&gt;'</span>.format (</span><br><span class=\"line\">\t\t\ttime=time.strftime (<span class=\"string\">'%m%d_%H%M%S'</span>),</span><br><span class=\"line\">\t\t\tinfo=info))</span><br><span class=\"line\">\t\tself.vis.text (self.log_text, win=win)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__getattr__</span> <span class=\"params\">(self, name)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> getattr (self.vis, name)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t</span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> args.test:</span><br><span class=\"line\">\t\ttest()</span><br><span class=\"line\">\t<span class=\"keyword\">else</span>:</span><br><span class=\"line\">\t\ttrain()</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>输入：</li>\n<li><p>训练:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python train.py --cuda --plt</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>测试:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python train.py --cuda --test</span><br></pre></td></tr></table></figure>\n<ul>\n<li><code>--cuda</code>表示用GPU</li>\n<li><code>--plt</code>表示启动画图功能</li>\n<li><code>--vis</code> 表示使用visdom可视化</li>\n<li>具体可看参数列表:</li>\n<li><img src=\"/回顾-GAN/q.png\" alt></li>\n</ul>\n</li>\n</ul>\n<p><strong> 输出：</strong><br><img src=\"https://blog.mviai.com/images/回顾-GAN/r.png\" alt><br><img src=\"https://blog.mviai.com/images/回顾-GAN/r1.png\" alt><br><img src=\"https://blog.mviai.com/images/回顾-GAN/r2.png\" alt></p>\n<p><strong> 注：为什么结果这样，为了迎合网络，简单我把图片改的不成样 具体可以看参数设置</strong></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"1-GAN-简介：\"><a href=\"#1-GAN-简介：\" class=\"headerlink\" title=\"1.GAN 简介：\"></a>1.GAN 简介：</h1><p><a href=\"https://arxiv.org/abs/1406.2661\" target=\"_blank\" rel=\"noopener\">GAN</a>是2014年放出的一篇开山之作.LSTM作者认为GAN是其他模型的变种,因为他在92年提出PM（PredictabilityMinimization）模型,所以他一直认为GAN是goodfellow在自己PM模型上的改进!哈哈!!</p>\n<hr>\n<p>GAN的主要灵感来源于博弈论中零和博弈的思想,即一个网络与另一个网络对抗!从而互相提升自己,我以前曾想有没有互助网络!答案是肯定的,遇到在说!</p>\n<hr>\n<h1 id=\"2-GAN网络结构\"><a href=\"#2-GAN网络结构\" class=\"headerlink\" title=\"2. GAN网络结构:\"></a>2. GAN网络结构:</h1><p>如图:<br><img src=\"https://blog.mviai.com/images/回顾-GAN/net.png\" alt></p>\n<ul>\n<li>从这图告诉我什么呢?<ul>\n<li>首先看到是两个大字 G  D ,G表示生成网络,D表示判别网络!</li>\n<li>然后我们看这类似电路的网络图,我们从左往右看!<ul>\n<li>(主干线) 在变量空间构造Noise(噪声)→送给→G(生成网络)→生出→假东西</li>\n<li>（看G上面） 一堆真东西</li>\n<li>真东西（上面），假东西（G生出来的）交给D（判别网络）给出两个的有多像真东西几率<font color=\"red\">  （当然给出真东西（上面）几率为100%（因为本来就是真的），假东西（G生出来的）几率为0~100%）</font><ul>\n<li>如果很差，就告诉D（生成网络）你不行啊！！，然后D借鉴上次失败重新生成假东西，去骗G！</li>\n<li>就这样持续了。。。。。。世纪，最终达到平衡，这时候G肯定很强大了</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>然后我们说下平衡核心：<br><img src=\"https://blog.mviai.com/images/回顾-GAN/g.jpg\" alt><ul>\n<li>然后我们从右到左说下:<ul>\n<li>首先想解释E E就是期望(期望就是概率求和)<br>还有有就是log,这是逻辑回归那取对数似然出来的</li>\n<li>最右边,G(z):其中z表示噪声.G(z)就表示生成的假东西,D(G(z))就表示D是否要告诉G(‘你不行’)的概率<ul>\n<li>下角的 z-Pz表示一个噪声到噪声数据集</li>\n</ul>\n</li>\n<li>然后是D(x)表示看模板(真东西)是不是真东西概率<ul>\n<li>下角的 x-Pdata 表示x到真实数据集(表示要慢慢来,慢慢学,不然容易崩溃哟)</li>\n</ul>\n</li>\n<li>最后 min max ,你肯定有点不解,不是应该maxG吗? 简单理解下,当G最失败(最小)时候,就是让D看假东西得出概率最大.   (最垃圾时候,D都说你行,那就别说G强大时候了)   即在局部最大中试图找出全局最大</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h1 id=\"3-GAN的创新点\"><a href=\"#3-GAN的创新点\" class=\"headerlink\" title=\"3.GAN的创新点:\"></a>3.GAN的创新点:</h1><ul>\n<li><ol>\n<li>相比较传统的模型，他存在两个不同的网络，而不是单一的网络，并且训练方式采用的是对抗训练方式</li>\n</ol>\n</li>\n<li><ol start=\"2\">\n<li>GAN中G的梯度更新信息自于判别模型D的一个反传梯度。，而不是来自数据样本</li>\n</ol>\n</li>\n</ul>\n<hr>\n<h1 id=\"4-GAN的优缺点\"><a href=\"#4-GAN的优缺点\" class=\"headerlink\" title=\"4.GAN的优缺点:\"></a>4.GAN的优缺点:</h1><h4 id=\"优点\"><a href=\"#优点\" class=\"headerlink\" title=\"优点:\"></a>优点:</h4><p>●   训练时不需要对隐变量做推断,而且G参数来源于D</p>\n<p>●   GAN是一种生成式模型，相比较其他生成模型（玻尔兹曼机和GSNs）只用到了反向传播,而不需要复杂的马尔科夫链</p>\n<p>●  相比其他所有模型, GAN可以产生更加清晰，真实的样本</p>\n<p>●  GAN采用的是一种无监督的学习方式训练，可以被广泛用在无监督学习和半监督学习领域</p>\n<p>●  相比于变分自编码器, GANs没有引入任何决定性偏置( deterministic bias),变分方法引入决定性偏置,因为他们优化对数似然的下界,而不是似然度本身,这看起来导致了VAEs生成的实例比GANs更模糊</p>\n<p>●  相比VAE, GANs没有变分下界,如果鉴别器训练良好,那么生成器可以完美的学习到训练样本的分布.换句话说,GANs是渐进一致的,但是VAE是有偏差的</p>\n<p>●  GAN应用到一些场景上，比如图片风格迁移，超分辨率，图像补全，去噪，避免了损失函数设计的困难，不管三七二十一，只要有一个的基准，直接上判别器，剩下的就交给对抗训练了。</p>\n<h4 id=\"缺点\"><a href=\"#缺点\" class=\"headerlink\" title=\"缺点:\"></a>缺点:</h4><p>●  很不好训练,一是DG的同仇敌忾问题(同步)</p>\n<p>●  G参数来源于D,所以很难解释G的模型分布</p>\n<p>●  训练GAN需要达到纳什均衡,有时候可以用梯度下降法做到,有时候做不到.我们还没有找到很好的达到纳什均衡的方法,所以训练GAN相比VAE或者PixelRNN是不稳定的,但我认为在实践中它还是比训练玻尔兹曼机稳定的多</p>\n<p>●  GAN不适合处理离散形式的数据，比如文本</p>\n<p>●  GAN存在训练不稳定、梯度消失、模式崩溃的问题（就是自我欺骗,最后谁也不行!解决在WGAN）</p>\n<h1 id=\"5-GAN的训练建议\"><a href=\"#5-GAN的训练建议\" class=\"headerlink\" title=\"5.GAN的训练建议:\"></a>5.GAN的训练建议:</h1><p>注:来自<a href=\"https://github.com/soumith/ganhacks#authors\" target=\"_blank\" rel=\"noopener\">https://github.com/soumith/ganhacks#authors</a><br><strong> 1.标准化输入</strong></p>\n<ul>\n<li>在-1和1之间标准化图像</li>\n<li>Tanh作为发电机输出的最后一层</li>\n</ul>\n<p><strong> 2：修改的损失函数</strong><br>在GAN论文中，优化G的损失函数是min (log 1-D)，但实际上人们实际使用max log D</p>\n<ul>\n<li>因为第一个损失在早期就已经消失了</li>\n<li>Goodfellow et。al（2014）<br><strong> 在实践中，运作良好：</strong> </li>\n<li>训练生成器时调换标签：real = fake，fake = real</li>\n</ul>\n<p><strong> 3：使用球形</strong></p>\n<ul>\n<li>不要从统一分布中取样<br><img src=\"https://blog.mviai.com/images/回顾-GAN/cube.png\" alt></li>\n<li><p>来自高斯分布的样本<br><img src=\"https://blog.mviai.com/images/回顾-GAN/sphere.png\" alt></p>\n</li>\n<li><p>进行插值时，通过大圆进行插值，而不是从A点到B点的直线</p>\n</li>\n<li>Tom White的采样生成网络参考代码<a href=\"https://github.com/dribnet/plat\" target=\"_blank\" rel=\"noopener\">https://github.com/dribnet/plat</a></li>\n</ul>\n<p><strong> 4：BatchNorm </strong></p>\n<ul>\n<li>构建真实和假的不同小批次，即每个小批量只需要包含所有真实图像或所有生成的图像。</li>\n<li>当batchnorm不是一个选项时，使用实例标准化（对于每个样本，减去平均值并除以标准偏差）。<br><img src=\"https://blog.mviai.com/images/回顾-GAN/batchmix.png\" alt></li>\n</ul>\n<p><strong> 5：避免稀疏梯度：ReLU，MaxPool</strong></p>\n<ul>\n<li>如果你的梯度稀疏，GANs的稳定性就会受到影响</li>\n<li>LeakyReLU =优良（G和D都有）</li>\n<li>对于Downsampling，使用：Average Pooling，Conv2d+ stride</li>\n<li>对于Upsampling，请使用：PixelShuffle,ConvTranspose2d + stride<ul>\n<li><a href=\"https：//arxiv.org/abs/1609.05158\">PixelShuffle</a></li>\n</ul>\n</li>\n</ul>\n<p><strong> 6：使用平滑和复杂的标签</strong></p>\n<ul>\n<li>标签平滑，即如果你有两个目标标签：Real = 1和Fake = 0，那么对于每个传入的样本，如果它是真的，那么用0.7到1.2之间的随机数替换标签，如果它是假的样本，将其替换为0.0和0.3</li>\n<li>使标签对于鉴别器来说是有噪声的：在训练鉴别器时偶尔会调换标签</li>\n</ul>\n<p><strong> 7：DCGAN /混合模型</strong> </p>\n<ul>\n<li>尽可能使用DCGAN。有用！</li>\n<li>如果您无法使用DCGAN并且没有模型稳定，请使用混合型号：KL + GAN或VAE + GAN</li>\n</ul>\n<p><strong> 8：使用RL的稳定性技巧</strong> </p>\n<ul>\n<li>重复性经验<ul>\n<li>保留过去几代的重复缓冲区并偶尔展示它们</li>\n<li>保持G和D过去的检查点，并偶尔交换它们几次迭代</li>\n</ul>\n</li>\n<li>所有稳定性技巧都适用于深层确定性策略梯度( policy gradient)</li>\n<li>见Pfau＆Vinyals（2016）</li>\n</ul>\n<p><strong> 9：使用Adam Optimizer</strong></p>\n<ul>\n<li><p>optim.Adam规则！</p>\n</li>\n<li><p>使用SGD作为鉴别器，使用Adam作为生成器</p>\n</li>\n</ul>\n<p><strong> 10：尽早跟踪故障</strong></p>\n<ul>\n<li>D损失为0：故障模式</li>\n<li>检查渐变的规范：如果他们超过100件事情搞砸了</li>\n<li>当事情正在发挥作用时，D损失的方差很小，并且随着时间的推移而下降，而且存在巨大的差异和尖峰</li>\n<li>如果生成器的损失稳定下降，那就是用垃圾愚弄D（马丁说）</li>\n</ul>\n<p><strong> 11：不要通过统计平衡损失（除非你有充分的理由）</strong></p>\n<ul>\n<li><p>不要试图找到一个（G的数量/ D的数量）计划来解开训练这很难，我们都尝试过。</p>\n</li>\n<li><p>如果您确实尝试过，请采用原则性方法，而不是直觉</p>\n<ul>\n<li>例如<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">while</span> lossD &gt; A:</span><br><span class=\"line\">  train D</span><br><span class=\"line\"><span class=\"keyword\">while</span> lossG &gt; B:</span><br><span class=\"line\">  train G</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n</li>\n</ul>\n<p><strong> 12：如果你有标签，请使用它们</strong> </p>\n<ul>\n<li>如果您有可用的标签，则训练鉴别器以对样品进行分类：辅助GAN</li>\n</ul>\n<p><strong> 13：向输入添加噪声，随时间衰减</strong></p>\n<ul>\n<li><p>在D的输入上添加一些人为噪声（Arjovsky et.al.Huszar，2016）</p>\n<ul>\n<li><a href=\"http://www.inference.vc/instance-noise-a-trick-for-stabilising-gan-training/\" target=\"_blank\" rel=\"noopener\">http://www.inference.vc/instance-noise-a-trick-for-stabilising-gan-training/</a></li>\n<li><a href=\"https://openreview.net/forum?id=Hk4_qw5xe\" target=\"_blank\" rel=\"noopener\">https://openreview.net/forum?id=Hk4_qw5xe</a></li>\n</ul>\n</li>\n<li><p>在生成器的每一层都加入高斯噪声（Zhao et al。EBGAN）</p>\n<ul>\n<li>改进的GAN：OpenAI代码也有它（注释掉）</li>\n</ul>\n</li>\n</ul>\n<p><strong> 14：[notsure]（有时）更多的训练鉴别器</strong></p>\n<ul>\n<li>特别是当你有噪音时</li>\n<li>很难找到D迭代次数与G次迭代的时间表</li>\n</ul>\n<p><strong> 15：[notsure]批量鉴别 </strong> </p>\n<ul>\n<li>结果喜忧参半</li>\n</ul>\n<p><strong> 16：条件GAN中的离散变量</strong></p>\n<ul>\n<li>使用嵌入层</li>\n<li>添加为图像的附加通道</li>\n<li>保持低维度嵌入和上采样以匹配图像通道大小</li>\n</ul>\n<p><strong> 17：在train和test阶段使用G中的Dropouts </strong></p>\n<ul>\n<li>以随机的形式提供噪音（50％）。</li>\n<li>在训练和测试时间应用于我们的发电机的几个层</li>\n<li><a href=\"https://arxiv.org/pdf/1611.07004v1.pdf\" target=\"_blank\" rel=\"noopener\">https://arxiv.org/pdf/1611.07004v1.pdf</a></li>\n</ul>\n<p><strong> 18.其他小技巧 </strong></p>\n<ul>\n<li>输入规范化到（-1，1）之间，最后一层的激活函数使用tanh</li>\n<li>使用wassertein GAN的损失函数</li>\n<li>学习率不要设置太大，初始1e-4可以参考，另外可以随着训练进行不断缩小学习率</li>\n<li>给D的网络层增加高斯噪声，相当于是一种正则</li>\n</ul>\n<hr>\n<hr>\n<h1 id=\"6-GANs的发展\"><a href=\"#6-GANs的发展\" class=\"headerlink\" title=\"6.GANs的发展:\"></a>6.GANs的发展:</h1><p><img src=\"https://blog.mviai.com/images/回顾-GAN/2014.png\" alt><br><img src=\"https://blog.mviai.com/images/回顾-GAN/2016.png\" alt><br><img src=\"https://blog.mviai.com/images/回顾-GAN/2017.png\" alt><br>更多,可以浏览:<a href=\"https://github.com/hindupuravinash\" target=\"_blank\" rel=\"noopener\">https://github.com/hindupuravinash</a></p>\n<h1 id=\"7-pytorch实现\"><a href=\"#7-pytorch实现\" class=\"headerlink\" title=\"7. pytorch实现:\"></a>7. pytorch实现:</h1><p><strong> 目录结构:</strong><br><img src=\"https://blog.mviai.com/images/回顾-GAN/m.png\" alt></p>\n<ul>\n<li>注:从上到下依次是模型保存文件夹-&gt;数据集文件夹-&gt;生成文件夹</li>\n</ul>\n<p><strong> 设计网络常用计算:</strong></p>\n<ul>\n<li>反卷积:<br><img src=\"https://blog.mviai.com/images/回顾-GAN/反conv.png\" alt></li>\n<li>卷积:<br><img src=\"https://blog.mviai.com/images/回顾-GAN/conv.png\" alt></li>\n</ul>\n<p><strong> network.py文件:</strong><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">为了简单明了,所以今天还是创最最简单的GAN</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">首先 有两个网络 分别是G D</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#我们首先建立G</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">G</span><span class=\"params\">(nn.Module)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self,args)</span>:</span></span><br><span class=\"line\">        super(G,self).__init__()</span><br><span class=\"line\">        ngf = args.ngf  <span class=\"comment\"># 生成器feature map数(该层卷积核的个数，有多少个卷积核，经过卷积就会产生多少个feature map)</span></span><br><span class=\"line\">        self.G_layer= nn.Sequential(</span><br><span class=\"line\">                <span class=\"comment\">#输入是一个nz维度的噪声，我们可以认为它是一个1 * 1 * nz的feature map</span></span><br><span class=\"line\">                nn.ConvTranspose2d(args.nz, <span class=\"number\">3</span>,<span class=\"number\">5</span>,<span class=\"number\">1</span>,<span class=\"number\">0</span>),<span class=\"comment\"># 反conv2d</span></span><br><span class=\"line\">                nn.BatchNorm2d (<span class=\"number\">3</span>),</span><br><span class=\"line\">                nn.LeakyReLU(<span class=\"literal\">True</span>),)</span><br><span class=\"line\">                <span class=\"comment\"># 输出大小为3*5*5</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">#前向传播</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self,x)</span>:</span></span><br><span class=\"line\">        out=self.G_layer(x)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#建立D</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">D</span><span class=\"params\">(nn.Module)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self,args)</span>:</span></span><br><span class=\"line\">        super(D,self).__init__()</span><br><span class=\"line\">        ndf = args.ndf  <span class=\"comment\"># 生成器feature map数(该层卷积核的个数，有多少个卷积核，经过卷积就会产生多少个feature map)</span></span><br><span class=\"line\">        self.D_layer= nn.Sequential(</span><br><span class=\"line\">                <span class=\"comment\"># 输入 3 x 5 x 5,</span></span><br><span class=\"line\">                nn.Conv2d(<span class=\"number\">3</span>,ndf, <span class=\"number\">3</span>),</span><br><span class=\"line\">                nn.BatchNorm2d (ndf),</span><br><span class=\"line\">                nn.LeakyReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">                <span class=\"comment\">#输出 (ndf)*1*1</span></span><br><span class=\"line\">                nn.Conv2d (ndf,<span class=\"number\">1</span>,<span class=\"number\">1</span>),</span><br><span class=\"line\">                <span class=\"comment\"># 输出 1*0*0</span></span><br><span class=\"line\">                nn.Sigmoid())<span class=\"comment\">#告诉D概率</span></span><br><span class=\"line\">                </span><br><span class=\"line\">    <span class=\"comment\">#前向传播</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self,x)</span>:</span></span><br><span class=\"line\">        out=self.D_layer(x)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br></pre></td></tr></table></figure></p>\n<p><strong> train.py文件:</strong><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br><span class=\"line\">277</span><br><span class=\"line\">278</span><br><span class=\"line\">279</span><br><span class=\"line\">280</span><br><span class=\"line\">281</span><br><span class=\"line\">282</span><br><span class=\"line\">283</span><br><span class=\"line\">284</span><br><span class=\"line\">285</span><br><span class=\"line\">286</span><br><span class=\"line\">287</span><br><span class=\"line\">288</span><br><span class=\"line\">289</span><br><span class=\"line\">290</span><br><span class=\"line\">291</span><br><span class=\"line\">292</span><br><span class=\"line\">293</span><br><span class=\"line\">294</span><br><span class=\"line\">295</span><br><span class=\"line\">296</span><br><span class=\"line\">297</span><br><span class=\"line\">298</span><br><span class=\"line\">299</span><br><span class=\"line\">300</span><br><span class=\"line\">301</span><br><span class=\"line\">302</span><br><span class=\"line\">303</span><br><span class=\"line\">304</span><br><span class=\"line\">305</span><br><span class=\"line\">306</span><br><span class=\"line\">307</span><br><span class=\"line\">308</span><br><span class=\"line\">309</span><br><span class=\"line\">310</span><br><span class=\"line\">311</span><br><span class=\"line\">312</span><br><span class=\"line\">313</span><br><span class=\"line\">314</span><br><span class=\"line\">315</span><br><span class=\"line\">316</span><br><span class=\"line\">317</span><br><span class=\"line\">318</span><br><span class=\"line\">319</span><br><span class=\"line\">320</span><br><span class=\"line\">321</span><br><span class=\"line\">322</span><br><span class=\"line\">323</span><br><span class=\"line\">324</span><br><span class=\"line\">325</span><br><span class=\"line\">326</span><br><span class=\"line\">327</span><br><span class=\"line\">328</span><br><span class=\"line\">329</span><br><span class=\"line\">330</span><br><span class=\"line\">331</span><br><span class=\"line\">332</span><br><span class=\"line\">333</span><br><span class=\"line\">334</span><br><span class=\"line\">335</span><br><span class=\"line\">336</span><br><span class=\"line\">337</span><br><span class=\"line\">338</span><br><span class=\"line\">339</span><br><span class=\"line\">340</span><br><span class=\"line\">341</span><br><span class=\"line\">342</span><br><span class=\"line\">343</span><br><span class=\"line\">344</span><br><span class=\"line\">345</span><br><span class=\"line\">346</span><br><span class=\"line\">347</span><br><span class=\"line\">348</span><br><span class=\"line\">349</span><br><span class=\"line\">350</span><br><span class=\"line\">351</span><br><span class=\"line\">352</span><br><span class=\"line\">353</span><br><span class=\"line\">354</span><br><span class=\"line\">355</span><br><span class=\"line\">356</span><br><span class=\"line\">357</span><br><span class=\"line\">358</span><br><span class=\"line\">359</span><br><span class=\"line\">360</span><br><span class=\"line\">361</span><br><span class=\"line\">362</span><br><span class=\"line\">363</span><br><span class=\"line\">364</span><br><span class=\"line\">365</span><br><span class=\"line\">366</span><br><span class=\"line\">367</span><br><span class=\"line\">368</span><br><span class=\"line\">369</span><br><span class=\"line\">370</span><br><span class=\"line\">371</span><br><span class=\"line\">372</span><br><span class=\"line\">373</span><br><span class=\"line\">374</span><br><span class=\"line\">375</span><br><span class=\"line\">376</span><br><span class=\"line\">377</span><br><span class=\"line\">378</span><br><span class=\"line\">379</span><br><span class=\"line\">380</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision.datasets <span class=\"keyword\">as</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision.transforms <span class=\"keyword\">as</span>  transforms</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.backends.cudnn <span class=\"keyword\">as</span> cudnn</span><br><span class=\"line\"><span class=\"comment\"># 工具包</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> argparse</span><br><span class=\"line\"><span class=\"comment\"># 载入网络</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> network <span class=\"keyword\">import</span> G, D</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############参数设置#############</span></span><br><span class=\"line\"><span class=\"comment\">####命令行设置########</span></span><br><span class=\"line\">parser = argparse.ArgumentParser (description=<span class=\"string\">'GAN'</span>)  <span class=\"comment\"># 导入命令行模块</span></span><br><span class=\"line\"><span class=\"comment\"># 对关于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明</span></span><br><span class=\"line\"><span class=\"comment\">#关于训练参数</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--batch_size'</span>, type=int, default=<span class=\"number\">12</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'训练batch-size大小 (default: 64)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--imageSize'</span>, type=int, default=<span class=\"number\">5</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'图片尺寸'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--max_epoch'</span>, type=int, default=<span class=\"number\">5</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'最大迭代数 (default: 5)'</span>)</span><br><span class=\"line\"><span class=\"comment\">#关于网络参数</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--lr_g'</span>, type=float, default=<span class=\"number\">2e-4</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'生成器学习率 (default: 2e-4)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--lr_d'</span>, type=float, default=<span class=\"number\">2e-4</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'判别器学习率 (default: 2e-4)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--ngf'</span>, type=int, default=<span class=\"number\">32</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'生成器feature map数'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--ndf'</span>, type=int, default=<span class=\"number\">32</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'判别器feature map数'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--d_every'</span>, type=int, default=<span class=\"number\">1</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'每几个batch训练一次判别器'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--g_every'</span>, type=int, default=<span class=\"number\">2</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'每几个batch训练一次生成器'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--nz'</span>, type=int, default=<span class=\"number\">5</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'噪声维度'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#关于优化器参数</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--beta1'</span>, type=int, default=<span class=\"number\">0.5</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'Adam优化器的beta1参数'</span>)</span><br><span class=\"line\"><span class=\"comment\">#路径</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--dataset'</span>, default=<span class=\"string\">'data/'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'数据集路径'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--save_data'</span>,  default=<span class=\"string\">'save/'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'保存路径'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#可视化</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--vis'</span>, action=<span class=\"string\">'store_true'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'是否使用visdom可视化'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--plot_every'</span>, type=int, default=<span class=\"number\">1</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'每间隔_batch，visdom画图一次'</span>)</span><br><span class=\"line\"><span class=\"comment\"># 其他</span></span><br><span class=\"line\"></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--cuda'</span>, action=<span class=\"string\">'store_true'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'开启cuda训练'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--plt'</span>, action=<span class=\"string\">'store_true'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'开启画图'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--test'</span>, action=<span class=\"string\">'store_true'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'开启测试生成'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--save_every'</span>, type=int, default=<span class=\"number\">3</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'几个epoch保存一次模型 (default: 3)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--seed'</span>, type=int, default=<span class=\"number\">1</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'随机种子 (default: 1)'</span>)</span><br><span class=\"line\">args = parser.parse_args ()  <span class=\"comment\"># 相当于激活命令</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#训练过程</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">train</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">\t<span class=\"comment\">###############判断gpu#############</span></span><br><span class=\"line\">\tdevice = torch.device (<span class=\"string\">'cuda'</span>) <span class=\"keyword\">if</span> args.cuda <span class=\"keyword\">else</span> torch.device (<span class=\"string\">'cpu'</span>)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">####### 为CPU设置种子用于生成随机数，以使得结果是确定的##########</span></span><br><span class=\"line\">\ttorch.manual_seed (args.seed)</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> args.cuda:</span><br><span class=\"line\">\t\ttorch.cuda.manual_seed (args.seed)</span><br><span class=\"line\">\tcudnn.benchmark = <span class=\"literal\">True</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">#################可视化###############</span></span><br><span class=\"line\">\t<span class=\"keyword\">if</span> args.vis:</span><br><span class=\"line\">\t\tvis = Visualizer (<span class=\"string\">'GANs'</span>)</span><br><span class=\"line\">\t<span class=\"comment\">##########数据转换#####################</span></span><br><span class=\"line\">\tdata_transforms = transforms.Compose ([transforms.Scale (args.imageSize),  <span class=\"comment\"># 通过调整比例调整大小,会报警</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   transforms.CenterCrop (args.imageSize),  <span class=\"comment\"># 在中心裁剪给指定大小方形PIL图像</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   transforms.ToTensor (),<span class=\"comment\"># 转换成pytorch 变量tensor</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   transforms.Normalize ((<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>), (<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>))])</span><br><span class=\"line\">\t<span class=\"comment\">###############数据载入################</span></span><br><span class=\"line\">\ttrain_dataset = datasets.ImageFolder (root=args.dataset,  <span class=\"comment\"># 数据路径目录</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t  transform=data_transforms)  <span class=\"comment\"># 把数据转换成上面约束样子</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\"># test_dataset = datasets.ImageFolder (root=args.dataset,</span></span><br><span class=\"line\">\t<span class=\"comment\"># \t\t\t\t\t\t\t\t\t transform=data_transforms)</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">##############数据装载###############</span></span><br><span class=\"line\">\ttrain_loader = torch.utils.data.DataLoader (dataset=train_dataset,  <span class=\"comment\"># 装载数据</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\t\tbatch_size=args.batch_size,  <span class=\"comment\"># 设置批大小</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\t\tshuffle=<span class=\"literal\">True</span>)  <span class=\"comment\"># 是否随机打乱</span></span><br><span class=\"line\">\t<span class=\"comment\"># test_loader = torch.utils.data.DataLoader (dataset=test_dataset,</span></span><br><span class=\"line\">\t<span class=\"comment\"># \t\t\t\t\t\t\t\t\t\t   batch_size=args.batch_size,</span></span><br><span class=\"line\">\t<span class=\"comment\"># \t\t\t\t\t\t\t\t\t\t   shuffle=True)</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">#############模型载入#################</span></span><br><span class=\"line\">\tnetG ,netD= G (args),D (args)</span><br><span class=\"line\">\tnetG.to (device)</span><br><span class=\"line\">\tnetD.to (device)</span><br><span class=\"line\">\t<span class=\"keyword\">print</span> (netD, netG)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">###############损失函数##################</span></span><br><span class=\"line\">\toptimizerD = torch.optim.Adam (netD.parameters (), lr=args.lr_d,betas=(<span class=\"number\">0.5</span>, <span class=\"number\">0.999</span>))  <span class=\"comment\"># Adam优化器</span></span><br><span class=\"line\">\toptimizerG = torch.optim.Adam (netG.parameters (), lr=args.lr_g,betas=(<span class=\"number\">0.5</span>, <span class=\"number\">0.999</span>))  <span class=\"comment\"># Adam优化器</span></span><br><span class=\"line\">\t<span class=\"comment\">###############画图参数保存##################</span></span><br><span class=\"line\">\tG_losses = []</span><br><span class=\"line\">\tD_losses = []</span><br><span class=\"line\">\timg_list = []</span><br><span class=\"line\">\t<span class=\"comment\">#############训练过程#####################</span></span><br><span class=\"line\">\t<span class=\"keyword\">import</span> tqdm</span><br><span class=\"line\">\t<span class=\"comment\"># Tqdm是一个快速，可扩展的Python进度条，可以在Python</span></span><br><span class=\"line\">\t<span class=\"comment\"># 长循环中添加一个进度提示信息，用户只需要封装任意的迭代器</span></span><br><span class=\"line\">\t<span class=\"comment\"># tqdm (iterator)。</span></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range (args.max_epoch):</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> i, (images, labels) <span class=\"keyword\">in</span> tqdm.tqdm(enumerate (train_loader)):  <span class=\"comment\"># 枚举出来</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\">#数据处理</span></span><br><span class=\"line\">\t\t\timages = images.to (device)</span><br><span class=\"line\">\t\t\t<span class=\"comment\"># 装箱</span></span><br><span class=\"line\">\t\t\timages = Variable (images)</span><br><span class=\"line\">\t\t\tnoises=Variable(torch.randn(args.batch_size, args.nz, <span class=\"number\">1</span>, <span class=\"number\">1</span>).to(device))</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\t<span class=\"comment\">#遍历每张图片,并且根据指定的训练机制训练</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> i % args.d_every==<span class=\"number\">0</span>:<span class=\"comment\">#满足此条件训练D</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D前向传播</span></span><br><span class=\"line\">\t\t\t\toptimizerD.zero_grad ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D网络输出</span></span><br><span class=\"line\">\t\t\t\toutput_r = netD (images)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G网络输出</span></span><br><span class=\"line\">\t\t\t\tnoises.data.copy_ (torch.randn (args.batch_size, args.nz, <span class=\"number\">1</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">\t\t\t\tfake = netG (noises).detach ()  <span class=\"comment\"># 根据噪声生成假图</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#把假图给d</span></span><br><span class=\"line\">\t\t\t\toutput_f = netD (fake)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D的损失</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#print(fake.size(),output_f.size(),output_r.size())</span></span><br><span class=\"line\">\t\t\t\tD_loss = - torch.mean (torch.log (output_r) + torch.log (<span class=\"number\">1.</span> - output_f))</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D反向传播</span></span><br><span class=\"line\">\t\t\t\tD_loss.backward ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#度量</span></span><br><span class=\"line\">\t\t\t\tD_x = output_r.mean ().item ()</span><br><span class=\"line\">\t\t\t\tD_G_z1 = output_f.mean ().item ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D更新参数</span></span><br><span class=\"line\">\t\t\t\toptimizerD.step ()</span><br><span class=\"line\">\t\t\t\t</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> i % args.g_every==<span class=\"number\">0</span>:<span class=\"comment\">#满足此条件训练G</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G前向传播</span></span><br><span class=\"line\">\t\t\t\toptimizerG.zero_grad ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G网络输出</span></span><br><span class=\"line\">\t\t\t\tfake = netG (noises)  <span class=\"comment\"># 根据噪声生成假图</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#把假图给G</span></span><br><span class=\"line\">\t\t\t\toutput_f = netD (fake)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G的损失</span></span><br><span class=\"line\">\t\t\t\tG_loss = torch.mean (torch.log (<span class=\"number\">1.</span> - output_f))</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G反向传播</span></span><br><span class=\"line\">\t\t\t\tG_loss.backward ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#度量</span></span><br><span class=\"line\">\t\t\t\tD_G_z2 = output_f.mean ().item ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D更新参数</span></span><br><span class=\"line\">\t\t\t\toptimizerG.step ()</span><br><span class=\"line\">\t\t\t\t</span><br><span class=\"line\">\t\t\t<span class=\"comment\">###########################################</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\">##########可视化(可选)#####################</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> args.vis <span class=\"keyword\">and</span> i % args.plot_every == args.plot_every - <span class=\"number\">1</span>:</span><br><span class=\"line\">\t\t\t\tfake = netG (noises)</span><br><span class=\"line\">\t\t\t\tvis.images (fake.detach ().cpu ().numpy () [:<span class=\"number\">64</span>] * <span class=\"number\">0.5</span> + <span class=\"number\">0.5</span>, win=<span class=\"string\">'fixfake'</span>)</span><br><span class=\"line\">\t\t\t\tvis.images (images.data.cpu ().numpy () [:<span class=\"number\">64</span>] * <span class=\"number\">0.5</span> + <span class=\"number\">0.5</span>, win=<span class=\"string\">'real'</span>)</span><br><span class=\"line\">\t\t\t\tvis.plot (<span class=\"string\">'errord'</span>, D_loss.item ())</span><br><span class=\"line\">\t\t\t\tvis.plot (<span class=\"string\">'errorg'</span>, G_loss.item ())</span><br><span class=\"line\">\t\t\t<span class=\"comment\">#######################################</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\">############打印记录###################</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> i % <span class=\"number\">1</span>== <span class=\"number\">0</span>:</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">print</span> (<span class=\"string\">'[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'</span></span><br><span class=\"line\">\t\t\t\t\t   % (epoch, args.max_epoch, i, len (train_loader),</span><br><span class=\"line\">\t\t\t\t\t\t  D_loss.item (), G_loss.item (), D_x, D_G_z1, D_G_z2))</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">########添加画图参数########</span></span><br><span class=\"line\">\t\t\t\tG_losses.append (G_loss.item ())</span><br><span class=\"line\">\t\t\t\tD_losses.append (D_loss.item ())</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">with</span> torch.no_grad ():</span><br><span class=\"line\">\t\t\t\t\tnoises = torch.randn (args.batch_size, args.nz, <span class=\"number\">1</span>, <span class=\"number\">1</span>).to (device)</span><br><span class=\"line\">\t\t\t\t\tfake = netG (noises).detach ().cpu ()</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">import</span> torchvision.utils <span class=\"keyword\">as</span> vutils</span><br><span class=\"line\">\t\t\t\timg_list.append (vutils.make_grid (fake, padding=<span class=\"number\">2</span>, normalize=<span class=\"literal\">True</span>))</span><br><span class=\"line\">\t</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">\t\t<span class=\"comment\">#######################################</span></span><br><span class=\"line\">\t\t<span class=\"comment\">############保存模型###################</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (epoch + <span class=\"number\">1</span>) % args.save_every == <span class=\"number\">0</span>:</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">import</span> torchvision <span class=\"keyword\">as</span> tv</span><br><span class=\"line\">\t\t\t<span class=\"comment\"># 保存模型、图片</span></span><br><span class=\"line\">\t\t\ttv.utils.save_image (fake.data [:<span class=\"number\">64</span>], <span class=\"string\">'%s/%s.png'</span> % (args.save_data, epoch), normalize=<span class=\"literal\">True</span>,range=(<span class=\"number\">-1</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">\t\t\ttorch.save (netD.state_dict (), <span class=\"string\">'checkpoints/netd_%s.pth'</span> % epoch)</span><br><span class=\"line\">\t\t\ttorch.save (netG.state_dict (), <span class=\"string\">'checkpoints/netg_%s.pth'</span> % epoch)</span><br><span class=\"line\">\t\t\tprint(<span class=\"string\">'完成%s的模型保存'</span>%epoch)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">#######################################</span></span><br><span class=\"line\">\t<span class=\"comment\">############画图###################</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> args.plt:</span><br><span class=\"line\">\t\t<span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\">\t\t<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\">\t\t<span class=\"keyword\">import</span> torchvision.utils <span class=\"keyword\">as</span> vutils</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\tplt.figure (figsize=(<span class=\"number\">10</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\">\t\tplt.title (<span class=\"string\">\"GAN\"</span>)</span><br><span class=\"line\">\t\tplt.plot (G_losses, label=<span class=\"string\">\"G\"</span>)</span><br><span class=\"line\">\t\tplt.plot (D_losses, label=<span class=\"string\">\"D\"</span>)</span><br><span class=\"line\">\t\tplt.xlabel (<span class=\"string\">\"迭代次数\"</span>)</span><br><span class=\"line\">\t\tplt.ylabel (<span class=\"string\">\"损失\"</span>)</span><br><span class=\"line\">\t\tplt.legend ()</span><br><span class=\"line\">\t\tplt.show ()</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 从数据集加载</span></span><br><span class=\"line\">\t\treal_batch = next (iter (train_dataset))</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 画出真图</span></span><br><span class=\"line\">\t\tplt.figure (figsize=(<span class=\"number\">15</span>, <span class=\"number\">10</span>))</span><br><span class=\"line\">\t\tplt.subplot (<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">\t\tplt.axis (<span class=\"string\">\"off\"</span>)</span><br><span class=\"line\">\t\tplt.title (<span class=\"string\">\"真图\"</span>)</span><br><span class=\"line\">\t\tplt.imshow (np.transpose (</span><br><span class=\"line\">\t\t\tvutils.make_grid (real_batch [<span class=\"number\">0</span>].to (device) [:<span class=\"number\">64</span>], padding=<span class=\"number\">5</span>, normalize=<span class=\"literal\">True</span>).cpu (),</span><br><span class=\"line\">\t\t\t(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>)))</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 画出假图</span></span><br><span class=\"line\">\t\tplt.subplot (<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">\t\tplt.axis (<span class=\"string\">\"off\"</span>)</span><br><span class=\"line\">\t\tplt.title (<span class=\"string\">\"假图\"</span>)</span><br><span class=\"line\">\t\tplt.imshow (np.transpose (img_list [<span class=\"number\">-1</span>], (<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>)))</span><br><span class=\"line\">\t\tplt.show ()</span><br><span class=\"line\">\t\t\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@torch.no_grad()#禁用梯度计算</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">test</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">\t<span class=\"comment\">#判断Gpu</span></span><br><span class=\"line\">\tdevice = torch.device (<span class=\"string\">'cuda'</span>) <span class=\"keyword\">if</span> args.cuda <span class=\"keyword\">else</span> torch.device (<span class=\"string\">'cpu'</span>)</span><br><span class=\"line\">\t<span class=\"comment\">#初始化网络</span></span><br><span class=\"line\">\tnetg, netd = netG (args).eval (), netD (args).eval ()</span><br><span class=\"line\">\t<span class=\"comment\">#定义噪声</span></span><br><span class=\"line\">\tnoises = torch.randn (args.batch_size, args.nz, <span class=\"number\">1</span>, <span class=\"number\">1</span>).to (device)</span><br><span class=\"line\">\t<span class=\"comment\">#载入网络</span></span><br><span class=\"line\">\tnetd.load_state_dict (torch.load (<span class=\"string\">'checkpoints/netd_%s.pth'</span>%args.max_epoch))</span><br><span class=\"line\">\tnetg.load_state_dict (torch.load (<span class=\"string\">'checkpoints/netg_%s.pth'</span>%args.max_epoch))</span><br><span class=\"line\">\t<span class=\"comment\">#设备化</span></span><br><span class=\"line\">\tnetd.to (device)</span><br><span class=\"line\">\tnetg.to (device)</span><br><span class=\"line\">\t<span class=\"comment\"># 生成图片，并计算图片在判别器的分数</span></span><br><span class=\"line\">\tfake_img = netg (noises)</span><br><span class=\"line\">\tscores = netd (fake_img).detach ()</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\"># 挑选最好的某几张</span></span><br><span class=\"line\">\tindexs = scores.topk (<span class=\"number\">5</span>) [<span class=\"number\">1</span>]</span><br><span class=\"line\">\tresult = []</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> indexs:</span><br><span class=\"line\">\t\tresult.append (fake_img.data [i])</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\"># 保存图片</span></span><br><span class=\"line\">\t<span class=\"keyword\">import</span> torchvision <span class=\"keyword\">as</span> tv</span><br><span class=\"line\">\ttv.utils.save_image (torch.stack (result), <span class=\"number\">5</span>, normalize=<span class=\"literal\">True</span>, range=(<span class=\"number\">-1</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">###################可视化类##################################</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> visdom</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision <span class=\"keyword\">as</span> tv</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Visualizer</span> <span class=\"params\">()</span>:</span></span><br><span class=\"line\">\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t封装了visdom的基本操作，但是你仍然可以通过`self.vis.function`</span></span><br><span class=\"line\"><span class=\"string\">\t调用原生的visdom接口</span></span><br><span class=\"line\"><span class=\"string\">\t\"\"\"</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span> <span class=\"params\">(self, env=<span class=\"string\">'default'</span>, **kwargs)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">import</span> visdom</span><br><span class=\"line\">\t\tself.vis = visdom.Visdom (env=env, use_incoming_socket=<span class=\"literal\">False</span>, **kwargs)</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 画的第几个数，相当于横座标</span></span><br><span class=\"line\">\t\t<span class=\"comment\"># 保存（’loss',23） 即loss的第23个点</span></span><br><span class=\"line\">\t\tself.index = &#123;&#125;</span><br><span class=\"line\">\t\tself.log_text = <span class=\"string\">''</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">reinit</span> <span class=\"params\">(self, env=<span class=\"string\">'default'</span>, **kwargs)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\t修改visdom的配置</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\tself.vis = visdom.Visdom (env=env, use_incoming_socket=<span class=\"literal\">False</span>, **kwargs)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> self</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">plot_many</span> <span class=\"params\">(self, d)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\t一次plot多个</span></span><br><span class=\"line\"><span class=\"string\">\t\t@params d: dict (name,value) i.e. ('loss',0.11)</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> d.items ():</span><br><span class=\"line\">\t\t\tself.plot (k, v)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">img_many</span> <span class=\"params\">(self, d)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> d.items ():</span><br><span class=\"line\">\t\t\tself.img (k, v)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">plot</span> <span class=\"params\">(self, name, y)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\tself.plot('loss',1.00)</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\tx = self.index.get (name, <span class=\"number\">0</span>)</span><br><span class=\"line\">\t\tself.vis.line (Y=np.array ([y]), X=np.array ([x]),</span><br><span class=\"line\">\t\t\t\t\t   win=(name),</span><br><span class=\"line\">\t\t\t\t\t   opts=dict (title=name),</span><br><span class=\"line\">\t\t\t\t\t   update=<span class=\"literal\">None</span> <span class=\"keyword\">if</span> x == <span class=\"number\">0</span> <span class=\"keyword\">else</span> <span class=\"string\">'append'</span></span><br><span class=\"line\">\t\t\t\t\t   )</span><br><span class=\"line\">\t\tself.index [name] = x + <span class=\"number\">1</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">img</span> <span class=\"params\">(self, name, img_)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\tself.img('input_img',t.Tensor(64,64))</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> len (img_.size ()) &lt; <span class=\"number\">3</span>:</span><br><span class=\"line\">\t\t\timg_ = img_.cpu ().unsqueeze (<span class=\"number\">0</span>)</span><br><span class=\"line\">\t\tself.vis.image (img_.cpu (),</span><br><span class=\"line\">\t\t\t\t\t\twin=(name),</span><br><span class=\"line\">\t\t\t\t\t\topts=dict (title=name)</span><br><span class=\"line\">\t\t\t\t\t\t)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">img_grid_many</span> <span class=\"params\">(self, d)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> d.items ():</span><br><span class=\"line\">\t\t\tself.img_grid (k, v)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">img_grid</span> <span class=\"params\">(self, name, input_3d)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\t一个batch的图片转成一个网格图，i.e. input（36，64，64）</span></span><br><span class=\"line\"><span class=\"string\">\t\t会变成 6*6 的网格图，每个格子大小64*64</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\tself.img (name, tv.utils.make_grid (</span><br><span class=\"line\">\t\t\tinput_3d.cpu () [<span class=\"number\">0</span>].unsqueeze (<span class=\"number\">1</span>).clamp (max=<span class=\"number\">1</span>, min=<span class=\"number\">0</span>)))</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">log</span> <span class=\"params\">(self, info, win=<span class=\"string\">'log_text'</span>)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\tself.log(&#123;'loss':1,'lr':0.0001&#125;)</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\tself.log_text += (<span class=\"string\">'[&#123;time&#125;] &#123;info&#125; &lt;br&gt;'</span>.format (</span><br><span class=\"line\">\t\t\ttime=time.strftime (<span class=\"string\">'%m%d_%H%M%S'</span>),</span><br><span class=\"line\">\t\t\tinfo=info))</span><br><span class=\"line\">\t\tself.vis.text (self.log_text, win=win)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__getattr__</span> <span class=\"params\">(self, name)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> getattr (self.vis, name)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t</span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> args.test:</span><br><span class=\"line\">\t\ttest()</span><br><span class=\"line\">\t<span class=\"keyword\">else</span>:</span><br><span class=\"line\">\t\ttrain()</span><br></pre></td></tr></table></figure></p>\n<ul>\n<li>输入：</li>\n<li><p>训练:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python train.py --cuda --plt</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>测试:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python train.py --cuda --test</span><br></pre></td></tr></table></figure>\n<ul>\n<li><code>--cuda</code>表示用GPU</li>\n<li><code>--plt</code>表示启动画图功能</li>\n<li><code>--vis</code> 表示使用visdom可视化</li>\n<li>具体可看参数列表:</li>\n<li><img src=\"/回顾-GAN/q.png\" alt></li>\n</ul>\n</li>\n</ul>\n<p><strong> 输出：</strong><br><img src=\"https://blog.mviai.com/images/回顾-GAN/r.png\" alt><br><img src=\"https://blog.mviai.com/images/回顾-GAN/r1.png\" alt><br><img src=\"https://blog.mviai.com/images/回顾-GAN/r2.png\" alt></p>\n<p><strong> 注：为什么结果这样，为了迎合网络，简单我把图片改的不成样 具体可以看参数设置</strong></p>\n"},{"title":"回顾-VAEGAN","date":"2018-12-23T19:38:57.000Z","_content":"\n# 1.VAEGAN 简介:\n关于如何解决VAE解码器产生图片模糊问题?\n作者将VAE作为生成器 与 判别器结合为新GAN,即VAEGAN\n通过GANs去提升了VAE的图片生成质量.\n*********\n# 2.VAEGAN 网络结构:\n还是先来看图:\n官方图:\n![](https://blog.mviai.com/images/回顾-VAEGAN/n2.png)\n网络图:\n![](https://blog.mviai.com/images/回顾-VAEGAN/n.jpg)\n**可以看出什么呢?**\n\n\n* 1.输入一张真实图片(x)-编码器->正态分布(z)-解码器->生成图片(~x)  \n    * <font color =red> 左边就是VAE,VAE希望生成图片与真实图片loss越小越好,但是loss小不见得图片就清晰.</font>\n\n\n* 2.为了解决这个问题,就将生成图片(~x) 给判别器,让判别器判断生成图片属于真实,还是属于生成,这样就可以让生成图片与真实图片难以区分,从而提升图片质量\n\n# 3. VAEGAN创新点:\n* 1.将元素方面的错误替换为特征方面的错误\n* 2.将VAEs和GANs合并为一个无监督生成模型，同时学习编码、生成和比较数据集样本。\n* 3.通过学习相似度度量训练的生成模型比接受过元素误差模拟训练的模型产生更好的图像样本\n* 4.证明了无监督训练可以产生更具有解纠缠因子的潜在图像表示法。\n* 5.在学习的潜空间中应用简单的算法可以生成反映这些属性变化的图像(使用编码器来计算潜在向量)。\n\n# 4.VAEGAN实现:\n* pytorch1.0\n\n\n**network.py**\n```python\n'''\n跟着图走\n\n'''\nimport torch.nn as nn\n\n#我们首先建立G (由一个编码器,一个解码器构成)\nclass G(nn.Module):\n    def __init__(self,args):\n        super(G,self).__init__()\n        ngf = args.ngf  #ngf 设置为128  卷积一般扩大两倍 参数为4,2,1\n        self.encoder= nn.Sequential(\n            # 输入一个真实图像3*64*64\n            nn.Conv2d (3, ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d (ngf),\n            nn.LeakyReLU (True),\n            # (ngf) x 32x 32\n            nn.Conv2d (ngf, ngf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d (ngf * 2),\n            nn.LeakyReLU (True),\n            # (ngf*2) x 16 x 16\n            nn.Conv2d (ngf * 2, ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d (ngf),\n            nn.LeakyReLU (True))\n       \n        #还原尺寸\n        self.decoder = nn.Sequential (\n                                 nn.ConvTranspose2d(ngf,ngf*2,4,2,1),\n                                 nn.BatchNorm2d(ngf*2),\n                                 nn.ReLU(),\n                                 nn.ConvTranspose2d (ngf*2,ngf,4,2,1),\n                                 nn.BatchNorm2d (ngf),\n                                 nn.ReLU (),\n                                 nn.ConvTranspose2d (ngf, 3, 4, 2, 1),\n                                 nn.Tanh ())\n                                 \n        #3*64*64\n        \n    #前向传播\n    def forward(self,x):\n        out=self.encoder(x)\n        out_x=self.decoder(out)\n        #print(out_x.size())\n        return out_x\n\n#建立D\nclass D(nn.Module):\n    def __init__(self,args):\n        super(D,self).__init__()\n        ndf = args.ndf  # ndf 128\n        self.D_layer= nn.Sequential(\n                # 输入 1 x 64 x 64,\n                nn.Conv2d (3, ndf, 4, 2, 1, bias=False),\n                nn.BatchNorm2d (ndf),\n                nn.LeakyReLU (True),\n                #输出 (ndf)*32*32\n                nn.Conv2d(ndf,ndf*2,4,2,1, bias=False),\n                nn.BatchNorm2d (ndf*2),\n                nn.LeakyReLU (True),\n                # 输出 (ndf*2)*16*16\n                nn.Conv2d (ndf*2, ndf*4, 4, 2, 1, bias=False),\n                nn.BatchNorm2d (ndf*4),\n                nn.LeakyReLU (True),\n                # 输出 (ndf*4)*8*8\n                nn.Conv2d (ndf*4, ndf*8, 4, 2, 1, bias=False),\n                nn.BatchNorm2d (ndf*8),\n                nn.LeakyReLU (True),\n                # 输出 (ndf*8)*4*4\n                nn.Conv2d (ndf * 8, 1, 4, 1, 0, bias=False),\n                # 输出 1*1*1\n                nn.Sigmoid())#告诉D概率\n                \n    #前向传播\n    def forward(self,x):\n        out=self.D_layer(x)\n        return out\n\n\n\n\n```\n**train.py**\n```python \nimport torch\nimport torch.nn as nn\nimport torchvision.datasets as datasets\nimport torchvision.transforms as  transforms\nfrom torch.autograd import Variable\nimport torch.backends.cudnn as cudnn\n# 工具包\nimport argparse\n# 载入网络\nfrom network import G, D\n\n#############参数设置#############\n####命令行设置########\nparser = argparse.ArgumentParser (description='GANs')  # 导入命令行模块\n# 对关于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明\n#关于训练参数\nparser.add_argument ('--batch_size', type=int, default=64,\n\t\t\t\t\t help='训练batch-size大小 (default: 64)')\nparser.add_argument ('--imageSize', type=int, default=64,\n\t\t\t\t\t help='图片尺寸')\nparser.add_argument ('--max_epoch', type=int, default=20,\n\t\t\t\t\t help='最大迭代数 (default: 12)')\n#关于网络参数\nparser.add_argument ('--lr_g', type=float, default=2e-4,\n\t\t\t\t\t help='生成器学习率 (default: 2e-4)')\nparser.add_argument ('--lr_d', type=float, default=2e-4,\n\t\t\t\t\t help='判别器学习率 (default: 2e-4)')\nparser.add_argument ('--ngf', type=int, default=64,\n\t\t\t\t\t help='生成器feature map数')\nparser.add_argument ('--ndf', type=int, default=64,\n\t\t\t\t\t help='判别器feature map数')\nparser.add_argument ('--d_every', type=int, default=1,\n\t\t\t\t\t help='每几个batch训练一次判别器')\nparser.add_argument ('--g_every', type=int, default=4,\n\t\t\t\t\t help='每几个batch训练一次生成器')\nparser.add_argument ('--nz', type=int, default=3,\n\t\t\t\t\t help='噪声维度')\n\n#关于优化器参数\nparser.add_argument ('--beta1', type=int, default=0.5,\n\t\t\t\t\t help='Adam优化器的beta1参数')\n#路径\nparser.add_argument ('--dataset', default='data/',\n\t\t\t\t\t help='数据集路径')\n\nparser.add_argument ('--save_data',  default='save/',\n\t\t\t\t\t help='保存路径')\n\n#可视化\nparser.add_argument ('--vis', action='store_true',\n\t\t\t\t\t help='使用visdom可视化')\nparser.add_argument ('--plot_every', type=int, default=1,\n\t\t\t\t\t help='每间隔_batch，visdom画图一次')\n# 其他\n\nparser.add_argument ('--cuda', action='store_true',\n\t\t\t\t\t help='开启cuda训练')\nparser.add_argument ('--plt', action='store_true',\n\t\t\t\t\t help='开启画图')\nparser.add_argument ('--test', action='store_true',\n\t\t\t\t\t help='开启测试生成')\nparser.add_argument ('--save_every', type=int, default=5,\n\t\t\t\t\t help='几个epoch保存一次模型 (default: 2)')\nparser.add_argument ('--seed', type=int, default=1,\n\t\t\t\t\t help='随机种子 (default: 1)')\nargs = parser.parse_args ()  # 相当于激活命令\n\n\n#训练过程\ndef train():\n\t###############判断gpu#############\n\tdevice = torch.device ('cuda') if args.cuda else torch.device ('cpu')\n\t\n\t####### 为CPU设置种子用于生成随机数，以使得结果是确定的##########\n\ttorch.manual_seed (args.seed)\n\tif args.cuda:\n\t\ttorch.cuda.manual_seed (args.seed)\n\tcudnn.benchmark = True\n\t\n\t#################可视化###############\n\tif args.vis:\n\t\tvis = Visualizer ('GANs')\n\t##########数据转换#####################\n\tdata_transforms = transforms.Compose ([transforms.Scale (args.imageSize),  # 通过调整比例调整大小,会报警\n\t\t\t\t\t\t\t\t\t\t   transforms.CenterCrop (args.imageSize),  # 在中心裁剪给指定大小方形PIL图像\n\t\t\t\t\t\t\t\t\t\t   transforms.ToTensor (),# 转换成pytorch 变量tensor\n\t\t\t\t\t\t\t\t\t\t   transforms.Normalize ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\t###############数据载入################\n\t# train_dataset = datasets.ImageFolder (root=args.dataset,  # 数据路径目录\n\t# \t\t\t\t\t\t\t\t\t  transform=data_transforms)  # 把数据转换成上面约束样子\n\t\n\ttrain_dataset = datasets.CIFAR10(root=args.dataset,\n\t\t\t\t\t\t\t\t\t train=True,\n\t\t\t\t\t\t\t\t\t transform=data_transforms,\n\t\t\t\t\t\t\t\t\t download=False)\n\t# test_dataset = datasets.ImageFolder (root=args.dataset,\n\t# \t\t\t\t\t\t\t\t\t transform=data_transforms)\n\t\n\t##############数据装载###############\n\ttrain_loader = torch.utils.data.DataLoader (dataset=train_dataset,  # 装载数据\n\t\t\t\t\t\t\t\t\t\t\t\tbatch_size=args.batch_size,  # 设置批大小\n\t\t\t\t\t\t\t\t\t\t\t\tshuffle=True)  # 是否随机打乱\n\t# test_loader = torch.utils.data.DataLoader (dataset=test_dataset,\n\t# \t\t\t\t\t\t\t\t\t\t   batch_size=args.batch_size,\n\t# \t\t\t\t\t\t\t\t\t\t   shuffle=True)\n\t\n\t#############模型载入#################\n\tnetG ,netD= G (args),D (args)\n\tnetG.to (device)\n\tnetD.to (device)\n\tprint (netD, netG)\n\t\n\t###############损失函数##################\n\tcriterion = torch.nn.BCELoss ().to (device)\n\toptimizerD = torch.optim.Adam (netD.parameters (), lr=args.lr_d,betas=(0.5, 0.999))  # Adam优化器\n\toptimizerG = torch.optim.Adam (netG.parameters (), lr=args.lr_g,betas=(0.5, 0.999))  # Adam优化器\n\t###############画图参数保存##################\n\tG_losses = []\n\tD_losses = []\n\timg_list = []\n\t#############训练过程#####################\n\timport tqdm\n\t# Tqdm是一个快速，可扩展的Python进度条，可以在Python\n\t# 长循环中添加一个进度提示信息，用户只需要封装任意的迭代器\n\t# tqdm (iterator)。\n\tfor epoch in range (args.max_epoch):\n\t\tfor i, (images, labels) in tqdm.tqdm(enumerate (train_loader)):  # 枚举出来\n\t\t\t#数据处理\n\t\t\timages = images.to (device)\n\t\t\t# 装箱\n\t\t\timages = Variable (images)\n\t\t\tnoises=Variable(torch.randn(images.size(0), args.nz, 1, 1).to(device))\n\t\t\t\n\t\t\t#遍历每张图片,并且根据指定的训练机制训练\n\t\t\tif i % args.d_every==0:#满足此条件训练D\n\t\t\t\t#D前向传播\n\t\t\t\toptimizerD.zero_grad ()\n\t\t\t\t#D网络输出\n\t\t\t\toutput_r = netD (images).view(-1)\n\t\t\t\t#定义真张量\n\t\t\t\t#返回第一个参数为大小 第二参数为值 的张量\n\t\t\t\ttrue_label = torch.full ((images.size(0),), 1, device=device)\n\t\t\t\t#判别真的损失\n\t\t\t\td_real_loss = criterion(output_r, true_label)\n\t\t\t\t#反向传播\n\t\t\t\td_real_loss.backward()\n\t\t\t\t#G网络输出\n\t\t\t\tfake = netG (images) # 根据真生成图\n\t\t\t\t#把假图给d\n\t\t\t\toutput_f = netD (fake).view(-1)\n\t\t\t\t#d假的损失\n\t\t\t\t#print(fake.size(),output_f.size(),output_r.size())\n\t\t\t\t# 返回第一个参数为大小 第二参数为值 的张量\n\t\t\t\tfake_label = torch.full ((images.size (0),), 0, device=device)\n\t\t\t\td_fake_loss= criterion(output_f,fake_label)\n\t\t\t\t#D假反向传播\n\t\t\t\td_fake_loss.backward ()\n\t\t\t\t# 总损失\n\t\t\t\tD_loss=d_fake_loss+d_real_loss\n\t\t\t\t#D更新参数\n\t\t\t\toptimizerD.step ()\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t# 度量\n\t\t\t\tD_x = output_r.mean ().item ()\n\t\t\t\tD_G_z1 = output_f.mean ().item ()\n\t\t\t\n\t\t\tif i % args.g_every==0:#满足此条件训练G\n\t\t\t\t#G前向传播\n\t\t\t\toptimizerG.zero_grad ()\n\t\t\t\t#G网络输出\n\t\t\t\tfake = netG (images)  # 根据噪声生成假图\n\t\t\t\t#把假图给G\n\t\t\t\toutput_f = netD (fake).view(-1)\n\t\t\t\t#G的损失\n\t\t\t\ttrue_label = torch.full ((images.size (0),), 1, device=device)\n\t\t\t\tG_loss = criterion(output_f,true_label)\n\t\t\t\t#G反向传播\n\t\t\t\tG_loss.backward ()\n\t\t\t\t#度量\n\t\t\t\tD_G_z2 = output_f.mean ().item ()\n\t\t\t\t#D更新参数\n\t\t\t\toptimizerG.step ()\n\t\t\t\t\n\t\t\t###########################################\n\t\t\t##########可视化(可选)#####################\n\t\t\tif args.vis and i % args.plot_every == args.plot_every - 1:\n\t\t\t\tfake = netG (noises)\n\t\t\t\tvis.images (fake.detach ().cpu ().numpy () [:64] * 0.5 + 0.5, win='fixfake')\n\t\t\t\tvis.images (images.data.cpu ().numpy () [:64] * 0.5 + 0.5, win='real')\n\t\t\t\tvis.plot ('errord', D_loss.item ())\n\t\t\t\tvis.plot ('errorg', G_loss.item ())\n\t\t\t#######################################\n\t\t\t############打印记录###################\n\t\t\tif i % 1== 0:\n\t\t\t\tprint ('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n\t\t\t\t\t   % (epoch, args.max_epoch, i, len (train_loader),\n\t\t\t\t\t\t  D_loss.item (), G_loss.item (), D_x, D_G_z1, D_G_z2))\n\t\t\t\t########添加画图参数########\n\t\t\t\tG_losses.append (G_loss.item ())\n\t\t\t\tD_losses.append (D_loss.item ())\n\t\t\t\twith torch.no_grad ():\n\t\t\t\t\tnoises = torch.randn (args.batch_size, args.nz, 1, 1).to (device)\n\t\t\t\t\tfake = netG (images).detach ().cpu ()\n\t\t\t\timport torchvision.utils as vutils\n\t\t\t\timg_list.append (vutils.make_grid (fake, padding=2, normalize=True))\n\t\n\n\n\t\t#######################################\n\t\t############保存模型###################\n\t\n\t\tif (epoch + 1) % args.save_every == 0:\n\t\t\timport torchvision as tv\n\t\t\t# 保存模型、图片\n\t\t\ttv.utils.save_image (fake.data [:64], '%s/%s.png' % (args.save_data, epoch), normalize=True,range=(-1, 1))\n\t\t\ttorch.save (netD.state_dict (), 'checkpoints/netd_%s.pth' % epoch)\n\t\t\ttorch.save (netG.state_dict (), 'checkpoints/netg_%s.pth' % epoch)\n\t\t\tprint('完成%s的模型保存'%epoch)\n\n\t#######################################\n\t############画图###################\n\t\n\tif args.plt:\n\t\timport matplotlib.pyplot as plt\n\t\timport numpy as np\n\t\timport torchvision.utils as vutils\n\t\t\n\t\tplt.figure (figsize=(10, 5))\n\t\tplt.title (\"GAN\")\n\t\tplt.plot (G_losses, label=\"G\")\n\t\tplt.plot (D_losses, label=\"D\")\n\t\tplt.xlabel (\"迭代次数\",fontproperties='SimHei')\n\t\tplt.ylabel (\"损失\",fontproperties='SimHei')\n\t\tplt.legend ()\n\t\tplt.show ()\n\t\t\n\t\t# 从数据集加载\n\t\treal_batch = next (iter (train_dataset))\n\t\t\n\t\t# 画出真图\n\t\tplt.figure (figsize=(15, 10))\n\t\tplt.subplot (1, 2, 1)\n\t\tplt.axis (\"off\")\n\t\tplt.title (\"真图\",fontproperties='SimHei')\n\t\tplt.imshow (np.transpose (\n\t\t\tvutils.make_grid (real_batch [0].to (device) [:64], padding=5, normalize=True).cpu (),\n\t\t\t(1, 2, 0)))\n\t\t\n\t\t# 画出假图\n\t\tplt.subplot (1, 2, 2)\n\t\tplt.axis (\"off\")\n\t\tplt.title (\"假图\",fontproperties='SimHei')\n\t\tplt.imshow (np.transpose (img_list [-1], (1, 2, 0)))\n\t\tplt.show ()\n\t\t\t\t\n\n\t\t\n\n\t\t\n\n@torch.no_grad()#禁用梯度计算\ndef test():\n\t#判断Gpu\n\tdevice = torch.device ('cuda') if args.cuda else torch.device ('cpu')\n\t#初始化网络\n\tnetg, netd = netG (args).eval (), netD (args).eval ()\n\t#定义噪声\n\tnoises = torch.randn (args.batch_size, args.nz, 1, 1).to (device)\n\t#载入网络\n\tnetd.load_state_dict (torch.load ('checkpoints/netd_%s.pth'%args.max_epoch))\n\tnetg.load_state_dict (torch.load ('checkpoints/netg_%s.pth'%args.max_epoch))\n\t#设备化\n\tnetd.to (device)\n\tnetg.to (device)\n\t# 生成图片，并计算图片在判别器的分数\n\tfake_img = netg (noises)\n\tscores = netd (fake_img).detach ()\n\t\n\t# 挑选最好的某几张\n\tindexs = scores.topk (5) [1]\n\tresult = []\n\tfor i in indexs:\n\t\tresult.append (fake_img.data [i])\n\t\n\t# 保存图片\n\timport torchvision as tv\n\ttv.utils.save_image (torch.stack (result), 5, normalize=True, range=(-1, 1))\n\n\n\n\n\n\n\n\n\n\n\n\t\n\t###################可视化类##################################\nimport visdom\nimport time\nimport torchvision as tv\nimport numpy as np\n\n\nclass Visualizer ():\n\t\"\"\"\n\t封装了visdom的基本操作，但是你仍然可以通过`self.vis.function`\n\t调用原生的visdom接口\n\t\"\"\"\n\t\n\tdef __init__ (self, env='default', **kwargs):\n\t\timport visdom\n\t\tself.vis = visdom.Visdom (env=env, use_incoming_socket=False, **kwargs)\n\t\t\n\t\t# 画的第几个数，相当于横座标\n\t\t# 保存（’loss',23） 即loss的第23个点\n\t\tself.index = {}\n\t\tself.log_text = ''\n\t\n\tdef reinit (self, env='default', **kwargs):\n\t\t\"\"\"\n\t\t修改visdom的配置\n\t\t\"\"\"\n\t\tself.vis = visdom.Visdom (env=env, use_incoming_socket=False, **kwargs)\n\t\treturn self\n\t\n\tdef plot_many (self, d):\n\t\t\"\"\"\n\t\t一次plot多个\n\t\t@params d: dict (name,value) i.e. ('loss',0.11)\n\t\t\"\"\"\n\t\tfor k, v in d.items ():\n\t\t\tself.plot (k, v)\n\t\n\tdef img_many (self, d):\n\t\tfor k, v in d.items ():\n\t\t\tself.img (k, v)\n\t\n\tdef plot (self, name, y):\n\t\t\"\"\"\n\t\tself.plot('loss',1.00)\n\t\t\"\"\"\n\t\tx = self.index.get (name, 0)\n\t\tself.vis.line (Y=np.array ([y]), X=np.array ([x]),\n\t\t\t\t\t   win=(name),\n\t\t\t\t\t   opts=dict (title=name),\n\t\t\t\t\t   update=None if x == 0 else 'append'\n\t\t\t\t\t   )\n\t\tself.index [name] = x + 1\n\t\n\tdef img (self, name, img_):\n\t\t\"\"\"\n\t\tself.img('input_img',t.Tensor(64,64))\n\t\t\"\"\"\n\t\t\n\t\tif len (img_.size ()) < 3:\n\t\t\timg_ = img_.cpu ().unsqueeze (0)\n\t\tself.vis.image (img_.cpu (),\n\t\t\t\t\t\twin=(name),\n\t\t\t\t\t\topts=dict (title=name)\n\t\t\t\t\t\t)\n\t\n\tdef img_grid_many (self, d):\n\t\tfor k, v in d.items ():\n\t\t\tself.img_grid (k, v)\n\t\n\tdef img_grid (self, name, input_3d):\n\t\t\"\"\"\n\t\t一个batch的图片转成一个网格图，i.e. input（36，64，64）\n\t\t会变成 6*6 的网格图，每个格子大小64*64\n\t\t\"\"\"\n\t\tself.img (name, tv.utils.make_grid (\n\t\t\tinput_3d.cpu () [0].unsqueeze (1).clamp (max=1, min=0)))\n\t\n\tdef log (self, info, win='log_text'):\n\t\t\"\"\"\n\t\tself.log({'loss':1,'lr':0.0001})\n\t\t\"\"\"\n\t\t\n\t\tself.log_text += ('[{time}] {info} <br>'.format (\n\t\t\ttime=time.strftime ('%m%d_%H%M%S'),\n\t\t\tinfo=info))\n\t\tself.vis.text (self.log_text, win=win)\n\t\n\tdef __getattr__ (self, name):\n\t\treturn getattr (self.vis, name)\n\t\n\t\n\t\nif __name__ == '__main__':\n\tif args.test:\n\t\ttest()\n\telse:\n\t\ttrain()\n```\n\n**输出:\n![](https://blog.mviai.com/images/回顾-VAEGAN/r.png)\n\n\n","source":"_posts/回顾-VAEGAN.md","raw":"---\n\ntitle: 回顾-VAEGAN\ndate: 2018-12-24 03:38:57\ntags:\n    - VAEGAN\ncategories: \n    - 框架\n    - pytorch\n    - GAN\n---\n\n# 1.VAEGAN 简介:\n关于如何解决VAE解码器产生图片模糊问题?\n作者将VAE作为生成器 与 判别器结合为新GAN,即VAEGAN\n通过GANs去提升了VAE的图片生成质量.\n*********\n# 2.VAEGAN 网络结构:\n还是先来看图:\n官方图:\n![](https://blog.mviai.com/images/回顾-VAEGAN/n2.png)\n网络图:\n![](https://blog.mviai.com/images/回顾-VAEGAN/n.jpg)\n**可以看出什么呢?**\n\n\n* 1.输入一张真实图片(x)-编码器->正态分布(z)-解码器->生成图片(~x)  \n    * <font color =red> 左边就是VAE,VAE希望生成图片与真实图片loss越小越好,但是loss小不见得图片就清晰.</font>\n\n\n* 2.为了解决这个问题,就将生成图片(~x) 给判别器,让判别器判断生成图片属于真实,还是属于生成,这样就可以让生成图片与真实图片难以区分,从而提升图片质量\n\n# 3. VAEGAN创新点:\n* 1.将元素方面的错误替换为特征方面的错误\n* 2.将VAEs和GANs合并为一个无监督生成模型，同时学习编码、生成和比较数据集样本。\n* 3.通过学习相似度度量训练的生成模型比接受过元素误差模拟训练的模型产生更好的图像样本\n* 4.证明了无监督训练可以产生更具有解纠缠因子的潜在图像表示法。\n* 5.在学习的潜空间中应用简单的算法可以生成反映这些属性变化的图像(使用编码器来计算潜在向量)。\n\n# 4.VAEGAN实现:\n* pytorch1.0\n\n\n**network.py**\n```python\n'''\n跟着图走\n\n'''\nimport torch.nn as nn\n\n#我们首先建立G (由一个编码器,一个解码器构成)\nclass G(nn.Module):\n    def __init__(self,args):\n        super(G,self).__init__()\n        ngf = args.ngf  #ngf 设置为128  卷积一般扩大两倍 参数为4,2,1\n        self.encoder= nn.Sequential(\n            # 输入一个真实图像3*64*64\n            nn.Conv2d (3, ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d (ngf),\n            nn.LeakyReLU (True),\n            # (ngf) x 32x 32\n            nn.Conv2d (ngf, ngf * 2, 4, 2, 1, bias=False),\n            nn.BatchNorm2d (ngf * 2),\n            nn.LeakyReLU (True),\n            # (ngf*2) x 16 x 16\n            nn.Conv2d (ngf * 2, ngf, 4, 2, 1, bias=False),\n            nn.BatchNorm2d (ngf),\n            nn.LeakyReLU (True))\n       \n        #还原尺寸\n        self.decoder = nn.Sequential (\n                                 nn.ConvTranspose2d(ngf,ngf*2,4,2,1),\n                                 nn.BatchNorm2d(ngf*2),\n                                 nn.ReLU(),\n                                 nn.ConvTranspose2d (ngf*2,ngf,4,2,1),\n                                 nn.BatchNorm2d (ngf),\n                                 nn.ReLU (),\n                                 nn.ConvTranspose2d (ngf, 3, 4, 2, 1),\n                                 nn.Tanh ())\n                                 \n        #3*64*64\n        \n    #前向传播\n    def forward(self,x):\n        out=self.encoder(x)\n        out_x=self.decoder(out)\n        #print(out_x.size())\n        return out_x\n\n#建立D\nclass D(nn.Module):\n    def __init__(self,args):\n        super(D,self).__init__()\n        ndf = args.ndf  # ndf 128\n        self.D_layer= nn.Sequential(\n                # 输入 1 x 64 x 64,\n                nn.Conv2d (3, ndf, 4, 2, 1, bias=False),\n                nn.BatchNorm2d (ndf),\n                nn.LeakyReLU (True),\n                #输出 (ndf)*32*32\n                nn.Conv2d(ndf,ndf*2,4,2,1, bias=False),\n                nn.BatchNorm2d (ndf*2),\n                nn.LeakyReLU (True),\n                # 输出 (ndf*2)*16*16\n                nn.Conv2d (ndf*2, ndf*4, 4, 2, 1, bias=False),\n                nn.BatchNorm2d (ndf*4),\n                nn.LeakyReLU (True),\n                # 输出 (ndf*4)*8*8\n                nn.Conv2d (ndf*4, ndf*8, 4, 2, 1, bias=False),\n                nn.BatchNorm2d (ndf*8),\n                nn.LeakyReLU (True),\n                # 输出 (ndf*8)*4*4\n                nn.Conv2d (ndf * 8, 1, 4, 1, 0, bias=False),\n                # 输出 1*1*1\n                nn.Sigmoid())#告诉D概率\n                \n    #前向传播\n    def forward(self,x):\n        out=self.D_layer(x)\n        return out\n\n\n\n\n```\n**train.py**\n```python \nimport torch\nimport torch.nn as nn\nimport torchvision.datasets as datasets\nimport torchvision.transforms as  transforms\nfrom torch.autograd import Variable\nimport torch.backends.cudnn as cudnn\n# 工具包\nimport argparse\n# 载入网络\nfrom network import G, D\n\n#############参数设置#############\n####命令行设置########\nparser = argparse.ArgumentParser (description='GANs')  # 导入命令行模块\n# 对关于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明\n#关于训练参数\nparser.add_argument ('--batch_size', type=int, default=64,\n\t\t\t\t\t help='训练batch-size大小 (default: 64)')\nparser.add_argument ('--imageSize', type=int, default=64,\n\t\t\t\t\t help='图片尺寸')\nparser.add_argument ('--max_epoch', type=int, default=20,\n\t\t\t\t\t help='最大迭代数 (default: 12)')\n#关于网络参数\nparser.add_argument ('--lr_g', type=float, default=2e-4,\n\t\t\t\t\t help='生成器学习率 (default: 2e-4)')\nparser.add_argument ('--lr_d', type=float, default=2e-4,\n\t\t\t\t\t help='判别器学习率 (default: 2e-4)')\nparser.add_argument ('--ngf', type=int, default=64,\n\t\t\t\t\t help='生成器feature map数')\nparser.add_argument ('--ndf', type=int, default=64,\n\t\t\t\t\t help='判别器feature map数')\nparser.add_argument ('--d_every', type=int, default=1,\n\t\t\t\t\t help='每几个batch训练一次判别器')\nparser.add_argument ('--g_every', type=int, default=4,\n\t\t\t\t\t help='每几个batch训练一次生成器')\nparser.add_argument ('--nz', type=int, default=3,\n\t\t\t\t\t help='噪声维度')\n\n#关于优化器参数\nparser.add_argument ('--beta1', type=int, default=0.5,\n\t\t\t\t\t help='Adam优化器的beta1参数')\n#路径\nparser.add_argument ('--dataset', default='data/',\n\t\t\t\t\t help='数据集路径')\n\nparser.add_argument ('--save_data',  default='save/',\n\t\t\t\t\t help='保存路径')\n\n#可视化\nparser.add_argument ('--vis', action='store_true',\n\t\t\t\t\t help='使用visdom可视化')\nparser.add_argument ('--plot_every', type=int, default=1,\n\t\t\t\t\t help='每间隔_batch，visdom画图一次')\n# 其他\n\nparser.add_argument ('--cuda', action='store_true',\n\t\t\t\t\t help='开启cuda训练')\nparser.add_argument ('--plt', action='store_true',\n\t\t\t\t\t help='开启画图')\nparser.add_argument ('--test', action='store_true',\n\t\t\t\t\t help='开启测试生成')\nparser.add_argument ('--save_every', type=int, default=5,\n\t\t\t\t\t help='几个epoch保存一次模型 (default: 2)')\nparser.add_argument ('--seed', type=int, default=1,\n\t\t\t\t\t help='随机种子 (default: 1)')\nargs = parser.parse_args ()  # 相当于激活命令\n\n\n#训练过程\ndef train():\n\t###############判断gpu#############\n\tdevice = torch.device ('cuda') if args.cuda else torch.device ('cpu')\n\t\n\t####### 为CPU设置种子用于生成随机数，以使得结果是确定的##########\n\ttorch.manual_seed (args.seed)\n\tif args.cuda:\n\t\ttorch.cuda.manual_seed (args.seed)\n\tcudnn.benchmark = True\n\t\n\t#################可视化###############\n\tif args.vis:\n\t\tvis = Visualizer ('GANs')\n\t##########数据转换#####################\n\tdata_transforms = transforms.Compose ([transforms.Scale (args.imageSize),  # 通过调整比例调整大小,会报警\n\t\t\t\t\t\t\t\t\t\t   transforms.CenterCrop (args.imageSize),  # 在中心裁剪给指定大小方形PIL图像\n\t\t\t\t\t\t\t\t\t\t   transforms.ToTensor (),# 转换成pytorch 变量tensor\n\t\t\t\t\t\t\t\t\t\t   transforms.Normalize ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\t###############数据载入################\n\t# train_dataset = datasets.ImageFolder (root=args.dataset,  # 数据路径目录\n\t# \t\t\t\t\t\t\t\t\t  transform=data_transforms)  # 把数据转换成上面约束样子\n\t\n\ttrain_dataset = datasets.CIFAR10(root=args.dataset,\n\t\t\t\t\t\t\t\t\t train=True,\n\t\t\t\t\t\t\t\t\t transform=data_transforms,\n\t\t\t\t\t\t\t\t\t download=False)\n\t# test_dataset = datasets.ImageFolder (root=args.dataset,\n\t# \t\t\t\t\t\t\t\t\t transform=data_transforms)\n\t\n\t##############数据装载###############\n\ttrain_loader = torch.utils.data.DataLoader (dataset=train_dataset,  # 装载数据\n\t\t\t\t\t\t\t\t\t\t\t\tbatch_size=args.batch_size,  # 设置批大小\n\t\t\t\t\t\t\t\t\t\t\t\tshuffle=True)  # 是否随机打乱\n\t# test_loader = torch.utils.data.DataLoader (dataset=test_dataset,\n\t# \t\t\t\t\t\t\t\t\t\t   batch_size=args.batch_size,\n\t# \t\t\t\t\t\t\t\t\t\t   shuffle=True)\n\t\n\t#############模型载入#################\n\tnetG ,netD= G (args),D (args)\n\tnetG.to (device)\n\tnetD.to (device)\n\tprint (netD, netG)\n\t\n\t###############损失函数##################\n\tcriterion = torch.nn.BCELoss ().to (device)\n\toptimizerD = torch.optim.Adam (netD.parameters (), lr=args.lr_d,betas=(0.5, 0.999))  # Adam优化器\n\toptimizerG = torch.optim.Adam (netG.parameters (), lr=args.lr_g,betas=(0.5, 0.999))  # Adam优化器\n\t###############画图参数保存##################\n\tG_losses = []\n\tD_losses = []\n\timg_list = []\n\t#############训练过程#####################\n\timport tqdm\n\t# Tqdm是一个快速，可扩展的Python进度条，可以在Python\n\t# 长循环中添加一个进度提示信息，用户只需要封装任意的迭代器\n\t# tqdm (iterator)。\n\tfor epoch in range (args.max_epoch):\n\t\tfor i, (images, labels) in tqdm.tqdm(enumerate (train_loader)):  # 枚举出来\n\t\t\t#数据处理\n\t\t\timages = images.to (device)\n\t\t\t# 装箱\n\t\t\timages = Variable (images)\n\t\t\tnoises=Variable(torch.randn(images.size(0), args.nz, 1, 1).to(device))\n\t\t\t\n\t\t\t#遍历每张图片,并且根据指定的训练机制训练\n\t\t\tif i % args.d_every==0:#满足此条件训练D\n\t\t\t\t#D前向传播\n\t\t\t\toptimizerD.zero_grad ()\n\t\t\t\t#D网络输出\n\t\t\t\toutput_r = netD (images).view(-1)\n\t\t\t\t#定义真张量\n\t\t\t\t#返回第一个参数为大小 第二参数为值 的张量\n\t\t\t\ttrue_label = torch.full ((images.size(0),), 1, device=device)\n\t\t\t\t#判别真的损失\n\t\t\t\td_real_loss = criterion(output_r, true_label)\n\t\t\t\t#反向传播\n\t\t\t\td_real_loss.backward()\n\t\t\t\t#G网络输出\n\t\t\t\tfake = netG (images) # 根据真生成图\n\t\t\t\t#把假图给d\n\t\t\t\toutput_f = netD (fake).view(-1)\n\t\t\t\t#d假的损失\n\t\t\t\t#print(fake.size(),output_f.size(),output_r.size())\n\t\t\t\t# 返回第一个参数为大小 第二参数为值 的张量\n\t\t\t\tfake_label = torch.full ((images.size (0),), 0, device=device)\n\t\t\t\td_fake_loss= criterion(output_f,fake_label)\n\t\t\t\t#D假反向传播\n\t\t\t\td_fake_loss.backward ()\n\t\t\t\t# 总损失\n\t\t\t\tD_loss=d_fake_loss+d_real_loss\n\t\t\t\t#D更新参数\n\t\t\t\toptimizerD.step ()\n\t\t\t\t\n\t\t\t\t\n\t\t\t\t# 度量\n\t\t\t\tD_x = output_r.mean ().item ()\n\t\t\t\tD_G_z1 = output_f.mean ().item ()\n\t\t\t\n\t\t\tif i % args.g_every==0:#满足此条件训练G\n\t\t\t\t#G前向传播\n\t\t\t\toptimizerG.zero_grad ()\n\t\t\t\t#G网络输出\n\t\t\t\tfake = netG (images)  # 根据噪声生成假图\n\t\t\t\t#把假图给G\n\t\t\t\toutput_f = netD (fake).view(-1)\n\t\t\t\t#G的损失\n\t\t\t\ttrue_label = torch.full ((images.size (0),), 1, device=device)\n\t\t\t\tG_loss = criterion(output_f,true_label)\n\t\t\t\t#G反向传播\n\t\t\t\tG_loss.backward ()\n\t\t\t\t#度量\n\t\t\t\tD_G_z2 = output_f.mean ().item ()\n\t\t\t\t#D更新参数\n\t\t\t\toptimizerG.step ()\n\t\t\t\t\n\t\t\t###########################################\n\t\t\t##########可视化(可选)#####################\n\t\t\tif args.vis and i % args.plot_every == args.plot_every - 1:\n\t\t\t\tfake = netG (noises)\n\t\t\t\tvis.images (fake.detach ().cpu ().numpy () [:64] * 0.5 + 0.5, win='fixfake')\n\t\t\t\tvis.images (images.data.cpu ().numpy () [:64] * 0.5 + 0.5, win='real')\n\t\t\t\tvis.plot ('errord', D_loss.item ())\n\t\t\t\tvis.plot ('errorg', G_loss.item ())\n\t\t\t#######################################\n\t\t\t############打印记录###################\n\t\t\tif i % 1== 0:\n\t\t\t\tprint ('[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'\n\t\t\t\t\t   % (epoch, args.max_epoch, i, len (train_loader),\n\t\t\t\t\t\t  D_loss.item (), G_loss.item (), D_x, D_G_z1, D_G_z2))\n\t\t\t\t########添加画图参数########\n\t\t\t\tG_losses.append (G_loss.item ())\n\t\t\t\tD_losses.append (D_loss.item ())\n\t\t\t\twith torch.no_grad ():\n\t\t\t\t\tnoises = torch.randn (args.batch_size, args.nz, 1, 1).to (device)\n\t\t\t\t\tfake = netG (images).detach ().cpu ()\n\t\t\t\timport torchvision.utils as vutils\n\t\t\t\timg_list.append (vutils.make_grid (fake, padding=2, normalize=True))\n\t\n\n\n\t\t#######################################\n\t\t############保存模型###################\n\t\n\t\tif (epoch + 1) % args.save_every == 0:\n\t\t\timport torchvision as tv\n\t\t\t# 保存模型、图片\n\t\t\ttv.utils.save_image (fake.data [:64], '%s/%s.png' % (args.save_data, epoch), normalize=True,range=(-1, 1))\n\t\t\ttorch.save (netD.state_dict (), 'checkpoints/netd_%s.pth' % epoch)\n\t\t\ttorch.save (netG.state_dict (), 'checkpoints/netg_%s.pth' % epoch)\n\t\t\tprint('完成%s的模型保存'%epoch)\n\n\t#######################################\n\t############画图###################\n\t\n\tif args.plt:\n\t\timport matplotlib.pyplot as plt\n\t\timport numpy as np\n\t\timport torchvision.utils as vutils\n\t\t\n\t\tplt.figure (figsize=(10, 5))\n\t\tplt.title (\"GAN\")\n\t\tplt.plot (G_losses, label=\"G\")\n\t\tplt.plot (D_losses, label=\"D\")\n\t\tplt.xlabel (\"迭代次数\",fontproperties='SimHei')\n\t\tplt.ylabel (\"损失\",fontproperties='SimHei')\n\t\tplt.legend ()\n\t\tplt.show ()\n\t\t\n\t\t# 从数据集加载\n\t\treal_batch = next (iter (train_dataset))\n\t\t\n\t\t# 画出真图\n\t\tplt.figure (figsize=(15, 10))\n\t\tplt.subplot (1, 2, 1)\n\t\tplt.axis (\"off\")\n\t\tplt.title (\"真图\",fontproperties='SimHei')\n\t\tplt.imshow (np.transpose (\n\t\t\tvutils.make_grid (real_batch [0].to (device) [:64], padding=5, normalize=True).cpu (),\n\t\t\t(1, 2, 0)))\n\t\t\n\t\t# 画出假图\n\t\tplt.subplot (1, 2, 2)\n\t\tplt.axis (\"off\")\n\t\tplt.title (\"假图\",fontproperties='SimHei')\n\t\tplt.imshow (np.transpose (img_list [-1], (1, 2, 0)))\n\t\tplt.show ()\n\t\t\t\t\n\n\t\t\n\n\t\t\n\n@torch.no_grad()#禁用梯度计算\ndef test():\n\t#判断Gpu\n\tdevice = torch.device ('cuda') if args.cuda else torch.device ('cpu')\n\t#初始化网络\n\tnetg, netd = netG (args).eval (), netD (args).eval ()\n\t#定义噪声\n\tnoises = torch.randn (args.batch_size, args.nz, 1, 1).to (device)\n\t#载入网络\n\tnetd.load_state_dict (torch.load ('checkpoints/netd_%s.pth'%args.max_epoch))\n\tnetg.load_state_dict (torch.load ('checkpoints/netg_%s.pth'%args.max_epoch))\n\t#设备化\n\tnetd.to (device)\n\tnetg.to (device)\n\t# 生成图片，并计算图片在判别器的分数\n\tfake_img = netg (noises)\n\tscores = netd (fake_img).detach ()\n\t\n\t# 挑选最好的某几张\n\tindexs = scores.topk (5) [1]\n\tresult = []\n\tfor i in indexs:\n\t\tresult.append (fake_img.data [i])\n\t\n\t# 保存图片\n\timport torchvision as tv\n\ttv.utils.save_image (torch.stack (result), 5, normalize=True, range=(-1, 1))\n\n\n\n\n\n\n\n\n\n\n\n\t\n\t###################可视化类##################################\nimport visdom\nimport time\nimport torchvision as tv\nimport numpy as np\n\n\nclass Visualizer ():\n\t\"\"\"\n\t封装了visdom的基本操作，但是你仍然可以通过`self.vis.function`\n\t调用原生的visdom接口\n\t\"\"\"\n\t\n\tdef __init__ (self, env='default', **kwargs):\n\t\timport visdom\n\t\tself.vis = visdom.Visdom (env=env, use_incoming_socket=False, **kwargs)\n\t\t\n\t\t# 画的第几个数，相当于横座标\n\t\t# 保存（’loss',23） 即loss的第23个点\n\t\tself.index = {}\n\t\tself.log_text = ''\n\t\n\tdef reinit (self, env='default', **kwargs):\n\t\t\"\"\"\n\t\t修改visdom的配置\n\t\t\"\"\"\n\t\tself.vis = visdom.Visdom (env=env, use_incoming_socket=False, **kwargs)\n\t\treturn self\n\t\n\tdef plot_many (self, d):\n\t\t\"\"\"\n\t\t一次plot多个\n\t\t@params d: dict (name,value) i.e. ('loss',0.11)\n\t\t\"\"\"\n\t\tfor k, v in d.items ():\n\t\t\tself.plot (k, v)\n\t\n\tdef img_many (self, d):\n\t\tfor k, v in d.items ():\n\t\t\tself.img (k, v)\n\t\n\tdef plot (self, name, y):\n\t\t\"\"\"\n\t\tself.plot('loss',1.00)\n\t\t\"\"\"\n\t\tx = self.index.get (name, 0)\n\t\tself.vis.line (Y=np.array ([y]), X=np.array ([x]),\n\t\t\t\t\t   win=(name),\n\t\t\t\t\t   opts=dict (title=name),\n\t\t\t\t\t   update=None if x == 0 else 'append'\n\t\t\t\t\t   )\n\t\tself.index [name] = x + 1\n\t\n\tdef img (self, name, img_):\n\t\t\"\"\"\n\t\tself.img('input_img',t.Tensor(64,64))\n\t\t\"\"\"\n\t\t\n\t\tif len (img_.size ()) < 3:\n\t\t\timg_ = img_.cpu ().unsqueeze (0)\n\t\tself.vis.image (img_.cpu (),\n\t\t\t\t\t\twin=(name),\n\t\t\t\t\t\topts=dict (title=name)\n\t\t\t\t\t\t)\n\t\n\tdef img_grid_many (self, d):\n\t\tfor k, v in d.items ():\n\t\t\tself.img_grid (k, v)\n\t\n\tdef img_grid (self, name, input_3d):\n\t\t\"\"\"\n\t\t一个batch的图片转成一个网格图，i.e. input（36，64，64）\n\t\t会变成 6*6 的网格图，每个格子大小64*64\n\t\t\"\"\"\n\t\tself.img (name, tv.utils.make_grid (\n\t\t\tinput_3d.cpu () [0].unsqueeze (1).clamp (max=1, min=0)))\n\t\n\tdef log (self, info, win='log_text'):\n\t\t\"\"\"\n\t\tself.log({'loss':1,'lr':0.0001})\n\t\t\"\"\"\n\t\t\n\t\tself.log_text += ('[{time}] {info} <br>'.format (\n\t\t\ttime=time.strftime ('%m%d_%H%M%S'),\n\t\t\tinfo=info))\n\t\tself.vis.text (self.log_text, win=win)\n\t\n\tdef __getattr__ (self, name):\n\t\treturn getattr (self.vis, name)\n\t\n\t\n\t\nif __name__ == '__main__':\n\tif args.test:\n\t\ttest()\n\telse:\n\t\ttrain()\n```\n\n**输出:\n![](https://blog.mviai.com/images/回顾-VAEGAN/r.png)\n\n\n","slug":"回顾-VAEGAN","published":1,"updated":"2021-07-26T09:58:02.579Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m20001iigtastcd8ych","content":"<h1 id=\"1-VAEGAN-简介\"><a href=\"#1-VAEGAN-简介\" class=\"headerlink\" title=\"1.VAEGAN 简介:\"></a>1.VAEGAN 简介:</h1><p>关于如何解决VAE解码器产生图片模糊问题?<br>作者将VAE作为生成器 与 判别器结合为新GAN,即VAEGAN<br>通过GANs去提升了VAE的图片生成质量.</p>\n<hr>\n<h1 id=\"2-VAEGAN-网络结构\"><a href=\"#2-VAEGAN-网络结构\" class=\"headerlink\" title=\"2.VAEGAN 网络结构:\"></a>2.VAEGAN 网络结构:</h1><p>还是先来看图:<br>官方图:<br><img src=\"https://blog.mviai.com/images/回顾-VAEGAN/n2.png\" alt><br>网络图:<br><img src=\"https://blog.mviai.com/images/回顾-VAEGAN/n.jpg\" alt><br><strong>可以看出什么呢?</strong></p>\n<ul>\n<li>1.输入一张真实图片(x)-编码器-&gt;正态分布(z)-解码器-&gt;生成图片(~x)  <ul>\n<li><font color=\"red\"> 左边就是VAE,VAE希望生成图片与真实图片loss越小越好,但是loss小不见得图片就清晰.</font>\n\n\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>2.为了解决这个问题,就将生成图片(~x) 给判别器,让判别器判断生成图片属于真实,还是属于生成,这样就可以让生成图片与真实图片难以区分,从而提升图片质量</li>\n</ul>\n<h1 id=\"3-VAEGAN创新点\"><a href=\"#3-VAEGAN创新点\" class=\"headerlink\" title=\"3. VAEGAN创新点:\"></a>3. VAEGAN创新点:</h1><ul>\n<li>1.将元素方面的错误替换为特征方面的错误</li>\n<li>2.将VAEs和GANs合并为一个无监督生成模型，同时学习编码、生成和比较数据集样本。</li>\n<li>3.通过学习相似度度量训练的生成模型比接受过元素误差模拟训练的模型产生更好的图像样本</li>\n<li>4.证明了无监督训练可以产生更具有解纠缠因子的潜在图像表示法。</li>\n<li>5.在学习的潜空间中应用简单的算法可以生成反映这些属性变化的图像(使用编码器来计算潜在向量)。</li>\n</ul>\n<h1 id=\"4-VAEGAN实现\"><a href=\"#4-VAEGAN实现\" class=\"headerlink\" title=\"4.VAEGAN实现:\"></a>4.VAEGAN实现:</h1><ul>\n<li>pytorch1.0</li>\n</ul>\n<p><strong>network.py</strong><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">跟着图走</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#我们首先建立G (由一个编码器,一个解码器构成)</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">G</span><span class=\"params\">(nn.Module)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self,args)</span>:</span></span><br><span class=\"line\">        super(G,self).__init__()</span><br><span class=\"line\">        ngf = args.ngf  <span class=\"comment\">#ngf 设置为128  卷积一般扩大两倍 参数为4,2,1</span></span><br><span class=\"line\">        self.encoder= nn.Sequential(</span><br><span class=\"line\">            <span class=\"comment\"># 输入一个真实图像3*64*64</span></span><br><span class=\"line\">            nn.Conv2d (<span class=\"number\">3</span>, ngf, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">            nn.BatchNorm2d (ngf),</span><br><span class=\"line\">            nn.LeakyReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">            <span class=\"comment\"># (ngf) x 32x 32</span></span><br><span class=\"line\">            nn.Conv2d (ngf, ngf * <span class=\"number\">2</span>, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">            nn.BatchNorm2d (ngf * <span class=\"number\">2</span>),</span><br><span class=\"line\">            nn.LeakyReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">            <span class=\"comment\"># (ngf*2) x 16 x 16</span></span><br><span class=\"line\">            nn.Conv2d (ngf * <span class=\"number\">2</span>, ngf, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">            nn.BatchNorm2d (ngf),</span><br><span class=\"line\">            nn.LeakyReLU (<span class=\"literal\">True</span>))</span><br><span class=\"line\">       </span><br><span class=\"line\">        <span class=\"comment\">#还原尺寸</span></span><br><span class=\"line\">        self.decoder = nn.Sequential (</span><br><span class=\"line\">                                 nn.ConvTranspose2d(ngf,ngf*<span class=\"number\">2</span>,<span class=\"number\">4</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>),</span><br><span class=\"line\">                                 nn.BatchNorm2d(ngf*<span class=\"number\">2</span>),</span><br><span class=\"line\">                                 nn.ReLU(),</span><br><span class=\"line\">                                 nn.ConvTranspose2d (ngf*<span class=\"number\">2</span>,ngf,<span class=\"number\">4</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>),</span><br><span class=\"line\">                                 nn.BatchNorm2d (ngf),</span><br><span class=\"line\">                                 nn.ReLU (),</span><br><span class=\"line\">                                 nn.ConvTranspose2d (ngf, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>),</span><br><span class=\"line\">                                 nn.Tanh ())</span><br><span class=\"line\">                                 </span><br><span class=\"line\">        <span class=\"comment\">#3*64*64</span></span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"comment\">#前向传播</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self,x)</span>:</span></span><br><span class=\"line\">        out=self.encoder(x)</span><br><span class=\"line\">        out_x=self.decoder(out)</span><br><span class=\"line\">        <span class=\"comment\">#print(out_x.size())</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> out_x</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#建立D</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">D</span><span class=\"params\">(nn.Module)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self,args)</span>:</span></span><br><span class=\"line\">        super(D,self).__init__()</span><br><span class=\"line\">        ndf = args.ndf  <span class=\"comment\"># ndf 128</span></span><br><span class=\"line\">        self.D_layer= nn.Sequential(</span><br><span class=\"line\">                <span class=\"comment\"># 输入 1 x 64 x 64,</span></span><br><span class=\"line\">                nn.Conv2d (<span class=\"number\">3</span>, ndf, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">                nn.BatchNorm2d (ndf),</span><br><span class=\"line\">                nn.LeakyReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">                <span class=\"comment\">#输出 (ndf)*32*32</span></span><br><span class=\"line\">                nn.Conv2d(ndf,ndf*<span class=\"number\">2</span>,<span class=\"number\">4</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">                nn.BatchNorm2d (ndf*<span class=\"number\">2</span>),</span><br><span class=\"line\">                nn.LeakyReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">                <span class=\"comment\"># 输出 (ndf*2)*16*16</span></span><br><span class=\"line\">                nn.Conv2d (ndf*<span class=\"number\">2</span>, ndf*<span class=\"number\">4</span>, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">                nn.BatchNorm2d (ndf*<span class=\"number\">4</span>),</span><br><span class=\"line\">                nn.LeakyReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">                <span class=\"comment\"># 输出 (ndf*4)*8*8</span></span><br><span class=\"line\">                nn.Conv2d (ndf*<span class=\"number\">4</span>, ndf*<span class=\"number\">8</span>, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">                nn.BatchNorm2d (ndf*<span class=\"number\">8</span>),</span><br><span class=\"line\">                nn.LeakyReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">                <span class=\"comment\"># 输出 (ndf*8)*4*4</span></span><br><span class=\"line\">                nn.Conv2d (ndf * <span class=\"number\">8</span>, <span class=\"number\">1</span>, <span class=\"number\">4</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">                <span class=\"comment\"># 输出 1*1*1</span></span><br><span class=\"line\">                nn.Sigmoid())<span class=\"comment\">#告诉D概率</span></span><br><span class=\"line\">                </span><br><span class=\"line\">    <span class=\"comment\">#前向传播</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self,x)</span>:</span></span><br><span class=\"line\">        out=self.D_layer(x)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br></pre></td></tr></table></figure></p>\n<p><strong>train.py</strong><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br><span class=\"line\">277</span><br><span class=\"line\">278</span><br><span class=\"line\">279</span><br><span class=\"line\">280</span><br><span class=\"line\">281</span><br><span class=\"line\">282</span><br><span class=\"line\">283</span><br><span class=\"line\">284</span><br><span class=\"line\">285</span><br><span class=\"line\">286</span><br><span class=\"line\">287</span><br><span class=\"line\">288</span><br><span class=\"line\">289</span><br><span class=\"line\">290</span><br><span class=\"line\">291</span><br><span class=\"line\">292</span><br><span class=\"line\">293</span><br><span class=\"line\">294</span><br><span class=\"line\">295</span><br><span class=\"line\">296</span><br><span class=\"line\">297</span><br><span class=\"line\">298</span><br><span class=\"line\">299</span><br><span class=\"line\">300</span><br><span class=\"line\">301</span><br><span class=\"line\">302</span><br><span class=\"line\">303</span><br><span class=\"line\">304</span><br><span class=\"line\">305</span><br><span class=\"line\">306</span><br><span class=\"line\">307</span><br><span class=\"line\">308</span><br><span class=\"line\">309</span><br><span class=\"line\">310</span><br><span class=\"line\">311</span><br><span class=\"line\">312</span><br><span class=\"line\">313</span><br><span class=\"line\">314</span><br><span class=\"line\">315</span><br><span class=\"line\">316</span><br><span class=\"line\">317</span><br><span class=\"line\">318</span><br><span class=\"line\">319</span><br><span class=\"line\">320</span><br><span class=\"line\">321</span><br><span class=\"line\">322</span><br><span class=\"line\">323</span><br><span class=\"line\">324</span><br><span class=\"line\">325</span><br><span class=\"line\">326</span><br><span class=\"line\">327</span><br><span class=\"line\">328</span><br><span class=\"line\">329</span><br><span class=\"line\">330</span><br><span class=\"line\">331</span><br><span class=\"line\">332</span><br><span class=\"line\">333</span><br><span class=\"line\">334</span><br><span class=\"line\">335</span><br><span class=\"line\">336</span><br><span class=\"line\">337</span><br><span class=\"line\">338</span><br><span class=\"line\">339</span><br><span class=\"line\">340</span><br><span class=\"line\">341</span><br><span class=\"line\">342</span><br><span class=\"line\">343</span><br><span class=\"line\">344</span><br><span class=\"line\">345</span><br><span class=\"line\">346</span><br><span class=\"line\">347</span><br><span class=\"line\">348</span><br><span class=\"line\">349</span><br><span class=\"line\">350</span><br><span class=\"line\">351</span><br><span class=\"line\">352</span><br><span class=\"line\">353</span><br><span class=\"line\">354</span><br><span class=\"line\">355</span><br><span class=\"line\">356</span><br><span class=\"line\">357</span><br><span class=\"line\">358</span><br><span class=\"line\">359</span><br><span class=\"line\">360</span><br><span class=\"line\">361</span><br><span class=\"line\">362</span><br><span class=\"line\">363</span><br><span class=\"line\">364</span><br><span class=\"line\">365</span><br><span class=\"line\">366</span><br><span class=\"line\">367</span><br><span class=\"line\">368</span><br><span class=\"line\">369</span><br><span class=\"line\">370</span><br><span class=\"line\">371</span><br><span class=\"line\">372</span><br><span class=\"line\">373</span><br><span class=\"line\">374</span><br><span class=\"line\">375</span><br><span class=\"line\">376</span><br><span class=\"line\">377</span><br><span class=\"line\">378</span><br><span class=\"line\">379</span><br><span class=\"line\">380</span><br><span class=\"line\">381</span><br><span class=\"line\">382</span><br><span class=\"line\">383</span><br><span class=\"line\">384</span><br><span class=\"line\">385</span><br><span class=\"line\">386</span><br><span class=\"line\">387</span><br><span class=\"line\">388</span><br><span class=\"line\">389</span><br><span class=\"line\">390</span><br><span class=\"line\">391</span><br><span class=\"line\">392</span><br><span class=\"line\">393</span><br><span class=\"line\">394</span><br><span class=\"line\">395</span><br><span class=\"line\">396</span><br><span class=\"line\">397</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision.datasets <span class=\"keyword\">as</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision.transforms <span class=\"keyword\">as</span>  transforms</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.backends.cudnn <span class=\"keyword\">as</span> cudnn</span><br><span class=\"line\"><span class=\"comment\"># 工具包</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> argparse</span><br><span class=\"line\"><span class=\"comment\"># 载入网络</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> network <span class=\"keyword\">import</span> G, D</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############参数设置#############</span></span><br><span class=\"line\"><span class=\"comment\">####命令行设置########</span></span><br><span class=\"line\">parser = argparse.ArgumentParser (description=<span class=\"string\">'GANs'</span>)  <span class=\"comment\"># 导入命令行模块</span></span><br><span class=\"line\"><span class=\"comment\"># 对关于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明</span></span><br><span class=\"line\"><span class=\"comment\">#关于训练参数</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--batch_size'</span>, type=int, default=<span class=\"number\">64</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'训练batch-size大小 (default: 64)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--imageSize'</span>, type=int, default=<span class=\"number\">64</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'图片尺寸'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--max_epoch'</span>, type=int, default=<span class=\"number\">20</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'最大迭代数 (default: 12)'</span>)</span><br><span class=\"line\"><span class=\"comment\">#关于网络参数</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--lr_g'</span>, type=float, default=<span class=\"number\">2e-4</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'生成器学习率 (default: 2e-4)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--lr_d'</span>, type=float, default=<span class=\"number\">2e-4</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'判别器学习率 (default: 2e-4)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--ngf'</span>, type=int, default=<span class=\"number\">64</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'生成器feature map数'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--ndf'</span>, type=int, default=<span class=\"number\">64</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'判别器feature map数'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--d_every'</span>, type=int, default=<span class=\"number\">1</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'每几个batch训练一次判别器'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--g_every'</span>, type=int, default=<span class=\"number\">4</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'每几个batch训练一次生成器'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--nz'</span>, type=int, default=<span class=\"number\">3</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'噪声维度'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#关于优化器参数</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--beta1'</span>, type=int, default=<span class=\"number\">0.5</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'Adam优化器的beta1参数'</span>)</span><br><span class=\"line\"><span class=\"comment\">#路径</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--dataset'</span>, default=<span class=\"string\">'data/'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'数据集路径'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--save_data'</span>,  default=<span class=\"string\">'save/'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'保存路径'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#可视化</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--vis'</span>, action=<span class=\"string\">'store_true'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'使用visdom可视化'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--plot_every'</span>, type=int, default=<span class=\"number\">1</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'每间隔_batch，visdom画图一次'</span>)</span><br><span class=\"line\"><span class=\"comment\"># 其他</span></span><br><span class=\"line\"></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--cuda'</span>, action=<span class=\"string\">'store_true'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'开启cuda训练'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--plt'</span>, action=<span class=\"string\">'store_true'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'开启画图'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--test'</span>, action=<span class=\"string\">'store_true'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'开启测试生成'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--save_every'</span>, type=int, default=<span class=\"number\">5</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'几个epoch保存一次模型 (default: 2)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--seed'</span>, type=int, default=<span class=\"number\">1</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'随机种子 (default: 1)'</span>)</span><br><span class=\"line\">args = parser.parse_args ()  <span class=\"comment\"># 相当于激活命令</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#训练过程</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">train</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">\t<span class=\"comment\">###############判断gpu#############</span></span><br><span class=\"line\">\tdevice = torch.device (<span class=\"string\">'cuda'</span>) <span class=\"keyword\">if</span> args.cuda <span class=\"keyword\">else</span> torch.device (<span class=\"string\">'cpu'</span>)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">####### 为CPU设置种子用于生成随机数，以使得结果是确定的##########</span></span><br><span class=\"line\">\ttorch.manual_seed (args.seed)</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> args.cuda:</span><br><span class=\"line\">\t\ttorch.cuda.manual_seed (args.seed)</span><br><span class=\"line\">\tcudnn.benchmark = <span class=\"literal\">True</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">#################可视化###############</span></span><br><span class=\"line\">\t<span class=\"keyword\">if</span> args.vis:</span><br><span class=\"line\">\t\tvis = Visualizer (<span class=\"string\">'GANs'</span>)</span><br><span class=\"line\">\t<span class=\"comment\">##########数据转换#####################</span></span><br><span class=\"line\">\tdata_transforms = transforms.Compose ([transforms.Scale (args.imageSize),  <span class=\"comment\"># 通过调整比例调整大小,会报警</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   transforms.CenterCrop (args.imageSize),  <span class=\"comment\"># 在中心裁剪给指定大小方形PIL图像</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   transforms.ToTensor (),<span class=\"comment\"># 转换成pytorch 变量tensor</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   transforms.Normalize ((<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>), (<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>))])</span><br><span class=\"line\">\t<span class=\"comment\">###############数据载入################</span></span><br><span class=\"line\">\t<span class=\"comment\"># train_dataset = datasets.ImageFolder (root=args.dataset,  # 数据路径目录</span></span><br><span class=\"line\">\t<span class=\"comment\"># \t\t\t\t\t\t\t\t\t  transform=data_transforms)  # 把数据转换成上面约束样子</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\ttrain_dataset = datasets.CIFAR10(root=args.dataset,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t train=<span class=\"literal\">True</span>,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t transform=data_transforms,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t download=<span class=\"literal\">False</span>)</span><br><span class=\"line\">\t<span class=\"comment\"># test_dataset = datasets.ImageFolder (root=args.dataset,</span></span><br><span class=\"line\">\t<span class=\"comment\"># \t\t\t\t\t\t\t\t\t transform=data_transforms)</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">##############数据装载###############</span></span><br><span class=\"line\">\ttrain_loader = torch.utils.data.DataLoader (dataset=train_dataset,  <span class=\"comment\"># 装载数据</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\t\tbatch_size=args.batch_size,  <span class=\"comment\"># 设置批大小</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\t\tshuffle=<span class=\"literal\">True</span>)  <span class=\"comment\"># 是否随机打乱</span></span><br><span class=\"line\">\t<span class=\"comment\"># test_loader = torch.utils.data.DataLoader (dataset=test_dataset,</span></span><br><span class=\"line\">\t<span class=\"comment\"># \t\t\t\t\t\t\t\t\t\t   batch_size=args.batch_size,</span></span><br><span class=\"line\">\t<span class=\"comment\"># \t\t\t\t\t\t\t\t\t\t   shuffle=True)</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">#############模型载入#################</span></span><br><span class=\"line\">\tnetG ,netD= G (args),D (args)</span><br><span class=\"line\">\tnetG.to (device)</span><br><span class=\"line\">\tnetD.to (device)</span><br><span class=\"line\">\t<span class=\"keyword\">print</span> (netD, netG)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">###############损失函数##################</span></span><br><span class=\"line\">\tcriterion = torch.nn.BCELoss ().to (device)</span><br><span class=\"line\">\toptimizerD = torch.optim.Adam (netD.parameters (), lr=args.lr_d,betas=(<span class=\"number\">0.5</span>, <span class=\"number\">0.999</span>))  <span class=\"comment\"># Adam优化器</span></span><br><span class=\"line\">\toptimizerG = torch.optim.Adam (netG.parameters (), lr=args.lr_g,betas=(<span class=\"number\">0.5</span>, <span class=\"number\">0.999</span>))  <span class=\"comment\"># Adam优化器</span></span><br><span class=\"line\">\t<span class=\"comment\">###############画图参数保存##################</span></span><br><span class=\"line\">\tG_losses = []</span><br><span class=\"line\">\tD_losses = []</span><br><span class=\"line\">\timg_list = []</span><br><span class=\"line\">\t<span class=\"comment\">#############训练过程#####################</span></span><br><span class=\"line\">\t<span class=\"keyword\">import</span> tqdm</span><br><span class=\"line\">\t<span class=\"comment\"># Tqdm是一个快速，可扩展的Python进度条，可以在Python</span></span><br><span class=\"line\">\t<span class=\"comment\"># 长循环中添加一个进度提示信息，用户只需要封装任意的迭代器</span></span><br><span class=\"line\">\t<span class=\"comment\"># tqdm (iterator)。</span></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range (args.max_epoch):</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> i, (images, labels) <span class=\"keyword\">in</span> tqdm.tqdm(enumerate (train_loader)):  <span class=\"comment\"># 枚举出来</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\">#数据处理</span></span><br><span class=\"line\">\t\t\timages = images.to (device)</span><br><span class=\"line\">\t\t\t<span class=\"comment\"># 装箱</span></span><br><span class=\"line\">\t\t\timages = Variable (images)</span><br><span class=\"line\">\t\t\tnoises=Variable(torch.randn(images.size(<span class=\"number\">0</span>), args.nz, <span class=\"number\">1</span>, <span class=\"number\">1</span>).to(device))</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\t<span class=\"comment\">#遍历每张图片,并且根据指定的训练机制训练</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> i % args.d_every==<span class=\"number\">0</span>:<span class=\"comment\">#满足此条件训练D</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D前向传播</span></span><br><span class=\"line\">\t\t\t\toptimizerD.zero_grad ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D网络输出</span></span><br><span class=\"line\">\t\t\t\toutput_r = netD (images).view(<span class=\"number\">-1</span>)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#定义真张量</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#返回第一个参数为大小 第二参数为值 的张量</span></span><br><span class=\"line\">\t\t\t\ttrue_label = torch.full ((images.size(<span class=\"number\">0</span>),), <span class=\"number\">1</span>, device=device)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#判别真的损失</span></span><br><span class=\"line\">\t\t\t\td_real_loss = criterion(output_r, true_label)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#反向传播</span></span><br><span class=\"line\">\t\t\t\td_real_loss.backward()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G网络输出</span></span><br><span class=\"line\">\t\t\t\tfake = netG (images) <span class=\"comment\"># 根据真生成图</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#把假图给d</span></span><br><span class=\"line\">\t\t\t\toutput_f = netD (fake).view(<span class=\"number\">-1</span>)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#d假的损失</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#print(fake.size(),output_f.size(),output_r.size())</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\"># 返回第一个参数为大小 第二参数为值 的张量</span></span><br><span class=\"line\">\t\t\t\tfake_label = torch.full ((images.size (<span class=\"number\">0</span>),), <span class=\"number\">0</span>, device=device)</span><br><span class=\"line\">\t\t\t\td_fake_loss= criterion(output_f,fake_label)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D假反向传播</span></span><br><span class=\"line\">\t\t\t\td_fake_loss.backward ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\"># 总损失</span></span><br><span class=\"line\">\t\t\t\tD_loss=d_fake_loss+d_real_loss</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D更新参数</span></span><br><span class=\"line\">\t\t\t\toptimizerD.step ()</span><br><span class=\"line\">\t\t\t\t</span><br><span class=\"line\">\t\t\t\t</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\"># 度量</span></span><br><span class=\"line\">\t\t\t\tD_x = output_r.mean ().item ()</span><br><span class=\"line\">\t\t\t\tD_G_z1 = output_f.mean ().item ()</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> i % args.g_every==<span class=\"number\">0</span>:<span class=\"comment\">#满足此条件训练G</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G前向传播</span></span><br><span class=\"line\">\t\t\t\toptimizerG.zero_grad ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G网络输出</span></span><br><span class=\"line\">\t\t\t\tfake = netG (images)  <span class=\"comment\"># 根据噪声生成假图</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#把假图给G</span></span><br><span class=\"line\">\t\t\t\toutput_f = netD (fake).view(<span class=\"number\">-1</span>)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G的损失</span></span><br><span class=\"line\">\t\t\t\ttrue_label = torch.full ((images.size (<span class=\"number\">0</span>),), <span class=\"number\">1</span>, device=device)</span><br><span class=\"line\">\t\t\t\tG_loss = criterion(output_f,true_label)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G反向传播</span></span><br><span class=\"line\">\t\t\t\tG_loss.backward ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#度量</span></span><br><span class=\"line\">\t\t\t\tD_G_z2 = output_f.mean ().item ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D更新参数</span></span><br><span class=\"line\">\t\t\t\toptimizerG.step ()</span><br><span class=\"line\">\t\t\t\t</span><br><span class=\"line\">\t\t\t<span class=\"comment\">###########################################</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\">##########可视化(可选)#####################</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> args.vis <span class=\"keyword\">and</span> i % args.plot_every == args.plot_every - <span class=\"number\">1</span>:</span><br><span class=\"line\">\t\t\t\tfake = netG (noises)</span><br><span class=\"line\">\t\t\t\tvis.images (fake.detach ().cpu ().numpy () [:<span class=\"number\">64</span>] * <span class=\"number\">0.5</span> + <span class=\"number\">0.5</span>, win=<span class=\"string\">'fixfake'</span>)</span><br><span class=\"line\">\t\t\t\tvis.images (images.data.cpu ().numpy () [:<span class=\"number\">64</span>] * <span class=\"number\">0.5</span> + <span class=\"number\">0.5</span>, win=<span class=\"string\">'real'</span>)</span><br><span class=\"line\">\t\t\t\tvis.plot (<span class=\"string\">'errord'</span>, D_loss.item ())</span><br><span class=\"line\">\t\t\t\tvis.plot (<span class=\"string\">'errorg'</span>, G_loss.item ())</span><br><span class=\"line\">\t\t\t<span class=\"comment\">#######################################</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\">############打印记录###################</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> i % <span class=\"number\">1</span>== <span class=\"number\">0</span>:</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">print</span> (<span class=\"string\">'[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'</span></span><br><span class=\"line\">\t\t\t\t\t   % (epoch, args.max_epoch, i, len (train_loader),</span><br><span class=\"line\">\t\t\t\t\t\t  D_loss.item (), G_loss.item (), D_x, D_G_z1, D_G_z2))</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">########添加画图参数########</span></span><br><span class=\"line\">\t\t\t\tG_losses.append (G_loss.item ())</span><br><span class=\"line\">\t\t\t\tD_losses.append (D_loss.item ())</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">with</span> torch.no_grad ():</span><br><span class=\"line\">\t\t\t\t\tnoises = torch.randn (args.batch_size, args.nz, <span class=\"number\">1</span>, <span class=\"number\">1</span>).to (device)</span><br><span class=\"line\">\t\t\t\t\tfake = netG (images).detach ().cpu ()</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">import</span> torchvision.utils <span class=\"keyword\">as</span> vutils</span><br><span class=\"line\">\t\t\t\timg_list.append (vutils.make_grid (fake, padding=<span class=\"number\">2</span>, normalize=<span class=\"literal\">True</span>))</span><br><span class=\"line\">\t</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">\t\t<span class=\"comment\">#######################################</span></span><br><span class=\"line\">\t\t<span class=\"comment\">############保存模型###################</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (epoch + <span class=\"number\">1</span>) % args.save_every == <span class=\"number\">0</span>:</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">import</span> torchvision <span class=\"keyword\">as</span> tv</span><br><span class=\"line\">\t\t\t<span class=\"comment\"># 保存模型、图片</span></span><br><span class=\"line\">\t\t\ttv.utils.save_image (fake.data [:<span class=\"number\">64</span>], <span class=\"string\">'%s/%s.png'</span> % (args.save_data, epoch), normalize=<span class=\"literal\">True</span>,range=(<span class=\"number\">-1</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">\t\t\ttorch.save (netD.state_dict (), <span class=\"string\">'checkpoints/netd_%s.pth'</span> % epoch)</span><br><span class=\"line\">\t\t\ttorch.save (netG.state_dict (), <span class=\"string\">'checkpoints/netg_%s.pth'</span> % epoch)</span><br><span class=\"line\">\t\t\tprint(<span class=\"string\">'完成%s的模型保存'</span>%epoch)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">#######################################</span></span><br><span class=\"line\">\t<span class=\"comment\">############画图###################</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> args.plt:</span><br><span class=\"line\">\t\t<span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\">\t\t<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\">\t\t<span class=\"keyword\">import</span> torchvision.utils <span class=\"keyword\">as</span> vutils</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\tplt.figure (figsize=(<span class=\"number\">10</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\">\t\tplt.title (<span class=\"string\">\"GAN\"</span>)</span><br><span class=\"line\">\t\tplt.plot (G_losses, label=<span class=\"string\">\"G\"</span>)</span><br><span class=\"line\">\t\tplt.plot (D_losses, label=<span class=\"string\">\"D\"</span>)</span><br><span class=\"line\">\t\tplt.xlabel (<span class=\"string\">\"迭代次数\"</span>,fontproperties=<span class=\"string\">'SimHei'</span>)</span><br><span class=\"line\">\t\tplt.ylabel (<span class=\"string\">\"损失\"</span>,fontproperties=<span class=\"string\">'SimHei'</span>)</span><br><span class=\"line\">\t\tplt.legend ()</span><br><span class=\"line\">\t\tplt.show ()</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 从数据集加载</span></span><br><span class=\"line\">\t\treal_batch = next (iter (train_dataset))</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 画出真图</span></span><br><span class=\"line\">\t\tplt.figure (figsize=(<span class=\"number\">15</span>, <span class=\"number\">10</span>))</span><br><span class=\"line\">\t\tplt.subplot (<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">\t\tplt.axis (<span class=\"string\">\"off\"</span>)</span><br><span class=\"line\">\t\tplt.title (<span class=\"string\">\"真图\"</span>,fontproperties=<span class=\"string\">'SimHei'</span>)</span><br><span class=\"line\">\t\tplt.imshow (np.transpose (</span><br><span class=\"line\">\t\t\tvutils.make_grid (real_batch [<span class=\"number\">0</span>].to (device) [:<span class=\"number\">64</span>], padding=<span class=\"number\">5</span>, normalize=<span class=\"literal\">True</span>).cpu (),</span><br><span class=\"line\">\t\t\t(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>)))</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 画出假图</span></span><br><span class=\"line\">\t\tplt.subplot (<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">\t\tplt.axis (<span class=\"string\">\"off\"</span>)</span><br><span class=\"line\">\t\tplt.title (<span class=\"string\">\"假图\"</span>,fontproperties=<span class=\"string\">'SimHei'</span>)</span><br><span class=\"line\">\t\tplt.imshow (np.transpose (img_list [<span class=\"number\">-1</span>], (<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>)))</span><br><span class=\"line\">\t\tplt.show ()</span><br><span class=\"line\">\t\t\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@torch.no_grad()#禁用梯度计算</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">test</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">\t<span class=\"comment\">#判断Gpu</span></span><br><span class=\"line\">\tdevice = torch.device (<span class=\"string\">'cuda'</span>) <span class=\"keyword\">if</span> args.cuda <span class=\"keyword\">else</span> torch.device (<span class=\"string\">'cpu'</span>)</span><br><span class=\"line\">\t<span class=\"comment\">#初始化网络</span></span><br><span class=\"line\">\tnetg, netd = netG (args).eval (), netD (args).eval ()</span><br><span class=\"line\">\t<span class=\"comment\">#定义噪声</span></span><br><span class=\"line\">\tnoises = torch.randn (args.batch_size, args.nz, <span class=\"number\">1</span>, <span class=\"number\">1</span>).to (device)</span><br><span class=\"line\">\t<span class=\"comment\">#载入网络</span></span><br><span class=\"line\">\tnetd.load_state_dict (torch.load (<span class=\"string\">'checkpoints/netd_%s.pth'</span>%args.max_epoch))</span><br><span class=\"line\">\tnetg.load_state_dict (torch.load (<span class=\"string\">'checkpoints/netg_%s.pth'</span>%args.max_epoch))</span><br><span class=\"line\">\t<span class=\"comment\">#设备化</span></span><br><span class=\"line\">\tnetd.to (device)</span><br><span class=\"line\">\tnetg.to (device)</span><br><span class=\"line\">\t<span class=\"comment\"># 生成图片，并计算图片在判别器的分数</span></span><br><span class=\"line\">\tfake_img = netg (noises)</span><br><span class=\"line\">\tscores = netd (fake_img).detach ()</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\"># 挑选最好的某几张</span></span><br><span class=\"line\">\tindexs = scores.topk (<span class=\"number\">5</span>) [<span class=\"number\">1</span>]</span><br><span class=\"line\">\tresult = []</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> indexs:</span><br><span class=\"line\">\t\tresult.append (fake_img.data [i])</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\"># 保存图片</span></span><br><span class=\"line\">\t<span class=\"keyword\">import</span> torchvision <span class=\"keyword\">as</span> tv</span><br><span class=\"line\">\ttv.utils.save_image (torch.stack (result), <span class=\"number\">5</span>, normalize=<span class=\"literal\">True</span>, range=(<span class=\"number\">-1</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">###################可视化类##################################</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> visdom</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision <span class=\"keyword\">as</span> tv</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Visualizer</span> <span class=\"params\">()</span>:</span></span><br><span class=\"line\">\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t封装了visdom的基本操作，但是你仍然可以通过`self.vis.function`</span></span><br><span class=\"line\"><span class=\"string\">\t调用原生的visdom接口</span></span><br><span class=\"line\"><span class=\"string\">\t\"\"\"</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span> <span class=\"params\">(self, env=<span class=\"string\">'default'</span>, **kwargs)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">import</span> visdom</span><br><span class=\"line\">\t\tself.vis = visdom.Visdom (env=env, use_incoming_socket=<span class=\"literal\">False</span>, **kwargs)</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 画的第几个数，相当于横座标</span></span><br><span class=\"line\">\t\t<span class=\"comment\"># 保存（’loss',23） 即loss的第23个点</span></span><br><span class=\"line\">\t\tself.index = &#123;&#125;</span><br><span class=\"line\">\t\tself.log_text = <span class=\"string\">''</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">reinit</span> <span class=\"params\">(self, env=<span class=\"string\">'default'</span>, **kwargs)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\t修改visdom的配置</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\tself.vis = visdom.Visdom (env=env, use_incoming_socket=<span class=\"literal\">False</span>, **kwargs)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> self</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">plot_many</span> <span class=\"params\">(self, d)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\t一次plot多个</span></span><br><span class=\"line\"><span class=\"string\">\t\t@params d: dict (name,value) i.e. ('loss',0.11)</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> d.items ():</span><br><span class=\"line\">\t\t\tself.plot (k, v)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">img_many</span> <span class=\"params\">(self, d)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> d.items ():</span><br><span class=\"line\">\t\t\tself.img (k, v)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">plot</span> <span class=\"params\">(self, name, y)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\tself.plot('loss',1.00)</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\tx = self.index.get (name, <span class=\"number\">0</span>)</span><br><span class=\"line\">\t\tself.vis.line (Y=np.array ([y]), X=np.array ([x]),</span><br><span class=\"line\">\t\t\t\t\t   win=(name),</span><br><span class=\"line\">\t\t\t\t\t   opts=dict (title=name),</span><br><span class=\"line\">\t\t\t\t\t   update=<span class=\"literal\">None</span> <span class=\"keyword\">if</span> x == <span class=\"number\">0</span> <span class=\"keyword\">else</span> <span class=\"string\">'append'</span></span><br><span class=\"line\">\t\t\t\t\t   )</span><br><span class=\"line\">\t\tself.index [name] = x + <span class=\"number\">1</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">img</span> <span class=\"params\">(self, name, img_)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\tself.img('input_img',t.Tensor(64,64))</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> len (img_.size ()) &lt; <span class=\"number\">3</span>:</span><br><span class=\"line\">\t\t\timg_ = img_.cpu ().unsqueeze (<span class=\"number\">0</span>)</span><br><span class=\"line\">\t\tself.vis.image (img_.cpu (),</span><br><span class=\"line\">\t\t\t\t\t\twin=(name),</span><br><span class=\"line\">\t\t\t\t\t\topts=dict (title=name)</span><br><span class=\"line\">\t\t\t\t\t\t)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">img_grid_many</span> <span class=\"params\">(self, d)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> d.items ():</span><br><span class=\"line\">\t\t\tself.img_grid (k, v)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">img_grid</span> <span class=\"params\">(self, name, input_3d)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\t一个batch的图片转成一个网格图，i.e. input（36，64，64）</span></span><br><span class=\"line\"><span class=\"string\">\t\t会变成 6*6 的网格图，每个格子大小64*64</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\tself.img (name, tv.utils.make_grid (</span><br><span class=\"line\">\t\t\tinput_3d.cpu () [<span class=\"number\">0</span>].unsqueeze (<span class=\"number\">1</span>).clamp (max=<span class=\"number\">1</span>, min=<span class=\"number\">0</span>)))</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">log</span> <span class=\"params\">(self, info, win=<span class=\"string\">'log_text'</span>)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\tself.log(&#123;'loss':1,'lr':0.0001&#125;)</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\tself.log_text += (<span class=\"string\">'[&#123;time&#125;] &#123;info&#125; &lt;br&gt;'</span>.format (</span><br><span class=\"line\">\t\t\ttime=time.strftime (<span class=\"string\">'%m%d_%H%M%S'</span>),</span><br><span class=\"line\">\t\t\tinfo=info))</span><br><span class=\"line\">\t\tself.vis.text (self.log_text, win=win)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__getattr__</span> <span class=\"params\">(self, name)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> getattr (self.vis, name)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t</span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> args.test:</span><br><span class=\"line\">\t\ttest()</span><br><span class=\"line\">\t<span class=\"keyword\">else</span>:</span><br><span class=\"line\">\t\ttrain()</span><br></pre></td></tr></table></figure></p>\n<p>**输出:<br><img src=\"https://blog.mviai.com/images/回顾-VAEGAN/r.png\" alt></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"1-VAEGAN-简介\"><a href=\"#1-VAEGAN-简介\" class=\"headerlink\" title=\"1.VAEGAN 简介:\"></a>1.VAEGAN 简介:</h1><p>关于如何解决VAE解码器产生图片模糊问题?<br>作者将VAE作为生成器 与 判别器结合为新GAN,即VAEGAN<br>通过GANs去提升了VAE的图片生成质量.</p>\n<hr>\n<h1 id=\"2-VAEGAN-网络结构\"><a href=\"#2-VAEGAN-网络结构\" class=\"headerlink\" title=\"2.VAEGAN 网络结构:\"></a>2.VAEGAN 网络结构:</h1><p>还是先来看图:<br>官方图:<br><img src=\"https://blog.mviai.com/images/回顾-VAEGAN/n2.png\" alt><br>网络图:<br><img src=\"https://blog.mviai.com/images/回顾-VAEGAN/n.jpg\" alt><br><strong>可以看出什么呢?</strong></p>\n<ul>\n<li>1.输入一张真实图片(x)-编码器-&gt;正态分布(z)-解码器-&gt;生成图片(~x)  <ul>\n<li><font color=\"red\"> 左边就是VAE,VAE希望生成图片与真实图片loss越小越好,但是loss小不见得图片就清晰.</font>\n\n\n</li>\n</ul>\n</li>\n</ul>\n<ul>\n<li>2.为了解决这个问题,就将生成图片(~x) 给判别器,让判别器判断生成图片属于真实,还是属于生成,这样就可以让生成图片与真实图片难以区分,从而提升图片质量</li>\n</ul>\n<h1 id=\"3-VAEGAN创新点\"><a href=\"#3-VAEGAN创新点\" class=\"headerlink\" title=\"3. VAEGAN创新点:\"></a>3. VAEGAN创新点:</h1><ul>\n<li>1.将元素方面的错误替换为特征方面的错误</li>\n<li>2.将VAEs和GANs合并为一个无监督生成模型，同时学习编码、生成和比较数据集样本。</li>\n<li>3.通过学习相似度度量训练的生成模型比接受过元素误差模拟训练的模型产生更好的图像样本</li>\n<li>4.证明了无监督训练可以产生更具有解纠缠因子的潜在图像表示法。</li>\n<li>5.在学习的潜空间中应用简单的算法可以生成反映这些属性变化的图像(使用编码器来计算潜在向量)。</li>\n</ul>\n<h1 id=\"4-VAEGAN实现\"><a href=\"#4-VAEGAN实现\" class=\"headerlink\" title=\"4.VAEGAN实现:\"></a>4.VAEGAN实现:</h1><ul>\n<li>pytorch1.0</li>\n</ul>\n<p><strong>network.py</strong><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">跟着图走</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#我们首先建立G (由一个编码器,一个解码器构成)</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">G</span><span class=\"params\">(nn.Module)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self,args)</span>:</span></span><br><span class=\"line\">        super(G,self).__init__()</span><br><span class=\"line\">        ngf = args.ngf  <span class=\"comment\">#ngf 设置为128  卷积一般扩大两倍 参数为4,2,1</span></span><br><span class=\"line\">        self.encoder= nn.Sequential(</span><br><span class=\"line\">            <span class=\"comment\"># 输入一个真实图像3*64*64</span></span><br><span class=\"line\">            nn.Conv2d (<span class=\"number\">3</span>, ngf, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">            nn.BatchNorm2d (ngf),</span><br><span class=\"line\">            nn.LeakyReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">            <span class=\"comment\"># (ngf) x 32x 32</span></span><br><span class=\"line\">            nn.Conv2d (ngf, ngf * <span class=\"number\">2</span>, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">            nn.BatchNorm2d (ngf * <span class=\"number\">2</span>),</span><br><span class=\"line\">            nn.LeakyReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">            <span class=\"comment\"># (ngf*2) x 16 x 16</span></span><br><span class=\"line\">            nn.Conv2d (ngf * <span class=\"number\">2</span>, ngf, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">            nn.BatchNorm2d (ngf),</span><br><span class=\"line\">            nn.LeakyReLU (<span class=\"literal\">True</span>))</span><br><span class=\"line\">       </span><br><span class=\"line\">        <span class=\"comment\">#还原尺寸</span></span><br><span class=\"line\">        self.decoder = nn.Sequential (</span><br><span class=\"line\">                                 nn.ConvTranspose2d(ngf,ngf*<span class=\"number\">2</span>,<span class=\"number\">4</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>),</span><br><span class=\"line\">                                 nn.BatchNorm2d(ngf*<span class=\"number\">2</span>),</span><br><span class=\"line\">                                 nn.ReLU(),</span><br><span class=\"line\">                                 nn.ConvTranspose2d (ngf*<span class=\"number\">2</span>,ngf,<span class=\"number\">4</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>),</span><br><span class=\"line\">                                 nn.BatchNorm2d (ngf),</span><br><span class=\"line\">                                 nn.ReLU (),</span><br><span class=\"line\">                                 nn.ConvTranspose2d (ngf, <span class=\"number\">3</span>, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>),</span><br><span class=\"line\">                                 nn.Tanh ())</span><br><span class=\"line\">                                 </span><br><span class=\"line\">        <span class=\"comment\">#3*64*64</span></span><br><span class=\"line\">        </span><br><span class=\"line\">    <span class=\"comment\">#前向传播</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self,x)</span>:</span></span><br><span class=\"line\">        out=self.encoder(x)</span><br><span class=\"line\">        out_x=self.decoder(out)</span><br><span class=\"line\">        <span class=\"comment\">#print(out_x.size())</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> out_x</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#建立D</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">D</span><span class=\"params\">(nn.Module)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self,args)</span>:</span></span><br><span class=\"line\">        super(D,self).__init__()</span><br><span class=\"line\">        ndf = args.ndf  <span class=\"comment\"># ndf 128</span></span><br><span class=\"line\">        self.D_layer= nn.Sequential(</span><br><span class=\"line\">                <span class=\"comment\"># 输入 1 x 64 x 64,</span></span><br><span class=\"line\">                nn.Conv2d (<span class=\"number\">3</span>, ndf, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">                nn.BatchNorm2d (ndf),</span><br><span class=\"line\">                nn.LeakyReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">                <span class=\"comment\">#输出 (ndf)*32*32</span></span><br><span class=\"line\">                nn.Conv2d(ndf,ndf*<span class=\"number\">2</span>,<span class=\"number\">4</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">                nn.BatchNorm2d (ndf*<span class=\"number\">2</span>),</span><br><span class=\"line\">                nn.LeakyReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">                <span class=\"comment\"># 输出 (ndf*2)*16*16</span></span><br><span class=\"line\">                nn.Conv2d (ndf*<span class=\"number\">2</span>, ndf*<span class=\"number\">4</span>, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">                nn.BatchNorm2d (ndf*<span class=\"number\">4</span>),</span><br><span class=\"line\">                nn.LeakyReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">                <span class=\"comment\"># 输出 (ndf*4)*8*8</span></span><br><span class=\"line\">                nn.Conv2d (ndf*<span class=\"number\">4</span>, ndf*<span class=\"number\">8</span>, <span class=\"number\">4</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">                nn.BatchNorm2d (ndf*<span class=\"number\">8</span>),</span><br><span class=\"line\">                nn.LeakyReLU (<span class=\"literal\">True</span>),</span><br><span class=\"line\">                <span class=\"comment\"># 输出 (ndf*8)*4*4</span></span><br><span class=\"line\">                nn.Conv2d (ndf * <span class=\"number\">8</span>, <span class=\"number\">1</span>, <span class=\"number\">4</span>, <span class=\"number\">1</span>, <span class=\"number\">0</span>, bias=<span class=\"literal\">False</span>),</span><br><span class=\"line\">                <span class=\"comment\"># 输出 1*1*1</span></span><br><span class=\"line\">                nn.Sigmoid())<span class=\"comment\">#告诉D概率</span></span><br><span class=\"line\">                </span><br><span class=\"line\">    <span class=\"comment\">#前向传播</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self,x)</span>:</span></span><br><span class=\"line\">        out=self.D_layer(x)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> out</span><br></pre></td></tr></table></figure></p>\n<p><strong>train.py</strong><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br><span class=\"line\">107</span><br><span class=\"line\">108</span><br><span class=\"line\">109</span><br><span class=\"line\">110</span><br><span class=\"line\">111</span><br><span class=\"line\">112</span><br><span class=\"line\">113</span><br><span class=\"line\">114</span><br><span class=\"line\">115</span><br><span class=\"line\">116</span><br><span class=\"line\">117</span><br><span class=\"line\">118</span><br><span class=\"line\">119</span><br><span class=\"line\">120</span><br><span class=\"line\">121</span><br><span class=\"line\">122</span><br><span class=\"line\">123</span><br><span class=\"line\">124</span><br><span class=\"line\">125</span><br><span class=\"line\">126</span><br><span class=\"line\">127</span><br><span class=\"line\">128</span><br><span class=\"line\">129</span><br><span class=\"line\">130</span><br><span class=\"line\">131</span><br><span class=\"line\">132</span><br><span class=\"line\">133</span><br><span class=\"line\">134</span><br><span class=\"line\">135</span><br><span class=\"line\">136</span><br><span class=\"line\">137</span><br><span class=\"line\">138</span><br><span class=\"line\">139</span><br><span class=\"line\">140</span><br><span class=\"line\">141</span><br><span class=\"line\">142</span><br><span class=\"line\">143</span><br><span class=\"line\">144</span><br><span class=\"line\">145</span><br><span class=\"line\">146</span><br><span class=\"line\">147</span><br><span class=\"line\">148</span><br><span class=\"line\">149</span><br><span class=\"line\">150</span><br><span class=\"line\">151</span><br><span class=\"line\">152</span><br><span class=\"line\">153</span><br><span class=\"line\">154</span><br><span class=\"line\">155</span><br><span class=\"line\">156</span><br><span class=\"line\">157</span><br><span class=\"line\">158</span><br><span class=\"line\">159</span><br><span class=\"line\">160</span><br><span class=\"line\">161</span><br><span class=\"line\">162</span><br><span class=\"line\">163</span><br><span class=\"line\">164</span><br><span class=\"line\">165</span><br><span class=\"line\">166</span><br><span class=\"line\">167</span><br><span class=\"line\">168</span><br><span class=\"line\">169</span><br><span class=\"line\">170</span><br><span class=\"line\">171</span><br><span class=\"line\">172</span><br><span class=\"line\">173</span><br><span class=\"line\">174</span><br><span class=\"line\">175</span><br><span class=\"line\">176</span><br><span class=\"line\">177</span><br><span class=\"line\">178</span><br><span class=\"line\">179</span><br><span class=\"line\">180</span><br><span class=\"line\">181</span><br><span class=\"line\">182</span><br><span class=\"line\">183</span><br><span class=\"line\">184</span><br><span class=\"line\">185</span><br><span class=\"line\">186</span><br><span class=\"line\">187</span><br><span class=\"line\">188</span><br><span class=\"line\">189</span><br><span class=\"line\">190</span><br><span class=\"line\">191</span><br><span class=\"line\">192</span><br><span class=\"line\">193</span><br><span class=\"line\">194</span><br><span class=\"line\">195</span><br><span class=\"line\">196</span><br><span class=\"line\">197</span><br><span class=\"line\">198</span><br><span class=\"line\">199</span><br><span class=\"line\">200</span><br><span class=\"line\">201</span><br><span class=\"line\">202</span><br><span class=\"line\">203</span><br><span class=\"line\">204</span><br><span class=\"line\">205</span><br><span class=\"line\">206</span><br><span class=\"line\">207</span><br><span class=\"line\">208</span><br><span class=\"line\">209</span><br><span class=\"line\">210</span><br><span class=\"line\">211</span><br><span class=\"line\">212</span><br><span class=\"line\">213</span><br><span class=\"line\">214</span><br><span class=\"line\">215</span><br><span class=\"line\">216</span><br><span class=\"line\">217</span><br><span class=\"line\">218</span><br><span class=\"line\">219</span><br><span class=\"line\">220</span><br><span class=\"line\">221</span><br><span class=\"line\">222</span><br><span class=\"line\">223</span><br><span class=\"line\">224</span><br><span class=\"line\">225</span><br><span class=\"line\">226</span><br><span class=\"line\">227</span><br><span class=\"line\">228</span><br><span class=\"line\">229</span><br><span class=\"line\">230</span><br><span class=\"line\">231</span><br><span class=\"line\">232</span><br><span class=\"line\">233</span><br><span class=\"line\">234</span><br><span class=\"line\">235</span><br><span class=\"line\">236</span><br><span class=\"line\">237</span><br><span class=\"line\">238</span><br><span class=\"line\">239</span><br><span class=\"line\">240</span><br><span class=\"line\">241</span><br><span class=\"line\">242</span><br><span class=\"line\">243</span><br><span class=\"line\">244</span><br><span class=\"line\">245</span><br><span class=\"line\">246</span><br><span class=\"line\">247</span><br><span class=\"line\">248</span><br><span class=\"line\">249</span><br><span class=\"line\">250</span><br><span class=\"line\">251</span><br><span class=\"line\">252</span><br><span class=\"line\">253</span><br><span class=\"line\">254</span><br><span class=\"line\">255</span><br><span class=\"line\">256</span><br><span class=\"line\">257</span><br><span class=\"line\">258</span><br><span class=\"line\">259</span><br><span class=\"line\">260</span><br><span class=\"line\">261</span><br><span class=\"line\">262</span><br><span class=\"line\">263</span><br><span class=\"line\">264</span><br><span class=\"line\">265</span><br><span class=\"line\">266</span><br><span class=\"line\">267</span><br><span class=\"line\">268</span><br><span class=\"line\">269</span><br><span class=\"line\">270</span><br><span class=\"line\">271</span><br><span class=\"line\">272</span><br><span class=\"line\">273</span><br><span class=\"line\">274</span><br><span class=\"line\">275</span><br><span class=\"line\">276</span><br><span class=\"line\">277</span><br><span class=\"line\">278</span><br><span class=\"line\">279</span><br><span class=\"line\">280</span><br><span class=\"line\">281</span><br><span class=\"line\">282</span><br><span class=\"line\">283</span><br><span class=\"line\">284</span><br><span class=\"line\">285</span><br><span class=\"line\">286</span><br><span class=\"line\">287</span><br><span class=\"line\">288</span><br><span class=\"line\">289</span><br><span class=\"line\">290</span><br><span class=\"line\">291</span><br><span class=\"line\">292</span><br><span class=\"line\">293</span><br><span class=\"line\">294</span><br><span class=\"line\">295</span><br><span class=\"line\">296</span><br><span class=\"line\">297</span><br><span class=\"line\">298</span><br><span class=\"line\">299</span><br><span class=\"line\">300</span><br><span class=\"line\">301</span><br><span class=\"line\">302</span><br><span class=\"line\">303</span><br><span class=\"line\">304</span><br><span class=\"line\">305</span><br><span class=\"line\">306</span><br><span class=\"line\">307</span><br><span class=\"line\">308</span><br><span class=\"line\">309</span><br><span class=\"line\">310</span><br><span class=\"line\">311</span><br><span class=\"line\">312</span><br><span class=\"line\">313</span><br><span class=\"line\">314</span><br><span class=\"line\">315</span><br><span class=\"line\">316</span><br><span class=\"line\">317</span><br><span class=\"line\">318</span><br><span class=\"line\">319</span><br><span class=\"line\">320</span><br><span class=\"line\">321</span><br><span class=\"line\">322</span><br><span class=\"line\">323</span><br><span class=\"line\">324</span><br><span class=\"line\">325</span><br><span class=\"line\">326</span><br><span class=\"line\">327</span><br><span class=\"line\">328</span><br><span class=\"line\">329</span><br><span class=\"line\">330</span><br><span class=\"line\">331</span><br><span class=\"line\">332</span><br><span class=\"line\">333</span><br><span class=\"line\">334</span><br><span class=\"line\">335</span><br><span class=\"line\">336</span><br><span class=\"line\">337</span><br><span class=\"line\">338</span><br><span class=\"line\">339</span><br><span class=\"line\">340</span><br><span class=\"line\">341</span><br><span class=\"line\">342</span><br><span class=\"line\">343</span><br><span class=\"line\">344</span><br><span class=\"line\">345</span><br><span class=\"line\">346</span><br><span class=\"line\">347</span><br><span class=\"line\">348</span><br><span class=\"line\">349</span><br><span class=\"line\">350</span><br><span class=\"line\">351</span><br><span class=\"line\">352</span><br><span class=\"line\">353</span><br><span class=\"line\">354</span><br><span class=\"line\">355</span><br><span class=\"line\">356</span><br><span class=\"line\">357</span><br><span class=\"line\">358</span><br><span class=\"line\">359</span><br><span class=\"line\">360</span><br><span class=\"line\">361</span><br><span class=\"line\">362</span><br><span class=\"line\">363</span><br><span class=\"line\">364</span><br><span class=\"line\">365</span><br><span class=\"line\">366</span><br><span class=\"line\">367</span><br><span class=\"line\">368</span><br><span class=\"line\">369</span><br><span class=\"line\">370</span><br><span class=\"line\">371</span><br><span class=\"line\">372</span><br><span class=\"line\">373</span><br><span class=\"line\">374</span><br><span class=\"line\">375</span><br><span class=\"line\">376</span><br><span class=\"line\">377</span><br><span class=\"line\">378</span><br><span class=\"line\">379</span><br><span class=\"line\">380</span><br><span class=\"line\">381</span><br><span class=\"line\">382</span><br><span class=\"line\">383</span><br><span class=\"line\">384</span><br><span class=\"line\">385</span><br><span class=\"line\">386</span><br><span class=\"line\">387</span><br><span class=\"line\">388</span><br><span class=\"line\">389</span><br><span class=\"line\">390</span><br><span class=\"line\">391</span><br><span class=\"line\">392</span><br><span class=\"line\">393</span><br><span class=\"line\">394</span><br><span class=\"line\">395</span><br><span class=\"line\">396</span><br><span class=\"line\">397</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision.datasets <span class=\"keyword\">as</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision.transforms <span class=\"keyword\">as</span>  transforms</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.backends.cudnn <span class=\"keyword\">as</span> cudnn</span><br><span class=\"line\"><span class=\"comment\"># 工具包</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> argparse</span><br><span class=\"line\"><span class=\"comment\"># 载入网络</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> network <span class=\"keyword\">import</span> G, D</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############参数设置#############</span></span><br><span class=\"line\"><span class=\"comment\">####命令行设置########</span></span><br><span class=\"line\">parser = argparse.ArgumentParser (description=<span class=\"string\">'GANs'</span>)  <span class=\"comment\"># 导入命令行模块</span></span><br><span class=\"line\"><span class=\"comment\"># 对关于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明</span></span><br><span class=\"line\"><span class=\"comment\">#关于训练参数</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--batch_size'</span>, type=int, default=<span class=\"number\">64</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'训练batch-size大小 (default: 64)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--imageSize'</span>, type=int, default=<span class=\"number\">64</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'图片尺寸'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--max_epoch'</span>, type=int, default=<span class=\"number\">20</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'最大迭代数 (default: 12)'</span>)</span><br><span class=\"line\"><span class=\"comment\">#关于网络参数</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--lr_g'</span>, type=float, default=<span class=\"number\">2e-4</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'生成器学习率 (default: 2e-4)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--lr_d'</span>, type=float, default=<span class=\"number\">2e-4</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'判别器学习率 (default: 2e-4)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--ngf'</span>, type=int, default=<span class=\"number\">64</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'生成器feature map数'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--ndf'</span>, type=int, default=<span class=\"number\">64</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'判别器feature map数'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--d_every'</span>, type=int, default=<span class=\"number\">1</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'每几个batch训练一次判别器'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--g_every'</span>, type=int, default=<span class=\"number\">4</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'每几个batch训练一次生成器'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--nz'</span>, type=int, default=<span class=\"number\">3</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'噪声维度'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#关于优化器参数</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--beta1'</span>, type=int, default=<span class=\"number\">0.5</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'Adam优化器的beta1参数'</span>)</span><br><span class=\"line\"><span class=\"comment\">#路径</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--dataset'</span>, default=<span class=\"string\">'data/'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'数据集路径'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--save_data'</span>,  default=<span class=\"string\">'save/'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'保存路径'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#可视化</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--vis'</span>, action=<span class=\"string\">'store_true'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'使用visdom可视化'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--plot_every'</span>, type=int, default=<span class=\"number\">1</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'每间隔_batch，visdom画图一次'</span>)</span><br><span class=\"line\"><span class=\"comment\"># 其他</span></span><br><span class=\"line\"></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--cuda'</span>, action=<span class=\"string\">'store_true'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'开启cuda训练'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--plt'</span>, action=<span class=\"string\">'store_true'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'开启画图'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--test'</span>, action=<span class=\"string\">'store_true'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'开启测试生成'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--save_every'</span>, type=int, default=<span class=\"number\">5</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'几个epoch保存一次模型 (default: 2)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--seed'</span>, type=int, default=<span class=\"number\">1</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'随机种子 (default: 1)'</span>)</span><br><span class=\"line\">args = parser.parse_args ()  <span class=\"comment\"># 相当于激活命令</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#训练过程</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">train</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">\t<span class=\"comment\">###############判断gpu#############</span></span><br><span class=\"line\">\tdevice = torch.device (<span class=\"string\">'cuda'</span>) <span class=\"keyword\">if</span> args.cuda <span class=\"keyword\">else</span> torch.device (<span class=\"string\">'cpu'</span>)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">####### 为CPU设置种子用于生成随机数，以使得结果是确定的##########</span></span><br><span class=\"line\">\ttorch.manual_seed (args.seed)</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> args.cuda:</span><br><span class=\"line\">\t\ttorch.cuda.manual_seed (args.seed)</span><br><span class=\"line\">\tcudnn.benchmark = <span class=\"literal\">True</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">#################可视化###############</span></span><br><span class=\"line\">\t<span class=\"keyword\">if</span> args.vis:</span><br><span class=\"line\">\t\tvis = Visualizer (<span class=\"string\">'GANs'</span>)</span><br><span class=\"line\">\t<span class=\"comment\">##########数据转换#####################</span></span><br><span class=\"line\">\tdata_transforms = transforms.Compose ([transforms.Scale (args.imageSize),  <span class=\"comment\"># 通过调整比例调整大小,会报警</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   transforms.CenterCrop (args.imageSize),  <span class=\"comment\"># 在中心裁剪给指定大小方形PIL图像</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   transforms.ToTensor (),<span class=\"comment\"># 转换成pytorch 变量tensor</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   transforms.Normalize ((<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>), (<span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>, <span class=\"number\">0.5</span>))])</span><br><span class=\"line\">\t<span class=\"comment\">###############数据载入################</span></span><br><span class=\"line\">\t<span class=\"comment\"># train_dataset = datasets.ImageFolder (root=args.dataset,  # 数据路径目录</span></span><br><span class=\"line\">\t<span class=\"comment\"># \t\t\t\t\t\t\t\t\t  transform=data_transforms)  # 把数据转换成上面约束样子</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\ttrain_dataset = datasets.CIFAR10(root=args.dataset,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t train=<span class=\"literal\">True</span>,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t transform=data_transforms,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t download=<span class=\"literal\">False</span>)</span><br><span class=\"line\">\t<span class=\"comment\"># test_dataset = datasets.ImageFolder (root=args.dataset,</span></span><br><span class=\"line\">\t<span class=\"comment\"># \t\t\t\t\t\t\t\t\t transform=data_transforms)</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">##############数据装载###############</span></span><br><span class=\"line\">\ttrain_loader = torch.utils.data.DataLoader (dataset=train_dataset,  <span class=\"comment\"># 装载数据</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\t\tbatch_size=args.batch_size,  <span class=\"comment\"># 设置批大小</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\t\tshuffle=<span class=\"literal\">True</span>)  <span class=\"comment\"># 是否随机打乱</span></span><br><span class=\"line\">\t<span class=\"comment\"># test_loader = torch.utils.data.DataLoader (dataset=test_dataset,</span></span><br><span class=\"line\">\t<span class=\"comment\"># \t\t\t\t\t\t\t\t\t\t   batch_size=args.batch_size,</span></span><br><span class=\"line\">\t<span class=\"comment\"># \t\t\t\t\t\t\t\t\t\t   shuffle=True)</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">#############模型载入#################</span></span><br><span class=\"line\">\tnetG ,netD= G (args),D (args)</span><br><span class=\"line\">\tnetG.to (device)</span><br><span class=\"line\">\tnetD.to (device)</span><br><span class=\"line\">\t<span class=\"keyword\">print</span> (netD, netG)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">###############损失函数##################</span></span><br><span class=\"line\">\tcriterion = torch.nn.BCELoss ().to (device)</span><br><span class=\"line\">\toptimizerD = torch.optim.Adam (netD.parameters (), lr=args.lr_d,betas=(<span class=\"number\">0.5</span>, <span class=\"number\">0.999</span>))  <span class=\"comment\"># Adam优化器</span></span><br><span class=\"line\">\toptimizerG = torch.optim.Adam (netG.parameters (), lr=args.lr_g,betas=(<span class=\"number\">0.5</span>, <span class=\"number\">0.999</span>))  <span class=\"comment\"># Adam优化器</span></span><br><span class=\"line\">\t<span class=\"comment\">###############画图参数保存##################</span></span><br><span class=\"line\">\tG_losses = []</span><br><span class=\"line\">\tD_losses = []</span><br><span class=\"line\">\timg_list = []</span><br><span class=\"line\">\t<span class=\"comment\">#############训练过程#####################</span></span><br><span class=\"line\">\t<span class=\"keyword\">import</span> tqdm</span><br><span class=\"line\">\t<span class=\"comment\"># Tqdm是一个快速，可扩展的Python进度条，可以在Python</span></span><br><span class=\"line\">\t<span class=\"comment\"># 长循环中添加一个进度提示信息，用户只需要封装任意的迭代器</span></span><br><span class=\"line\">\t<span class=\"comment\"># tqdm (iterator)。</span></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range (args.max_epoch):</span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> i, (images, labels) <span class=\"keyword\">in</span> tqdm.tqdm(enumerate (train_loader)):  <span class=\"comment\"># 枚举出来</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\">#数据处理</span></span><br><span class=\"line\">\t\t\timages = images.to (device)</span><br><span class=\"line\">\t\t\t<span class=\"comment\"># 装箱</span></span><br><span class=\"line\">\t\t\timages = Variable (images)</span><br><span class=\"line\">\t\t\tnoises=Variable(torch.randn(images.size(<span class=\"number\">0</span>), args.nz, <span class=\"number\">1</span>, <span class=\"number\">1</span>).to(device))</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\t<span class=\"comment\">#遍历每张图片,并且根据指定的训练机制训练</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> i % args.d_every==<span class=\"number\">0</span>:<span class=\"comment\">#满足此条件训练D</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D前向传播</span></span><br><span class=\"line\">\t\t\t\toptimizerD.zero_grad ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D网络输出</span></span><br><span class=\"line\">\t\t\t\toutput_r = netD (images).view(<span class=\"number\">-1</span>)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#定义真张量</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#返回第一个参数为大小 第二参数为值 的张量</span></span><br><span class=\"line\">\t\t\t\ttrue_label = torch.full ((images.size(<span class=\"number\">0</span>),), <span class=\"number\">1</span>, device=device)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#判别真的损失</span></span><br><span class=\"line\">\t\t\t\td_real_loss = criterion(output_r, true_label)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#反向传播</span></span><br><span class=\"line\">\t\t\t\td_real_loss.backward()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G网络输出</span></span><br><span class=\"line\">\t\t\t\tfake = netG (images) <span class=\"comment\"># 根据真生成图</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#把假图给d</span></span><br><span class=\"line\">\t\t\t\toutput_f = netD (fake).view(<span class=\"number\">-1</span>)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#d假的损失</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#print(fake.size(),output_f.size(),output_r.size())</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\"># 返回第一个参数为大小 第二参数为值 的张量</span></span><br><span class=\"line\">\t\t\t\tfake_label = torch.full ((images.size (<span class=\"number\">0</span>),), <span class=\"number\">0</span>, device=device)</span><br><span class=\"line\">\t\t\t\td_fake_loss= criterion(output_f,fake_label)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D假反向传播</span></span><br><span class=\"line\">\t\t\t\td_fake_loss.backward ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\"># 总损失</span></span><br><span class=\"line\">\t\t\t\tD_loss=d_fake_loss+d_real_loss</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D更新参数</span></span><br><span class=\"line\">\t\t\t\toptimizerD.step ()</span><br><span class=\"line\">\t\t\t\t</span><br><span class=\"line\">\t\t\t\t</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\"># 度量</span></span><br><span class=\"line\">\t\t\t\tD_x = output_r.mean ().item ()</span><br><span class=\"line\">\t\t\t\tD_G_z1 = output_f.mean ().item ()</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> i % args.g_every==<span class=\"number\">0</span>:<span class=\"comment\">#满足此条件训练G</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G前向传播</span></span><br><span class=\"line\">\t\t\t\toptimizerG.zero_grad ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G网络输出</span></span><br><span class=\"line\">\t\t\t\tfake = netG (images)  <span class=\"comment\"># 根据噪声生成假图</span></span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#把假图给G</span></span><br><span class=\"line\">\t\t\t\toutput_f = netD (fake).view(<span class=\"number\">-1</span>)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G的损失</span></span><br><span class=\"line\">\t\t\t\ttrue_label = torch.full ((images.size (<span class=\"number\">0</span>),), <span class=\"number\">1</span>, device=device)</span><br><span class=\"line\">\t\t\t\tG_loss = criterion(output_f,true_label)</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#G反向传播</span></span><br><span class=\"line\">\t\t\t\tG_loss.backward ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#度量</span></span><br><span class=\"line\">\t\t\t\tD_G_z2 = output_f.mean ().item ()</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">#D更新参数</span></span><br><span class=\"line\">\t\t\t\toptimizerG.step ()</span><br><span class=\"line\">\t\t\t\t</span><br><span class=\"line\">\t\t\t<span class=\"comment\">###########################################</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\">##########可视化(可选)#####################</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> args.vis <span class=\"keyword\">and</span> i % args.plot_every == args.plot_every - <span class=\"number\">1</span>:</span><br><span class=\"line\">\t\t\t\tfake = netG (noises)</span><br><span class=\"line\">\t\t\t\tvis.images (fake.detach ().cpu ().numpy () [:<span class=\"number\">64</span>] * <span class=\"number\">0.5</span> + <span class=\"number\">0.5</span>, win=<span class=\"string\">'fixfake'</span>)</span><br><span class=\"line\">\t\t\t\tvis.images (images.data.cpu ().numpy () [:<span class=\"number\">64</span>] * <span class=\"number\">0.5</span> + <span class=\"number\">0.5</span>, win=<span class=\"string\">'real'</span>)</span><br><span class=\"line\">\t\t\t\tvis.plot (<span class=\"string\">'errord'</span>, D_loss.item ())</span><br><span class=\"line\">\t\t\t\tvis.plot (<span class=\"string\">'errorg'</span>, G_loss.item ())</span><br><span class=\"line\">\t\t\t<span class=\"comment\">#######################################</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\">############打印记录###################</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> i % <span class=\"number\">1</span>== <span class=\"number\">0</span>:</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">print</span> (<span class=\"string\">'[%d/%d][%d/%d]\\tLoss_D: %.4f\\tLoss_G: %.4f\\tD(x): %.4f\\tD(G(z)): %.4f / %.4f'</span></span><br><span class=\"line\">\t\t\t\t\t   % (epoch, args.max_epoch, i, len (train_loader),</span><br><span class=\"line\">\t\t\t\t\t\t  D_loss.item (), G_loss.item (), D_x, D_G_z1, D_G_z2))</span><br><span class=\"line\">\t\t\t\t<span class=\"comment\">########添加画图参数########</span></span><br><span class=\"line\">\t\t\t\tG_losses.append (G_loss.item ())</span><br><span class=\"line\">\t\t\t\tD_losses.append (D_loss.item ())</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">with</span> torch.no_grad ():</span><br><span class=\"line\">\t\t\t\t\tnoises = torch.randn (args.batch_size, args.nz, <span class=\"number\">1</span>, <span class=\"number\">1</span>).to (device)</span><br><span class=\"line\">\t\t\t\t\tfake = netG (images).detach ().cpu ()</span><br><span class=\"line\">\t\t\t\t<span class=\"keyword\">import</span> torchvision.utils <span class=\"keyword\">as</span> vutils</span><br><span class=\"line\">\t\t\t\timg_list.append (vutils.make_grid (fake, padding=<span class=\"number\">2</span>, normalize=<span class=\"literal\">True</span>))</span><br><span class=\"line\">\t</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">\t\t<span class=\"comment\">#######################################</span></span><br><span class=\"line\">\t\t<span class=\"comment\">############保存模型###################</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (epoch + <span class=\"number\">1</span>) % args.save_every == <span class=\"number\">0</span>:</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">import</span> torchvision <span class=\"keyword\">as</span> tv</span><br><span class=\"line\">\t\t\t<span class=\"comment\"># 保存模型、图片</span></span><br><span class=\"line\">\t\t\ttv.utils.save_image (fake.data [:<span class=\"number\">64</span>], <span class=\"string\">'%s/%s.png'</span> % (args.save_data, epoch), normalize=<span class=\"literal\">True</span>,range=(<span class=\"number\">-1</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\">\t\t\ttorch.save (netD.state_dict (), <span class=\"string\">'checkpoints/netd_%s.pth'</span> % epoch)</span><br><span class=\"line\">\t\t\ttorch.save (netG.state_dict (), <span class=\"string\">'checkpoints/netg_%s.pth'</span> % epoch)</span><br><span class=\"line\">\t\t\tprint(<span class=\"string\">'完成%s的模型保存'</span>%epoch)</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">#######################################</span></span><br><span class=\"line\">\t<span class=\"comment\">############画图###################</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> args.plt:</span><br><span class=\"line\">\t\t<span class=\"keyword\">import</span> matplotlib.pyplot <span class=\"keyword\">as</span> plt</span><br><span class=\"line\">\t\t<span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\">\t\t<span class=\"keyword\">import</span> torchvision.utils <span class=\"keyword\">as</span> vutils</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\tplt.figure (figsize=(<span class=\"number\">10</span>, <span class=\"number\">5</span>))</span><br><span class=\"line\">\t\tplt.title (<span class=\"string\">\"GAN\"</span>)</span><br><span class=\"line\">\t\tplt.plot (G_losses, label=<span class=\"string\">\"G\"</span>)</span><br><span class=\"line\">\t\tplt.plot (D_losses, label=<span class=\"string\">\"D\"</span>)</span><br><span class=\"line\">\t\tplt.xlabel (<span class=\"string\">\"迭代次数\"</span>,fontproperties=<span class=\"string\">'SimHei'</span>)</span><br><span class=\"line\">\t\tplt.ylabel (<span class=\"string\">\"损失\"</span>,fontproperties=<span class=\"string\">'SimHei'</span>)</span><br><span class=\"line\">\t\tplt.legend ()</span><br><span class=\"line\">\t\tplt.show ()</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 从数据集加载</span></span><br><span class=\"line\">\t\treal_batch = next (iter (train_dataset))</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 画出真图</span></span><br><span class=\"line\">\t\tplt.figure (figsize=(<span class=\"number\">15</span>, <span class=\"number\">10</span>))</span><br><span class=\"line\">\t\tplt.subplot (<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">1</span>)</span><br><span class=\"line\">\t\tplt.axis (<span class=\"string\">\"off\"</span>)</span><br><span class=\"line\">\t\tplt.title (<span class=\"string\">\"真图\"</span>,fontproperties=<span class=\"string\">'SimHei'</span>)</span><br><span class=\"line\">\t\tplt.imshow (np.transpose (</span><br><span class=\"line\">\t\t\tvutils.make_grid (real_batch [<span class=\"number\">0</span>].to (device) [:<span class=\"number\">64</span>], padding=<span class=\"number\">5</span>, normalize=<span class=\"literal\">True</span>).cpu (),</span><br><span class=\"line\">\t\t\t(<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>)))</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 画出假图</span></span><br><span class=\"line\">\t\tplt.subplot (<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">2</span>)</span><br><span class=\"line\">\t\tplt.axis (<span class=\"string\">\"off\"</span>)</span><br><span class=\"line\">\t\tplt.title (<span class=\"string\">\"假图\"</span>,fontproperties=<span class=\"string\">'SimHei'</span>)</span><br><span class=\"line\">\t\tplt.imshow (np.transpose (img_list [<span class=\"number\">-1</span>], (<span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>)))</span><br><span class=\"line\">\t\tplt.show ()</span><br><span class=\"line\">\t\t\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">@torch.no_grad()#禁用梯度计算</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">test</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">\t<span class=\"comment\">#判断Gpu</span></span><br><span class=\"line\">\tdevice = torch.device (<span class=\"string\">'cuda'</span>) <span class=\"keyword\">if</span> args.cuda <span class=\"keyword\">else</span> torch.device (<span class=\"string\">'cpu'</span>)</span><br><span class=\"line\">\t<span class=\"comment\">#初始化网络</span></span><br><span class=\"line\">\tnetg, netd = netG (args).eval (), netD (args).eval ()</span><br><span class=\"line\">\t<span class=\"comment\">#定义噪声</span></span><br><span class=\"line\">\tnoises = torch.randn (args.batch_size, args.nz, <span class=\"number\">1</span>, <span class=\"number\">1</span>).to (device)</span><br><span class=\"line\">\t<span class=\"comment\">#载入网络</span></span><br><span class=\"line\">\tnetd.load_state_dict (torch.load (<span class=\"string\">'checkpoints/netd_%s.pth'</span>%args.max_epoch))</span><br><span class=\"line\">\tnetg.load_state_dict (torch.load (<span class=\"string\">'checkpoints/netg_%s.pth'</span>%args.max_epoch))</span><br><span class=\"line\">\t<span class=\"comment\">#设备化</span></span><br><span class=\"line\">\tnetd.to (device)</span><br><span class=\"line\">\tnetg.to (device)</span><br><span class=\"line\">\t<span class=\"comment\"># 生成图片，并计算图片在判别器的分数</span></span><br><span class=\"line\">\tfake_img = netg (noises)</span><br><span class=\"line\">\tscores = netd (fake_img).detach ()</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\"># 挑选最好的某几张</span></span><br><span class=\"line\">\tindexs = scores.topk (<span class=\"number\">5</span>) [<span class=\"number\">1</span>]</span><br><span class=\"line\">\tresult = []</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> indexs:</span><br><span class=\"line\">\t\tresult.append (fake_img.data [i])</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\"># 保存图片</span></span><br><span class=\"line\">\t<span class=\"keyword\">import</span> torchvision <span class=\"keyword\">as</span> tv</span><br><span class=\"line\">\ttv.utils.save_image (torch.stack (result), <span class=\"number\">5</span>, normalize=<span class=\"literal\">True</span>, range=(<span class=\"number\">-1</span>, <span class=\"number\">1</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">###################可视化类##################################</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> visdom</span><br><span class=\"line\"><span class=\"keyword\">import</span> time</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision <span class=\"keyword\">as</span> tv</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Visualizer</span> <span class=\"params\">()</span>:</span></span><br><span class=\"line\">\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t封装了visdom的基本操作，但是你仍然可以通过`self.vis.function`</span></span><br><span class=\"line\"><span class=\"string\">\t调用原生的visdom接口</span></span><br><span class=\"line\"><span class=\"string\">\t\"\"\"</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span> <span class=\"params\">(self, env=<span class=\"string\">'default'</span>, **kwargs)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">import</span> visdom</span><br><span class=\"line\">\t\tself.vis = visdom.Visdom (env=env, use_incoming_socket=<span class=\"literal\">False</span>, **kwargs)</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 画的第几个数，相当于横座标</span></span><br><span class=\"line\">\t\t<span class=\"comment\"># 保存（’loss',23） 即loss的第23个点</span></span><br><span class=\"line\">\t\tself.index = &#123;&#125;</span><br><span class=\"line\">\t\tself.log_text = <span class=\"string\">''</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">reinit</span> <span class=\"params\">(self, env=<span class=\"string\">'default'</span>, **kwargs)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\t修改visdom的配置</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\tself.vis = visdom.Visdom (env=env, use_incoming_socket=<span class=\"literal\">False</span>, **kwargs)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> self</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">plot_many</span> <span class=\"params\">(self, d)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\t一次plot多个</span></span><br><span class=\"line\"><span class=\"string\">\t\t@params d: dict (name,value) i.e. ('loss',0.11)</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> d.items ():</span><br><span class=\"line\">\t\t\tself.plot (k, v)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">img_many</span> <span class=\"params\">(self, d)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> d.items ():</span><br><span class=\"line\">\t\t\tself.img (k, v)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">plot</span> <span class=\"params\">(self, name, y)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\tself.plot('loss',1.00)</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\tx = self.index.get (name, <span class=\"number\">0</span>)</span><br><span class=\"line\">\t\tself.vis.line (Y=np.array ([y]), X=np.array ([x]),</span><br><span class=\"line\">\t\t\t\t\t   win=(name),</span><br><span class=\"line\">\t\t\t\t\t   opts=dict (title=name),</span><br><span class=\"line\">\t\t\t\t\t   update=<span class=\"literal\">None</span> <span class=\"keyword\">if</span> x == <span class=\"number\">0</span> <span class=\"keyword\">else</span> <span class=\"string\">'append'</span></span><br><span class=\"line\">\t\t\t\t\t   )</span><br><span class=\"line\">\t\tself.index [name] = x + <span class=\"number\">1</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">img</span> <span class=\"params\">(self, name, img_)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\tself.img('input_img',t.Tensor(64,64))</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> len (img_.size ()) &lt; <span class=\"number\">3</span>:</span><br><span class=\"line\">\t\t\timg_ = img_.cpu ().unsqueeze (<span class=\"number\">0</span>)</span><br><span class=\"line\">\t\tself.vis.image (img_.cpu (),</span><br><span class=\"line\">\t\t\t\t\t\twin=(name),</span><br><span class=\"line\">\t\t\t\t\t\topts=dict (title=name)</span><br><span class=\"line\">\t\t\t\t\t\t)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">img_grid_many</span> <span class=\"params\">(self, d)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> k, v <span class=\"keyword\">in</span> d.items ():</span><br><span class=\"line\">\t\t\tself.img_grid (k, v)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">img_grid</span> <span class=\"params\">(self, name, input_3d)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\t一个batch的图片转成一个网格图，i.e. input（36，64，64）</span></span><br><span class=\"line\"><span class=\"string\">\t\t会变成 6*6 的网格图，每个格子大小64*64</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\tself.img (name, tv.utils.make_grid (</span><br><span class=\"line\">\t\t\tinput_3d.cpu () [<span class=\"number\">0</span>].unsqueeze (<span class=\"number\">1</span>).clamp (max=<span class=\"number\">1</span>, min=<span class=\"number\">0</span>)))</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">log</span> <span class=\"params\">(self, info, win=<span class=\"string\">'log_text'</span>)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">\t\tself.log(&#123;'loss':1,'lr':0.0001&#125;)</span></span><br><span class=\"line\"><span class=\"string\">\t\t\"\"\"</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\tself.log_text += (<span class=\"string\">'[&#123;time&#125;] &#123;info&#125; &lt;br&gt;'</span>.format (</span><br><span class=\"line\">\t\t\ttime=time.strftime (<span class=\"string\">'%m%d_%H%M%S'</span>),</span><br><span class=\"line\">\t\t\tinfo=info))</span><br><span class=\"line\">\t\tself.vis.text (self.log_text, win=win)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__getattr__</span> <span class=\"params\">(self, name)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> getattr (self.vis, name)</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t</span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ == <span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">\t<span class=\"keyword\">if</span> args.test:</span><br><span class=\"line\">\t\ttest()</span><br><span class=\"line\">\t<span class=\"keyword\">else</span>:</span><br><span class=\"line\">\t\ttrain()</span><br></pre></td></tr></table></figure></p>\n<p>**输出:<br><img src=\"https://blog.mviai.com/images/回顾-VAEGAN/r.png\" alt></p>\n"},{"title":"回顾-Resnet","date":"2018-12-20T05:40:56.000Z","_content":"# 1.Resnet 简介:\nMSRA（微软亚洲研究院）何凯明团队的深度残差网络（[Deep Residual Network](http://arxiv.org/pdf/1512.03385.pdf)）在2015年的ImageNet上取得冠军，该网络简称为ResNet（由算法Residual命名），\n\n层数达到了152层，top-5错误率降到了3.57，而2014年冠军GoogLeNet的错误率是6.7。ResNet取得了5项第一，并又一次刷新了CNN模型在ImageNet上的历史!\n****************\n# 2. Resnet 网络结构:\n** 1.昨天我们看了vgg,深刻的感觉到了加深网络所带来的好处,即:**\n\n* <font color=red> 1.从我写的cnn一层→→Alexnet 的八层→→vgg16的十六层,可以看出层数越深,获取的特征越丰富,拟合能力越强\n</font>\n\n** 2.当然肯定想说,想通过VGG堆叠那样无限制加深网络,来加强拟合能力! 当然你会遇到以下问题**\n* 1.对于原来的网络，如果简单地增加深度，会导致梯度弥散或梯度爆炸(注:就是前向传的过去,反向传不回来(想成小时候传话游戏,传着传着就变味了)).\n * <font color=red> 遇到这个问题,其实可以正则化初始化和加入正则化层（Batch Normalization）或中间层添加辅助损失（auxiliary loss）作为额外的监督。,这样训练几十层应该没问题!</font>\n* 2.上面加深,没啥问题,但是在更深的网络有更高的训练误差和测试误差,即退化问题?   \n(你肯定想问,我不是刚说越深越强吗?现在怎么又不行了?\n(回答这个,最简单就是名字,退化嘛,就像无限逼近定理一样,理想很丰满,现实很骨感))\n    * <font color=red> 退化问题,推断能是因为深层的网络并不是那么好训练(也就是求解器很难去利用多层网络拟合同等函数(再简单一点,课程太多,学的有点崩溃))</font>\n***********\n### 3.如何解决所谓的退化问题?\n** 1. 首先我们看作者怎么玩的?**\n如图:\n![](https://blog.mviai.com/images\\回顾-Resnet\\res.png)\n\n** 注 : 图太大,就保存在桌面缩小慢慢对比**\n*************\n** 1.1:我们继续看图说故事!**\n   * 1.我们首先看vgg19和34层网络(图左和图中),作者跟大家一样想法,加深到34层,并且通过无数爬坑失败经验!进行改进了,如下:\n     * 图中与图左差别:\n         * 1.把每个maxpool(池化层)都改成了stride=2的卷积层做下采样(下采样就是缩小图片图片)\n         * 2.去掉了最后那个耗费资源的全连接,用global average pool层替换\n*************** \n然后就遇到了退化问题........\n然后尝试了..................次\n***************\n** 终于在一次尝试中使用改进[Highway Network](https://arxiv.org/pdf/1507.06228v2.pdf)带参数gate控制shortcut(就是图右的弯曲黑线,我叫它脑筋急转弯),以前我觉得是学LSTM(学这个最深感触,就是感觉在学电路分析)中也有一个forget gate来控制着流入下一阶段的信息量.**\n\n---------所以知识都是互通的!\n* 1,怎么改进呢?\n    *  上面是Highway Network(公路网络),不是还有更快的高速公路吗,就改成高速公路(刚才说的图右的弯曲黑线),什么是高速公路(官方叫恒等式变化),即简单,直接\n \n********* \n**下面我们来看看这所谓高速路是不是水泥构造:\n如图:**\n![](https://blog.mviai.com/images\\回顾-Resnet\\c.png)\n*************\n* 从这个图,我们能看出什么呢?\n    * 假设直下来表示很努力很努力的同学,弯弯曲曲的代表喜欢耍的同学!\nx代表刚入学,大家都一样,最下面(F(x)+x)代表清华北大哈!\n<font color=red> \n* 现在,我要喜欢耍的同学考入清华北大!\n     * 怎么做呢?\n         * 清华北大=F(x)+x,我是x!\n我是不是只要学习我没有的F(x)呢, F(x)怎么来呢?\n        * F(x)=清华北大-x,这就是残差,\n            所以我们不用想怎么考清华北大,而是想考清华北大同学有啥优点!,学习其优点,就可以无限接近清华北大!</font>\n*****************    \n** 注: 后面三层残差,这个函数变成清华北大=F(x)+wx,多了个w,W是卷积操作，用来调整x的channel维度的。 \n意思喊你不要一下啥都学,适合自己才是最好的!**\n***********    \n # 3.Resnet创新点: \n * 1.shortcut连接的方式使用恒等映射，如果residual block的输入输出维度不一致，对增加的维度用0来填充(使用0填充时，可以保证模型的复杂度最低，这对于更深的网络是更加有利的)；\n * 2.shortcut连接的方式维度一致时使用恒等映射,不一致时使用线性投影以保证维度一致\n * 3.ResNets并不能更好的表征某一方面的特征，但是ResNets允许逐层深入地表征更多的模型。(可看经典的残差网络变体)\n * 4.残差网络使得前馈式/反向传播算法非常顺利进行，在极大程度上，残差网络使得优化较深层模型更为简单 \n * 5.“shortcut”快捷连接添加既不产生额外的参数，也不会增加计算的复杂度。\n * 6.快捷连接简单的执行身份映射，并将它们的输出添加到叠加层的输出。通过反向传播的SGD，整个网络仍然可以被训练成终端到端的形式。\n\n*************\n*** 更多信息,可以看原文( 标题1处的链接 ) ***\n***********\n\n# 4.PyTorch实现:\n** 为了简化,采用resnet32网络!**\n如图:\n![](https://blog.mviai.com/images/回顾-Resnet/r.png)\n![](https://blog.mviai.com/images/回顾-Resnet/b.png)\n* 网络架构:Resnet.py文件:\n```python\nimport torch\n\n\n'''\n今天在vgg基础上再优雅点\n'''\n#遵从原来步骤\nclass Resnet(torch.nn.Module):\n\t#初始化\n\tdef __init__(self):\n\t\tsuper(Resnet, self).__init__()\n\t\t# self.Sumlayers=self.make_layers()#这里我们交由make_layers函数创建相似的模块\n\t\t# #假设我们上面已经创好五个模块(文章第一幅图block1->block5)\n\t\n\t\t#现在最顶端的不同层,看文章34层那个最上面橘色简化图的7*7\n\t\tself.top=torch.nn.Sequential(\n\t\t\ttorch.nn.Conv2d(3,64,7,2,3),\n\t\t\ttorch.nn.BatchNorm2d(64),\n\t\t\ttorch.nn.ReLU (inplace=True),\n\t\t\ttorch.nn.MaxPool2d(3,2,1))#最顶部构建完成\n\n\t\t\t\n\t\t\t\n\t\t#中间重复太多,交给make_layers函数创建相似的模块\n\t\t#第三个参数来表示有多少个捷径(高速公路)\n\t\t\n\t\t#先来一打紫色的(文中图)\n\t\tself.layer1 = self.make_layer (64,64,3)\n\t\t# 再来一打绿色的(文中图)\n\t\tself.layer2 = self.make_layer (64, 128, 4,stride=2)#图中第一个有/2\n\t\t# 再来一打橘色的(文中图)\n\t\tself.layer3 = self.make_layer ( 128,256, 6,stride=2)#图中第一个有/2\n\t\t# 再来一打银色的(文中图)\n\t\tself.layer4= self.make_layer (256, 512, 3, stride=2)  # 图中第一个有/2\n\t\t#中间重复的构造完了\n\t\t\n\t\t\n\t\t#开始最后的了\n\t\t\n\t\tself.avgPool =torch.nn.AvgPool2d(7)#全局平均化\n\t\tself.fc = torch.nn.Linear (512, 2)#最后分成猫狗两类\n\t\tself.last=torch.nn.Softmax (dim=1)\n\t\t\n\t\n\t\t\n\t#前向传播\n\tdef forward (self, x):\n\t\tx = self.top (x)\n\t\tx = self.layer1 (x)\n\t\tx = self.layer2 (x)\n\t\tx = self.layer3 (x)\n\t\tx = self.layer4 (x)\n\t\tx = self.avgPool(x)\n\t\tres = x.view (x.size (0), -1)  # 展平多维的卷积图成 一维\n\t\tout = self.fc(res)\n\t\tout = self.last(out)\n\t\treturn out\n\t\n\t\n\t#构建刚才的构建模块函数make_layers\n\tdef make_layer(self,in_c,out_c,n_block,stride=1):\n\n\t\t#创建一个列表,用来放后面层 ,后面我们直接往里面添加就可以了\n\t\tSumlayers=[]\n\t\t\n\t\t#构建捷径(高速公路)\n\t\tshortcut=torch.nn.Sequential(\n\t\t\ttorch.nn.Conv2d(in_c,out_c,1,stride),#1*1卷积\n\t\t\ttorch.nn.BatchNorm2d(out_c),\n\t\t)\n\t\t#构建完成残差\n\t\tSumlayers.append(ResBlock(in_c,out_c,stride,shortcut))\n\n\t\t#构建右边的公路\n\t\tfor i in range(1,n_block):\n\t\t\tSumlayers.append (ResBlock (out_c, out_c))#注意输入,输出应该一样\n\t\t\n\t\treturn torch.nn.Sequential (*Sumlayers) #然后把构建好模型传出\n\t\n\n#构建残差块 因为参数是变动的,所以引入变量,最后一个变量表示快捷通道个数,默认没有\nclass ResBlock(torch.nn.Module):\n\tdef __init__(self,in_c,out_c,stride=1,shortcut=None):\n\t\tsuper(ResBlock, self).__init__()\n\t\t#左边的公路\n\t\tself.left=torch.nn.Sequential(\n\t\t\ttorch.nn.Conv2d (in_c,out_c,3,stride,1),\n\t\t\ttorch.nn.BatchNorm2d (out_c),\n\t\t\ttorch.nn.ReLU (inplace=True),\n\n\t\t\ttorch.nn.Conv2d (out_c,out_c,3,1,1),#注意 这里输入输出应该一样\n\t\t\ttorch.nn.BatchNorm2d (out_c)\n\t\t)\n\n\t\t#右边的高速公路\n\t\tself.right=shortcut\n\n\t\t#最后\n\t\tself.last_y=torch.nn.ReLU()\n\t#前向\n\tdef forward(self, x):\n\t\ty_l=self.left(x)\n\t\ty_r = x if self.right is None else self.right (x) #如果有高数路为空,就直接保存在res中,否则执行高速路保存在res\n\t\tsum_x=y_l+y_r #两个总和\n\t\tout=self.last_y(sum_x)\n\t\treturn out\n\n\n\n\n```\n* 网络架构:Train.py文件:\n```python\nimport torch\nimport torch.nn as nn\nimport torchvision.datasets as datasets\nimport torchvision.transforms as  transforms\nfrom torch.autograd import Variable\n\n# 工具包\nimport argparse\n# 载入网络\nfrom Resnet import Resnet\n\n#############参数设置#############\n####命令行设置########\nparser = argparse.ArgumentParser (description='CNN')  # 导入命令行模块\n# 对于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明\nparser.add_argument ('--batch-size', type=int, default=2, metavar='N',\n\t\t\t\t\t help='训练batch-size大小 (default: 2)')\nparser.add_argument ('--epochs', type=int, default=10, metavar='N',\n\t\t\t\t\t help='训练epochs大小 (default: 10)')\nparser.add_argument ('--lr', type=float, default=0.001, metavar='LR',\n\t\t\t\t\t help='学习率 (default: 0.001)')\nparser.add_argument ('--no-cuda', action='store_true', default=False,\n\t\t\t\t\t help='不开启cuda训练')\nparser.add_argument ('--seed', type=int, default=1, metavar='S',\n\t\t\t\t\t help='随机种子 (default: 1)')\nparser.add_argument ('--log-interval', type=int, default=1, metavar='N',\n\t\t\t\t\t help='记录等待n批次 (default: 1)')\nargs = parser.parse_args ()  # 相当于激活命令\n\nargs.cuda = not args.no_cuda and torch.cuda.is_available ()  # 判断gpu\n\ntorch.manual_seed (args.seed)\nif args.cuda:\n\ttorch.cuda.manual_seed (args.seed)  # 为CPU设置种子用于生成随机数，以使得结果是确定的\n\n##########数据转换#####################\ndata_transforms = transforms.Compose ([transforms.Scale (224),  # 通过调整比例调整大小,会报警\n\t\t\t\t\t\t\t\t\t   transforms.CenterCrop (224),  # 在中心裁剪给指定大小方形PIL图像\n\t\t\t\t\t\t\t\t\t   transforms.ToTensor ()])  # 转换成pytorch 变量tensor\n###############数据载入################\ntrain_dataset = datasets.ImageFolder (root=\"./data/train/\",  # 保存目录\n\t\t\t\t\t\t\t\t\t  transform=data_transforms)  # 把数据转换成上面约束样子\n\ntest_dataset = datasets.ImageFolder (root='./data/test/',\n\t\t\t\t\t\t\t\t\t transform=data_transforms)\n\n##########数据如下####\n# # root/dog/xxx.png\n# # root/dog/xxy.png\n# # root/dog/xxz.png\n# #\n# # root/cat/123.png\n# # root/cat/nsdf3.png\n# # root/cat/asd932_.png\n######################\n\n##############数据装载###############\ntrain_loader = torch.utils.data.DataLoader (dataset=train_dataset,  # 装载数据\n\t\t\t\t\t\t\t\t\t\t\tbatch_size=args.batch_size,  # 设置批大小\n\t\t\t\t\t\t\t\t\t\t\tshuffle=True)  # 是否随机打乱\ntest_loader = torch.utils.data.DataLoader (dataset=test_dataset,\n\t\t\t\t\t\t\t\t\t\t   batch_size=args.batch_size,\n\t\t\t\t\t\t\t\t\t\t   shuffle=True)\n\n#############模型载入#################\nResnet=Resnet ()\nif not args.no_cuda:\n\tprint ('正在使用gpu')\n\tResnet.cuda ()\nprint (Resnet)\n\n###############损失函数##################\ncriterion = nn.CrossEntropyLoss ()  # 内置标准损失\noptimizer = torch.optim.Adam (Resnet.parameters (), lr=args.lr)  # Adam优化器\n#############训练过程#####################\ntotal_loss = 0 #内存循环使用\nfor epoch in range (args.epochs):\n\tfor i, (images, labels) in enumerate (train_loader):  # 枚举出来\n\t\tif not args.no_cuda:  # 数据处理是否用gpu\n\t\t\timages = images.cuda ()\n\t\t\tlabels = labels.cuda ()\n\t\t\n\t\timages = Variable (images)  # 装箱\n\t\tlabels = Variable (labels)\n\t\t\n\t\t##前向传播\n\t\toptimizer.zero_grad ()\n\t\toutputs = Resnet (images)\n\t\t# 损失\n\t\tloss = criterion (outputs, labels)\n\t\t# 反向传播\n\t\tloss.backward ()\n\t\toptimizer.step ()#更新参数\n\t\ttotal_loss += loss#内存循环使用 防止cuda超出内存\n\t\t##打印记录\n\t\t\n\t\tif (i + 1) % args.log_interval == 0:\n\t\t\tprint ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'\n\t\t\t\t   % (epoch + 1, args.epochs, i + 1, len (train_dataset) // args.batch_size, loss.item ()))\n\t\t\n\t\t# 保存模型\n\t\ttorch.save (Resnet.state_dict (), 'Resnet.pkl')\n\n\n```\n结果:\n![](https://blog.mviai.com/images/回顾-Resnet/ret.png)\n* 注意残差的前向传播 ,一不小心都不知道自己哪里错了!!\n","source":"_posts/回顾-Resnet.md","raw":"---\ntitle: 回顾-Resnet\ndate: 2018-12-20 13:40:56\ntags:\n    - Resnet\n\ncategories: \n    - 框架\n    - pytorch\n    - Resnet\n---\n# 1.Resnet 简介:\nMSRA（微软亚洲研究院）何凯明团队的深度残差网络（[Deep Residual Network](http://arxiv.org/pdf/1512.03385.pdf)）在2015年的ImageNet上取得冠军，该网络简称为ResNet（由算法Residual命名），\n\n层数达到了152层，top-5错误率降到了3.57，而2014年冠军GoogLeNet的错误率是6.7。ResNet取得了5项第一，并又一次刷新了CNN模型在ImageNet上的历史!\n****************\n# 2. Resnet 网络结构:\n** 1.昨天我们看了vgg,深刻的感觉到了加深网络所带来的好处,即:**\n\n* <font color=red> 1.从我写的cnn一层→→Alexnet 的八层→→vgg16的十六层,可以看出层数越深,获取的特征越丰富,拟合能力越强\n</font>\n\n** 2.当然肯定想说,想通过VGG堆叠那样无限制加深网络,来加强拟合能力! 当然你会遇到以下问题**\n* 1.对于原来的网络，如果简单地增加深度，会导致梯度弥散或梯度爆炸(注:就是前向传的过去,反向传不回来(想成小时候传话游戏,传着传着就变味了)).\n * <font color=red> 遇到这个问题,其实可以正则化初始化和加入正则化层（Batch Normalization）或中间层添加辅助损失（auxiliary loss）作为额外的监督。,这样训练几十层应该没问题!</font>\n* 2.上面加深,没啥问题,但是在更深的网络有更高的训练误差和测试误差,即退化问题?   \n(你肯定想问,我不是刚说越深越强吗?现在怎么又不行了?\n(回答这个,最简单就是名字,退化嘛,就像无限逼近定理一样,理想很丰满,现实很骨感))\n    * <font color=red> 退化问题,推断能是因为深层的网络并不是那么好训练(也就是求解器很难去利用多层网络拟合同等函数(再简单一点,课程太多,学的有点崩溃))</font>\n***********\n### 3.如何解决所谓的退化问题?\n** 1. 首先我们看作者怎么玩的?**\n如图:\n![](https://blog.mviai.com/images\\回顾-Resnet\\res.png)\n\n** 注 : 图太大,就保存在桌面缩小慢慢对比**\n*************\n** 1.1:我们继续看图说故事!**\n   * 1.我们首先看vgg19和34层网络(图左和图中),作者跟大家一样想法,加深到34层,并且通过无数爬坑失败经验!进行改进了,如下:\n     * 图中与图左差别:\n         * 1.把每个maxpool(池化层)都改成了stride=2的卷积层做下采样(下采样就是缩小图片图片)\n         * 2.去掉了最后那个耗费资源的全连接,用global average pool层替换\n*************** \n然后就遇到了退化问题........\n然后尝试了..................次\n***************\n** 终于在一次尝试中使用改进[Highway Network](https://arxiv.org/pdf/1507.06228v2.pdf)带参数gate控制shortcut(就是图右的弯曲黑线,我叫它脑筋急转弯),以前我觉得是学LSTM(学这个最深感触,就是感觉在学电路分析)中也有一个forget gate来控制着流入下一阶段的信息量.**\n\n---------所以知识都是互通的!\n* 1,怎么改进呢?\n    *  上面是Highway Network(公路网络),不是还有更快的高速公路吗,就改成高速公路(刚才说的图右的弯曲黑线),什么是高速公路(官方叫恒等式变化),即简单,直接\n \n********* \n**下面我们来看看这所谓高速路是不是水泥构造:\n如图:**\n![](https://blog.mviai.com/images\\回顾-Resnet\\c.png)\n*************\n* 从这个图,我们能看出什么呢?\n    * 假设直下来表示很努力很努力的同学,弯弯曲曲的代表喜欢耍的同学!\nx代表刚入学,大家都一样,最下面(F(x)+x)代表清华北大哈!\n<font color=red> \n* 现在,我要喜欢耍的同学考入清华北大!\n     * 怎么做呢?\n         * 清华北大=F(x)+x,我是x!\n我是不是只要学习我没有的F(x)呢, F(x)怎么来呢?\n        * F(x)=清华北大-x,这就是残差,\n            所以我们不用想怎么考清华北大,而是想考清华北大同学有啥优点!,学习其优点,就可以无限接近清华北大!</font>\n*****************    \n** 注: 后面三层残差,这个函数变成清华北大=F(x)+wx,多了个w,W是卷积操作，用来调整x的channel维度的。 \n意思喊你不要一下啥都学,适合自己才是最好的!**\n***********    \n # 3.Resnet创新点: \n * 1.shortcut连接的方式使用恒等映射，如果residual block的输入输出维度不一致，对增加的维度用0来填充(使用0填充时，可以保证模型的复杂度最低，这对于更深的网络是更加有利的)；\n * 2.shortcut连接的方式维度一致时使用恒等映射,不一致时使用线性投影以保证维度一致\n * 3.ResNets并不能更好的表征某一方面的特征，但是ResNets允许逐层深入地表征更多的模型。(可看经典的残差网络变体)\n * 4.残差网络使得前馈式/反向传播算法非常顺利进行，在极大程度上，残差网络使得优化较深层模型更为简单 \n * 5.“shortcut”快捷连接添加既不产生额外的参数，也不会增加计算的复杂度。\n * 6.快捷连接简单的执行身份映射，并将它们的输出添加到叠加层的输出。通过反向传播的SGD，整个网络仍然可以被训练成终端到端的形式。\n\n*************\n*** 更多信息,可以看原文( 标题1处的链接 ) ***\n***********\n\n# 4.PyTorch实现:\n** 为了简化,采用resnet32网络!**\n如图:\n![](https://blog.mviai.com/images/回顾-Resnet/r.png)\n![](https://blog.mviai.com/images/回顾-Resnet/b.png)\n* 网络架构:Resnet.py文件:\n```python\nimport torch\n\n\n'''\n今天在vgg基础上再优雅点\n'''\n#遵从原来步骤\nclass Resnet(torch.nn.Module):\n\t#初始化\n\tdef __init__(self):\n\t\tsuper(Resnet, self).__init__()\n\t\t# self.Sumlayers=self.make_layers()#这里我们交由make_layers函数创建相似的模块\n\t\t# #假设我们上面已经创好五个模块(文章第一幅图block1->block5)\n\t\n\t\t#现在最顶端的不同层,看文章34层那个最上面橘色简化图的7*7\n\t\tself.top=torch.nn.Sequential(\n\t\t\ttorch.nn.Conv2d(3,64,7,2,3),\n\t\t\ttorch.nn.BatchNorm2d(64),\n\t\t\ttorch.nn.ReLU (inplace=True),\n\t\t\ttorch.nn.MaxPool2d(3,2,1))#最顶部构建完成\n\n\t\t\t\n\t\t\t\n\t\t#中间重复太多,交给make_layers函数创建相似的模块\n\t\t#第三个参数来表示有多少个捷径(高速公路)\n\t\t\n\t\t#先来一打紫色的(文中图)\n\t\tself.layer1 = self.make_layer (64,64,3)\n\t\t# 再来一打绿色的(文中图)\n\t\tself.layer2 = self.make_layer (64, 128, 4,stride=2)#图中第一个有/2\n\t\t# 再来一打橘色的(文中图)\n\t\tself.layer3 = self.make_layer ( 128,256, 6,stride=2)#图中第一个有/2\n\t\t# 再来一打银色的(文中图)\n\t\tself.layer4= self.make_layer (256, 512, 3, stride=2)  # 图中第一个有/2\n\t\t#中间重复的构造完了\n\t\t\n\t\t\n\t\t#开始最后的了\n\t\t\n\t\tself.avgPool =torch.nn.AvgPool2d(7)#全局平均化\n\t\tself.fc = torch.nn.Linear (512, 2)#最后分成猫狗两类\n\t\tself.last=torch.nn.Softmax (dim=1)\n\t\t\n\t\n\t\t\n\t#前向传播\n\tdef forward (self, x):\n\t\tx = self.top (x)\n\t\tx = self.layer1 (x)\n\t\tx = self.layer2 (x)\n\t\tx = self.layer3 (x)\n\t\tx = self.layer4 (x)\n\t\tx = self.avgPool(x)\n\t\tres = x.view (x.size (0), -1)  # 展平多维的卷积图成 一维\n\t\tout = self.fc(res)\n\t\tout = self.last(out)\n\t\treturn out\n\t\n\t\n\t#构建刚才的构建模块函数make_layers\n\tdef make_layer(self,in_c,out_c,n_block,stride=1):\n\n\t\t#创建一个列表,用来放后面层 ,后面我们直接往里面添加就可以了\n\t\tSumlayers=[]\n\t\t\n\t\t#构建捷径(高速公路)\n\t\tshortcut=torch.nn.Sequential(\n\t\t\ttorch.nn.Conv2d(in_c,out_c,1,stride),#1*1卷积\n\t\t\ttorch.nn.BatchNorm2d(out_c),\n\t\t)\n\t\t#构建完成残差\n\t\tSumlayers.append(ResBlock(in_c,out_c,stride,shortcut))\n\n\t\t#构建右边的公路\n\t\tfor i in range(1,n_block):\n\t\t\tSumlayers.append (ResBlock (out_c, out_c))#注意输入,输出应该一样\n\t\t\n\t\treturn torch.nn.Sequential (*Sumlayers) #然后把构建好模型传出\n\t\n\n#构建残差块 因为参数是变动的,所以引入变量,最后一个变量表示快捷通道个数,默认没有\nclass ResBlock(torch.nn.Module):\n\tdef __init__(self,in_c,out_c,stride=1,shortcut=None):\n\t\tsuper(ResBlock, self).__init__()\n\t\t#左边的公路\n\t\tself.left=torch.nn.Sequential(\n\t\t\ttorch.nn.Conv2d (in_c,out_c,3,stride,1),\n\t\t\ttorch.nn.BatchNorm2d (out_c),\n\t\t\ttorch.nn.ReLU (inplace=True),\n\n\t\t\ttorch.nn.Conv2d (out_c,out_c,3,1,1),#注意 这里输入输出应该一样\n\t\t\ttorch.nn.BatchNorm2d (out_c)\n\t\t)\n\n\t\t#右边的高速公路\n\t\tself.right=shortcut\n\n\t\t#最后\n\t\tself.last_y=torch.nn.ReLU()\n\t#前向\n\tdef forward(self, x):\n\t\ty_l=self.left(x)\n\t\ty_r = x if self.right is None else self.right (x) #如果有高数路为空,就直接保存在res中,否则执行高速路保存在res\n\t\tsum_x=y_l+y_r #两个总和\n\t\tout=self.last_y(sum_x)\n\t\treturn out\n\n\n\n\n```\n* 网络架构:Train.py文件:\n```python\nimport torch\nimport torch.nn as nn\nimport torchvision.datasets as datasets\nimport torchvision.transforms as  transforms\nfrom torch.autograd import Variable\n\n# 工具包\nimport argparse\n# 载入网络\nfrom Resnet import Resnet\n\n#############参数设置#############\n####命令行设置########\nparser = argparse.ArgumentParser (description='CNN')  # 导入命令行模块\n# 对于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明\nparser.add_argument ('--batch-size', type=int, default=2, metavar='N',\n\t\t\t\t\t help='训练batch-size大小 (default: 2)')\nparser.add_argument ('--epochs', type=int, default=10, metavar='N',\n\t\t\t\t\t help='训练epochs大小 (default: 10)')\nparser.add_argument ('--lr', type=float, default=0.001, metavar='LR',\n\t\t\t\t\t help='学习率 (default: 0.001)')\nparser.add_argument ('--no-cuda', action='store_true', default=False,\n\t\t\t\t\t help='不开启cuda训练')\nparser.add_argument ('--seed', type=int, default=1, metavar='S',\n\t\t\t\t\t help='随机种子 (default: 1)')\nparser.add_argument ('--log-interval', type=int, default=1, metavar='N',\n\t\t\t\t\t help='记录等待n批次 (default: 1)')\nargs = parser.parse_args ()  # 相当于激活命令\n\nargs.cuda = not args.no_cuda and torch.cuda.is_available ()  # 判断gpu\n\ntorch.manual_seed (args.seed)\nif args.cuda:\n\ttorch.cuda.manual_seed (args.seed)  # 为CPU设置种子用于生成随机数，以使得结果是确定的\n\n##########数据转换#####################\ndata_transforms = transforms.Compose ([transforms.Scale (224),  # 通过调整比例调整大小,会报警\n\t\t\t\t\t\t\t\t\t   transforms.CenterCrop (224),  # 在中心裁剪给指定大小方形PIL图像\n\t\t\t\t\t\t\t\t\t   transforms.ToTensor ()])  # 转换成pytorch 变量tensor\n###############数据载入################\ntrain_dataset = datasets.ImageFolder (root=\"./data/train/\",  # 保存目录\n\t\t\t\t\t\t\t\t\t  transform=data_transforms)  # 把数据转换成上面约束样子\n\ntest_dataset = datasets.ImageFolder (root='./data/test/',\n\t\t\t\t\t\t\t\t\t transform=data_transforms)\n\n##########数据如下####\n# # root/dog/xxx.png\n# # root/dog/xxy.png\n# # root/dog/xxz.png\n# #\n# # root/cat/123.png\n# # root/cat/nsdf3.png\n# # root/cat/asd932_.png\n######################\n\n##############数据装载###############\ntrain_loader = torch.utils.data.DataLoader (dataset=train_dataset,  # 装载数据\n\t\t\t\t\t\t\t\t\t\t\tbatch_size=args.batch_size,  # 设置批大小\n\t\t\t\t\t\t\t\t\t\t\tshuffle=True)  # 是否随机打乱\ntest_loader = torch.utils.data.DataLoader (dataset=test_dataset,\n\t\t\t\t\t\t\t\t\t\t   batch_size=args.batch_size,\n\t\t\t\t\t\t\t\t\t\t   shuffle=True)\n\n#############模型载入#################\nResnet=Resnet ()\nif not args.no_cuda:\n\tprint ('正在使用gpu')\n\tResnet.cuda ()\nprint (Resnet)\n\n###############损失函数##################\ncriterion = nn.CrossEntropyLoss ()  # 内置标准损失\noptimizer = torch.optim.Adam (Resnet.parameters (), lr=args.lr)  # Adam优化器\n#############训练过程#####################\ntotal_loss = 0 #内存循环使用\nfor epoch in range (args.epochs):\n\tfor i, (images, labels) in enumerate (train_loader):  # 枚举出来\n\t\tif not args.no_cuda:  # 数据处理是否用gpu\n\t\t\timages = images.cuda ()\n\t\t\tlabels = labels.cuda ()\n\t\t\n\t\timages = Variable (images)  # 装箱\n\t\tlabels = Variable (labels)\n\t\t\n\t\t##前向传播\n\t\toptimizer.zero_grad ()\n\t\toutputs = Resnet (images)\n\t\t# 损失\n\t\tloss = criterion (outputs, labels)\n\t\t# 反向传播\n\t\tloss.backward ()\n\t\toptimizer.step ()#更新参数\n\t\ttotal_loss += loss#内存循环使用 防止cuda超出内存\n\t\t##打印记录\n\t\t\n\t\tif (i + 1) % args.log_interval == 0:\n\t\t\tprint ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'\n\t\t\t\t   % (epoch + 1, args.epochs, i + 1, len (train_dataset) // args.batch_size, loss.item ()))\n\t\t\n\t\t# 保存模型\n\t\ttorch.save (Resnet.state_dict (), 'Resnet.pkl')\n\n\n```\n结果:\n![](https://blog.mviai.com/images/回顾-Resnet/ret.png)\n* 注意残差的前向传播 ,一不小心都不知道自己哪里错了!!\n","slug":"回顾-Resnet","published":1,"updated":"2021-07-26T09:58:02.578Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m21001ligtat5p15sni","content":"<h1 id=\"1-Resnet-简介\"><a href=\"#1-Resnet-简介\" class=\"headerlink\" title=\"1.Resnet 简介:\"></a>1.Resnet 简介:</h1><p>MSRA（微软亚洲研究院）何凯明团队的深度残差网络（<a href=\"http://arxiv.org/pdf/1512.03385.pdf\" target=\"_blank\" rel=\"noopener\">Deep Residual Network</a>）在2015年的ImageNet上取得冠军，该网络简称为ResNet（由算法Residual命名），</p>\n<p>层数达到了152层，top-5错误率降到了3.57，而2014年冠军GoogLeNet的错误率是6.7。ResNet取得了5项第一，并又一次刷新了CNN模型在ImageNet上的历史!</p>\n<hr>\n<h1 id=\"2-Resnet-网络结构\"><a href=\"#2-Resnet-网络结构\" class=\"headerlink\" title=\"2. Resnet 网络结构:\"></a>2. Resnet 网络结构:</h1><p><strong> 1.昨天我们看了vgg,深刻的感觉到了加深网络所带来的好处,即:</strong></p>\n<ul>\n<li><font color=\"red\"> 1.从我写的cnn一层→→Alexnet 的八层→→vgg16的十六层,可以看出层数越深,获取的特征越丰富,拟合能力越强<br></font>\n\n</li>\n</ul>\n<p><strong> 2.当然肯定想说,想通过VGG堆叠那样无限制加深网络,来加强拟合能力! 当然你会遇到以下问题</strong></p>\n<ul>\n<li>1.对于原来的网络，如果简单地增加深度，会导致梯度弥散或梯度爆炸(注:就是前向传的过去,反向传不回来(想成小时候传话游戏,传着传着就变味了)).<ul>\n<li><font color=\"red\"> 遇到这个问题,其实可以正则化初始化和加入正则化层（Batch Normalization）或中间层添加辅助损失（auxiliary loss）作为额外的监督。,这样训练几十层应该没问题!</font></li>\n</ul>\n</li>\n<li>2.上面加深,没啥问题,但是在更深的网络有更高的训练误差和测试误差,即退化问题?<br>(你肯定想问,我不是刚说越深越强吗?现在怎么又不行了?<br>(回答这个,最简单就是名字,退化嘛,就像无限逼近定理一样,理想很丰满,现实很骨感))<ul>\n<li><font color=\"red\"> 退化问题,推断能是因为深层的网络并不是那么好训练(也就是求解器很难去利用多层网络拟合同等函数(再简单一点,课程太多,学的有点崩溃))</font>\n</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"3-如何解决所谓的退化问题\"><a href=\"#3-如何解决所谓的退化问题\" class=\"headerlink\" title=\"3.如何解决所谓的退化问题?\"></a>3.如何解决所谓的退化问题?</h3><p><strong> 1. 首先我们看作者怎么玩的?</strong><br>如图:<br><img src=\"https://blog.mviai.com/images\\回顾-Resnet\\res.png\" alt></p>\n<p><strong> 注 : 图太大,就保存在桌面缩小慢慢对比</strong></p>\n<hr>\n<p><strong> 1.1:我们继续看图说故事!</strong></p>\n<ul>\n<li>1.我们首先看vgg19和34层网络(图左和图中),作者跟大家一样想法,加深到34层,并且通过无数爬坑失败经验!进行改进了,如下:<ul>\n<li>图中与图左差别:<ul>\n<li>1.把每个maxpool(池化层)都改成了stride=2的卷积层做下采样(下采样就是缩小图片图片)</li>\n<li>2.去掉了最后那个耗费资源的全连接,用global average pool层替换</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<hr>\n<p>然后就遇到了退化问题……..<br>然后尝试了………………次</p>\n<hr>\n<p><strong> 终于在一次尝试中使用改进<a href=\"https://arxiv.org/pdf/1507.06228v2.pdf\" target=\"_blank\" rel=\"noopener\">Highway Network</a>带参数gate控制shortcut(就是图右的弯曲黑线,我叫它脑筋急转弯),以前我觉得是学LSTM(学这个最深感触,就是感觉在学电路分析)中也有一个forget gate来控制着流入下一阶段的信息量.</strong></p>\n<p>———所以知识都是互通的!</p>\n<ul>\n<li>1,怎么改进呢?<ul>\n<li>上面是Highway Network(公路网络),不是还有更快的高速公路吗,就改成高速公路(刚才说的图右的弯曲黑线),什么是高速公路(官方叫恒等式变化),即简单,直接</li>\n</ul>\n</li>\n</ul>\n<hr>\n<p><strong>下面我们来看看这所谓高速路是不是水泥构造:<br>如图:</strong><br><img src=\"https://blog.mviai.com/images\\回顾-Resnet\\c.png\" alt></p>\n<hr>\n<ul>\n<li>从这个图,我们能看出什么呢?<ul>\n<li>假设直下来表示很努力很努力的同学,弯弯曲曲的代表喜欢耍的同学!<br>x代表刚入学,大家都一样,最下面(F(x)+x)代表清华北大哈!<font color=\"red\"> </font></li>\n</ul>\n</li>\n<li>现在,我要喜欢耍的同学考入清华北大!<ul>\n<li>怎么做呢?<ul>\n<li>清华北大=F(x)+x,我是x!<br>我是不是只要学习我没有的F(x)呢, F(x)怎么来呢?<ul>\n<li>F(x)=清华北大-x,这就是残差,<br>所以我们不用想怎么考清华北大,而是想考清华北大同学有啥优点!,学习其优点,就可以无限接近清华北大!</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<hr>\n<p><strong> 注: 后面三层残差,这个函数变成清华北大=F(x)+wx,多了个w,W是卷积操作，用来调整x的channel维度的。<br>意思喊你不要一下啥都学,适合自己才是最好的!</strong></p>\n<hr>\n<h1 id=\"3-Resnet创新点\"><a href=\"#3-Resnet创新点\" class=\"headerlink\" title=\"3.Resnet创新点:\"></a>3.Resnet创新点:</h1><ul>\n<li>1.shortcut连接的方式使用恒等映射，如果residual block的输入输出维度不一致，对增加的维度用0来填充(使用0填充时，可以保证模型的复杂度最低，这对于更深的网络是更加有利的)；</li>\n<li>2.shortcut连接的方式维度一致时使用恒等映射,不一致时使用线性投影以保证维度一致</li>\n<li>3.ResNets并不能更好的表征某一方面的特征，但是ResNets允许逐层深入地表征更多的模型。(可看经典的残差网络变体)</li>\n<li>4.残差网络使得前馈式/反向传播算法非常顺利进行，在极大程度上，残差网络使得优化较深层模型更为简单 </li>\n<li>5.“shortcut”快捷连接添加既不产生额外的参数，也不会增加计算的复杂度。</li>\n<li>6.快捷连接简单的执行身份映射，并将它们的输出添加到叠加层的输出。通过反向传播的SGD，整个网络仍然可以被训练成终端到端的形式。</li>\n</ul>\n<hr>\n<p><strong><em> 更多信息,可以看原文( 标题1处的链接 ) </em></strong></p>\n<hr>\n<h1 id=\"4-PyTorch实现\"><a href=\"#4-PyTorch实现\" class=\"headerlink\" title=\"4.PyTorch实现:\"></a>4.PyTorch实现:</h1><p><strong> 为了简化,采用resnet32网络!</strong><br>如图:<br><img src=\"https://blog.mviai.com/images/回顾-Resnet/r.png\" alt><br><img src=\"https://blog.mviai.com/images/回顾-Resnet/b.png\" alt></p>\n<ul>\n<li><p>网络架构:Resnet.py文件:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">今天在vgg基础上再优雅点</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"comment\">#遵从原来步骤</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Resnet</span><span class=\"params\">(torch.nn.Module)</span>:</span></span><br><span class=\"line\">\t<span class=\"comment\">#初始化</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">\t\tsuper(Resnet, self).__init__()</span><br><span class=\"line\">\t\t<span class=\"comment\"># self.Sumlayers=self.make_layers()#这里我们交由make_layers函数创建相似的模块</span></span><br><span class=\"line\">\t\t<span class=\"comment\"># #假设我们上面已经创好五个模块(文章第一幅图block1-&gt;block5)</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t\t<span class=\"comment\">#现在最顶端的不同层,看文章34层那个最上面橘色简化图的7*7</span></span><br><span class=\"line\">\t\tself.top=torch.nn.Sequential(</span><br><span class=\"line\">\t\t\ttorch.nn.Conv2d(<span class=\"number\">3</span>,<span class=\"number\">64</span>,<span class=\"number\">7</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>),</span><br><span class=\"line\">\t\t\ttorch.nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">\t\t\ttorch.nn.ReLU (inplace=<span class=\"literal\">True</span>),</span><br><span class=\"line\">\t\t\ttorch.nn.MaxPool2d(<span class=\"number\">3</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>))<span class=\"comment\">#最顶部构建完成</span></span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\">#中间重复太多,交给make_layers函数创建相似的模块</span></span><br><span class=\"line\">\t\t<span class=\"comment\">#第三个参数来表示有多少个捷径(高速公路)</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\">#先来一打紫色的(文中图)</span></span><br><span class=\"line\">\t\tself.layer1 = self.make_layer (<span class=\"number\">64</span>,<span class=\"number\">64</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">\t\t<span class=\"comment\"># 再来一打绿色的(文中图)</span></span><br><span class=\"line\">\t\tself.layer2 = self.make_layer (<span class=\"number\">64</span>, <span class=\"number\">128</span>, <span class=\"number\">4</span>,stride=<span class=\"number\">2</span>)<span class=\"comment\">#图中第一个有/2</span></span><br><span class=\"line\">\t\t<span class=\"comment\"># 再来一打橘色的(文中图)</span></span><br><span class=\"line\">\t\tself.layer3 = self.make_layer ( <span class=\"number\">128</span>,<span class=\"number\">256</span>, <span class=\"number\">6</span>,stride=<span class=\"number\">2</span>)<span class=\"comment\">#图中第一个有/2</span></span><br><span class=\"line\">\t\t<span class=\"comment\"># 再来一打银色的(文中图)</span></span><br><span class=\"line\">\t\tself.layer4= self.make_layer (<span class=\"number\">256</span>, <span class=\"number\">512</span>, <span class=\"number\">3</span>, stride=<span class=\"number\">2</span>)  <span class=\"comment\"># 图中第一个有/2</span></span><br><span class=\"line\">\t\t<span class=\"comment\">#中间重复的构造完了</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\">#开始最后的了</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\tself.avgPool =torch.nn.AvgPool2d(<span class=\"number\">7</span>)<span class=\"comment\">#全局平均化</span></span><br><span class=\"line\">\t\tself.fc = torch.nn.Linear (<span class=\"number\">512</span>, <span class=\"number\">2</span>)<span class=\"comment\">#最后分成猫狗两类</span></span><br><span class=\"line\">\t\tself.last=torch.nn.Softmax (dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t<span class=\"comment\">#前向传播</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span> <span class=\"params\">(self, x)</span>:</span></span><br><span class=\"line\">\t\tx = self.top (x)</span><br><span class=\"line\">\t\tx = self.layer1 (x)</span><br><span class=\"line\">\t\tx = self.layer2 (x)</span><br><span class=\"line\">\t\tx = self.layer3 (x)</span><br><span class=\"line\">\t\tx = self.layer4 (x)</span><br><span class=\"line\">\t\tx = self.avgPool(x)</span><br><span class=\"line\">\t\tres = x.view (x.size (<span class=\"number\">0</span>), <span class=\"number\">-1</span>)  <span class=\"comment\"># 展平多维的卷积图成 一维</span></span><br><span class=\"line\">\t\tout = self.fc(res)</span><br><span class=\"line\">\t\tout = self.last(out)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> out</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">#构建刚才的构建模块函数make_layers</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">make_layer</span><span class=\"params\">(self,in_c,out_c,n_block,stride=<span class=\"number\">1</span>)</span>:</span></span><br><span class=\"line\"></span><br><span class=\"line\">\t\t<span class=\"comment\">#创建一个列表,用来放后面层 ,后面我们直接往里面添加就可以了</span></span><br><span class=\"line\">\t\tSumlayers=[]</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\">#构建捷径(高速公路)</span></span><br><span class=\"line\">\t\tshortcut=torch.nn.Sequential(</span><br><span class=\"line\">\t\t\ttorch.nn.Conv2d(in_c,out_c,<span class=\"number\">1</span>,stride),<span class=\"comment\">#1*1卷积</span></span><br><span class=\"line\">\t\t\ttorch.nn.BatchNorm2d(out_c),</span><br><span class=\"line\">\t\t)</span><br><span class=\"line\">\t\t<span class=\"comment\">#构建完成残差</span></span><br><span class=\"line\">\t\tSumlayers.append(ResBlock(in_c,out_c,stride,shortcut))</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t<span class=\"comment\">#构建右边的公路</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>,n_block):</span><br><span class=\"line\">\t\t\tSumlayers.append (ResBlock (out_c, out_c))<span class=\"comment\">#注意输入,输出应该一样</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> torch.nn.Sequential (*Sumlayers) <span class=\"comment\">#然后把构建好模型传出</span></span><br><span class=\"line\">\t</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#构建残差块 因为参数是变动的,所以引入变量,最后一个变量表示快捷通道个数,默认没有</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ResBlock</span><span class=\"params\">(torch.nn.Module)</span>:</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self,in_c,out_c,stride=<span class=\"number\">1</span>,shortcut=None)</span>:</span></span><br><span class=\"line\">\t\tsuper(ResBlock, self).__init__()</span><br><span class=\"line\">\t\t<span class=\"comment\">#左边的公路</span></span><br><span class=\"line\">\t\tself.left=torch.nn.Sequential(</span><br><span class=\"line\">\t\t\ttorch.nn.Conv2d (in_c,out_c,<span class=\"number\">3</span>,stride,<span class=\"number\">1</span>),</span><br><span class=\"line\">\t\t\ttorch.nn.BatchNorm2d (out_c),</span><br><span class=\"line\">\t\t\ttorch.nn.ReLU (inplace=<span class=\"literal\">True</span>),</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\ttorch.nn.Conv2d (out_c,out_c,<span class=\"number\">3</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>),<span class=\"comment\">#注意 这里输入输出应该一样</span></span><br><span class=\"line\">\t\t\ttorch.nn.BatchNorm2d (out_c)</span><br><span class=\"line\">\t\t)</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t<span class=\"comment\">#右边的高速公路</span></span><br><span class=\"line\">\t\tself.right=shortcut</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t<span class=\"comment\">#最后</span></span><br><span class=\"line\">\t\tself.last_y=torch.nn.ReLU()</span><br><span class=\"line\">\t<span class=\"comment\">#前向</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></span><br><span class=\"line\">\t\ty_l=self.left(x)</span><br><span class=\"line\">\t\ty_r = x <span class=\"keyword\">if</span> self.right <span class=\"keyword\">is</span> <span class=\"literal\">None</span> <span class=\"keyword\">else</span> self.right (x) <span class=\"comment\">#如果有高数路为空,就直接保存在res中,否则执行高速路保存在res</span></span><br><span class=\"line\">\t\tsum_x=y_l+y_r <span class=\"comment\">#两个总和</span></span><br><span class=\"line\">\t\tout=self.last_y(sum_x)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> out</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>网络架构:Train.py文件:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision.datasets <span class=\"keyword\">as</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision.transforms <span class=\"keyword\">as</span>  transforms</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 工具包</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> argparse</span><br><span class=\"line\"><span class=\"comment\"># 载入网络</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> Resnet <span class=\"keyword\">import</span> Resnet</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############参数设置#############</span></span><br><span class=\"line\"><span class=\"comment\">####命令行设置########</span></span><br><span class=\"line\">parser = argparse.ArgumentParser (description=<span class=\"string\">'CNN'</span>)  <span class=\"comment\"># 导入命令行模块</span></span><br><span class=\"line\"><span class=\"comment\"># 对于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--batch-size'</span>, type=int, default=<span class=\"number\">2</span>, metavar=<span class=\"string\">'N'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'训练batch-size大小 (default: 2)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--epochs'</span>, type=int, default=<span class=\"number\">10</span>, metavar=<span class=\"string\">'N'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'训练epochs大小 (default: 10)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--lr'</span>, type=float, default=<span class=\"number\">0.001</span>, metavar=<span class=\"string\">'LR'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'学习率 (default: 0.001)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--no-cuda'</span>, action=<span class=\"string\">'store_true'</span>, default=<span class=\"literal\">False</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'不开启cuda训练'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--seed'</span>, type=int, default=<span class=\"number\">1</span>, metavar=<span class=\"string\">'S'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'随机种子 (default: 1)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--log-interval'</span>, type=int, default=<span class=\"number\">1</span>, metavar=<span class=\"string\">'N'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'记录等待n批次 (default: 1)'</span>)</span><br><span class=\"line\">args = parser.parse_args ()  <span class=\"comment\"># 相当于激活命令</span></span><br><span class=\"line\"></span><br><span class=\"line\">args.cuda = <span class=\"keyword\">not</span> args.no_cuda <span class=\"keyword\">and</span> torch.cuda.is_available ()  <span class=\"comment\"># 判断gpu</span></span><br><span class=\"line\"></span><br><span class=\"line\">torch.manual_seed (args.seed)</span><br><span class=\"line\"><span class=\"keyword\">if</span> args.cuda:</span><br><span class=\"line\">\ttorch.cuda.manual_seed (args.seed)  <span class=\"comment\"># 为CPU设置种子用于生成随机数，以使得结果是确定的</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##########数据转换#####################</span></span><br><span class=\"line\">data_transforms = transforms.Compose ([transforms.Scale (<span class=\"number\">224</span>),  <span class=\"comment\"># 通过调整比例调整大小,会报警</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t   transforms.CenterCrop (<span class=\"number\">224</span>),  <span class=\"comment\"># 在中心裁剪给指定大小方形PIL图像</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t   transforms.ToTensor ()])  <span class=\"comment\"># 转换成pytorch 变量tensor</span></span><br><span class=\"line\"><span class=\"comment\">###############数据载入################</span></span><br><span class=\"line\">train_dataset = datasets.ImageFolder (root=<span class=\"string\">\"./data/train/\"</span>,  <span class=\"comment\"># 保存目录</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t  transform=data_transforms)  <span class=\"comment\"># 把数据转换成上面约束样子</span></span><br><span class=\"line\"></span><br><span class=\"line\">test_dataset = datasets.ImageFolder (root=<span class=\"string\">'./data/test/'</span>,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t transform=data_transforms)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##########数据如下####</span></span><br><span class=\"line\"><span class=\"comment\"># # root/dog/xxx.png</span></span><br><span class=\"line\"><span class=\"comment\"># # root/dog/xxy.png</span></span><br><span class=\"line\"><span class=\"comment\"># # root/dog/xxz.png</span></span><br><span class=\"line\"><span class=\"comment\"># #</span></span><br><span class=\"line\"><span class=\"comment\"># # root/cat/123.png</span></span><br><span class=\"line\"><span class=\"comment\"># # root/cat/nsdf3.png</span></span><br><span class=\"line\"><span class=\"comment\"># # root/cat/asd932_.png</span></span><br><span class=\"line\"><span class=\"comment\">######################</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##############数据装载###############</span></span><br><span class=\"line\">train_loader = torch.utils.data.DataLoader (dataset=train_dataset,  <span class=\"comment\"># 装载数据</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\tbatch_size=args.batch_size,  <span class=\"comment\"># 设置批大小</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\tshuffle=<span class=\"literal\">True</span>)  <span class=\"comment\"># 是否随机打乱</span></span><br><span class=\"line\">test_loader = torch.utils.data.DataLoader (dataset=test_dataset,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   batch_size=args.batch_size,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   shuffle=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############模型载入#################</span></span><br><span class=\"line\">Resnet=Resnet ()</span><br><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"keyword\">not</span> args.no_cuda:</span><br><span class=\"line\">\t<span class=\"keyword\">print</span> (<span class=\"string\">'正在使用gpu'</span>)</span><br><span class=\"line\">\tResnet.cuda ()</span><br><span class=\"line\"><span class=\"keyword\">print</span> (Resnet)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###############损失函数##################</span></span><br><span class=\"line\">criterion = nn.CrossEntropyLoss ()  <span class=\"comment\"># 内置标准损失</span></span><br><span class=\"line\">optimizer = torch.optim.Adam (Resnet.parameters (), lr=args.lr)  <span class=\"comment\"># Adam优化器</span></span><br><span class=\"line\"><span class=\"comment\">#############训练过程#####################</span></span><br><span class=\"line\">total_loss = <span class=\"number\">0</span> <span class=\"comment\">#内存循环使用</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range (args.epochs):</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i, (images, labels) <span class=\"keyword\">in</span> enumerate (train_loader):  <span class=\"comment\"># 枚举出来</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> <span class=\"keyword\">not</span> args.no_cuda:  <span class=\"comment\"># 数据处理是否用gpu</span></span><br><span class=\"line\">\t\t\timages = images.cuda ()</span><br><span class=\"line\">\t\t\tlabels = labels.cuda ()</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\timages = Variable (images)  <span class=\"comment\"># 装箱</span></span><br><span class=\"line\">\t\tlabels = Variable (labels)</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\">##前向传播</span></span><br><span class=\"line\">\t\toptimizer.zero_grad ()</span><br><span class=\"line\">\t\toutputs = Resnet (images)</span><br><span class=\"line\">\t\t<span class=\"comment\"># 损失</span></span><br><span class=\"line\">\t\tloss = criterion (outputs, labels)</span><br><span class=\"line\">\t\t<span class=\"comment\"># 反向传播</span></span><br><span class=\"line\">\t\tloss.backward ()</span><br><span class=\"line\">\t\toptimizer.step ()<span class=\"comment\">#更新参数</span></span><br><span class=\"line\">\t\ttotal_loss += loss<span class=\"comment\">#内存循环使用 防止cuda超出内存</span></span><br><span class=\"line\">\t\t<span class=\"comment\">##打印记录</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (i + <span class=\"number\">1</span>) % args.log_interval == <span class=\"number\">0</span>:</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">print</span> (<span class=\"string\">'Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'</span></span><br><span class=\"line\">\t\t\t\t   % (epoch + <span class=\"number\">1</span>, args.epochs, i + <span class=\"number\">1</span>, len (train_dataset) // args.batch_size, loss.item ()))</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 保存模型</span></span><br><span class=\"line\">\t\ttorch.save (Resnet.state_dict (), <span class=\"string\">'Resnet.pkl'</span>)</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>结果:<br><img src=\"https://blog.mviai.com/images/回顾-Resnet/ret.png\" alt></p>\n<ul>\n<li>注意残差的前向传播 ,一不小心都不知道自己哪里错了!!</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"1-Resnet-简介\"><a href=\"#1-Resnet-简介\" class=\"headerlink\" title=\"1.Resnet 简介:\"></a>1.Resnet 简介:</h1><p>MSRA（微软亚洲研究院）何凯明团队的深度残差网络（<a href=\"http://arxiv.org/pdf/1512.03385.pdf\" target=\"_blank\" rel=\"noopener\">Deep Residual Network</a>）在2015年的ImageNet上取得冠军，该网络简称为ResNet（由算法Residual命名），</p>\n<p>层数达到了152层，top-5错误率降到了3.57，而2014年冠军GoogLeNet的错误率是6.7。ResNet取得了5项第一，并又一次刷新了CNN模型在ImageNet上的历史!</p>\n<hr>\n<h1 id=\"2-Resnet-网络结构\"><a href=\"#2-Resnet-网络结构\" class=\"headerlink\" title=\"2. Resnet 网络结构:\"></a>2. Resnet 网络结构:</h1><p><strong> 1.昨天我们看了vgg,深刻的感觉到了加深网络所带来的好处,即:</strong></p>\n<ul>\n<li><font color=\"red\"> 1.从我写的cnn一层→→Alexnet 的八层→→vgg16的十六层,可以看出层数越深,获取的特征越丰富,拟合能力越强<br></font>\n\n</li>\n</ul>\n<p><strong> 2.当然肯定想说,想通过VGG堆叠那样无限制加深网络,来加强拟合能力! 当然你会遇到以下问题</strong></p>\n<ul>\n<li>1.对于原来的网络，如果简单地增加深度，会导致梯度弥散或梯度爆炸(注:就是前向传的过去,反向传不回来(想成小时候传话游戏,传着传着就变味了)).<ul>\n<li><font color=\"red\"> 遇到这个问题,其实可以正则化初始化和加入正则化层（Batch Normalization）或中间层添加辅助损失（auxiliary loss）作为额外的监督。,这样训练几十层应该没问题!</font></li>\n</ul>\n</li>\n<li>2.上面加深,没啥问题,但是在更深的网络有更高的训练误差和测试误差,即退化问题?<br>(你肯定想问,我不是刚说越深越强吗?现在怎么又不行了?<br>(回答这个,最简单就是名字,退化嘛,就像无限逼近定理一样,理想很丰满,现实很骨感))<ul>\n<li><font color=\"red\"> 退化问题,推断能是因为深层的网络并不是那么好训练(也就是求解器很难去利用多层网络拟合同等函数(再简单一点,课程太多,学的有点崩溃))</font>\n</li>\n</ul>\n</li>\n</ul>\n<hr>\n<h3 id=\"3-如何解决所谓的退化问题\"><a href=\"#3-如何解决所谓的退化问题\" class=\"headerlink\" title=\"3.如何解决所谓的退化问题?\"></a>3.如何解决所谓的退化问题?</h3><p><strong> 1. 首先我们看作者怎么玩的?</strong><br>如图:<br><img src=\"https://blog.mviai.com/images\\回顾-Resnet\\res.png\" alt></p>\n<p><strong> 注 : 图太大,就保存在桌面缩小慢慢对比</strong></p>\n<hr>\n<p><strong> 1.1:我们继续看图说故事!</strong></p>\n<ul>\n<li>1.我们首先看vgg19和34层网络(图左和图中),作者跟大家一样想法,加深到34层,并且通过无数爬坑失败经验!进行改进了,如下:<ul>\n<li>图中与图左差别:<ul>\n<li>1.把每个maxpool(池化层)都改成了stride=2的卷积层做下采样(下采样就是缩小图片图片)</li>\n<li>2.去掉了最后那个耗费资源的全连接,用global average pool层替换</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<hr>\n<p>然后就遇到了退化问题……..<br>然后尝试了………………次</p>\n<hr>\n<p><strong> 终于在一次尝试中使用改进<a href=\"https://arxiv.org/pdf/1507.06228v2.pdf\" target=\"_blank\" rel=\"noopener\">Highway Network</a>带参数gate控制shortcut(就是图右的弯曲黑线,我叫它脑筋急转弯),以前我觉得是学LSTM(学这个最深感触,就是感觉在学电路分析)中也有一个forget gate来控制着流入下一阶段的信息量.</strong></p>\n<p>———所以知识都是互通的!</p>\n<ul>\n<li>1,怎么改进呢?<ul>\n<li>上面是Highway Network(公路网络),不是还有更快的高速公路吗,就改成高速公路(刚才说的图右的弯曲黑线),什么是高速公路(官方叫恒等式变化),即简单,直接</li>\n</ul>\n</li>\n</ul>\n<hr>\n<p><strong>下面我们来看看这所谓高速路是不是水泥构造:<br>如图:</strong><br><img src=\"https://blog.mviai.com/images\\回顾-Resnet\\c.png\" alt></p>\n<hr>\n<ul>\n<li>从这个图,我们能看出什么呢?<ul>\n<li>假设直下来表示很努力很努力的同学,弯弯曲曲的代表喜欢耍的同学!<br>x代表刚入学,大家都一样,最下面(F(x)+x)代表清华北大哈!<font color=\"red\"> </font></li>\n</ul>\n</li>\n<li>现在,我要喜欢耍的同学考入清华北大!<ul>\n<li>怎么做呢?<ul>\n<li>清华北大=F(x)+x,我是x!<br>我是不是只要学习我没有的F(x)呢, F(x)怎么来呢?<ul>\n<li>F(x)=清华北大-x,这就是残差,<br>所以我们不用想怎么考清华北大,而是想考清华北大同学有啥优点!,学习其优点,就可以无限接近清华北大!</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<hr>\n<p><strong> 注: 后面三层残差,这个函数变成清华北大=F(x)+wx,多了个w,W是卷积操作，用来调整x的channel维度的。<br>意思喊你不要一下啥都学,适合自己才是最好的!</strong></p>\n<hr>\n<h1 id=\"3-Resnet创新点\"><a href=\"#3-Resnet创新点\" class=\"headerlink\" title=\"3.Resnet创新点:\"></a>3.Resnet创新点:</h1><ul>\n<li>1.shortcut连接的方式使用恒等映射，如果residual block的输入输出维度不一致，对增加的维度用0来填充(使用0填充时，可以保证模型的复杂度最低，这对于更深的网络是更加有利的)；</li>\n<li>2.shortcut连接的方式维度一致时使用恒等映射,不一致时使用线性投影以保证维度一致</li>\n<li>3.ResNets并不能更好的表征某一方面的特征，但是ResNets允许逐层深入地表征更多的模型。(可看经典的残差网络变体)</li>\n<li>4.残差网络使得前馈式/反向传播算法非常顺利进行，在极大程度上，残差网络使得优化较深层模型更为简单 </li>\n<li>5.“shortcut”快捷连接添加既不产生额外的参数，也不会增加计算的复杂度。</li>\n<li>6.快捷连接简单的执行身份映射，并将它们的输出添加到叠加层的输出。通过反向传播的SGD，整个网络仍然可以被训练成终端到端的形式。</li>\n</ul>\n<hr>\n<p><strong><em> 更多信息,可以看原文( 标题1处的链接 ) </em></strong></p>\n<hr>\n<h1 id=\"4-PyTorch实现\"><a href=\"#4-PyTorch实现\" class=\"headerlink\" title=\"4.PyTorch实现:\"></a>4.PyTorch实现:</h1><p><strong> 为了简化,采用resnet32网络!</strong><br>如图:<br><img src=\"https://blog.mviai.com/images/回顾-Resnet/r.png\" alt><br><img src=\"https://blog.mviai.com/images/回顾-Resnet/b.png\" alt></p>\n<ul>\n<li><p>网络架构:Resnet.py文件:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br><span class=\"line\">103</span><br><span class=\"line\">104</span><br><span class=\"line\">105</span><br><span class=\"line\">106</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">今天在vgg基础上再优雅点</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"comment\">#遵从原来步骤</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Resnet</span><span class=\"params\">(torch.nn.Module)</span>:</span></span><br><span class=\"line\">\t<span class=\"comment\">#初始化</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">\t\tsuper(Resnet, self).__init__()</span><br><span class=\"line\">\t\t<span class=\"comment\"># self.Sumlayers=self.make_layers()#这里我们交由make_layers函数创建相似的模块</span></span><br><span class=\"line\">\t\t<span class=\"comment\"># #假设我们上面已经创好五个模块(文章第一幅图block1-&gt;block5)</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t\t<span class=\"comment\">#现在最顶端的不同层,看文章34层那个最上面橘色简化图的7*7</span></span><br><span class=\"line\">\t\tself.top=torch.nn.Sequential(</span><br><span class=\"line\">\t\t\ttorch.nn.Conv2d(<span class=\"number\">3</span>,<span class=\"number\">64</span>,<span class=\"number\">7</span>,<span class=\"number\">2</span>,<span class=\"number\">3</span>),</span><br><span class=\"line\">\t\t\ttorch.nn.BatchNorm2d(<span class=\"number\">64</span>),</span><br><span class=\"line\">\t\t\ttorch.nn.ReLU (inplace=<span class=\"literal\">True</span>),</span><br><span class=\"line\">\t\t\ttorch.nn.MaxPool2d(<span class=\"number\">3</span>,<span class=\"number\">2</span>,<span class=\"number\">1</span>))<span class=\"comment\">#最顶部构建完成</span></span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\">#中间重复太多,交给make_layers函数创建相似的模块</span></span><br><span class=\"line\">\t\t<span class=\"comment\">#第三个参数来表示有多少个捷径(高速公路)</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\">#先来一打紫色的(文中图)</span></span><br><span class=\"line\">\t\tself.layer1 = self.make_layer (<span class=\"number\">64</span>,<span class=\"number\">64</span>,<span class=\"number\">3</span>)</span><br><span class=\"line\">\t\t<span class=\"comment\"># 再来一打绿色的(文中图)</span></span><br><span class=\"line\">\t\tself.layer2 = self.make_layer (<span class=\"number\">64</span>, <span class=\"number\">128</span>, <span class=\"number\">4</span>,stride=<span class=\"number\">2</span>)<span class=\"comment\">#图中第一个有/2</span></span><br><span class=\"line\">\t\t<span class=\"comment\"># 再来一打橘色的(文中图)</span></span><br><span class=\"line\">\t\tself.layer3 = self.make_layer ( <span class=\"number\">128</span>,<span class=\"number\">256</span>, <span class=\"number\">6</span>,stride=<span class=\"number\">2</span>)<span class=\"comment\">#图中第一个有/2</span></span><br><span class=\"line\">\t\t<span class=\"comment\"># 再来一打银色的(文中图)</span></span><br><span class=\"line\">\t\tself.layer4= self.make_layer (<span class=\"number\">256</span>, <span class=\"number\">512</span>, <span class=\"number\">3</span>, stride=<span class=\"number\">2</span>)  <span class=\"comment\"># 图中第一个有/2</span></span><br><span class=\"line\">\t\t<span class=\"comment\">#中间重复的构造完了</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\">#开始最后的了</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\tself.avgPool =torch.nn.AvgPool2d(<span class=\"number\">7</span>)<span class=\"comment\">#全局平均化</span></span><br><span class=\"line\">\t\tself.fc = torch.nn.Linear (<span class=\"number\">512</span>, <span class=\"number\">2</span>)<span class=\"comment\">#最后分成猫狗两类</span></span><br><span class=\"line\">\t\tself.last=torch.nn.Softmax (dim=<span class=\"number\">1</span>)</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t<span class=\"comment\">#前向传播</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span> <span class=\"params\">(self, x)</span>:</span></span><br><span class=\"line\">\t\tx = self.top (x)</span><br><span class=\"line\">\t\tx = self.layer1 (x)</span><br><span class=\"line\">\t\tx = self.layer2 (x)</span><br><span class=\"line\">\t\tx = self.layer3 (x)</span><br><span class=\"line\">\t\tx = self.layer4 (x)</span><br><span class=\"line\">\t\tx = self.avgPool(x)</span><br><span class=\"line\">\t\tres = x.view (x.size (<span class=\"number\">0</span>), <span class=\"number\">-1</span>)  <span class=\"comment\"># 展平多维的卷积图成 一维</span></span><br><span class=\"line\">\t\tout = self.fc(res)</span><br><span class=\"line\">\t\tout = self.last(out)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> out</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">#构建刚才的构建模块函数make_layers</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">make_layer</span><span class=\"params\">(self,in_c,out_c,n_block,stride=<span class=\"number\">1</span>)</span>:</span></span><br><span class=\"line\"></span><br><span class=\"line\">\t\t<span class=\"comment\">#创建一个列表,用来放后面层 ,后面我们直接往里面添加就可以了</span></span><br><span class=\"line\">\t\tSumlayers=[]</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\">#构建捷径(高速公路)</span></span><br><span class=\"line\">\t\tshortcut=torch.nn.Sequential(</span><br><span class=\"line\">\t\t\ttorch.nn.Conv2d(in_c,out_c,<span class=\"number\">1</span>,stride),<span class=\"comment\">#1*1卷积</span></span><br><span class=\"line\">\t\t\ttorch.nn.BatchNorm2d(out_c),</span><br><span class=\"line\">\t\t)</span><br><span class=\"line\">\t\t<span class=\"comment\">#构建完成残差</span></span><br><span class=\"line\">\t\tSumlayers.append(ResBlock(in_c,out_c,stride,shortcut))</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t<span class=\"comment\">#构建右边的公路</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>,n_block):</span><br><span class=\"line\">\t\t\tSumlayers.append (ResBlock (out_c, out_c))<span class=\"comment\">#注意输入,输出应该一样</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> torch.nn.Sequential (*Sumlayers) <span class=\"comment\">#然后把构建好模型传出</span></span><br><span class=\"line\">\t</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#构建残差块 因为参数是变动的,所以引入变量,最后一个变量表示快捷通道个数,默认没有</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ResBlock</span><span class=\"params\">(torch.nn.Module)</span>:</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self,in_c,out_c,stride=<span class=\"number\">1</span>,shortcut=None)</span>:</span></span><br><span class=\"line\">\t\tsuper(ResBlock, self).__init__()</span><br><span class=\"line\">\t\t<span class=\"comment\">#左边的公路</span></span><br><span class=\"line\">\t\tself.left=torch.nn.Sequential(</span><br><span class=\"line\">\t\t\ttorch.nn.Conv2d (in_c,out_c,<span class=\"number\">3</span>,stride,<span class=\"number\">1</span>),</span><br><span class=\"line\">\t\t\ttorch.nn.BatchNorm2d (out_c),</span><br><span class=\"line\">\t\t\ttorch.nn.ReLU (inplace=<span class=\"literal\">True</span>),</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t\ttorch.nn.Conv2d (out_c,out_c,<span class=\"number\">3</span>,<span class=\"number\">1</span>,<span class=\"number\">1</span>),<span class=\"comment\">#注意 这里输入输出应该一样</span></span><br><span class=\"line\">\t\t\ttorch.nn.BatchNorm2d (out_c)</span><br><span class=\"line\">\t\t)</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t<span class=\"comment\">#右边的高速公路</span></span><br><span class=\"line\">\t\tself.right=shortcut</span><br><span class=\"line\"></span><br><span class=\"line\">\t\t<span class=\"comment\">#最后</span></span><br><span class=\"line\">\t\tself.last_y=torch.nn.ReLU()</span><br><span class=\"line\">\t<span class=\"comment\">#前向</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span><span class=\"params\">(self, x)</span>:</span></span><br><span class=\"line\">\t\ty_l=self.left(x)</span><br><span class=\"line\">\t\ty_r = x <span class=\"keyword\">if</span> self.right <span class=\"keyword\">is</span> <span class=\"literal\">None</span> <span class=\"keyword\">else</span> self.right (x) <span class=\"comment\">#如果有高数路为空,就直接保存在res中,否则执行高速路保存在res</span></span><br><span class=\"line\">\t\tsum_x=y_l+y_r <span class=\"comment\">#两个总和</span></span><br><span class=\"line\">\t\tout=self.last_y(sum_x)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> out</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>网络架构:Train.py文件:</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision.datasets <span class=\"keyword\">as</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision.transforms <span class=\"keyword\">as</span>  transforms</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 工具包</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> argparse</span><br><span class=\"line\"><span class=\"comment\"># 载入网络</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> Resnet <span class=\"keyword\">import</span> Resnet</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############参数设置#############</span></span><br><span class=\"line\"><span class=\"comment\">####命令行设置########</span></span><br><span class=\"line\">parser = argparse.ArgumentParser (description=<span class=\"string\">'CNN'</span>)  <span class=\"comment\"># 导入命令行模块</span></span><br><span class=\"line\"><span class=\"comment\"># 对于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--batch-size'</span>, type=int, default=<span class=\"number\">2</span>, metavar=<span class=\"string\">'N'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'训练batch-size大小 (default: 2)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--epochs'</span>, type=int, default=<span class=\"number\">10</span>, metavar=<span class=\"string\">'N'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'训练epochs大小 (default: 10)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--lr'</span>, type=float, default=<span class=\"number\">0.001</span>, metavar=<span class=\"string\">'LR'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'学习率 (default: 0.001)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--no-cuda'</span>, action=<span class=\"string\">'store_true'</span>, default=<span class=\"literal\">False</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'不开启cuda训练'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--seed'</span>, type=int, default=<span class=\"number\">1</span>, metavar=<span class=\"string\">'S'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'随机种子 (default: 1)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--log-interval'</span>, type=int, default=<span class=\"number\">1</span>, metavar=<span class=\"string\">'N'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'记录等待n批次 (default: 1)'</span>)</span><br><span class=\"line\">args = parser.parse_args ()  <span class=\"comment\"># 相当于激活命令</span></span><br><span class=\"line\"></span><br><span class=\"line\">args.cuda = <span class=\"keyword\">not</span> args.no_cuda <span class=\"keyword\">and</span> torch.cuda.is_available ()  <span class=\"comment\"># 判断gpu</span></span><br><span class=\"line\"></span><br><span class=\"line\">torch.manual_seed (args.seed)</span><br><span class=\"line\"><span class=\"keyword\">if</span> args.cuda:</span><br><span class=\"line\">\ttorch.cuda.manual_seed (args.seed)  <span class=\"comment\"># 为CPU设置种子用于生成随机数，以使得结果是确定的</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##########数据转换#####################</span></span><br><span class=\"line\">data_transforms = transforms.Compose ([transforms.Scale (<span class=\"number\">224</span>),  <span class=\"comment\"># 通过调整比例调整大小,会报警</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t   transforms.CenterCrop (<span class=\"number\">224</span>),  <span class=\"comment\"># 在中心裁剪给指定大小方形PIL图像</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t   transforms.ToTensor ()])  <span class=\"comment\"># 转换成pytorch 变量tensor</span></span><br><span class=\"line\"><span class=\"comment\">###############数据载入################</span></span><br><span class=\"line\">train_dataset = datasets.ImageFolder (root=<span class=\"string\">\"./data/train/\"</span>,  <span class=\"comment\"># 保存目录</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t  transform=data_transforms)  <span class=\"comment\"># 把数据转换成上面约束样子</span></span><br><span class=\"line\"></span><br><span class=\"line\">test_dataset = datasets.ImageFolder (root=<span class=\"string\">'./data/test/'</span>,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t transform=data_transforms)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##########数据如下####</span></span><br><span class=\"line\"><span class=\"comment\"># # root/dog/xxx.png</span></span><br><span class=\"line\"><span class=\"comment\"># # root/dog/xxy.png</span></span><br><span class=\"line\"><span class=\"comment\"># # root/dog/xxz.png</span></span><br><span class=\"line\"><span class=\"comment\"># #</span></span><br><span class=\"line\"><span class=\"comment\"># # root/cat/123.png</span></span><br><span class=\"line\"><span class=\"comment\"># # root/cat/nsdf3.png</span></span><br><span class=\"line\"><span class=\"comment\"># # root/cat/asd932_.png</span></span><br><span class=\"line\"><span class=\"comment\">######################</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##############数据装载###############</span></span><br><span class=\"line\">train_loader = torch.utils.data.DataLoader (dataset=train_dataset,  <span class=\"comment\"># 装载数据</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\tbatch_size=args.batch_size,  <span class=\"comment\"># 设置批大小</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\tshuffle=<span class=\"literal\">True</span>)  <span class=\"comment\"># 是否随机打乱</span></span><br><span class=\"line\">test_loader = torch.utils.data.DataLoader (dataset=test_dataset,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   batch_size=args.batch_size,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   shuffle=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############模型载入#################</span></span><br><span class=\"line\">Resnet=Resnet ()</span><br><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"keyword\">not</span> args.no_cuda:</span><br><span class=\"line\">\t<span class=\"keyword\">print</span> (<span class=\"string\">'正在使用gpu'</span>)</span><br><span class=\"line\">\tResnet.cuda ()</span><br><span class=\"line\"><span class=\"keyword\">print</span> (Resnet)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###############损失函数##################</span></span><br><span class=\"line\">criterion = nn.CrossEntropyLoss ()  <span class=\"comment\"># 内置标准损失</span></span><br><span class=\"line\">optimizer = torch.optim.Adam (Resnet.parameters (), lr=args.lr)  <span class=\"comment\"># Adam优化器</span></span><br><span class=\"line\"><span class=\"comment\">#############训练过程#####################</span></span><br><span class=\"line\">total_loss = <span class=\"number\">0</span> <span class=\"comment\">#内存循环使用</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range (args.epochs):</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i, (images, labels) <span class=\"keyword\">in</span> enumerate (train_loader):  <span class=\"comment\"># 枚举出来</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> <span class=\"keyword\">not</span> args.no_cuda:  <span class=\"comment\"># 数据处理是否用gpu</span></span><br><span class=\"line\">\t\t\timages = images.cuda ()</span><br><span class=\"line\">\t\t\tlabels = labels.cuda ()</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\timages = Variable (images)  <span class=\"comment\"># 装箱</span></span><br><span class=\"line\">\t\tlabels = Variable (labels)</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\">##前向传播</span></span><br><span class=\"line\">\t\toptimizer.zero_grad ()</span><br><span class=\"line\">\t\toutputs = Resnet (images)</span><br><span class=\"line\">\t\t<span class=\"comment\"># 损失</span></span><br><span class=\"line\">\t\tloss = criterion (outputs, labels)</span><br><span class=\"line\">\t\t<span class=\"comment\"># 反向传播</span></span><br><span class=\"line\">\t\tloss.backward ()</span><br><span class=\"line\">\t\toptimizer.step ()<span class=\"comment\">#更新参数</span></span><br><span class=\"line\">\t\ttotal_loss += loss<span class=\"comment\">#内存循环使用 防止cuda超出内存</span></span><br><span class=\"line\">\t\t<span class=\"comment\">##打印记录</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (i + <span class=\"number\">1</span>) % args.log_interval == <span class=\"number\">0</span>:</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">print</span> (<span class=\"string\">'Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'</span></span><br><span class=\"line\">\t\t\t\t   % (epoch + <span class=\"number\">1</span>, args.epochs, i + <span class=\"number\">1</span>, len (train_dataset) // args.batch_size, loss.item ()))</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 保存模型</span></span><br><span class=\"line\">\t\ttorch.save (Resnet.state_dict (), <span class=\"string\">'Resnet.pkl'</span>)</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p>结果:<br><img src=\"https://blog.mviai.com/images/回顾-Resnet/ret.png\" alt></p>\n<ul>\n<li>注意残差的前向传播 ,一不小心都不知道自己哪里错了!!</li>\n</ul>\n"},{"title":"回顾-VGG","date":"2018-12-19T10:46:12.000Z","_content":"# 1. VGGNet 简介:\n1.VGG是由Simonyan 和Zisserman在文献《[Very Deep Convolutional Networks for Large Scale Image Recognition](https://arxiv.org/abs/1409.1556)》中提出卷积神经网络模型，其名称来源于作者所在的牛津大学视觉几何组(Visual Geometry Group)的缩写。\n\n2.该模型参加2014年的 ImageNet图像分类与定位挑战赛，取得了优异成绩：在分类任务上排名第二，在定位任务上排名第一。\n\n**************\n# 2. VGGNet 网络结构:\n根据VGG中根据<font color=red>卷积核大小和卷积层数目的不同,</font>分为A,A-LRN,B,C,D,E共6个网络结构配置!\n*********\nD,E就是常用配置,也就是常说的<font color=red>VGG16和VGG19</font>\n\n* 如图:\n ![](https://blog.mviai.com/images/回顾-VGG/table.png)\n \n ************\n ** 1.为什么叫vgg16? **\n 如图绿色(D配置),即VGG16配置,\n * 1.用conv3表示3\\*3卷积,conv3-xx中的xx表示通道数(也就是有多少个这样的卷积核)\n * 2.一共数下来 有13个conv3,3个FC(最下面那里),5个池化层(每个模块中间)\n * 3.13(卷积)+3(全连接)=16,不加池化层,是因为池化层不涉及权重.所以d配置叫VGG16,其他以此类推!\n ************\n* 官方图:\n  * 如图:\n  ![](https://blog.mviai.com/images/回顾-VGG/block.png)\n\n\n********\n* 这个图又看出什么?\n    * 1.每个卷积层(上面的conv3-xx)里面是表示conv+relu(图中黑色方块注释)\n    * 2.看到红色方块(池化层)没,是不是经过它,似乎方块都变小1/2了!\n        * 即池化层采用的参数均为2\\*2,步幅stride=2，max的池化方式，这样就能够使得每一个池化层的宽和高是前一层的1/2。\n*********\n\n* 输入图片大小变化图:\n![](https://blog.mviai.com/images/回顾-VGG/VGG16.png)\n\n*********\n* 这个图又看出什么?\n    * 1.图片从224\\*244大小→112\\*112→56\\*56→28\\*28→ 14\\*14→7\\*7大小(图最左边Size),大小一直减半\n    * 2.卷积通道数(卷积核数量)从64-->128-->256-->512,然后固定在512!   都是2倍数(因为计算机以2进制计算)----------------2是个好东西\n***********\n* 计算量图:\n ![](https://blog.mviai.com/images/回顾-VGG/c.png)\n** 注:memory=内存计算(红色),params=参数量计算(蓝色)**\n***********\n\n\n# 3.VGG优缺点:\n** 优点:**\n* 1.VGGNet的结构非常简洁，整个网络都使用了同样大小的卷积核尺寸（3x3）和最大池化尺寸（2x2）\n* 2.几个小滤波器（3x3）卷积层的组合比一个大滤波器（5x5或7x7）卷积层好\n* 3.通过不断加深网络结构可以提升性能.具有很高的拟合能力(怎么加深?(<font color=red>这个网络告诉我们就像汉堡一样一层层堆叠上去</font>))\n*************\n** 缺点:**\n* 1.训练时间过长(3个全连接啊(<font color=red>听说:发现这些全连接层即使被去除，对于性能也没有什么影响，这样就显著降低了参数数量</font>))，调参难度大\n* 2.需要的存储容量大，不利于部署。(单片机就那几MB可怜的空间)\n************\n\n# 4.PyTorch实现:\n* 网络架构:VGG.py文件:\n```python\nimport torch\n\n\n'''\n今天这个有点难得堆\n一个个写,重复性太高,而且不利于观看,不优雅\n重复性事我们交给你喊函数完成\n'''\n#遵从原来步骤\nclass VGG(torch.nn.Module):\n\t#初始化\n\tdef __init__(self):\n\t\tsuper(VGG, self).__init__()\n\t\tself.Sumlayers=self.make_layers()#这里我们交由make_layers函数创建相似的模块\n\t\t#假设我们上面已经创好五个模块(文章第一幅图block1->block5)\n\t\n\t\t#现在创建最后的Fc\n\t\tself.fc=torch.nn.Sequential(\n\t\t\ttorch.nn.Linear (7*7*512, 4096),  # 第一个全连接\n\t\t\ttorch.nn.ReLU(),\n\t\t\t\n\t\t\ttorch.nn.Linear (4096, 4096), # 第二个全连接\n\t\t\ttorch.nn.ReLU(),\n\t\t\t\n\t\t\ttorch.nn.Linear (4096, 2),  # 第三个全连接\n\t\t\t#  原版1000类       最后分成2类 因为只有猫狗两个类\n\t\t\ttorch.nn.ReLU(),\n\t\t\t\n\t\t\ttorch.nn.Softmax (dim=1),  # 最后一个 softmax 不填dim=1会报警 1.0以前好像可以直接写Softmax ()\n\t\t\t\n\t\t\t\n\t\t)\n\t\t\n\t#前向传播\n\tdef forward (self, x):\n\t\tconv = self.Sumlayers (x)\n\t\tres = conv.view (conv.size (0), -1)  # 展平多维的卷积图成 一维\n\t\tout = self.fc(res)\n\t\treturn out\n\t\n\t\n\t#构建刚才的构建模块函数make_layers\n\tdef make_layers(self):\n\t\t#创建一个列表,用来快速构造模块,你也可以测试vgg19等等\n\t\tvgg16=[64, 64, 'Maxpool', 128, 128, 'Maxpool', 256, 256, 256, 'Maxpool',\n\t\t\t\t\t   512, 512, 512, 'Maxpool', 512, 512, 512, 'Maxpool']\n\t\t#创建一个列表,用来放后面层 ,后面我们直接往里面添加就可以了\n\t\tSumlayers=[]\n\t\t\n\t\t#创建一个变量，来控制 卷积参数输入大小（in_channels）和输出大小（out_channels）\n\t\tin_c = 3 #第一次输入大小\n\t\t#遍历列表\n\t\tfor x in vgg16: #获取到每个配置,我这只有vgg16这一行\n\t\t\tif x =='Maxpool':#如果遇到Maxpool ,我们就创建maxpool层\n\t\t\t\tSumlayers+=[torch.nn.MaxPool2d(kernel_size=2, stride=2)]#参数看上文\n\t\t\telse: #否则我们创建conv(卷积模块)\n\t\t\t\tSumlayers+= [torch.nn.Conv2d (in_channels=in_c,out_channels=x , kernel_size=3, padding=1), #x是列表中的参数\n\t\t\t\t\t\t   \ttorch.nn.BatchNorm2d (x),#标准化一下\n\t\t\t\t\t\t   \ttorch.nn.ReLU ()]\n\t\t\t\tin_c=x #输出大小成为下个输入大小\n\t\t\n\t\treturn torch.nn.Sequential (*Sumlayers) #然后把构建好模型传出\n```\n**********\n*********\n* 网络架构:train.py文件:\n```python\nimport torch\nimport torch.nn as nn\nimport torchvision.datasets as datasets\nimport torchvision.transforms as  transforms\nfrom torch.autograd import Variable\n\n# 工具包\nimport argparse\n# 载入网络\nfrom VGG import VGG\n\n#############参数设置#############\n####命令行设置########\nparser = argparse.ArgumentParser (description='CNN')  # 导入命令行模块\n# 对于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明\nparser.add_argument ('--batch-size', type=int, default=2, metavar='N',\n\t\t\t\t\t help='训练batch-size大小 (default: 2)')\nparser.add_argument ('--epochs', type=int, default=10, metavar='N',\n\t\t\t\t\t help='训练epochs大小 (default: 10)')\nparser.add_argument ('--lr', type=float, default=0.001, metavar='LR',\n\t\t\t\t\t help='学习率 (default: 0.001)')\nparser.add_argument ('--no-cuda', action='store_true', default=False,\n\t\t\t\t\t help='不开启cuda训练')\nparser.add_argument ('--seed', type=int, default=1, metavar='S',\n\t\t\t\t\t help='随机种子 (default: 1)')\nparser.add_argument ('--log-interval', type=int, default=1, metavar='N',\n\t\t\t\t\t help='记录等待n批次 (default: 1)')\nargs = parser.parse_args ()  # 相当于激活命令\n\nargs.cuda = not args.no_cuda and torch.cuda.is_available ()  # 判断gpu\n\ntorch.manual_seed (args.seed)\nif args.cuda:\n\ttorch.cuda.manual_seed (args.seed)  # 为CPU设置种子用于生成随机数，以使得结果是确定的\n\n##########数据转换#####################\ndata_transforms = transforms.Compose ([transforms.Scale (224),  # 通过调整比例调整大小,会报警\n\t\t\t\t\t\t\t\t\t   transforms.CenterCrop (224),  # 在中心裁剪给指定大小方形PIL图像\n\t\t\t\t\t\t\t\t\t   transforms.ToTensor ()])  # 转换成pytorch 变量tensor\n###############数据载入################\ntrain_dataset = datasets.ImageFolder (root=\"./data/train/\",  # 保存目录\n\t\t\t\t\t\t\t\t\t  transform=data_transforms)  # 把数据转换成上面约束样子\n\ntest_dataset = datasets.ImageFolder (root='./data/test/',\n\t\t\t\t\t\t\t\t\t transform=data_transforms)\n\n##########数据如下####\n# # root/dog/xxx.png\n# # root/dog/xxy.png\n# # root/dog/xxz.png\n# #\n# # root/cat/123.png\n# # root/cat/nsdf3.png\n# # root/cat/asd932_.png\n######################\n\n##############数据装载###############\ntrain_loader = torch.utils.data.DataLoader (dataset=train_dataset,  # 装载数据\n\t\t\t\t\t\t\t\t\t\t\tbatch_size=args.batch_size,  # 设置批大小\n\t\t\t\t\t\t\t\t\t\t\tshuffle=True)  # 是否随机打乱\ntest_loader = torch.utils.data.DataLoader (dataset=test_dataset,\n\t\t\t\t\t\t\t\t\t\t   batch_size=args.batch_size,\n\t\t\t\t\t\t\t\t\t\t   shuffle=True)\n\n#############模型载入#################\nVGG=VGG ()\nif not args.no_cuda:\n\tprint ('正在使用gpu')\n\tVGG.cuda ()\nprint (VGG)\n\n###############损失函数##################\ncriterion = nn.CrossEntropyLoss ()  # 内置标准损失\noptimizer = torch.optim.Adam (VGG.parameters (), lr=args.lr)  # Adam优化器\n#############训练过程#####################\ntotal_loss = 0 #内存循环使用\nfor epoch in range (args.epochs):\n\tfor i, (images, labels) in enumerate (train_loader):  # 枚举出来\n\t\tif not args.no_cuda:  # 数据处理是否用gpu\n\t\t\timages = images.cuda ()\n\t\t\tlabels = labels.cuda ()\n\t\t\n\t\timages = Variable (images)  # 装箱\n\t\tlabels = Variable (labels)\n\t\t\n\t\t##前向传播\n\t\toptimizer.zero_grad ()\n\t\toutputs = VGG (images)\n\t\t# 损失\n\t\tloss = criterion (outputs, labels)\n\t\t# 反向传播\n\t\tloss.backward ()\n\t\toptimizer.step ()#更新参数\n\t\ttotal_loss += loss#内存循环使用 防止cuda超出内存\n\t\t##打印记录\n\t\t\n\t\tif (i + 1) % args.log_interval == 0:\n\t\t\tprint ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'\n\t\t\t\t   % (epoch + 1, args.epochs, i + 1, len (train_dataset) // args.batch_size, loss.item ()))\n\t\t\n\t\t# 保存模型\n\t\ttorch.save (VGG.state_dict (), 'VGG.pkl')\n\n\n```\n\n**************\n**********\n结果如图:\n![](https://blog.mviai.com/images/回顾-VGG/t.png)\n\n**注:如果提示内存不够,可以在命令行用下面命令训练:**\n```python\npython train.py --no-cuda --batch-size=2\n```\n** 因为我自带内存8g,显卡内存2g,所以我不用gpu跑**\n","source":"_posts/回顾-VGG.md","raw":"---\ntitle: 回顾-VGG\ndate: 2018-12-19 18:46:12\ntags:\n    - VGG\ncategories: \n    - 框架\n    - pytorch\n    - VGG\n---\n# 1. VGGNet 简介:\n1.VGG是由Simonyan 和Zisserman在文献《[Very Deep Convolutional Networks for Large Scale Image Recognition](https://arxiv.org/abs/1409.1556)》中提出卷积神经网络模型，其名称来源于作者所在的牛津大学视觉几何组(Visual Geometry Group)的缩写。\n\n2.该模型参加2014年的 ImageNet图像分类与定位挑战赛，取得了优异成绩：在分类任务上排名第二，在定位任务上排名第一。\n\n**************\n# 2. VGGNet 网络结构:\n根据VGG中根据<font color=red>卷积核大小和卷积层数目的不同,</font>分为A,A-LRN,B,C,D,E共6个网络结构配置!\n*********\nD,E就是常用配置,也就是常说的<font color=red>VGG16和VGG19</font>\n\n* 如图:\n ![](https://blog.mviai.com/images/回顾-VGG/table.png)\n \n ************\n ** 1.为什么叫vgg16? **\n 如图绿色(D配置),即VGG16配置,\n * 1.用conv3表示3\\*3卷积,conv3-xx中的xx表示通道数(也就是有多少个这样的卷积核)\n * 2.一共数下来 有13个conv3,3个FC(最下面那里),5个池化层(每个模块中间)\n * 3.13(卷积)+3(全连接)=16,不加池化层,是因为池化层不涉及权重.所以d配置叫VGG16,其他以此类推!\n ************\n* 官方图:\n  * 如图:\n  ![](https://blog.mviai.com/images/回顾-VGG/block.png)\n\n\n********\n* 这个图又看出什么?\n    * 1.每个卷积层(上面的conv3-xx)里面是表示conv+relu(图中黑色方块注释)\n    * 2.看到红色方块(池化层)没,是不是经过它,似乎方块都变小1/2了!\n        * 即池化层采用的参数均为2\\*2,步幅stride=2，max的池化方式，这样就能够使得每一个池化层的宽和高是前一层的1/2。\n*********\n\n* 输入图片大小变化图:\n![](https://blog.mviai.com/images/回顾-VGG/VGG16.png)\n\n*********\n* 这个图又看出什么?\n    * 1.图片从224\\*244大小→112\\*112→56\\*56→28\\*28→ 14\\*14→7\\*7大小(图最左边Size),大小一直减半\n    * 2.卷积通道数(卷积核数量)从64-->128-->256-->512,然后固定在512!   都是2倍数(因为计算机以2进制计算)----------------2是个好东西\n***********\n* 计算量图:\n ![](https://blog.mviai.com/images/回顾-VGG/c.png)\n** 注:memory=内存计算(红色),params=参数量计算(蓝色)**\n***********\n\n\n# 3.VGG优缺点:\n** 优点:**\n* 1.VGGNet的结构非常简洁，整个网络都使用了同样大小的卷积核尺寸（3x3）和最大池化尺寸（2x2）\n* 2.几个小滤波器（3x3）卷积层的组合比一个大滤波器（5x5或7x7）卷积层好\n* 3.通过不断加深网络结构可以提升性能.具有很高的拟合能力(怎么加深?(<font color=red>这个网络告诉我们就像汉堡一样一层层堆叠上去</font>))\n*************\n** 缺点:**\n* 1.训练时间过长(3个全连接啊(<font color=red>听说:发现这些全连接层即使被去除，对于性能也没有什么影响，这样就显著降低了参数数量</font>))，调参难度大\n* 2.需要的存储容量大，不利于部署。(单片机就那几MB可怜的空间)\n************\n\n# 4.PyTorch实现:\n* 网络架构:VGG.py文件:\n```python\nimport torch\n\n\n'''\n今天这个有点难得堆\n一个个写,重复性太高,而且不利于观看,不优雅\n重复性事我们交给你喊函数完成\n'''\n#遵从原来步骤\nclass VGG(torch.nn.Module):\n\t#初始化\n\tdef __init__(self):\n\t\tsuper(VGG, self).__init__()\n\t\tself.Sumlayers=self.make_layers()#这里我们交由make_layers函数创建相似的模块\n\t\t#假设我们上面已经创好五个模块(文章第一幅图block1->block5)\n\t\n\t\t#现在创建最后的Fc\n\t\tself.fc=torch.nn.Sequential(\n\t\t\ttorch.nn.Linear (7*7*512, 4096),  # 第一个全连接\n\t\t\ttorch.nn.ReLU(),\n\t\t\t\n\t\t\ttorch.nn.Linear (4096, 4096), # 第二个全连接\n\t\t\ttorch.nn.ReLU(),\n\t\t\t\n\t\t\ttorch.nn.Linear (4096, 2),  # 第三个全连接\n\t\t\t#  原版1000类       最后分成2类 因为只有猫狗两个类\n\t\t\ttorch.nn.ReLU(),\n\t\t\t\n\t\t\ttorch.nn.Softmax (dim=1),  # 最后一个 softmax 不填dim=1会报警 1.0以前好像可以直接写Softmax ()\n\t\t\t\n\t\t\t\n\t\t)\n\t\t\n\t#前向传播\n\tdef forward (self, x):\n\t\tconv = self.Sumlayers (x)\n\t\tres = conv.view (conv.size (0), -1)  # 展平多维的卷积图成 一维\n\t\tout = self.fc(res)\n\t\treturn out\n\t\n\t\n\t#构建刚才的构建模块函数make_layers\n\tdef make_layers(self):\n\t\t#创建一个列表,用来快速构造模块,你也可以测试vgg19等等\n\t\tvgg16=[64, 64, 'Maxpool', 128, 128, 'Maxpool', 256, 256, 256, 'Maxpool',\n\t\t\t\t\t   512, 512, 512, 'Maxpool', 512, 512, 512, 'Maxpool']\n\t\t#创建一个列表,用来放后面层 ,后面我们直接往里面添加就可以了\n\t\tSumlayers=[]\n\t\t\n\t\t#创建一个变量，来控制 卷积参数输入大小（in_channels）和输出大小（out_channels）\n\t\tin_c = 3 #第一次输入大小\n\t\t#遍历列表\n\t\tfor x in vgg16: #获取到每个配置,我这只有vgg16这一行\n\t\t\tif x =='Maxpool':#如果遇到Maxpool ,我们就创建maxpool层\n\t\t\t\tSumlayers+=[torch.nn.MaxPool2d(kernel_size=2, stride=2)]#参数看上文\n\t\t\telse: #否则我们创建conv(卷积模块)\n\t\t\t\tSumlayers+= [torch.nn.Conv2d (in_channels=in_c,out_channels=x , kernel_size=3, padding=1), #x是列表中的参数\n\t\t\t\t\t\t   \ttorch.nn.BatchNorm2d (x),#标准化一下\n\t\t\t\t\t\t   \ttorch.nn.ReLU ()]\n\t\t\t\tin_c=x #输出大小成为下个输入大小\n\t\t\n\t\treturn torch.nn.Sequential (*Sumlayers) #然后把构建好模型传出\n```\n**********\n*********\n* 网络架构:train.py文件:\n```python\nimport torch\nimport torch.nn as nn\nimport torchvision.datasets as datasets\nimport torchvision.transforms as  transforms\nfrom torch.autograd import Variable\n\n# 工具包\nimport argparse\n# 载入网络\nfrom VGG import VGG\n\n#############参数设置#############\n####命令行设置########\nparser = argparse.ArgumentParser (description='CNN')  # 导入命令行模块\n# 对于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明\nparser.add_argument ('--batch-size', type=int, default=2, metavar='N',\n\t\t\t\t\t help='训练batch-size大小 (default: 2)')\nparser.add_argument ('--epochs', type=int, default=10, metavar='N',\n\t\t\t\t\t help='训练epochs大小 (default: 10)')\nparser.add_argument ('--lr', type=float, default=0.001, metavar='LR',\n\t\t\t\t\t help='学习率 (default: 0.001)')\nparser.add_argument ('--no-cuda', action='store_true', default=False,\n\t\t\t\t\t help='不开启cuda训练')\nparser.add_argument ('--seed', type=int, default=1, metavar='S',\n\t\t\t\t\t help='随机种子 (default: 1)')\nparser.add_argument ('--log-interval', type=int, default=1, metavar='N',\n\t\t\t\t\t help='记录等待n批次 (default: 1)')\nargs = parser.parse_args ()  # 相当于激活命令\n\nargs.cuda = not args.no_cuda and torch.cuda.is_available ()  # 判断gpu\n\ntorch.manual_seed (args.seed)\nif args.cuda:\n\ttorch.cuda.manual_seed (args.seed)  # 为CPU设置种子用于生成随机数，以使得结果是确定的\n\n##########数据转换#####################\ndata_transforms = transforms.Compose ([transforms.Scale (224),  # 通过调整比例调整大小,会报警\n\t\t\t\t\t\t\t\t\t   transforms.CenterCrop (224),  # 在中心裁剪给指定大小方形PIL图像\n\t\t\t\t\t\t\t\t\t   transforms.ToTensor ()])  # 转换成pytorch 变量tensor\n###############数据载入################\ntrain_dataset = datasets.ImageFolder (root=\"./data/train/\",  # 保存目录\n\t\t\t\t\t\t\t\t\t  transform=data_transforms)  # 把数据转换成上面约束样子\n\ntest_dataset = datasets.ImageFolder (root='./data/test/',\n\t\t\t\t\t\t\t\t\t transform=data_transforms)\n\n##########数据如下####\n# # root/dog/xxx.png\n# # root/dog/xxy.png\n# # root/dog/xxz.png\n# #\n# # root/cat/123.png\n# # root/cat/nsdf3.png\n# # root/cat/asd932_.png\n######################\n\n##############数据装载###############\ntrain_loader = torch.utils.data.DataLoader (dataset=train_dataset,  # 装载数据\n\t\t\t\t\t\t\t\t\t\t\tbatch_size=args.batch_size,  # 设置批大小\n\t\t\t\t\t\t\t\t\t\t\tshuffle=True)  # 是否随机打乱\ntest_loader = torch.utils.data.DataLoader (dataset=test_dataset,\n\t\t\t\t\t\t\t\t\t\t   batch_size=args.batch_size,\n\t\t\t\t\t\t\t\t\t\t   shuffle=True)\n\n#############模型载入#################\nVGG=VGG ()\nif not args.no_cuda:\n\tprint ('正在使用gpu')\n\tVGG.cuda ()\nprint (VGG)\n\n###############损失函数##################\ncriterion = nn.CrossEntropyLoss ()  # 内置标准损失\noptimizer = torch.optim.Adam (VGG.parameters (), lr=args.lr)  # Adam优化器\n#############训练过程#####################\ntotal_loss = 0 #内存循环使用\nfor epoch in range (args.epochs):\n\tfor i, (images, labels) in enumerate (train_loader):  # 枚举出来\n\t\tif not args.no_cuda:  # 数据处理是否用gpu\n\t\t\timages = images.cuda ()\n\t\t\tlabels = labels.cuda ()\n\t\t\n\t\timages = Variable (images)  # 装箱\n\t\tlabels = Variable (labels)\n\t\t\n\t\t##前向传播\n\t\toptimizer.zero_grad ()\n\t\toutputs = VGG (images)\n\t\t# 损失\n\t\tloss = criterion (outputs, labels)\n\t\t# 反向传播\n\t\tloss.backward ()\n\t\toptimizer.step ()#更新参数\n\t\ttotal_loss += loss#内存循环使用 防止cuda超出内存\n\t\t##打印记录\n\t\t\n\t\tif (i + 1) % args.log_interval == 0:\n\t\t\tprint ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'\n\t\t\t\t   % (epoch + 1, args.epochs, i + 1, len (train_dataset) // args.batch_size, loss.item ()))\n\t\t\n\t\t# 保存模型\n\t\ttorch.save (VGG.state_dict (), 'VGG.pkl')\n\n\n```\n\n**************\n**********\n结果如图:\n![](https://blog.mviai.com/images/回顾-VGG/t.png)\n\n**注:如果提示内存不够,可以在命令行用下面命令训练:**\n```python\npython train.py --no-cuda --batch-size=2\n```\n** 因为我自带内存8g,显卡内存2g,所以我不用gpu跑**\n","slug":"回顾-VGG","published":1,"updated":"2021-07-26T09:58:02.580Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m22001nigtasoggl053","content":"<h1 id=\"1-VGGNet-简介\"><a href=\"#1-VGGNet-简介\" class=\"headerlink\" title=\"1. VGGNet 简介:\"></a>1. VGGNet 简介:</h1><p>1.VGG是由Simonyan 和Zisserman在文献《<a href=\"https://arxiv.org/abs/1409.1556\" target=\"_blank\" rel=\"noopener\">Very Deep Convolutional Networks for Large Scale Image Recognition</a>》中提出卷积神经网络模型，其名称来源于作者所在的牛津大学视觉几何组(Visual Geometry Group)的缩写。</p>\n<p>2.该模型参加2014年的 ImageNet图像分类与定位挑战赛，取得了优异成绩：在分类任务上排名第二，在定位任务上排名第一。</p>\n<hr>\n<h1 id=\"2-VGGNet-网络结构\"><a href=\"#2-VGGNet-网络结构\" class=\"headerlink\" title=\"2. VGGNet 网络结构:\"></a>2. VGGNet 网络结构:</h1><p>根据VGG中根据<font color=\"red\">卷积核大小和卷积层数目的不同,</font>分为A,A-LRN,B,C,D,E共6个网络结构配置!</p>\n<hr>\n<p>D,E就是常用配置,也就是常说的<font color=\"red\">VGG16和VGG19</font></p>\n<ul>\n<li><p>如图:<br><img src=\"https://blog.mviai.com/images/回顾-VGG/table.png\" alt></p>\n<hr>\n<p><strong> 1.为什么叫vgg16? </strong><br>如图绿色(D配置),即VGG16配置,</p>\n<ul>\n<li>1.用conv3表示3*3卷积,conv3-xx中的xx表示通道数(也就是有多少个这样的卷积核)</li>\n<li>2.一共数下来 有13个conv3,3个FC(最下面那里),5个池化层(每个模块中间)</li>\n<li>3.13(卷积)+3(全连接)=16,不加池化层,是因为池化层不涉及权重.所以d配置叫VGG16,其他以此类推!</li>\n</ul>\n<hr>\n</li>\n<li>官方图:<ul>\n<li>如图:<br><img src=\"https://blog.mviai.com/images/回顾-VGG/block.png\" alt></li>\n</ul>\n</li>\n</ul>\n<hr>\n<ul>\n<li>这个图又看出什么?<ul>\n<li>1.每个卷积层(上面的conv3-xx)里面是表示conv+relu(图中黑色方块注释)</li>\n<li>2.看到红色方块(池化层)没,是不是经过它,似乎方块都变小1/2了!<ul>\n<li>即池化层采用的参数均为2*2,步幅stride=2，max的池化方式，这样就能够使得每一个池化层的宽和高是前一层的1/2。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<hr>\n<ul>\n<li>输入图片大小变化图:<br><img src=\"https://blog.mviai.com/images/回顾-VGG/VGG16.png\" alt></li>\n</ul>\n<hr>\n<ul>\n<li>这个图又看出什么?<ul>\n<li>1.图片从224*244大小→112*112→56*56→28*28→ 14*14→7*7大小(图最左边Size),大小一直减半</li>\n<li>2.卷积通道数(卷积核数量)从64–&gt;128–&gt;256–&gt;512,然后固定在512!   都是2倍数(因为计算机以2进制计算)—————-2是个好东西</li>\n</ul>\n</li>\n</ul>\n<hr>\n<ul>\n<li>计算量图:<br><img src=\"https://blog.mviai.com/images/回顾-VGG/c.png\" alt><br><strong> 注:memory=内存计算(红色),params=参数量计算(蓝色)</strong></li>\n</ul>\n<hr>\n<h1 id=\"3-VGG优缺点\"><a href=\"#3-VGG优缺点\" class=\"headerlink\" title=\"3.VGG优缺点:\"></a>3.VGG优缺点:</h1><p><strong> 优点:</strong></p>\n<ul>\n<li>1.VGGNet的结构非常简洁，整个网络都使用了同样大小的卷积核尺寸（3x3）和最大池化尺寸（2x2）</li>\n<li>2.几个小滤波器（3x3）卷积层的组合比一个大滤波器（5x5或7x7）卷积层好</li>\n<li>3.通过不断加深网络结构可以提升性能.具有很高的拟合能力(怎么加深?(<font color=\"red\">这个网络告诉我们就像汉堡一样一层层堆叠上去</font>))</li>\n</ul>\n<hr>\n<p><strong> 缺点:</strong></p>\n<ul>\n<li>1.训练时间过长(3个全连接啊(<font color=\"red\">听说:发现这些全连接层即使被去除，对于性能也没有什么影响，这样就显著降低了参数数量</font>))，调参难度大</li>\n<li>2.需要的存储容量大，不利于部署。(单片机就那几MB可怜的空间)</li>\n</ul>\n<hr>\n<h1 id=\"4-PyTorch实现\"><a href=\"#4-PyTorch实现\" class=\"headerlink\" title=\"4.PyTorch实现:\"></a>4.PyTorch实现:</h1><ul>\n<li>网络架构:VGG.py文件:<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">今天这个有点难得堆</span></span><br><span class=\"line\"><span class=\"string\">一个个写,重复性太高,而且不利于观看,不优雅</span></span><br><span class=\"line\"><span class=\"string\">重复性事我们交给你喊函数完成</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"comment\">#遵从原来步骤</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">VGG</span><span class=\"params\">(torch.nn.Module)</span>:</span></span><br><span class=\"line\">\t<span class=\"comment\">#初始化</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">\t\tsuper(VGG, self).__init__()</span><br><span class=\"line\">\t\tself.Sumlayers=self.make_layers()<span class=\"comment\">#这里我们交由make_layers函数创建相似的模块</span></span><br><span class=\"line\">\t\t<span class=\"comment\">#假设我们上面已经创好五个模块(文章第一幅图block1-&gt;block5)</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t\t<span class=\"comment\">#现在创建最后的Fc</span></span><br><span class=\"line\">\t\tself.fc=torch.nn.Sequential(</span><br><span class=\"line\">\t\t\ttorch.nn.Linear (<span class=\"number\">7</span>*<span class=\"number\">7</span>*<span class=\"number\">512</span>, <span class=\"number\">4096</span>),  <span class=\"comment\"># 第一个全连接</span></span><br><span class=\"line\">\t\t\ttorch.nn.ReLU(),</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\ttorch.nn.Linear (<span class=\"number\">4096</span>, <span class=\"number\">4096</span>), <span class=\"comment\"># 第二个全连接</span></span><br><span class=\"line\">\t\t\ttorch.nn.ReLU(),</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\ttorch.nn.Linear (<span class=\"number\">4096</span>, <span class=\"number\">2</span>),  <span class=\"comment\"># 第三个全连接</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\">#  原版1000类       最后分成2类 因为只有猫狗两个类</span></span><br><span class=\"line\">\t\t\ttorch.nn.ReLU(),</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\ttorch.nn.Softmax (dim=<span class=\"number\">1</span>),  <span class=\"comment\"># 最后一个 softmax 不填dim=1会报警 1.0以前好像可以直接写Softmax ()</span></span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t)</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t<span class=\"comment\">#前向传播</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span> <span class=\"params\">(self, x)</span>:</span></span><br><span class=\"line\">\t\tconv = self.Sumlayers (x)</span><br><span class=\"line\">\t\tres = conv.view (conv.size (<span class=\"number\">0</span>), <span class=\"number\">-1</span>)  <span class=\"comment\"># 展平多维的卷积图成 一维</span></span><br><span class=\"line\">\t\tout = self.fc(res)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> out</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">#构建刚才的构建模块函数make_layers</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">make_layers</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"comment\">#创建一个列表,用来快速构造模块,你也可以测试vgg19等等</span></span><br><span class=\"line\">\t\tvgg16=[<span class=\"number\">64</span>, <span class=\"number\">64</span>, <span class=\"string\">'Maxpool'</span>, <span class=\"number\">128</span>, <span class=\"number\">128</span>, <span class=\"string\">'Maxpool'</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span>, <span class=\"string\">'Maxpool'</span>,</span><br><span class=\"line\">\t\t\t\t\t   <span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"string\">'Maxpool'</span>, <span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"string\">'Maxpool'</span>]</span><br><span class=\"line\">\t\t<span class=\"comment\">#创建一个列表,用来放后面层 ,后面我们直接往里面添加就可以了</span></span><br><span class=\"line\">\t\tSumlayers=[]</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\">#创建一个变量，来控制 卷积参数输入大小（in_channels）和输出大小（out_channels）</span></span><br><span class=\"line\">\t\tin_c = <span class=\"number\">3</span> <span class=\"comment\">#第一次输入大小</span></span><br><span class=\"line\">\t\t<span class=\"comment\">#遍历列表</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> vgg16: <span class=\"comment\">#获取到每个配置,我这只有vgg16这一行</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> x ==<span class=\"string\">'Maxpool'</span>:<span class=\"comment\">#如果遇到Maxpool ,我们就创建maxpool层</span></span><br><span class=\"line\">\t\t\t\tSumlayers+=[torch.nn.MaxPool2d(kernel_size=<span class=\"number\">2</span>, stride=<span class=\"number\">2</span>)]<span class=\"comment\">#参数看上文</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">else</span>: <span class=\"comment\">#否则我们创建conv(卷积模块)</span></span><br><span class=\"line\">\t\t\t\tSumlayers+= [torch.nn.Conv2d (in_channels=in_c,out_channels=x , kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>), <span class=\"comment\">#x是列表中的参数</span></span><br><span class=\"line\">\t\t\t\t\t\t   \ttorch.nn.BatchNorm2d (x),<span class=\"comment\">#标准化一下</span></span><br><span class=\"line\">\t\t\t\t\t\t   \ttorch.nn.ReLU ()]</span><br><span class=\"line\">\t\t\t\tin_c=x <span class=\"comment\">#输出大小成为下个输入大小</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> torch.nn.Sequential (*Sumlayers) <span class=\"comment\">#然后把构建好模型传出</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<hr>\n<hr>\n<ul>\n<li>网络架构:train.py文件:<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision.datasets <span class=\"keyword\">as</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision.transforms <span class=\"keyword\">as</span>  transforms</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 工具包</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> argparse</span><br><span class=\"line\"><span class=\"comment\"># 载入网络</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> VGG <span class=\"keyword\">import</span> VGG</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############参数设置#############</span></span><br><span class=\"line\"><span class=\"comment\">####命令行设置########</span></span><br><span class=\"line\">parser = argparse.ArgumentParser (description=<span class=\"string\">'CNN'</span>)  <span class=\"comment\"># 导入命令行模块</span></span><br><span class=\"line\"><span class=\"comment\"># 对于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--batch-size'</span>, type=int, default=<span class=\"number\">2</span>, metavar=<span class=\"string\">'N'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'训练batch-size大小 (default: 2)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--epochs'</span>, type=int, default=<span class=\"number\">10</span>, metavar=<span class=\"string\">'N'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'训练epochs大小 (default: 10)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--lr'</span>, type=float, default=<span class=\"number\">0.001</span>, metavar=<span class=\"string\">'LR'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'学习率 (default: 0.001)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--no-cuda'</span>, action=<span class=\"string\">'store_true'</span>, default=<span class=\"literal\">False</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'不开启cuda训练'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--seed'</span>, type=int, default=<span class=\"number\">1</span>, metavar=<span class=\"string\">'S'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'随机种子 (default: 1)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--log-interval'</span>, type=int, default=<span class=\"number\">1</span>, metavar=<span class=\"string\">'N'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'记录等待n批次 (default: 1)'</span>)</span><br><span class=\"line\">args = parser.parse_args ()  <span class=\"comment\"># 相当于激活命令</span></span><br><span class=\"line\"></span><br><span class=\"line\">args.cuda = <span class=\"keyword\">not</span> args.no_cuda <span class=\"keyword\">and</span> torch.cuda.is_available ()  <span class=\"comment\"># 判断gpu</span></span><br><span class=\"line\"></span><br><span class=\"line\">torch.manual_seed (args.seed)</span><br><span class=\"line\"><span class=\"keyword\">if</span> args.cuda:</span><br><span class=\"line\">\ttorch.cuda.manual_seed (args.seed)  <span class=\"comment\"># 为CPU设置种子用于生成随机数，以使得结果是确定的</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##########数据转换#####################</span></span><br><span class=\"line\">data_transforms = transforms.Compose ([transforms.Scale (<span class=\"number\">224</span>),  <span class=\"comment\"># 通过调整比例调整大小,会报警</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t   transforms.CenterCrop (<span class=\"number\">224</span>),  <span class=\"comment\"># 在中心裁剪给指定大小方形PIL图像</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t   transforms.ToTensor ()])  <span class=\"comment\"># 转换成pytorch 变量tensor</span></span><br><span class=\"line\"><span class=\"comment\">###############数据载入################</span></span><br><span class=\"line\">train_dataset = datasets.ImageFolder (root=<span class=\"string\">\"./data/train/\"</span>,  <span class=\"comment\"># 保存目录</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t  transform=data_transforms)  <span class=\"comment\"># 把数据转换成上面约束样子</span></span><br><span class=\"line\"></span><br><span class=\"line\">test_dataset = datasets.ImageFolder (root=<span class=\"string\">'./data/test/'</span>,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t transform=data_transforms)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##########数据如下####</span></span><br><span class=\"line\"><span class=\"comment\"># # root/dog/xxx.png</span></span><br><span class=\"line\"><span class=\"comment\"># # root/dog/xxy.png</span></span><br><span class=\"line\"><span class=\"comment\"># # root/dog/xxz.png</span></span><br><span class=\"line\"><span class=\"comment\"># #</span></span><br><span class=\"line\"><span class=\"comment\"># # root/cat/123.png</span></span><br><span class=\"line\"><span class=\"comment\"># # root/cat/nsdf3.png</span></span><br><span class=\"line\"><span class=\"comment\"># # root/cat/asd932_.png</span></span><br><span class=\"line\"><span class=\"comment\">######################</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##############数据装载###############</span></span><br><span class=\"line\">train_loader = torch.utils.data.DataLoader (dataset=train_dataset,  <span class=\"comment\"># 装载数据</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\tbatch_size=args.batch_size,  <span class=\"comment\"># 设置批大小</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\tshuffle=<span class=\"literal\">True</span>)  <span class=\"comment\"># 是否随机打乱</span></span><br><span class=\"line\">test_loader = torch.utils.data.DataLoader (dataset=test_dataset,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   batch_size=args.batch_size,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   shuffle=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############模型载入#################</span></span><br><span class=\"line\">VGG=VGG ()</span><br><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"keyword\">not</span> args.no_cuda:</span><br><span class=\"line\">\t<span class=\"keyword\">print</span> (<span class=\"string\">'正在使用gpu'</span>)</span><br><span class=\"line\">\tVGG.cuda ()</span><br><span class=\"line\"><span class=\"keyword\">print</span> (VGG)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###############损失函数##################</span></span><br><span class=\"line\">criterion = nn.CrossEntropyLoss ()  <span class=\"comment\"># 内置标准损失</span></span><br><span class=\"line\">optimizer = torch.optim.Adam (VGG.parameters (), lr=args.lr)  <span class=\"comment\"># Adam优化器</span></span><br><span class=\"line\"><span class=\"comment\">#############训练过程#####################</span></span><br><span class=\"line\">total_loss = <span class=\"number\">0</span> <span class=\"comment\">#内存循环使用</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range (args.epochs):</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i, (images, labels) <span class=\"keyword\">in</span> enumerate (train_loader):  <span class=\"comment\"># 枚举出来</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> <span class=\"keyword\">not</span> args.no_cuda:  <span class=\"comment\"># 数据处理是否用gpu</span></span><br><span class=\"line\">\t\t\timages = images.cuda ()</span><br><span class=\"line\">\t\t\tlabels = labels.cuda ()</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\timages = Variable (images)  <span class=\"comment\"># 装箱</span></span><br><span class=\"line\">\t\tlabels = Variable (labels)</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\">##前向传播</span></span><br><span class=\"line\">\t\toptimizer.zero_grad ()</span><br><span class=\"line\">\t\toutputs = VGG (images)</span><br><span class=\"line\">\t\t<span class=\"comment\"># 损失</span></span><br><span class=\"line\">\t\tloss = criterion (outputs, labels)</span><br><span class=\"line\">\t\t<span class=\"comment\"># 反向传播</span></span><br><span class=\"line\">\t\tloss.backward ()</span><br><span class=\"line\">\t\toptimizer.step ()<span class=\"comment\">#更新参数</span></span><br><span class=\"line\">\t\ttotal_loss += loss<span class=\"comment\">#内存循环使用 防止cuda超出内存</span></span><br><span class=\"line\">\t\t<span class=\"comment\">##打印记录</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (i + <span class=\"number\">1</span>) % args.log_interval == <span class=\"number\">0</span>:</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">print</span> (<span class=\"string\">'Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'</span></span><br><span class=\"line\">\t\t\t\t   % (epoch + <span class=\"number\">1</span>, args.epochs, i + <span class=\"number\">1</span>, len (train_dataset) // args.batch_size, loss.item ()))</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 保存模型</span></span><br><span class=\"line\">\t\ttorch.save (VGG.state_dict (), <span class=\"string\">'VGG.pkl'</span>)</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<hr>\n<hr>\n<p>结果如图:<br><img src=\"https://blog.mviai.com/images/回顾-VGG/t.png\" alt></p>\n<p><strong>注:如果提示内存不够,可以在命令行用下面命令训练:</strong><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python train.py --no-cuda --batch-size=<span class=\"number\">2</span></span><br></pre></td></tr></table></figure></p>\n<p><strong> 因为我自带内存8g,显卡内存2g,所以我不用gpu跑</strong></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"1-VGGNet-简介\"><a href=\"#1-VGGNet-简介\" class=\"headerlink\" title=\"1. VGGNet 简介:\"></a>1. VGGNet 简介:</h1><p>1.VGG是由Simonyan 和Zisserman在文献《<a href=\"https://arxiv.org/abs/1409.1556\" target=\"_blank\" rel=\"noopener\">Very Deep Convolutional Networks for Large Scale Image Recognition</a>》中提出卷积神经网络模型，其名称来源于作者所在的牛津大学视觉几何组(Visual Geometry Group)的缩写。</p>\n<p>2.该模型参加2014年的 ImageNet图像分类与定位挑战赛，取得了优异成绩：在分类任务上排名第二，在定位任务上排名第一。</p>\n<hr>\n<h1 id=\"2-VGGNet-网络结构\"><a href=\"#2-VGGNet-网络结构\" class=\"headerlink\" title=\"2. VGGNet 网络结构:\"></a>2. VGGNet 网络结构:</h1><p>根据VGG中根据<font color=\"red\">卷积核大小和卷积层数目的不同,</font>分为A,A-LRN,B,C,D,E共6个网络结构配置!</p>\n<hr>\n<p>D,E就是常用配置,也就是常说的<font color=\"red\">VGG16和VGG19</font></p>\n<ul>\n<li><p>如图:<br><img src=\"https://blog.mviai.com/images/回顾-VGG/table.png\" alt></p>\n<hr>\n<p><strong> 1.为什么叫vgg16? </strong><br>如图绿色(D配置),即VGG16配置,</p>\n<ul>\n<li>1.用conv3表示3*3卷积,conv3-xx中的xx表示通道数(也就是有多少个这样的卷积核)</li>\n<li>2.一共数下来 有13个conv3,3个FC(最下面那里),5个池化层(每个模块中间)</li>\n<li>3.13(卷积)+3(全连接)=16,不加池化层,是因为池化层不涉及权重.所以d配置叫VGG16,其他以此类推!</li>\n</ul>\n<hr>\n</li>\n<li>官方图:<ul>\n<li>如图:<br><img src=\"https://blog.mviai.com/images/回顾-VGG/block.png\" alt></li>\n</ul>\n</li>\n</ul>\n<hr>\n<ul>\n<li>这个图又看出什么?<ul>\n<li>1.每个卷积层(上面的conv3-xx)里面是表示conv+relu(图中黑色方块注释)</li>\n<li>2.看到红色方块(池化层)没,是不是经过它,似乎方块都变小1/2了!<ul>\n<li>即池化层采用的参数均为2*2,步幅stride=2，max的池化方式，这样就能够使得每一个池化层的宽和高是前一层的1/2。</li>\n</ul>\n</li>\n</ul>\n</li>\n</ul>\n<hr>\n<ul>\n<li>输入图片大小变化图:<br><img src=\"https://blog.mviai.com/images/回顾-VGG/VGG16.png\" alt></li>\n</ul>\n<hr>\n<ul>\n<li>这个图又看出什么?<ul>\n<li>1.图片从224*244大小→112*112→56*56→28*28→ 14*14→7*7大小(图最左边Size),大小一直减半</li>\n<li>2.卷积通道数(卷积核数量)从64–&gt;128–&gt;256–&gt;512,然后固定在512!   都是2倍数(因为计算机以2进制计算)—————-2是个好东西</li>\n</ul>\n</li>\n</ul>\n<hr>\n<ul>\n<li>计算量图:<br><img src=\"https://blog.mviai.com/images/回顾-VGG/c.png\" alt><br><strong> 注:memory=内存计算(红色),params=参数量计算(蓝色)</strong></li>\n</ul>\n<hr>\n<h1 id=\"3-VGG优缺点\"><a href=\"#3-VGG优缺点\" class=\"headerlink\" title=\"3.VGG优缺点:\"></a>3.VGG优缺点:</h1><p><strong> 优点:</strong></p>\n<ul>\n<li>1.VGGNet的结构非常简洁，整个网络都使用了同样大小的卷积核尺寸（3x3）和最大池化尺寸（2x2）</li>\n<li>2.几个小滤波器（3x3）卷积层的组合比一个大滤波器（5x5或7x7）卷积层好</li>\n<li>3.通过不断加深网络结构可以提升性能.具有很高的拟合能力(怎么加深?(<font color=\"red\">这个网络告诉我们就像汉堡一样一层层堆叠上去</font>))</li>\n</ul>\n<hr>\n<p><strong> 缺点:</strong></p>\n<ul>\n<li>1.训练时间过长(3个全连接啊(<font color=\"red\">听说:发现这些全连接层即使被去除，对于性能也没有什么影响，这样就显著降低了参数数量</font>))，调参难度大</li>\n<li>2.需要的存储容量大，不利于部署。(单片机就那几MB可怜的空间)</li>\n</ul>\n<hr>\n<h1 id=\"4-PyTorch实现\"><a href=\"#4-PyTorch实现\" class=\"headerlink\" title=\"4.PyTorch实现:\"></a>4.PyTorch实现:</h1><ul>\n<li>网络架构:VGG.py文件:<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">今天这个有点难得堆</span></span><br><span class=\"line\"><span class=\"string\">一个个写,重复性太高,而且不利于观看,不优雅</span></span><br><span class=\"line\"><span class=\"string\">重复性事我们交给你喊函数完成</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"comment\">#遵从原来步骤</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">VGG</span><span class=\"params\">(torch.nn.Module)</span>:</span></span><br><span class=\"line\">\t<span class=\"comment\">#初始化</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">\t\tsuper(VGG, self).__init__()</span><br><span class=\"line\">\t\tself.Sumlayers=self.make_layers()<span class=\"comment\">#这里我们交由make_layers函数创建相似的模块</span></span><br><span class=\"line\">\t\t<span class=\"comment\">#假设我们上面已经创好五个模块(文章第一幅图block1-&gt;block5)</span></span><br><span class=\"line\">\t</span><br><span class=\"line\">\t\t<span class=\"comment\">#现在创建最后的Fc</span></span><br><span class=\"line\">\t\tself.fc=torch.nn.Sequential(</span><br><span class=\"line\">\t\t\ttorch.nn.Linear (<span class=\"number\">7</span>*<span class=\"number\">7</span>*<span class=\"number\">512</span>, <span class=\"number\">4096</span>),  <span class=\"comment\"># 第一个全连接</span></span><br><span class=\"line\">\t\t\ttorch.nn.ReLU(),</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\ttorch.nn.Linear (<span class=\"number\">4096</span>, <span class=\"number\">4096</span>), <span class=\"comment\"># 第二个全连接</span></span><br><span class=\"line\">\t\t\ttorch.nn.ReLU(),</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\ttorch.nn.Linear (<span class=\"number\">4096</span>, <span class=\"number\">2</span>),  <span class=\"comment\"># 第三个全连接</span></span><br><span class=\"line\">\t\t\t<span class=\"comment\">#  原版1000类       最后分成2类 因为只有猫狗两个类</span></span><br><span class=\"line\">\t\t\ttorch.nn.ReLU(),</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\ttorch.nn.Softmax (dim=<span class=\"number\">1</span>),  <span class=\"comment\"># 最后一个 softmax 不填dim=1会报警 1.0以前好像可以直接写Softmax ()</span></span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t\t</span><br><span class=\"line\">\t\t)</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t<span class=\"comment\">#前向传播</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">forward</span> <span class=\"params\">(self, x)</span>:</span></span><br><span class=\"line\">\t\tconv = self.Sumlayers (x)</span><br><span class=\"line\">\t\tres = conv.view (conv.size (<span class=\"number\">0</span>), <span class=\"number\">-1</span>)  <span class=\"comment\"># 展平多维的卷积图成 一维</span></span><br><span class=\"line\">\t\tout = self.fc(res)</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> out</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">#构建刚才的构建模块函数make_layers</span></span><br><span class=\"line\">\t<span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">make_layers</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">\t\t<span class=\"comment\">#创建一个列表,用来快速构造模块,你也可以测试vgg19等等</span></span><br><span class=\"line\">\t\tvgg16=[<span class=\"number\">64</span>, <span class=\"number\">64</span>, <span class=\"string\">'Maxpool'</span>, <span class=\"number\">128</span>, <span class=\"number\">128</span>, <span class=\"string\">'Maxpool'</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span>, <span class=\"number\">256</span>, <span class=\"string\">'Maxpool'</span>,</span><br><span class=\"line\">\t\t\t\t\t   <span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"string\">'Maxpool'</span>, <span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"number\">512</span>, <span class=\"string\">'Maxpool'</span>]</span><br><span class=\"line\">\t\t<span class=\"comment\">#创建一个列表,用来放后面层 ,后面我们直接往里面添加就可以了</span></span><br><span class=\"line\">\t\tSumlayers=[]</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\">#创建一个变量，来控制 卷积参数输入大小（in_channels）和输出大小（out_channels）</span></span><br><span class=\"line\">\t\tin_c = <span class=\"number\">3</span> <span class=\"comment\">#第一次输入大小</span></span><br><span class=\"line\">\t\t<span class=\"comment\">#遍历列表</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> vgg16: <span class=\"comment\">#获取到每个配置,我这只有vgg16这一行</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">if</span> x ==<span class=\"string\">'Maxpool'</span>:<span class=\"comment\">#如果遇到Maxpool ,我们就创建maxpool层</span></span><br><span class=\"line\">\t\t\t\tSumlayers+=[torch.nn.MaxPool2d(kernel_size=<span class=\"number\">2</span>, stride=<span class=\"number\">2</span>)]<span class=\"comment\">#参数看上文</span></span><br><span class=\"line\">\t\t\t<span class=\"keyword\">else</span>: <span class=\"comment\">#否则我们创建conv(卷积模块)</span></span><br><span class=\"line\">\t\t\t\tSumlayers+= [torch.nn.Conv2d (in_channels=in_c,out_channels=x , kernel_size=<span class=\"number\">3</span>, padding=<span class=\"number\">1</span>), <span class=\"comment\">#x是列表中的参数</span></span><br><span class=\"line\">\t\t\t\t\t\t   \ttorch.nn.BatchNorm2d (x),<span class=\"comment\">#标准化一下</span></span><br><span class=\"line\">\t\t\t\t\t\t   \ttorch.nn.ReLU ()]</span><br><span class=\"line\">\t\t\t\tin_c=x <span class=\"comment\">#输出大小成为下个输入大小</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"keyword\">return</span> torch.nn.Sequential (*Sumlayers) <span class=\"comment\">#然后把构建好模型传出</span></span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<hr>\n<hr>\n<ul>\n<li>网络架构:train.py文件:<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br><span class=\"line\">70</span><br><span class=\"line\">71</span><br><span class=\"line\">72</span><br><span class=\"line\">73</span><br><span class=\"line\">74</span><br><span class=\"line\">75</span><br><span class=\"line\">76</span><br><span class=\"line\">77</span><br><span class=\"line\">78</span><br><span class=\"line\">79</span><br><span class=\"line\">80</span><br><span class=\"line\">81</span><br><span class=\"line\">82</span><br><span class=\"line\">83</span><br><span class=\"line\">84</span><br><span class=\"line\">85</span><br><span class=\"line\">86</span><br><span class=\"line\">87</span><br><span class=\"line\">88</span><br><span class=\"line\">89</span><br><span class=\"line\">90</span><br><span class=\"line\">91</span><br><span class=\"line\">92</span><br><span class=\"line\">93</span><br><span class=\"line\">94</span><br><span class=\"line\">95</span><br><span class=\"line\">96</span><br><span class=\"line\">97</span><br><span class=\"line\">98</span><br><span class=\"line\">99</span><br><span class=\"line\">100</span><br><span class=\"line\">101</span><br><span class=\"line\">102</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> torch</span><br><span class=\"line\"><span class=\"keyword\">import</span> torch.nn <span class=\"keyword\">as</span> nn</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision.datasets <span class=\"keyword\">as</span> datasets</span><br><span class=\"line\"><span class=\"keyword\">import</span> torchvision.transforms <span class=\"keyword\">as</span>  transforms</span><br><span class=\"line\"><span class=\"keyword\">from</span> torch.autograd <span class=\"keyword\">import</span> Variable</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 工具包</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> argparse</span><br><span class=\"line\"><span class=\"comment\"># 载入网络</span></span><br><span class=\"line\"><span class=\"keyword\">from</span> VGG <span class=\"keyword\">import</span> VGG</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############参数设置#############</span></span><br><span class=\"line\"><span class=\"comment\">####命令行设置########</span></span><br><span class=\"line\">parser = argparse.ArgumentParser (description=<span class=\"string\">'CNN'</span>)  <span class=\"comment\"># 导入命令行模块</span></span><br><span class=\"line\"><span class=\"comment\"># 对于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明</span></span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--batch-size'</span>, type=int, default=<span class=\"number\">2</span>, metavar=<span class=\"string\">'N'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'训练batch-size大小 (default: 2)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--epochs'</span>, type=int, default=<span class=\"number\">10</span>, metavar=<span class=\"string\">'N'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'训练epochs大小 (default: 10)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--lr'</span>, type=float, default=<span class=\"number\">0.001</span>, metavar=<span class=\"string\">'LR'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'学习率 (default: 0.001)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--no-cuda'</span>, action=<span class=\"string\">'store_true'</span>, default=<span class=\"literal\">False</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'不开启cuda训练'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--seed'</span>, type=int, default=<span class=\"number\">1</span>, metavar=<span class=\"string\">'S'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'随机种子 (default: 1)'</span>)</span><br><span class=\"line\">parser.add_argument (<span class=\"string\">'--log-interval'</span>, type=int, default=<span class=\"number\">1</span>, metavar=<span class=\"string\">'N'</span>,</span><br><span class=\"line\">\t\t\t\t\t help=<span class=\"string\">'记录等待n批次 (default: 1)'</span>)</span><br><span class=\"line\">args = parser.parse_args ()  <span class=\"comment\"># 相当于激活命令</span></span><br><span class=\"line\"></span><br><span class=\"line\">args.cuda = <span class=\"keyword\">not</span> args.no_cuda <span class=\"keyword\">and</span> torch.cuda.is_available ()  <span class=\"comment\"># 判断gpu</span></span><br><span class=\"line\"></span><br><span class=\"line\">torch.manual_seed (args.seed)</span><br><span class=\"line\"><span class=\"keyword\">if</span> args.cuda:</span><br><span class=\"line\">\ttorch.cuda.manual_seed (args.seed)  <span class=\"comment\"># 为CPU设置种子用于生成随机数，以使得结果是确定的</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##########数据转换#####################</span></span><br><span class=\"line\">data_transforms = transforms.Compose ([transforms.Scale (<span class=\"number\">224</span>),  <span class=\"comment\"># 通过调整比例调整大小,会报警</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t   transforms.CenterCrop (<span class=\"number\">224</span>),  <span class=\"comment\"># 在中心裁剪给指定大小方形PIL图像</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t   transforms.ToTensor ()])  <span class=\"comment\"># 转换成pytorch 变量tensor</span></span><br><span class=\"line\"><span class=\"comment\">###############数据载入################</span></span><br><span class=\"line\">train_dataset = datasets.ImageFolder (root=<span class=\"string\">\"./data/train/\"</span>,  <span class=\"comment\"># 保存目录</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t  transform=data_transforms)  <span class=\"comment\"># 把数据转换成上面约束样子</span></span><br><span class=\"line\"></span><br><span class=\"line\">test_dataset = datasets.ImageFolder (root=<span class=\"string\">'./data/test/'</span>,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t transform=data_transforms)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##########数据如下####</span></span><br><span class=\"line\"><span class=\"comment\"># # root/dog/xxx.png</span></span><br><span class=\"line\"><span class=\"comment\"># # root/dog/xxy.png</span></span><br><span class=\"line\"><span class=\"comment\"># # root/dog/xxz.png</span></span><br><span class=\"line\"><span class=\"comment\"># #</span></span><br><span class=\"line\"><span class=\"comment\"># # root/cat/123.png</span></span><br><span class=\"line\"><span class=\"comment\"># # root/cat/nsdf3.png</span></span><br><span class=\"line\"><span class=\"comment\"># # root/cat/asd932_.png</span></span><br><span class=\"line\"><span class=\"comment\">######################</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">##############数据装载###############</span></span><br><span class=\"line\">train_loader = torch.utils.data.DataLoader (dataset=train_dataset,  <span class=\"comment\"># 装载数据</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\tbatch_size=args.batch_size,  <span class=\"comment\"># 设置批大小</span></span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t\tshuffle=<span class=\"literal\">True</span>)  <span class=\"comment\"># 是否随机打乱</span></span><br><span class=\"line\">test_loader = torch.utils.data.DataLoader (dataset=test_dataset,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   batch_size=args.batch_size,</span><br><span class=\"line\">\t\t\t\t\t\t\t\t\t\t   shuffle=<span class=\"literal\">True</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#############模型载入#################</span></span><br><span class=\"line\">VGG=VGG ()</span><br><span class=\"line\"><span class=\"keyword\">if</span> <span class=\"keyword\">not</span> args.no_cuda:</span><br><span class=\"line\">\t<span class=\"keyword\">print</span> (<span class=\"string\">'正在使用gpu'</span>)</span><br><span class=\"line\">\tVGG.cuda ()</span><br><span class=\"line\"><span class=\"keyword\">print</span> (VGG)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">###############损失函数##################</span></span><br><span class=\"line\">criterion = nn.CrossEntropyLoss ()  <span class=\"comment\"># 内置标准损失</span></span><br><span class=\"line\">optimizer = torch.optim.Adam (VGG.parameters (), lr=args.lr)  <span class=\"comment\"># Adam优化器</span></span><br><span class=\"line\"><span class=\"comment\">#############训练过程#####################</span></span><br><span class=\"line\">total_loss = <span class=\"number\">0</span> <span class=\"comment\">#内存循环使用</span></span><br><span class=\"line\"><span class=\"keyword\">for</span> epoch <span class=\"keyword\">in</span> range (args.epochs):</span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i, (images, labels) <span class=\"keyword\">in</span> enumerate (train_loader):  <span class=\"comment\"># 枚举出来</span></span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> <span class=\"keyword\">not</span> args.no_cuda:  <span class=\"comment\"># 数据处理是否用gpu</span></span><br><span class=\"line\">\t\t\timages = images.cuda ()</span><br><span class=\"line\">\t\t\tlabels = labels.cuda ()</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\timages = Variable (images)  <span class=\"comment\"># 装箱</span></span><br><span class=\"line\">\t\tlabels = Variable (labels)</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\">##前向传播</span></span><br><span class=\"line\">\t\toptimizer.zero_grad ()</span><br><span class=\"line\">\t\toutputs = VGG (images)</span><br><span class=\"line\">\t\t<span class=\"comment\"># 损失</span></span><br><span class=\"line\">\t\tloss = criterion (outputs, labels)</span><br><span class=\"line\">\t\t<span class=\"comment\"># 反向传播</span></span><br><span class=\"line\">\t\tloss.backward ()</span><br><span class=\"line\">\t\toptimizer.step ()<span class=\"comment\">#更新参数</span></span><br><span class=\"line\">\t\ttotal_loss += loss<span class=\"comment\">#内存循环使用 防止cuda超出内存</span></span><br><span class=\"line\">\t\t<span class=\"comment\">##打印记录</span></span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"keyword\">if</span> (i + <span class=\"number\">1</span>) % args.log_interval == <span class=\"number\">0</span>:</span><br><span class=\"line\">\t\t\t<span class=\"keyword\">print</span> (<span class=\"string\">'Epoch [%d/%d], Iter [%d/%d] Loss: %.4f'</span></span><br><span class=\"line\">\t\t\t\t   % (epoch + <span class=\"number\">1</span>, args.epochs, i + <span class=\"number\">1</span>, len (train_dataset) // args.batch_size, loss.item ()))</span><br><span class=\"line\">\t\t</span><br><span class=\"line\">\t\t<span class=\"comment\"># 保存模型</span></span><br><span class=\"line\">\t\ttorch.save (VGG.state_dict (), <span class=\"string\">'VGG.pkl'</span>)</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<hr>\n<hr>\n<p>结果如图:<br><img src=\"https://blog.mviai.com/images/回顾-VGG/t.png\" alt></p>\n<p><strong>注:如果提示内存不够,可以在命令行用下面命令训练:</strong><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python train.py --no-cuda --batch-size=<span class=\"number\">2</span></span><br></pre></td></tr></table></figure></p>\n<p><strong> 因为我自带内存8g,显卡内存2g,所以我不用gpu跑</strong></p>\n"},{"title":"回顾-WGAN","date":"2018-12-26T19:38:57.000Z","_content":"# 1.WGAN 简介:\n\n\n\n\n\n# 2.WGAN 网络结构:\n\n\n\n\n\n# 3.WGAN 创新点:\n\n\n\n\n\n\n# 4.Pytorch 实现:\n\n\n\n\n","source":"_posts/回顾-WGAN.md","raw":"---\ntitle: 回顾-WGAN\ndate: 2018-12-27 03:38:57\ntags:\n    - WGAN\ncategories: \n    - 框架\n    - pytorch\n    - GAN\n---\n# 1.WGAN 简介:\n\n\n\n\n\n# 2.WGAN 网络结构:\n\n\n\n\n\n# 3.WGAN 创新点:\n\n\n\n\n\n\n# 4.Pytorch 实现:\n\n\n\n\n","slug":"回顾-WGAN","published":1,"updated":"2021-07-26T09:58:02.580Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m23001qigtaws455ryc","content":"<h1 id=\"1-WGAN-简介\"><a href=\"#1-WGAN-简介\" class=\"headerlink\" title=\"1.WGAN 简介:\"></a>1.WGAN 简介:</h1><h1 id=\"2-WGAN-网络结构\"><a href=\"#2-WGAN-网络结构\" class=\"headerlink\" title=\"2.WGAN 网络结构:\"></a>2.WGAN 网络结构:</h1><h1 id=\"3-WGAN-创新点\"><a href=\"#3-WGAN-创新点\" class=\"headerlink\" title=\"3.WGAN 创新点:\"></a>3.WGAN 创新点:</h1><h1 id=\"4-Pytorch-实现\"><a href=\"#4-Pytorch-实现\" class=\"headerlink\" title=\"4.Pytorch 实现:\"></a>4.Pytorch 实现:</h1>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"1-WGAN-简介\"><a href=\"#1-WGAN-简介\" class=\"headerlink\" title=\"1.WGAN 简介:\"></a>1.WGAN 简介:</h1><h1 id=\"2-WGAN-网络结构\"><a href=\"#2-WGAN-网络结构\" class=\"headerlink\" title=\"2.WGAN 网络结构:\"></a>2.WGAN 网络结构:</h1><h1 id=\"3-WGAN-创新点\"><a href=\"#3-WGAN-创新点\" class=\"headerlink\" title=\"3.WGAN 创新点:\"></a>3.WGAN 创新点:</h1><h1 id=\"4-Pytorch-实现\"><a href=\"#4-Pytorch-实现\" class=\"headerlink\" title=\"4.Pytorch 实现:\"></a>4.Pytorch 实现:</h1>"},{"title":"回顾-pix2pix","toc":false,"date":"2018-12-24T19:38:57.000Z","_content":"\n# 1.Pix2Pix 简介:\n* 1.这是基于CGAN的pix2pix模型!\n* 2.Pix2Pix与一般GAN不同的地方在于，其实现的目标是图像翻译，A-》B，比如，一张场景可以转换为RGB全彩图，也可以转化成素描，也可以转化为灰度图。\n* 顾名思义，Pix2Pix指的是像素对像素的翻译，图像大小保持不变。G网络的输入是A图像，通过G网络生成的图像叫做FakeB，而真实的图像就是RealB。\n* 论文: https://arxiv.org/abs/1611.07004\n* 项目：https://github.com/phillipi/pix2pix\n\n# 2.Pix2Pix 网络架构:\n** <font color=red> 生成网络: </font>**\n生成器G使用U-net实现:\n![](https://blog.mviai.com/images/回顾-pix2pix/g.png)\n* 1. 从图中可以看出u-net采用跳跃式链接的全卷积结构(有点像resnet的跨层链接)\n\nU-net来源于VAE的encoder-decoder:\n如图;\n![](https://blog.mviai.com/images/回顾-pix2pix/u.png)\n**注:U-Net通过卷积和反卷积实现的U形形状的网络结构；输入和输出都是3个维度**\n\n\n** <font color=red> 判别网络: </font>**\n判别器D使用马尔科夫性的判别器(PatchGAN)([论文](http://openaccess.thecvf.com/content_cvpr_2017/papers/Isola_Image-To-Image_Translation_With_CVPR_2017_paper.pdf))\n* 简单来说:PatchGAN可以理解为一种风格/纹理损失网络\n![](https://blog.mviai.com/images/回顾-pix2pix/d.png)\n** 注:根据kernelsize是1的进行将为，最终实现1个chanel的图像**\n\n** <font color=red> 损失函数: </font>**\n* 原始GAN(G不需要x):\n![](https://blog.mviai.com/images/回顾-pix2pix/gan.png)\n* CGAN(G需要x):\n![](https://blog.mviai.com/images/回顾-pix2pix/cgan.png)\n* 给GAN加个L1或L2,而Pix2pix使用的是L1架构，可以减少模糊程度:\n![](https://blog.mviai.com/images/回顾-pix2pix/l1.png)\n* 最终G损失:\n![](https://blog.mviai.com/images/回顾-pix2pix/g_f.png)\n** 注:最终的loss是针对一个chanel的图像的每个像素求MSE(均方差loss，fake的label为0，real的label为1)或BCE(二进制交叉熵)。**\n\n\n** <font color=red> 训练方法: </font>**\n* ![](https://blog.mviai.com/images/回顾-pix2pix/train.png)\n* 训练大致过程如上图所示。图片 x 作为此cGAN的条件，需要输入到G和D中。G的输入是{x,z}（其中，x 是需要转换的图片，z 是随机噪声），输出是生成的图片G(x,z)。D则需要分辨出{x,G(x,z)}和{x,y}。\n\n\n# 3.Pix2Pix 创新点:\n* 1.一般的方法都是训练CNN去缩小输入跟输出的欧氏距离,论文在GAN的基础上提出一个通用的方法：pix2pix 来解决这一类问题。通过pix2pix来完成成对的图像转换\n* 2.输入为图像而不是随机向量\n* 3.成对输入为图像而不是随机向量\n* 4.Patch判别器来降低计算量提升效果\n* 5.L1损失函数的加入来保证输入和输出之间的一致性。\n\n\n# 4. Pytorch实现:\n","source":"_posts/回顾-pix2pix.md","raw":"---\ntitle: 回顾-pix2pix\ntags:\n  - pix2pix\ncategories: \n    - 框架\n    - pytorch\n    - GAN\ntoc: false\n\ndate: 2018-12-25 03:38:57\n---\n\n# 1.Pix2Pix 简介:\n* 1.这是基于CGAN的pix2pix模型!\n* 2.Pix2Pix与一般GAN不同的地方在于，其实现的目标是图像翻译，A-》B，比如，一张场景可以转换为RGB全彩图，也可以转化成素描，也可以转化为灰度图。\n* 顾名思义，Pix2Pix指的是像素对像素的翻译，图像大小保持不变。G网络的输入是A图像，通过G网络生成的图像叫做FakeB，而真实的图像就是RealB。\n* 论文: https://arxiv.org/abs/1611.07004\n* 项目：https://github.com/phillipi/pix2pix\n\n# 2.Pix2Pix 网络架构:\n** <font color=red> 生成网络: </font>**\n生成器G使用U-net实现:\n![](https://blog.mviai.com/images/回顾-pix2pix/g.png)\n* 1. 从图中可以看出u-net采用跳跃式链接的全卷积结构(有点像resnet的跨层链接)\n\nU-net来源于VAE的encoder-decoder:\n如图;\n![](https://blog.mviai.com/images/回顾-pix2pix/u.png)\n**注:U-Net通过卷积和反卷积实现的U形形状的网络结构；输入和输出都是3个维度**\n\n\n** <font color=red> 判别网络: </font>**\n判别器D使用马尔科夫性的判别器(PatchGAN)([论文](http://openaccess.thecvf.com/content_cvpr_2017/papers/Isola_Image-To-Image_Translation_With_CVPR_2017_paper.pdf))\n* 简单来说:PatchGAN可以理解为一种风格/纹理损失网络\n![](https://blog.mviai.com/images/回顾-pix2pix/d.png)\n** 注:根据kernelsize是1的进行将为，最终实现1个chanel的图像**\n\n** <font color=red> 损失函数: </font>**\n* 原始GAN(G不需要x):\n![](https://blog.mviai.com/images/回顾-pix2pix/gan.png)\n* CGAN(G需要x):\n![](https://blog.mviai.com/images/回顾-pix2pix/cgan.png)\n* 给GAN加个L1或L2,而Pix2pix使用的是L1架构，可以减少模糊程度:\n![](https://blog.mviai.com/images/回顾-pix2pix/l1.png)\n* 最终G损失:\n![](https://blog.mviai.com/images/回顾-pix2pix/g_f.png)\n** 注:最终的loss是针对一个chanel的图像的每个像素求MSE(均方差loss，fake的label为0，real的label为1)或BCE(二进制交叉熵)。**\n\n\n** <font color=red> 训练方法: </font>**\n* ![](https://blog.mviai.com/images/回顾-pix2pix/train.png)\n* 训练大致过程如上图所示。图片 x 作为此cGAN的条件，需要输入到G和D中。G的输入是{x,z}（其中，x 是需要转换的图片，z 是随机噪声），输出是生成的图片G(x,z)。D则需要分辨出{x,G(x,z)}和{x,y}。\n\n\n# 3.Pix2Pix 创新点:\n* 1.一般的方法都是训练CNN去缩小输入跟输出的欧氏距离,论文在GAN的基础上提出一个通用的方法：pix2pix 来解决这一类问题。通过pix2pix来完成成对的图像转换\n* 2.输入为图像而不是随机向量\n* 3.成对输入为图像而不是随机向量\n* 4.Patch判别器来降低计算量提升效果\n* 5.L1损失函数的加入来保证输入和输出之间的一致性。\n\n\n# 4. Pytorch实现:\n","slug":"回顾-pix2pix","published":1,"updated":"2021-07-26T09:58:02.578Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m24001sigta4d4nsv0w","content":"<h1 id=\"1-Pix2Pix-简介\"><a href=\"#1-Pix2Pix-简介\" class=\"headerlink\" title=\"1.Pix2Pix 简介:\"></a>1.Pix2Pix 简介:</h1><ul>\n<li>1.这是基于CGAN的pix2pix模型!</li>\n<li>2.Pix2Pix与一般GAN不同的地方在于，其实现的目标是图像翻译，A-》B，比如，一张场景可以转换为RGB全彩图，也可以转化成素描，也可以转化为灰度图。</li>\n<li>顾名思义，Pix2Pix指的是像素对像素的翻译，图像大小保持不变。G网络的输入是A图像，通过G网络生成的图像叫做FakeB，而真实的图像就是RealB。</li>\n<li>论文: <a href=\"https://arxiv.org/abs/1611.07004\" target=\"_blank\" rel=\"noopener\">https://arxiv.org/abs/1611.07004</a></li>\n<li>项目：<a href=\"https://github.com/phillipi/pix2pix\" target=\"_blank\" rel=\"noopener\">https://github.com/phillipi/pix2pix</a></li>\n</ul>\n<h1 id=\"2-Pix2Pix-网络架构\"><a href=\"#2-Pix2Pix-网络架构\" class=\"headerlink\" title=\"2.Pix2Pix 网络架构:\"></a>2.Pix2Pix 网络架构:</h1><p><strong> <font color=\"red\"> 生成网络: </font></strong><br>生成器G使用U-net实现:<br><img src=\"https://blog.mviai.com/images/回顾-pix2pix/g.png\" alt></p>\n<ul>\n<li><ol>\n<li>从图中可以看出u-net采用跳跃式链接的全卷积结构(有点像resnet的跨层链接)</li>\n</ol>\n</li>\n</ul>\n<p>U-net来源于VAE的encoder-decoder:<br>如图;<br><img src=\"https://blog.mviai.com/images/回顾-pix2pix/u.png\" alt><br><strong>注:U-Net通过卷积和反卷积实现的U形形状的网络结构；输入和输出都是3个维度</strong></p>\n<p><strong> <font color=\"red\"> 判别网络: </font></strong><br>判别器D使用马尔科夫性的判别器(PatchGAN)(<a href=\"http://openaccess.thecvf.com/content_cvpr_2017/papers/Isola_Image-To-Image_Translation_With_CVPR_2017_paper.pdf\" target=\"_blank\" rel=\"noopener\">论文</a>)</p>\n<ul>\n<li>简单来说:PatchGAN可以理解为一种风格/纹理损失网络<br><img src=\"https://blog.mviai.com/images/回顾-pix2pix/d.png\" alt><br><strong> 注:根据kernelsize是1的进行将为，最终实现1个chanel的图像</strong></li>\n</ul>\n<p><strong> <font color=\"red\"> 损失函数: </font></strong></p>\n<ul>\n<li>原始GAN(G不需要x):<br><img src=\"https://blog.mviai.com/images/回顾-pix2pix/gan.png\" alt></li>\n<li>CGAN(G需要x):<br><img src=\"https://blog.mviai.com/images/回顾-pix2pix/cgan.png\" alt></li>\n<li>给GAN加个L1或L2,而Pix2pix使用的是L1架构，可以减少模糊程度:<br><img src=\"https://blog.mviai.com/images/回顾-pix2pix/l1.png\" alt></li>\n<li>最终G损失:<br><img src=\"https://blog.mviai.com/images/回顾-pix2pix/g_f.png\" alt><br><strong> 注:最终的loss是针对一个chanel的图像的每个像素求MSE(均方差loss，fake的label为0，real的label为1)或BCE(二进制交叉熵)。</strong></li>\n</ul>\n<p><strong> <font color=\"red\"> 训练方法: </font></strong></p>\n<ul>\n<li><img src=\"https://blog.mviai.com/images/回顾-pix2pix/train.png\" alt></li>\n<li>训练大致过程如上图所示。图片 x 作为此cGAN的条件，需要输入到G和D中。G的输入是{x,z}（其中，x 是需要转换的图片，z 是随机噪声），输出是生成的图片G(x,z)。D则需要分辨出{x,G(x,z)}和{x,y}。</li>\n</ul>\n<h1 id=\"3-Pix2Pix-创新点\"><a href=\"#3-Pix2Pix-创新点\" class=\"headerlink\" title=\"3.Pix2Pix 创新点:\"></a>3.Pix2Pix 创新点:</h1><ul>\n<li>1.一般的方法都是训练CNN去缩小输入跟输出的欧氏距离,论文在GAN的基础上提出一个通用的方法：pix2pix 来解决这一类问题。通过pix2pix来完成成对的图像转换</li>\n<li>2.输入为图像而不是随机向量</li>\n<li>3.成对输入为图像而不是随机向量</li>\n<li>4.Patch判别器来降低计算量提升效果</li>\n<li>5.L1损失函数的加入来保证输入和输出之间的一致性。</li>\n</ul>\n<h1 id=\"4-Pytorch实现\"><a href=\"#4-Pytorch实现\" class=\"headerlink\" title=\"4. Pytorch实现:\"></a>4. Pytorch实现:</h1>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"1-Pix2Pix-简介\"><a href=\"#1-Pix2Pix-简介\" class=\"headerlink\" title=\"1.Pix2Pix 简介:\"></a>1.Pix2Pix 简介:</h1><ul>\n<li>1.这是基于CGAN的pix2pix模型!</li>\n<li>2.Pix2Pix与一般GAN不同的地方在于，其实现的目标是图像翻译，A-》B，比如，一张场景可以转换为RGB全彩图，也可以转化成素描，也可以转化为灰度图。</li>\n<li>顾名思义，Pix2Pix指的是像素对像素的翻译，图像大小保持不变。G网络的输入是A图像，通过G网络生成的图像叫做FakeB，而真实的图像就是RealB。</li>\n<li>论文: <a href=\"https://arxiv.org/abs/1611.07004\" target=\"_blank\" rel=\"noopener\">https://arxiv.org/abs/1611.07004</a></li>\n<li>项目：<a href=\"https://github.com/phillipi/pix2pix\" target=\"_blank\" rel=\"noopener\">https://github.com/phillipi/pix2pix</a></li>\n</ul>\n<h1 id=\"2-Pix2Pix-网络架构\"><a href=\"#2-Pix2Pix-网络架构\" class=\"headerlink\" title=\"2.Pix2Pix 网络架构:\"></a>2.Pix2Pix 网络架构:</h1><p><strong> <font color=\"red\"> 生成网络: </font></strong><br>生成器G使用U-net实现:<br><img src=\"https://blog.mviai.com/images/回顾-pix2pix/g.png\" alt></p>\n<ul>\n<li><ol>\n<li>从图中可以看出u-net采用跳跃式链接的全卷积结构(有点像resnet的跨层链接)</li>\n</ol>\n</li>\n</ul>\n<p>U-net来源于VAE的encoder-decoder:<br>如图;<br><img src=\"https://blog.mviai.com/images/回顾-pix2pix/u.png\" alt><br><strong>注:U-Net通过卷积和反卷积实现的U形形状的网络结构；输入和输出都是3个维度</strong></p>\n<p><strong> <font color=\"red\"> 判别网络: </font></strong><br>判别器D使用马尔科夫性的判别器(PatchGAN)(<a href=\"http://openaccess.thecvf.com/content_cvpr_2017/papers/Isola_Image-To-Image_Translation_With_CVPR_2017_paper.pdf\" target=\"_blank\" rel=\"noopener\">论文</a>)</p>\n<ul>\n<li>简单来说:PatchGAN可以理解为一种风格/纹理损失网络<br><img src=\"https://blog.mviai.com/images/回顾-pix2pix/d.png\" alt><br><strong> 注:根据kernelsize是1的进行将为，最终实现1个chanel的图像</strong></li>\n</ul>\n<p><strong> <font color=\"red\"> 损失函数: </font></strong></p>\n<ul>\n<li>原始GAN(G不需要x):<br><img src=\"https://blog.mviai.com/images/回顾-pix2pix/gan.png\" alt></li>\n<li>CGAN(G需要x):<br><img src=\"https://blog.mviai.com/images/回顾-pix2pix/cgan.png\" alt></li>\n<li>给GAN加个L1或L2,而Pix2pix使用的是L1架构，可以减少模糊程度:<br><img src=\"https://blog.mviai.com/images/回顾-pix2pix/l1.png\" alt></li>\n<li>最终G损失:<br><img src=\"https://blog.mviai.com/images/回顾-pix2pix/g_f.png\" alt><br><strong> 注:最终的loss是针对一个chanel的图像的每个像素求MSE(均方差loss，fake的label为0，real的label为1)或BCE(二进制交叉熵)。</strong></li>\n</ul>\n<p><strong> <font color=\"red\"> 训练方法: </font></strong></p>\n<ul>\n<li><img src=\"https://blog.mviai.com/images/回顾-pix2pix/train.png\" alt></li>\n<li>训练大致过程如上图所示。图片 x 作为此cGAN的条件，需要输入到G和D中。G的输入是{x,z}（其中，x 是需要转换的图片，z 是随机噪声），输出是生成的图片G(x,z)。D则需要分辨出{x,G(x,z)}和{x,y}。</li>\n</ul>\n<h1 id=\"3-Pix2Pix-创新点\"><a href=\"#3-Pix2Pix-创新点\" class=\"headerlink\" title=\"3.Pix2Pix 创新点:\"></a>3.Pix2Pix 创新点:</h1><ul>\n<li>1.一般的方法都是训练CNN去缩小输入跟输出的欧氏距离,论文在GAN的基础上提出一个通用的方法：pix2pix 来解决这一类问题。通过pix2pix来完成成对的图像转换</li>\n<li>2.输入为图像而不是随机向量</li>\n<li>3.成对输入为图像而不是随机向量</li>\n<li>4.Patch判别器来降低计算量提升效果</li>\n<li>5.L1损失函数的加入来保证输入和输出之间的一致性。</li>\n</ul>\n<h1 id=\"4-Pytorch实现\"><a href=\"#4-Pytorch实现\" class=\"headerlink\" title=\"4. Pytorch实现:\"></a>4. Pytorch实现:</h1>"},{"title":"在Pytorch中正确设计dateset并加载数据集","date":"2019-05-07T12:40:50.000Z","_content":"\n\n# 一、前言\n在构建深度学习任务中，最重要的当然是如何设计我们的神经网络。\n\n但在实际的训练过程中，如何正确编写、使用加载数据集的代码同样是不可缺少的一环，在不同的任务中不同数据格式的任务中，加载数据的代码难免会有差别。为了避免重复编写并且避免一些与算法无关的错误，我们有必要讨论一下如何正确加载数据集。\n\n这里只讨论如何加载图像格式的数据集，对于文字或者其他的数据集不进行讨论。\n\n# 二、正确加载数据集\n加载数据集是深度学习训练过程中不可缺少的一环。一般地，在平常的时候，我们第一个想到的是将所有需要的数据聚成一堆一堆然后通过构建list去一一读取我们的数据：\n![](http:https://blog.mviai.com/images/dateset并加载数据集/1.png)\n假如我们编写了上述的图像加载数据集代码，在训练中我们就可以依靠<font color='#ff0000'>get_training_data()</font>这个函数来得到batch_size个数据，从而进行训练，乍看下去没什么问题，但是一旦我们的数据量超过1000：\n\n* 将所有的图像数据直接加载到numpy数据中会占用大量的内存\n* 由于需要对数据进行导入，每次训练的时候在数据读取阶段会占用大量的时间\n* 只使用了单线程去读取，读取效率比较低下\n* 拓展性很差，如果需要对数据进行一些预处理，只能采取一些不是特别优雅的做法\n\n既然问题这么多，到底说回来，我们应该如何正确地加载数据集呢？\n\n本文将会介绍如何根据Pytorch官方提供的数据加载模板，去编写自己的加载数据集类，从而实现高效稳定地加载我们的数据集。(Pytorch官方教程介绍)\n\n# 三、Dataset类\n<font color='#ff0000'>Dataset</font>类是Pytorch中图像数据集中最为重要的一个类，也是Pytorch中所有数据集加载类中应该继承的父类。其中父类中的两个私有成员函数必须被重载，否则将会触发错误提示：\n```python\ndef getitem(self, index):\ndef len(self):\n```\n其中<font color='#ff0000'>  ` __len__  ` </font>应该返回数据集的大小，而<font color='#ff0000'>`__getitem__`</font>应该编写支持数据集索引的函数，例如通过<font color='#ff0000'>`dataset [i]`</font>可以得到数据集中的第<font color='#ff0000'> i+1</font>个数据。\n\n![](https://blog.mviai.com/images/dateset并加载数据集/2.png)\n\n上面所示的这个类，其实也就是起到了封装我们加载函数的作用(对象处理起来更加方便明朗么)，在继承了这个Dataset类之后，我们需要实现的核心功能便是<font color='#ff0000'>  `__getitem__() ` </font>函数，<font color='#ff0000'>  `__getitem__() ` </font>是Python中类的默认成员函数，我们通过实现这个成员函数实现可以通过索引来返回图像数据的功能。\n\n那么怎么得到图像从而去返回呢？当然不会直接将图像数据加载到内存中，相反我们只需要得到图像的地址就足够了，然后在调用的时候通过不同的读取方式读取即可。\n\n关于读取方式：https://oldpan.me/archives/pytorch-transforms-opencv-scikit-image\n\n定义自己的数据集类\n那么我们开始定义一个自己的数据集类吧。\n\n首先继承上面的<font color='#ff0000'>` dataset ` </font>类。然后在<font color='#ff0000'>`__init__() ` </font>方法中得到图像的路径，然后将图像路径组成一个数组，这样在<font color='#ff0000'>`__getitim__() ` </font>中就可以直接读取：\n```python\n# 假设下面这个类是读取船只的数据类\nclass ShipDataset(Dataset):\n    \"\"\"\n     root：图像存放地址根路径\n     augment：是否需要图像增强\n    \"\"\"\n    def __init__(self, root, augment=None):\n        # 这个list存放所有图像的地址\n        self.image_files = np.array([x.path for x in os.scandir(root) if\n            x.name.endswith(\".jpg\") or x.name.endswith(\".png\") or x.name.endswith(\".JPG\")]\n        self.augment = augment   # 是否需要图像增强\n\n    def __getitem__(self, index):\n        # 读取图像数据并返回\n        # 这里的open_image是读取图像函数，可以用PIL、opencv等库进行读取\n        return open_image(self.image_files[index])\n\n    def __len__(self):\n        # 返回图像的数量\n        return len(self.image_files)\n        \n```\n如果我们需要在读取数据的同时对图像进行增强的话，可以在<font color='#ff0000'>  `__getitem__(self, index)`</font>函数中设置图像增强的代码，例如：\n```python\n    def __getitem__(self, index):\n        if self.augment:\n            image = open_image(self.image_files[index])\n            iamge = self.augment(iamge)  # 这里对图像进行了增强\n            return image\n        else:\n            # 如果不进行增强，直接读取图像数据并返回\n            # 这里的open_image是读取图像函数，可以用PIL、opencv等库进行读取\n            return open_image(self.image_files[index])\n            \n```\n当然，图像增强的方法可以使用Pytorch内置的图像增强方式，也可以使用自定义或者其他的图像增强库。这个很灵活，当然要记住一点，在Pytorch中得到的图像必须是<font color='#ff0000'>  `tensor`</font>，也就是说我们还需要再修改一下<font color='#ff0000'>`__getitem__(self, index)`</font>：\n```python\n    def __getitem__(self, index):\n        if self.augment:\n            image = open_image(self.image_files[index])\n            iamge = self.augment(iamge)  # 这里对图像进行了增强\n            return to_tensor(image)      # 将读取到的图像变成tensor再传出\n        else:\n            # 如果不进行增强，直接读取图像数据并返回\n            # 这里的open_image是读取图像函数，可以用PIL、opencv等库进行读取\n            return to_tensor(open_image(self.image_files[index]))\n            ```\n这样，一个基本的数据类就设计好了。\n\n## DataLoader类\n之前所说的<font color='#ff0000'>  `Dataset `</font>类是读入数据集数据并且对读入的数据进行了索引。但是光有这个功能是不够用的，在实际的加载数据集的过程中，我们的数据量往往都很大，对此我们还需要一下几个功能：\n\n* 可以分批次读取：batch-size\n* 可以对数据进行随机读取，可以对数据进行洗牌操作(shuffling)，打乱数据集内数据分布的顺序\n* 可以并行加载数据(利用多核处理器加快载入数据的效率)\n\n这时候就需要<font color='#ff0000'>  `Dataloader`</font>类了，<font color='#ff0000'> `Dataloader`</font>这个类并不需要我们自己设计代码，我们只需要利用<font color='#ff0000'> `DataLoader`</font>类读取我们设计好的<font color='#ff0000'>` ShipDataset`</font>即可：\n```python\n# 利用之前创建好的ShipDataset类去创建数据对象\nship_train_dataset = ShipDataset(data_path, augment=transform)\n# 利用dataloader读取我们的数据对象，并设定batch-size和工作现场\nship_train_loader = DataLoader(ship_train_dataset, batch_size=16, num_workers=4, shuffle=False, **kwargs)\n\n```\n\n这时候通过<font color='#ff0000'> `ship_train_loader`</font>返回的数据就是按照batch-size来返回特定数量的训练数据的tensor，而且此时利用了多线程，读取数据的速度相比单线程快很多。\n\n我们这样读取:\n```python\nfor image in train_loader:\n\n        image = image.to(device)  # 将tensor数据移动到device当中\n        optimizer.zero_grad()\n        output = model(image)     # model模型处理(n,c,h,w)格式的数据，n为batch-size\n        ...\n        \n```\n读取数据的基本模式就是这样，当然在实际中不可能这么简单，我们除了图像数据可能还有json、csv等文件需要我们去读取配合图像完成任务。但是原理基本都是一样的，具体复杂点的例子可以查看官方的例程介绍，这里就不赘述了。\n\n# 创建自己的数据集\n除了设计读取数据集的代码，我们实际的图像数据应该怎么去放置呢？\n\n一般来说，我们自己制作的数据集一般包含三个部分：***train***、***val***和***test***，我们一般放在三个文件夹中，然后利用代码读取。这样是最舒服最方便的了。\n\n但是因为某些原因，我们得到的数据集却不是这样放好的，比如只有一个文件夹，所有文件都放里头了。或者好几个trian的文件夹需要我们去合并。\n\n当然，如果数据集很小的话(例如小于1000个)，那就无所谓了，直接打开文件夹移动就行，但是如果数据为10W以上级别。直接打开文件夹移动文件那电脑会直接卡死(内存32G，6核处理器依旧卡顿)。那么怎么去整体我们的数据，让代码可以顺利训练数据放去训练？\n\n这里有两种方式。\n\n## 1、自己写脚本移动这些文件\n这里以Linux为例，linux下为.sh脚本文件，window则为bat文件。\n\n将下面的脚本代码保存为<font color='#ff0000'> `mm.sh`</font>(随便起的)，自己修改<font color='#ff0000'> `path/from/ `</font>和<font color='#ff0000'> `path/to/ `</font>的地址，tail后面为移动文件的数量。\n```\nfor file in $(ls path/from/ -p | grep -v / | tail -100)\ndo\nmv $file path/to/\ndone\n```\n如果移动过程中遇到下面的问题，试着改编权限再来一次。\n```\nmv: cannot stat '03c5d57c0.jpg': No such file or directory\n```\n\n## 2、编写代码灵活读取train、val、以及test文件夹中的数据\n之前所说的读取方式ShipDataset类仅仅支持一个文件夹的读取，但是我们得到的只是一个文件夹里面包含了我们采集的数据，但是这些数据有比较多(比如50G)，也不好进行移动分成三份(训练集、验证集和测试集)，这时我们需要自己设计编写代码去实现这些功能。\n\n至于如何去编写，大家可以阅读fastai的源代码去理解一下基本思路(很好的思路，可以好好借鉴下)，fastai是一个包装了Pytorch的快速深度学习开发库：https://oldpan.me/archives/fastai-1-0-quick-study\n\n\n本文转自：https://oldpan.me/archives/how-to-load-dataset-in-correctly-pytorch\n","source":"_posts/在Pytorch中正确设计dateset并加载数据集.md","raw":"---\ntitle: 在Pytorch中正确设计dateset并加载数据集\ndate: 2019-05-07 20:40:50\ntags:\n        - 加载数据集\ncategories:\n - 框架\n - pytorch\n - 数据加载\n    \n---\n\n\n# 一、前言\n在构建深度学习任务中，最重要的当然是如何设计我们的神经网络。\n\n但在实际的训练过程中，如何正确编写、使用加载数据集的代码同样是不可缺少的一环，在不同的任务中不同数据格式的任务中，加载数据的代码难免会有差别。为了避免重复编写并且避免一些与算法无关的错误，我们有必要讨论一下如何正确加载数据集。\n\n这里只讨论如何加载图像格式的数据集，对于文字或者其他的数据集不进行讨论。\n\n# 二、正确加载数据集\n加载数据集是深度学习训练过程中不可缺少的一环。一般地，在平常的时候，我们第一个想到的是将所有需要的数据聚成一堆一堆然后通过构建list去一一读取我们的数据：\n![](http:https://blog.mviai.com/images/dateset并加载数据集/1.png)\n假如我们编写了上述的图像加载数据集代码，在训练中我们就可以依靠<font color='#ff0000'>get_training_data()</font>这个函数来得到batch_size个数据，从而进行训练，乍看下去没什么问题，但是一旦我们的数据量超过1000：\n\n* 将所有的图像数据直接加载到numpy数据中会占用大量的内存\n* 由于需要对数据进行导入，每次训练的时候在数据读取阶段会占用大量的时间\n* 只使用了单线程去读取，读取效率比较低下\n* 拓展性很差，如果需要对数据进行一些预处理，只能采取一些不是特别优雅的做法\n\n既然问题这么多，到底说回来，我们应该如何正确地加载数据集呢？\n\n本文将会介绍如何根据Pytorch官方提供的数据加载模板，去编写自己的加载数据集类，从而实现高效稳定地加载我们的数据集。(Pytorch官方教程介绍)\n\n# 三、Dataset类\n<font color='#ff0000'>Dataset</font>类是Pytorch中图像数据集中最为重要的一个类，也是Pytorch中所有数据集加载类中应该继承的父类。其中父类中的两个私有成员函数必须被重载，否则将会触发错误提示：\n```python\ndef getitem(self, index):\ndef len(self):\n```\n其中<font color='#ff0000'>  ` __len__  ` </font>应该返回数据集的大小，而<font color='#ff0000'>`__getitem__`</font>应该编写支持数据集索引的函数，例如通过<font color='#ff0000'>`dataset [i]`</font>可以得到数据集中的第<font color='#ff0000'> i+1</font>个数据。\n\n![](https://blog.mviai.com/images/dateset并加载数据集/2.png)\n\n上面所示的这个类，其实也就是起到了封装我们加载函数的作用(对象处理起来更加方便明朗么)，在继承了这个Dataset类之后，我们需要实现的核心功能便是<font color='#ff0000'>  `__getitem__() ` </font>函数，<font color='#ff0000'>  `__getitem__() ` </font>是Python中类的默认成员函数，我们通过实现这个成员函数实现可以通过索引来返回图像数据的功能。\n\n那么怎么得到图像从而去返回呢？当然不会直接将图像数据加载到内存中，相反我们只需要得到图像的地址就足够了，然后在调用的时候通过不同的读取方式读取即可。\n\n关于读取方式：https://oldpan.me/archives/pytorch-transforms-opencv-scikit-image\n\n定义自己的数据集类\n那么我们开始定义一个自己的数据集类吧。\n\n首先继承上面的<font color='#ff0000'>` dataset ` </font>类。然后在<font color='#ff0000'>`__init__() ` </font>方法中得到图像的路径，然后将图像路径组成一个数组，这样在<font color='#ff0000'>`__getitim__() ` </font>中就可以直接读取：\n```python\n# 假设下面这个类是读取船只的数据类\nclass ShipDataset(Dataset):\n    \"\"\"\n     root：图像存放地址根路径\n     augment：是否需要图像增强\n    \"\"\"\n    def __init__(self, root, augment=None):\n        # 这个list存放所有图像的地址\n        self.image_files = np.array([x.path for x in os.scandir(root) if\n            x.name.endswith(\".jpg\") or x.name.endswith(\".png\") or x.name.endswith(\".JPG\")]\n        self.augment = augment   # 是否需要图像增强\n\n    def __getitem__(self, index):\n        # 读取图像数据并返回\n        # 这里的open_image是读取图像函数，可以用PIL、opencv等库进行读取\n        return open_image(self.image_files[index])\n\n    def __len__(self):\n        # 返回图像的数量\n        return len(self.image_files)\n        \n```\n如果我们需要在读取数据的同时对图像进行增强的话，可以在<font color='#ff0000'>  `__getitem__(self, index)`</font>函数中设置图像增强的代码，例如：\n```python\n    def __getitem__(self, index):\n        if self.augment:\n            image = open_image(self.image_files[index])\n            iamge = self.augment(iamge)  # 这里对图像进行了增强\n            return image\n        else:\n            # 如果不进行增强，直接读取图像数据并返回\n            # 这里的open_image是读取图像函数，可以用PIL、opencv等库进行读取\n            return open_image(self.image_files[index])\n            \n```\n当然，图像增强的方法可以使用Pytorch内置的图像增强方式，也可以使用自定义或者其他的图像增强库。这个很灵活，当然要记住一点，在Pytorch中得到的图像必须是<font color='#ff0000'>  `tensor`</font>，也就是说我们还需要再修改一下<font color='#ff0000'>`__getitem__(self, index)`</font>：\n```python\n    def __getitem__(self, index):\n        if self.augment:\n            image = open_image(self.image_files[index])\n            iamge = self.augment(iamge)  # 这里对图像进行了增强\n            return to_tensor(image)      # 将读取到的图像变成tensor再传出\n        else:\n            # 如果不进行增强，直接读取图像数据并返回\n            # 这里的open_image是读取图像函数，可以用PIL、opencv等库进行读取\n            return to_tensor(open_image(self.image_files[index]))\n            ```\n这样，一个基本的数据类就设计好了。\n\n## DataLoader类\n之前所说的<font color='#ff0000'>  `Dataset `</font>类是读入数据集数据并且对读入的数据进行了索引。但是光有这个功能是不够用的，在实际的加载数据集的过程中，我们的数据量往往都很大，对此我们还需要一下几个功能：\n\n* 可以分批次读取：batch-size\n* 可以对数据进行随机读取，可以对数据进行洗牌操作(shuffling)，打乱数据集内数据分布的顺序\n* 可以并行加载数据(利用多核处理器加快载入数据的效率)\n\n这时候就需要<font color='#ff0000'>  `Dataloader`</font>类了，<font color='#ff0000'> `Dataloader`</font>这个类并不需要我们自己设计代码，我们只需要利用<font color='#ff0000'> `DataLoader`</font>类读取我们设计好的<font color='#ff0000'>` ShipDataset`</font>即可：\n```python\n# 利用之前创建好的ShipDataset类去创建数据对象\nship_train_dataset = ShipDataset(data_path, augment=transform)\n# 利用dataloader读取我们的数据对象，并设定batch-size和工作现场\nship_train_loader = DataLoader(ship_train_dataset, batch_size=16, num_workers=4, shuffle=False, **kwargs)\n\n```\n\n这时候通过<font color='#ff0000'> `ship_train_loader`</font>返回的数据就是按照batch-size来返回特定数量的训练数据的tensor，而且此时利用了多线程，读取数据的速度相比单线程快很多。\n\n我们这样读取:\n```python\nfor image in train_loader:\n\n        image = image.to(device)  # 将tensor数据移动到device当中\n        optimizer.zero_grad()\n        output = model(image)     # model模型处理(n,c,h,w)格式的数据，n为batch-size\n        ...\n        \n```\n读取数据的基本模式就是这样，当然在实际中不可能这么简单，我们除了图像数据可能还有json、csv等文件需要我们去读取配合图像完成任务。但是原理基本都是一样的，具体复杂点的例子可以查看官方的例程介绍，这里就不赘述了。\n\n# 创建自己的数据集\n除了设计读取数据集的代码，我们实际的图像数据应该怎么去放置呢？\n\n一般来说，我们自己制作的数据集一般包含三个部分：***train***、***val***和***test***，我们一般放在三个文件夹中，然后利用代码读取。这样是最舒服最方便的了。\n\n但是因为某些原因，我们得到的数据集却不是这样放好的，比如只有一个文件夹，所有文件都放里头了。或者好几个trian的文件夹需要我们去合并。\n\n当然，如果数据集很小的话(例如小于1000个)，那就无所谓了，直接打开文件夹移动就行，但是如果数据为10W以上级别。直接打开文件夹移动文件那电脑会直接卡死(内存32G，6核处理器依旧卡顿)。那么怎么去整体我们的数据，让代码可以顺利训练数据放去训练？\n\n这里有两种方式。\n\n## 1、自己写脚本移动这些文件\n这里以Linux为例，linux下为.sh脚本文件，window则为bat文件。\n\n将下面的脚本代码保存为<font color='#ff0000'> `mm.sh`</font>(随便起的)，自己修改<font color='#ff0000'> `path/from/ `</font>和<font color='#ff0000'> `path/to/ `</font>的地址，tail后面为移动文件的数量。\n```\nfor file in $(ls path/from/ -p | grep -v / | tail -100)\ndo\nmv $file path/to/\ndone\n```\n如果移动过程中遇到下面的问题，试着改编权限再来一次。\n```\nmv: cannot stat '03c5d57c0.jpg': No such file or directory\n```\n\n## 2、编写代码灵活读取train、val、以及test文件夹中的数据\n之前所说的读取方式ShipDataset类仅仅支持一个文件夹的读取，但是我们得到的只是一个文件夹里面包含了我们采集的数据，但是这些数据有比较多(比如50G)，也不好进行移动分成三份(训练集、验证集和测试集)，这时我们需要自己设计编写代码去实现这些功能。\n\n至于如何去编写，大家可以阅读fastai的源代码去理解一下基本思路(很好的思路，可以好好借鉴下)，fastai是一个包装了Pytorch的快速深度学习开发库：https://oldpan.me/archives/fastai-1-0-quick-study\n\n\n本文转自：https://oldpan.me/archives/how-to-load-dataset-in-correctly-pytorch\n","slug":"在Pytorch中正确设计dateset并加载数据集","published":1,"updated":"2021-07-26T09:58:02.584Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m26001wigtacpznq66k","content":"<h1 id=\"一、前言\"><a href=\"#一、前言\" class=\"headerlink\" title=\"一、前言\"></a>一、前言</h1><p>在构建深度学习任务中，最重要的当然是如何设计我们的神经网络。</p>\n<p>但在实际的训练过程中，如何正确编写、使用加载数据集的代码同样是不可缺少的一环，在不同的任务中不同数据格式的任务中，加载数据的代码难免会有差别。为了避免重复编写并且避免一些与算法无关的错误，我们有必要讨论一下如何正确加载数据集。</p>\n<p>这里只讨论如何加载图像格式的数据集，对于文字或者其他的数据集不进行讨论。</p>\n<h1 id=\"二、正确加载数据集\"><a href=\"#二、正确加载数据集\" class=\"headerlink\" title=\"二、正确加载数据集\"></a>二、正确加载数据集</h1><p>加载数据集是深度学习训练过程中不可缺少的一环。一般地，在平常的时候，我们第一个想到的是将所有需要的数据聚成一堆一堆然后通过构建list去一一读取我们的数据：<br><img src=\"http:https://blog.mviai.com/images/dateset并加载数据集/1.png\" alt><br>假如我们编写了上述的图像加载数据集代码，在训练中我们就可以依靠<font color=\"#ff0000\">get_training_data()</font>这个函数来得到batch_size个数据，从而进行训练，乍看下去没什么问题，但是一旦我们的数据量超过1000：</p>\n<ul>\n<li>将所有的图像数据直接加载到numpy数据中会占用大量的内存</li>\n<li>由于需要对数据进行导入，每次训练的时候在数据读取阶段会占用大量的时间</li>\n<li>只使用了单线程去读取，读取效率比较低下</li>\n<li>拓展性很差，如果需要对数据进行一些预处理，只能采取一些不是特别优雅的做法</li>\n</ul>\n<p>既然问题这么多，到底说回来，我们应该如何正确地加载数据集呢？</p>\n<p>本文将会介绍如何根据Pytorch官方提供的数据加载模板，去编写自己的加载数据集类，从而实现高效稳定地加载我们的数据集。(Pytorch官方教程介绍)</p>\n<h1 id=\"三、Dataset类\"><a href=\"#三、Dataset类\" class=\"headerlink\" title=\"三、Dataset类\"></a>三、Dataset类</h1><p><font color=\"#ff0000\">Dataset</font>类是Pytorch中图像数据集中最为重要的一个类，也是Pytorch中所有数据集加载类中应该继承的父类。其中父类中的两个私有成员函数必须被重载，否则将会触发错误提示：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">getitem</span><span class=\"params\">(self, index)</span>:</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">len</span><span class=\"params\">(self)</span>:</span></span><br></pre></td></tr></table></figure></p>\n<p>其中<font color=\"#ff0000\">  <code>__len__</code> </font>应该返回数据集的大小，而<font color=\"#ff0000\"><code>__getitem__</code></font>应该编写支持数据集索引的函数，例如通过<font color=\"#ff0000\"><code>dataset [i]</code></font>可以得到数据集中的第<font color=\"#ff0000\"> i+1</font>个数据。</p>\n<p><img src=\"https://blog.mviai.com/images/dateset并加载数据集/2.png\" alt></p>\n<p>上面所示的这个类，其实也就是起到了封装我们加载函数的作用(对象处理起来更加方便明朗么)，在继承了这个Dataset类之后，我们需要实现的核心功能便是<font color=\"#ff0000\">  <code>__getitem__()</code> </font>函数，<font color=\"#ff0000\">  <code>__getitem__()</code> </font>是Python中类的默认成员函数，我们通过实现这个成员函数实现可以通过索引来返回图像数据的功能。</p>\n<p>那么怎么得到图像从而去返回呢？当然不会直接将图像数据加载到内存中，相反我们只需要得到图像的地址就足够了，然后在调用的时候通过不同的读取方式读取即可。</p>\n<p>关于读取方式：<a href=\"https://oldpan.me/archives/pytorch-transforms-opencv-scikit-image\" target=\"_blank\" rel=\"noopener\">https://oldpan.me/archives/pytorch-transforms-opencv-scikit-image</a></p>\n<p>定义自己的数据集类<br>那么我们开始定义一个自己的数据集类吧。</p>\n<p>首先继承上面的<font color=\"#ff0000\"><code>dataset</code> </font>类。然后在<font color=\"#ff0000\"><code>__init__()</code> </font>方法中得到图像的路径，然后将图像路径组成一个数组，这样在<font color=\"#ff0000\"><code>__getitim__()</code> </font>中就可以直接读取：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 假设下面这个类是读取船只的数据类</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ShipDataset</span><span class=\"params\">(Dataset)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">     root：图像存放地址根路径</span></span><br><span class=\"line\"><span class=\"string\">     augment：是否需要图像增强</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, root, augment=None)</span>:</span></span><br><span class=\"line\">        <span class=\"comment\"># 这个list存放所有图像的地址</span></span><br><span class=\"line\">        self.image_files = np.array([x.path <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> os.scandir(root) <span class=\"keyword\">if</span></span><br><span class=\"line\">            x.name.endswith(<span class=\"string\">\".jpg\"</span>) <span class=\"keyword\">or</span> x.name.endswith(<span class=\"string\">\".png\"</span>) <span class=\"keyword\">or</span> x.name.endswith(<span class=\"string\">\".JPG\"</span>)]</span><br><span class=\"line\">        self.augment = augment   <span class=\"comment\"># 是否需要图像增强</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__getitem__</span><span class=\"params\">(self, index)</span>:</span></span><br><span class=\"line\">        <span class=\"comment\"># 读取图像数据并返回</span></span><br><span class=\"line\">        <span class=\"comment\"># 这里的open_image是读取图像函数，可以用PIL、opencv等库进行读取</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> open_image(self.image_files[index])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__len__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"comment\"># 返回图像的数量</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> len(self.image_files)</span><br></pre></td></tr></table></figure></p>\n<p>如果我们需要在读取数据的同时对图像进行增强的话，可以在<font color=\"#ff0000\">  <code>__getitem__(self, index)</code></font>函数中设置图像增强的代码，例如：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__getitem__</span><span class=\"params\">(self, index)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> self.augment:</span><br><span class=\"line\">        image = open_image(self.image_files[index])</span><br><span class=\"line\">        iamge = self.augment(iamge)  <span class=\"comment\"># 这里对图像进行了增强</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> image</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"comment\"># 如果不进行增强，直接读取图像数据并返回</span></span><br><span class=\"line\">        <span class=\"comment\"># 这里的open_image是读取图像函数，可以用PIL、opencv等库进行读取</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> open_image(self.image_files[index])</span><br></pre></td></tr></table></figure></p>\n<p>当然，图像增强的方法可以使用Pytorch内置的图像增强方式，也可以使用自定义或者其他的图像增强库。这个很灵活，当然要记住一点，在Pytorch中得到的图像必须是<font color=\"#ff0000\">  <code>tensor</code></font>，也就是说我们还需要再修改一下<font color=\"#ff0000\"><code>__getitem__(self, index)</code></font>：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__getitem__</span><span class=\"params\">(self, index)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> self.augment:</span><br><span class=\"line\">        image = open_image(self.image_files[index])</span><br><span class=\"line\">        iamge = self.augment(iamge)  <span class=\"comment\"># 这里对图像进行了增强</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> to_tensor(image)      <span class=\"comment\"># 将读取到的图像变成tensor再传出</span></span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"comment\"># 如果不进行增强，直接读取图像数据并返回</span></span><br><span class=\"line\">        <span class=\"comment\"># 这里的open_image是读取图像函数，可以用PIL、opencv等库进行读取</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> to_tensor(open_image(self.image_files[index]))</span><br></pre></td></tr></table></figure></p>\n<p>这样，一个基本的数据类就设计好了。</p>\n<h2 id=\"DataLoader类\"><a href=\"#DataLoader类\" class=\"headerlink\" title=\"DataLoader类\"></a>DataLoader类</h2><p>之前所说的<font color=\"#ff0000\">  <code>Dataset</code></font>类是读入数据集数据并且对读入的数据进行了索引。但是光有这个功能是不够用的，在实际的加载数据集的过程中，我们的数据量往往都很大，对此我们还需要一下几个功能：</p>\n<ul>\n<li>可以分批次读取：batch-size</li>\n<li>可以对数据进行随机读取，可以对数据进行洗牌操作(shuffling)，打乱数据集内数据分布的顺序</li>\n<li>可以并行加载数据(利用多核处理器加快载入数据的效率)</li>\n</ul>\n<p>这时候就需要<font color=\"#ff0000\">  <code>Dataloader</code></font>类了，<font color=\"#ff0000\"> <code>Dataloader</code></font>这个类并不需要我们自己设计代码，我们只需要利用<font color=\"#ff0000\"> <code>DataLoader</code></font>类读取我们设计好的<font color=\"#ff0000\"><code>ShipDataset</code></font>即可：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 利用之前创建好的ShipDataset类去创建数据对象</span></span><br><span class=\"line\">ship_train_dataset = ShipDataset(data_path, augment=transform)</span><br><span class=\"line\"><span class=\"comment\"># 利用dataloader读取我们的数据对象，并设定batch-size和工作现场</span></span><br><span class=\"line\">ship_train_loader = DataLoader(ship_train_dataset, batch_size=<span class=\"number\">16</span>, num_workers=<span class=\"number\">4</span>, shuffle=<span class=\"literal\">False</span>, **kwargs)</span><br></pre></td></tr></table></figure></p>\n<p>这时候通过<font color=\"#ff0000\"> <code>ship_train_loader</code></font>返回的数据就是按照batch-size来返回特定数量的训练数据的tensor，而且此时利用了多线程，读取数据的速度相比单线程快很多。</p>\n<p>我们这样读取:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> image <span class=\"keyword\">in</span> train_loader:</span><br><span class=\"line\"></span><br><span class=\"line\">        image = image.to(device)  <span class=\"comment\"># 将tensor数据移动到device当中</span></span><br><span class=\"line\">        optimizer.zero_grad()</span><br><span class=\"line\">        output = model(image)     <span class=\"comment\"># model模型处理(n,c,h,w)格式的数据，n为batch-size</span></span><br><span class=\"line\">        ...</span><br></pre></td></tr></table></figure></p>\n<p>读取数据的基本模式就是这样，当然在实际中不可能这么简单，我们除了图像数据可能还有json、csv等文件需要我们去读取配合图像完成任务。但是原理基本都是一样的，具体复杂点的例子可以查看官方的例程介绍，这里就不赘述了。</p>\n<h1 id=\"创建自己的数据集\"><a href=\"#创建自己的数据集\" class=\"headerlink\" title=\"创建自己的数据集\"></a>创建自己的数据集</h1><p>除了设计读取数据集的代码，我们实际的图像数据应该怎么去放置呢？</p>\n<p>一般来说，我们自己制作的数据集一般包含三个部分：<strong><em>train</em></strong>、<strong><em>val</em></strong>和<strong><em>test</em></strong>，我们一般放在三个文件夹中，然后利用代码读取。这样是最舒服最方便的了。</p>\n<p>但是因为某些原因，我们得到的数据集却不是这样放好的，比如只有一个文件夹，所有文件都放里头了。或者好几个trian的文件夹需要我们去合并。</p>\n<p>当然，如果数据集很小的话(例如小于1000个)，那就无所谓了，直接打开文件夹移动就行，但是如果数据为10W以上级别。直接打开文件夹移动文件那电脑会直接卡死(内存32G，6核处理器依旧卡顿)。那么怎么去整体我们的数据，让代码可以顺利训练数据放去训练？</p>\n<p>这里有两种方式。</p>\n<h2 id=\"1、自己写脚本移动这些文件\"><a href=\"#1、自己写脚本移动这些文件\" class=\"headerlink\" title=\"1、自己写脚本移动这些文件\"></a>1、自己写脚本移动这些文件</h2><p>这里以Linux为例，linux下为.sh脚本文件，window则为bat文件。</p>\n<p>将下面的脚本代码保存为<font color=\"#ff0000\"> <code>mm.sh</code></font>(随便起的)，自己修改<font color=\"#ff0000\"> <code>path/from/</code></font>和<font color=\"#ff0000\"> <code>path/to/</code></font>的地址，tail后面为移动文件的数量。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">for file in $(ls path/from/ -p | grep -v / | tail -100)</span><br><span class=\"line\">do</span><br><span class=\"line\">mv $file path/to/</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure></p>\n<p>如果移动过程中遇到下面的问题，试着改编权限再来一次。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mv: cannot stat &apos;03c5d57c0.jpg&apos;: No such file or directory</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"2、编写代码灵活读取train、val、以及test文件夹中的数据\"><a href=\"#2、编写代码灵活读取train、val、以及test文件夹中的数据\" class=\"headerlink\" title=\"2、编写代码灵活读取train、val、以及test文件夹中的数据\"></a>2、编写代码灵活读取train、val、以及test文件夹中的数据</h2><p>之前所说的读取方式ShipDataset类仅仅支持一个文件夹的读取，但是我们得到的只是一个文件夹里面包含了我们采集的数据，但是这些数据有比较多(比如50G)，也不好进行移动分成三份(训练集、验证集和测试集)，这时我们需要自己设计编写代码去实现这些功能。</p>\n<p>至于如何去编写，大家可以阅读fastai的源代码去理解一下基本思路(很好的思路，可以好好借鉴下)，fastai是一个包装了Pytorch的快速深度学习开发库：<a href=\"https://oldpan.me/archives/fastai-1-0-quick-study\" target=\"_blank\" rel=\"noopener\">https://oldpan.me/archives/fastai-1-0-quick-study</a></p>\n<p>本文转自：<a href=\"https://oldpan.me/archives/how-to-load-dataset-in-correctly-pytorch\" target=\"_blank\" rel=\"noopener\">https://oldpan.me/archives/how-to-load-dataset-in-correctly-pytorch</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"一、前言\"><a href=\"#一、前言\" class=\"headerlink\" title=\"一、前言\"></a>一、前言</h1><p>在构建深度学习任务中，最重要的当然是如何设计我们的神经网络。</p>\n<p>但在实际的训练过程中，如何正确编写、使用加载数据集的代码同样是不可缺少的一环，在不同的任务中不同数据格式的任务中，加载数据的代码难免会有差别。为了避免重复编写并且避免一些与算法无关的错误，我们有必要讨论一下如何正确加载数据集。</p>\n<p>这里只讨论如何加载图像格式的数据集，对于文字或者其他的数据集不进行讨论。</p>\n<h1 id=\"二、正确加载数据集\"><a href=\"#二、正确加载数据集\" class=\"headerlink\" title=\"二、正确加载数据集\"></a>二、正确加载数据集</h1><p>加载数据集是深度学习训练过程中不可缺少的一环。一般地，在平常的时候，我们第一个想到的是将所有需要的数据聚成一堆一堆然后通过构建list去一一读取我们的数据：<br><img src=\"http:https://blog.mviai.com/images/dateset并加载数据集/1.png\" alt><br>假如我们编写了上述的图像加载数据集代码，在训练中我们就可以依靠<font color=\"#ff0000\">get_training_data()</font>这个函数来得到batch_size个数据，从而进行训练，乍看下去没什么问题，但是一旦我们的数据量超过1000：</p>\n<ul>\n<li>将所有的图像数据直接加载到numpy数据中会占用大量的内存</li>\n<li>由于需要对数据进行导入，每次训练的时候在数据读取阶段会占用大量的时间</li>\n<li>只使用了单线程去读取，读取效率比较低下</li>\n<li>拓展性很差，如果需要对数据进行一些预处理，只能采取一些不是特别优雅的做法</li>\n</ul>\n<p>既然问题这么多，到底说回来，我们应该如何正确地加载数据集呢？</p>\n<p>本文将会介绍如何根据Pytorch官方提供的数据加载模板，去编写自己的加载数据集类，从而实现高效稳定地加载我们的数据集。(Pytorch官方教程介绍)</p>\n<h1 id=\"三、Dataset类\"><a href=\"#三、Dataset类\" class=\"headerlink\" title=\"三、Dataset类\"></a>三、Dataset类</h1><p><font color=\"#ff0000\">Dataset</font>类是Pytorch中图像数据集中最为重要的一个类，也是Pytorch中所有数据集加载类中应该继承的父类。其中父类中的两个私有成员函数必须被重载，否则将会触发错误提示：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">getitem</span><span class=\"params\">(self, index)</span>:</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">len</span><span class=\"params\">(self)</span>:</span></span><br></pre></td></tr></table></figure></p>\n<p>其中<font color=\"#ff0000\">  <code>__len__</code> </font>应该返回数据集的大小，而<font color=\"#ff0000\"><code>__getitem__</code></font>应该编写支持数据集索引的函数，例如通过<font color=\"#ff0000\"><code>dataset [i]</code></font>可以得到数据集中的第<font color=\"#ff0000\"> i+1</font>个数据。</p>\n<p><img src=\"https://blog.mviai.com/images/dateset并加载数据集/2.png\" alt></p>\n<p>上面所示的这个类，其实也就是起到了封装我们加载函数的作用(对象处理起来更加方便明朗么)，在继承了这个Dataset类之后，我们需要实现的核心功能便是<font color=\"#ff0000\">  <code>__getitem__()</code> </font>函数，<font color=\"#ff0000\">  <code>__getitem__()</code> </font>是Python中类的默认成员函数，我们通过实现这个成员函数实现可以通过索引来返回图像数据的功能。</p>\n<p>那么怎么得到图像从而去返回呢？当然不会直接将图像数据加载到内存中，相反我们只需要得到图像的地址就足够了，然后在调用的时候通过不同的读取方式读取即可。</p>\n<p>关于读取方式：<a href=\"https://oldpan.me/archives/pytorch-transforms-opencv-scikit-image\" target=\"_blank\" rel=\"noopener\">https://oldpan.me/archives/pytorch-transforms-opencv-scikit-image</a></p>\n<p>定义自己的数据集类<br>那么我们开始定义一个自己的数据集类吧。</p>\n<p>首先继承上面的<font color=\"#ff0000\"><code>dataset</code> </font>类。然后在<font color=\"#ff0000\"><code>__init__()</code> </font>方法中得到图像的路径，然后将图像路径组成一个数组，这样在<font color=\"#ff0000\"><code>__getitim__()</code> </font>中就可以直接读取：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 假设下面这个类是读取船只的数据类</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ShipDataset</span><span class=\"params\">(Dataset)</span>:</span></span><br><span class=\"line\">    <span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">     root：图像存放地址根路径</span></span><br><span class=\"line\"><span class=\"string\">     augment：是否需要图像增强</span></span><br><span class=\"line\"><span class=\"string\">    \"\"\"</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, root, augment=None)</span>:</span></span><br><span class=\"line\">        <span class=\"comment\"># 这个list存放所有图像的地址</span></span><br><span class=\"line\">        self.image_files = np.array([x.path <span class=\"keyword\">for</span> x <span class=\"keyword\">in</span> os.scandir(root) <span class=\"keyword\">if</span></span><br><span class=\"line\">            x.name.endswith(<span class=\"string\">\".jpg\"</span>) <span class=\"keyword\">or</span> x.name.endswith(<span class=\"string\">\".png\"</span>) <span class=\"keyword\">or</span> x.name.endswith(<span class=\"string\">\".JPG\"</span>)]</span><br><span class=\"line\">        self.augment = augment   <span class=\"comment\"># 是否需要图像增强</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__getitem__</span><span class=\"params\">(self, index)</span>:</span></span><br><span class=\"line\">        <span class=\"comment\"># 读取图像数据并返回</span></span><br><span class=\"line\">        <span class=\"comment\"># 这里的open_image是读取图像函数，可以用PIL、opencv等库进行读取</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> open_image(self.image_files[index])</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__len__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        <span class=\"comment\"># 返回图像的数量</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> len(self.image_files)</span><br></pre></td></tr></table></figure></p>\n<p>如果我们需要在读取数据的同时对图像进行增强的话，可以在<font color=\"#ff0000\">  <code>__getitem__(self, index)</code></font>函数中设置图像增强的代码，例如：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__getitem__</span><span class=\"params\">(self, index)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> self.augment:</span><br><span class=\"line\">        image = open_image(self.image_files[index])</span><br><span class=\"line\">        iamge = self.augment(iamge)  <span class=\"comment\"># 这里对图像进行了增强</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> image</span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"comment\"># 如果不进行增强，直接读取图像数据并返回</span></span><br><span class=\"line\">        <span class=\"comment\"># 这里的open_image是读取图像函数，可以用PIL、opencv等库进行读取</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> open_image(self.image_files[index])</span><br></pre></td></tr></table></figure></p>\n<p>当然，图像增强的方法可以使用Pytorch内置的图像增强方式，也可以使用自定义或者其他的图像增强库。这个很灵活，当然要记住一点，在Pytorch中得到的图像必须是<font color=\"#ff0000\">  <code>tensor</code></font>，也就是说我们还需要再修改一下<font color=\"#ff0000\"><code>__getitem__(self, index)</code></font>：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__getitem__</span><span class=\"params\">(self, index)</span>:</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> self.augment:</span><br><span class=\"line\">        image = open_image(self.image_files[index])</span><br><span class=\"line\">        iamge = self.augment(iamge)  <span class=\"comment\"># 这里对图像进行了增强</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> to_tensor(image)      <span class=\"comment\"># 将读取到的图像变成tensor再传出</span></span><br><span class=\"line\">    <span class=\"keyword\">else</span>:</span><br><span class=\"line\">        <span class=\"comment\"># 如果不进行增强，直接读取图像数据并返回</span></span><br><span class=\"line\">        <span class=\"comment\"># 这里的open_image是读取图像函数，可以用PIL、opencv等库进行读取</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> to_tensor(open_image(self.image_files[index]))</span><br></pre></td></tr></table></figure></p>\n<p>这样，一个基本的数据类就设计好了。</p>\n<h2 id=\"DataLoader类\"><a href=\"#DataLoader类\" class=\"headerlink\" title=\"DataLoader类\"></a>DataLoader类</h2><p>之前所说的<font color=\"#ff0000\">  <code>Dataset</code></font>类是读入数据集数据并且对读入的数据进行了索引。但是光有这个功能是不够用的，在实际的加载数据集的过程中，我们的数据量往往都很大，对此我们还需要一下几个功能：</p>\n<ul>\n<li>可以分批次读取：batch-size</li>\n<li>可以对数据进行随机读取，可以对数据进行洗牌操作(shuffling)，打乱数据集内数据分布的顺序</li>\n<li>可以并行加载数据(利用多核处理器加快载入数据的效率)</li>\n</ul>\n<p>这时候就需要<font color=\"#ff0000\">  <code>Dataloader</code></font>类了，<font color=\"#ff0000\"> <code>Dataloader</code></font>这个类并不需要我们自己设计代码，我们只需要利用<font color=\"#ff0000\"> <code>DataLoader</code></font>类读取我们设计好的<font color=\"#ff0000\"><code>ShipDataset</code></font>即可：<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># 利用之前创建好的ShipDataset类去创建数据对象</span></span><br><span class=\"line\">ship_train_dataset = ShipDataset(data_path, augment=transform)</span><br><span class=\"line\"><span class=\"comment\"># 利用dataloader读取我们的数据对象，并设定batch-size和工作现场</span></span><br><span class=\"line\">ship_train_loader = DataLoader(ship_train_dataset, batch_size=<span class=\"number\">16</span>, num_workers=<span class=\"number\">4</span>, shuffle=<span class=\"literal\">False</span>, **kwargs)</span><br></pre></td></tr></table></figure></p>\n<p>这时候通过<font color=\"#ff0000\"> <code>ship_train_loader</code></font>返回的数据就是按照batch-size来返回特定数量的训练数据的tensor，而且此时利用了多线程，读取数据的速度相比单线程快很多。</p>\n<p>我们这样读取:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">for</span> image <span class=\"keyword\">in</span> train_loader:</span><br><span class=\"line\"></span><br><span class=\"line\">        image = image.to(device)  <span class=\"comment\"># 将tensor数据移动到device当中</span></span><br><span class=\"line\">        optimizer.zero_grad()</span><br><span class=\"line\">        output = model(image)     <span class=\"comment\"># model模型处理(n,c,h,w)格式的数据，n为batch-size</span></span><br><span class=\"line\">        ...</span><br></pre></td></tr></table></figure></p>\n<p>读取数据的基本模式就是这样，当然在实际中不可能这么简单，我们除了图像数据可能还有json、csv等文件需要我们去读取配合图像完成任务。但是原理基本都是一样的，具体复杂点的例子可以查看官方的例程介绍，这里就不赘述了。</p>\n<h1 id=\"创建自己的数据集\"><a href=\"#创建自己的数据集\" class=\"headerlink\" title=\"创建自己的数据集\"></a>创建自己的数据集</h1><p>除了设计读取数据集的代码，我们实际的图像数据应该怎么去放置呢？</p>\n<p>一般来说，我们自己制作的数据集一般包含三个部分：<strong><em>train</em></strong>、<strong><em>val</em></strong>和<strong><em>test</em></strong>，我们一般放在三个文件夹中，然后利用代码读取。这样是最舒服最方便的了。</p>\n<p>但是因为某些原因，我们得到的数据集却不是这样放好的，比如只有一个文件夹，所有文件都放里头了。或者好几个trian的文件夹需要我们去合并。</p>\n<p>当然，如果数据集很小的话(例如小于1000个)，那就无所谓了，直接打开文件夹移动就行，但是如果数据为10W以上级别。直接打开文件夹移动文件那电脑会直接卡死(内存32G，6核处理器依旧卡顿)。那么怎么去整体我们的数据，让代码可以顺利训练数据放去训练？</p>\n<p>这里有两种方式。</p>\n<h2 id=\"1、自己写脚本移动这些文件\"><a href=\"#1、自己写脚本移动这些文件\" class=\"headerlink\" title=\"1、自己写脚本移动这些文件\"></a>1、自己写脚本移动这些文件</h2><p>这里以Linux为例，linux下为.sh脚本文件，window则为bat文件。</p>\n<p>将下面的脚本代码保存为<font color=\"#ff0000\"> <code>mm.sh</code></font>(随便起的)，自己修改<font color=\"#ff0000\"> <code>path/from/</code></font>和<font color=\"#ff0000\"> <code>path/to/</code></font>的地址，tail后面为移动文件的数量。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">for file in $(ls path/from/ -p | grep -v / | tail -100)</span><br><span class=\"line\">do</span><br><span class=\"line\">mv $file path/to/</span><br><span class=\"line\">done</span><br></pre></td></tr></table></figure></p>\n<p>如果移动过程中遇到下面的问题，试着改编权限再来一次。<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">mv: cannot stat &apos;03c5d57c0.jpg&apos;: No such file or directory</span><br></pre></td></tr></table></figure></p>\n<h2 id=\"2、编写代码灵活读取train、val、以及test文件夹中的数据\"><a href=\"#2、编写代码灵活读取train、val、以及test文件夹中的数据\" class=\"headerlink\" title=\"2、编写代码灵活读取train、val、以及test文件夹中的数据\"></a>2、编写代码灵活读取train、val、以及test文件夹中的数据</h2><p>之前所说的读取方式ShipDataset类仅仅支持一个文件夹的读取，但是我们得到的只是一个文件夹里面包含了我们采集的数据，但是这些数据有比较多(比如50G)，也不好进行移动分成三份(训练集、验证集和测试集)，这时我们需要自己设计编写代码去实现这些功能。</p>\n<p>至于如何去编写，大家可以阅读fastai的源代码去理解一下基本思路(很好的思路，可以好好借鉴下)，fastai是一个包装了Pytorch的快速深度学习开发库：<a href=\"https://oldpan.me/archives/fastai-1-0-quick-study\" target=\"_blank\" rel=\"noopener\">https://oldpan.me/archives/fastai-1-0-quick-study</a></p>\n<p>本文转自：<a href=\"https://oldpan.me/archives/how-to-load-dataset-in-correctly-pytorch\" target=\"_blank\" rel=\"noopener\">https://oldpan.me/archives/how-to-load-dataset-in-correctly-pytorch</a></p>\n"},{"title":"基于神经网络的入侵检测提取异常行为特征—绪论","url":"179.html","id":"179","date":"2018-04-17T05:04:08.000Z","_content":"\n\n1.兴趣来源\n------\n\n在学习计算机网络安全中的异常检测时，看到利用神经网路使用自适应学习技术来提取异常行为特征。 目前有两种主要的入侵检测，一是误用检测，二是异常检测。误用检测根据预定模式，最适用于对已知模式的可靠检测，但漏报率较高；异常检测基于一个假定（用户行为是可预测的，遵循一致性模式的，且随这用户事件的增加，自适应用户行为的变化），简而言之，就是可以检测未知攻击行为，但误报率高。 最早提出使用神经网络来构造系统/用户行为模式的是Fox，他使用Kohonen的自主学习算法（Self Organizing Map，SOM）来发现数据中隐藏的结构。\n\n2.选用Snort原因\n-----------\n\n1.Snort是免费开源软件。 2.Sonrt是用C语言编写。 3.Sonrt轻量级网络入侵检测软件。 4.Snort简单，高效，灵活。 5.Snort支持多操作平台。 6.支持多种数据库。\n\n3.Snort体系结构\n-----------\n\nSnort体系结构上由数据包捕获和解码，检测引擎，日志和报警三个子系统组成。\n\n4.神经网络检测构思模型\n------------\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/04/捕获到的网络数据流.png) 待续。。。\n","source":"_posts/基于神经网络的入侵检测提取异常行为特征—绪论.md","raw":"---\ntitle: 基于神经网络的入侵检测提取异常行为特征—绪论\nurl: 179.html\nid: 179\ncategories:\n  - 感悟\ndate: 2018-04-17 13:04:08\ntags:\n---\n\n\n1.兴趣来源\n------\n\n在学习计算机网络安全中的异常检测时，看到利用神经网路使用自适应学习技术来提取异常行为特征。 目前有两种主要的入侵检测，一是误用检测，二是异常检测。误用检测根据预定模式，最适用于对已知模式的可靠检测，但漏报率较高；异常检测基于一个假定（用户行为是可预测的，遵循一致性模式的，且随这用户事件的增加，自适应用户行为的变化），简而言之，就是可以检测未知攻击行为，但误报率高。 最早提出使用神经网络来构造系统/用户行为模式的是Fox，他使用Kohonen的自主学习算法（Self Organizing Map，SOM）来发现数据中隐藏的结构。\n\n2.选用Snort原因\n-----------\n\n1.Snort是免费开源软件。 2.Sonrt是用C语言编写。 3.Sonrt轻量级网络入侵检测软件。 4.Snort简单，高效，灵活。 5.Snort支持多操作平台。 6.支持多种数据库。\n\n3.Snort体系结构\n-----------\n\nSnort体系结构上由数据包捕获和解码，检测引擎，日志和报警三个子系统组成。\n\n4.神经网络检测构思模型\n------------\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/04/捕获到的网络数据流.png) 待续。。。\n","slug":"基于神经网络的入侵检测提取异常行为特征—绪论","published":1,"updated":"2021-07-26T09:58:02.580Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m27001yigtafjjiu2s9","content":"<h2 id=\"1-兴趣来源\"><a href=\"#1-兴趣来源\" class=\"headerlink\" title=\"1.兴趣来源\"></a>1.兴趣来源</h2><p>在学习计算机网络安全中的异常检测时，看到利用神经网路使用自适应学习技术来提取异常行为特征。 目前有两种主要的入侵检测，一是误用检测，二是异常检测。误用检测根据预定模式，最适用于对已知模式的可靠检测，但漏报率较高；异常检测基于一个假定（用户行为是可预测的，遵循一致性模式的，且随这用户事件的增加，自适应用户行为的变化），简而言之，就是可以检测未知攻击行为，但误报率高。 最早提出使用神经网络来构造系统/用户行为模式的是Fox，他使用Kohonen的自主学习算法（Self Organizing Map，SOM）来发现数据中隐藏的结构。</p>\n<h2 id=\"2-选用Snort原因\"><a href=\"#2-选用Snort原因\" class=\"headerlink\" title=\"2.选用Snort原因\"></a>2.选用Snort原因</h2><p>1.Snort是免费开源软件。 2.Sonrt是用C语言编写。 3.Sonrt轻量级网络入侵检测软件。 4.Snort简单，高效，灵活。 5.Snort支持多操作平台。 6.支持多种数据库。</p>\n<h2 id=\"3-Snort体系结构\"><a href=\"#3-Snort体系结构\" class=\"headerlink\" title=\"3.Snort体系结构\"></a>3.Snort体系结构</h2><p>Snort体系结构上由数据包捕获和解码，检测引擎，日志和报警三个子系统组成。</p>\n<h2 id=\"4-神经网络检测构思模型\"><a href=\"#4-神经网络检测构思模型\" class=\"headerlink\" title=\"4.神经网络检测构思模型\"></a>4.神经网络检测构思模型</h2><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/捕获到的网络数据流.png\" alt> 待续。。。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"1-兴趣来源\"><a href=\"#1-兴趣来源\" class=\"headerlink\" title=\"1.兴趣来源\"></a>1.兴趣来源</h2><p>在学习计算机网络安全中的异常检测时，看到利用神经网路使用自适应学习技术来提取异常行为特征。 目前有两种主要的入侵检测，一是误用检测，二是异常检测。误用检测根据预定模式，最适用于对已知模式的可靠检测，但漏报率较高；异常检测基于一个假定（用户行为是可预测的，遵循一致性模式的，且随这用户事件的增加，自适应用户行为的变化），简而言之，就是可以检测未知攻击行为，但误报率高。 最早提出使用神经网络来构造系统/用户行为模式的是Fox，他使用Kohonen的自主学习算法（Self Organizing Map，SOM）来发现数据中隐藏的结构。</p>\n<h2 id=\"2-选用Snort原因\"><a href=\"#2-选用Snort原因\" class=\"headerlink\" title=\"2.选用Snort原因\"></a>2.选用Snort原因</h2><p>1.Snort是免费开源软件。 2.Sonrt是用C语言编写。 3.Sonrt轻量级网络入侵检测软件。 4.Snort简单，高效，灵活。 5.Snort支持多操作平台。 6.支持多种数据库。</p>\n<h2 id=\"3-Snort体系结构\"><a href=\"#3-Snort体系结构\" class=\"headerlink\" title=\"3.Snort体系结构\"></a>3.Snort体系结构</h2><p>Snort体系结构上由数据包捕获和解码，检测引擎，日志和报警三个子系统组成。</p>\n<h2 id=\"4-神经网络检测构思模型\"><a href=\"#4-神经网络检测构思模型\" class=\"headerlink\" title=\"4.神经网络检测构思模型\"></a>4.神经网络检测构思模型</h2><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/捕获到的网络数据流.png\" alt> 待续。。。</p>\n"},{"title":"如何使用思维导图！","toc":false,"url":"172.html","id":"172","date":"2018-04-11T05:56:13.000Z","_content":"\n\n\n当你看到密密麻麻思维导图是不是很恶心！（密集恐惧症）\n--------------------------\n\n如图: ![](https://blog.mviai.com/images/wp-content/uploads/2018/04/物理层-95x150.png)\n\n所以希望大家下载思维导图文件（不是图片）！\n---------------------\n\n### 下载用相应软件打开：\n\n如图：\n\n### ![](https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-11_133904-150x113.png)\n\n### 然后点分类图右边的小圈圈，进行展开：\n\n如图：![](https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-11_133912-150x107.png)\n\n#### 然后想看哪方面，再点相应分类的小圈圈，再次进行展开 ：\n\n如图：![](https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-11_133931-150x90.png) **所以大家别在盯着图片看 ，只能看概括 ，自己点点，记忆更深刻，当然如果你能直接看图就能理解，那就很666**   软件有免费版，支持mac Windows Linux 手机。官网直接下载，无需激活直接就可以用。[链接点我](http://www.xmindchina.net/xiazai.html) \\[/success\\]","source":"_posts/如何使用思维导图.md","raw":"---\ntitle: 如何使用思维导图！\ntags:\n  - 思维导图\ncategories:\n  - 工具\n  - 日常工具\n  - 思维导图\ntoc: false\nurl: 172.html\nid: '172'\ndate: 2018-04-11 13:56:13\n---\n\n\n\n当你看到密密麻麻思维导图是不是很恶心！（密集恐惧症）\n--------------------------\n\n如图: ![](https://blog.mviai.com/images/wp-content/uploads/2018/04/物理层-95x150.png)\n\n所以希望大家下载思维导图文件（不是图片）！\n---------------------\n\n### 下载用相应软件打开：\n\n如图：\n\n### ![](https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-11_133904-150x113.png)\n\n### 然后点分类图右边的小圈圈，进行展开：\n\n如图：![](https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-11_133912-150x107.png)\n\n#### 然后想看哪方面，再点相应分类的小圈圈，再次进行展开 ：\n\n如图：![](https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-11_133931-150x90.png) **所以大家别在盯着图片看 ，只能看概括 ，自己点点，记忆更深刻，当然如果你能直接看图就能理解，那就很666**   软件有免费版，支持mac Windows Linux 手机。官网直接下载，无需激活直接就可以用。[链接点我](http://www.xmindchina.net/xiazai.html) \\[/success\\]","slug":"如何使用思维导图","published":1,"updated":"2021-07-26T10:04:15.989Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m280022igta03psn4v8","content":"<h2 id=\"当你看到密密麻麻思维导图是不是很恶心！（密集恐惧症）\"><a href=\"#当你看到密密麻麻思维导图是不是很恶心！（密集恐惧症）\" class=\"headerlink\" title=\"当你看到密密麻麻思维导图是不是很恶心！（密集恐惧症）\"></a>当你看到密密麻麻思维导图是不是很恶心！（密集恐惧症）</h2><p>如图: <img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/物理层-95x150.png\" alt></p>\n<h2 id=\"所以希望大家下载思维导图文件（不是图片）！\"><a href=\"#所以希望大家下载思维导图文件（不是图片）！\" class=\"headerlink\" title=\"所以希望大家下载思维导图文件（不是图片）！\"></a>所以希望大家下载思维导图文件（不是图片）！</h2><h3 id=\"下载用相应软件打开：\"><a href=\"#下载用相应软件打开：\" class=\"headerlink\" title=\"下载用相应软件打开：\"></a>下载用相应软件打开：</h3><p>如图：</p>\n<h3 id><a href=\"#\" class=\"headerlink\" title></a><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-11_133904-150x113.png\" alt></h3><h3 id=\"然后点分类图右边的小圈圈，进行展开：\"><a href=\"#然后点分类图右边的小圈圈，进行展开：\" class=\"headerlink\" title=\"然后点分类图右边的小圈圈，进行展开：\"></a>然后点分类图右边的小圈圈，进行展开：</h3><p>如图：<img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-11_133912-150x107.png\" alt></p>\n<h4 id=\"然后想看哪方面，再点相应分类的小圈圈，再次进行展开-：\"><a href=\"#然后想看哪方面，再点相应分类的小圈圈，再次进行展开-：\" class=\"headerlink\" title=\"然后想看哪方面，再点相应分类的小圈圈，再次进行展开 ：\"></a>然后想看哪方面，再点相应分类的小圈圈，再次进行展开 ：</h4><p>如图：<img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-11_133931-150x90.png\" alt> <strong>所以大家别在盯着图片看 ，只能看概括 ，自己点点，记忆更深刻，当然如果你能直接看图就能理解，那就很666</strong>   软件有免费版，支持mac Windows Linux 手机。官网直接下载，无需激活直接就可以用。<a href=\"http://www.xmindchina.net/xiazai.html\" target=\"_blank\" rel=\"noopener\">链接点我</a> [/success]</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"当你看到密密麻麻思维导图是不是很恶心！（密集恐惧症）\"><a href=\"#当你看到密密麻麻思维导图是不是很恶心！（密集恐惧症）\" class=\"headerlink\" title=\"当你看到密密麻麻思维导图是不是很恶心！（密集恐惧症）\"></a>当你看到密密麻麻思维导图是不是很恶心！（密集恐惧症）</h2><p>如图: <img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/物理层-95x150.png\" alt></p>\n<h2 id=\"所以希望大家下载思维导图文件（不是图片）！\"><a href=\"#所以希望大家下载思维导图文件（不是图片）！\" class=\"headerlink\" title=\"所以希望大家下载思维导图文件（不是图片）！\"></a>所以希望大家下载思维导图文件（不是图片）！</h2><h3 id=\"下载用相应软件打开：\"><a href=\"#下载用相应软件打开：\" class=\"headerlink\" title=\"下载用相应软件打开：\"></a>下载用相应软件打开：</h3><p>如图：</p>\n<h3 id><a href=\"#\" class=\"headerlink\" title></a><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-11_133904-150x113.png\" alt></h3><h3 id=\"然后点分类图右边的小圈圈，进行展开：\"><a href=\"#然后点分类图右边的小圈圈，进行展开：\" class=\"headerlink\" title=\"然后点分类图右边的小圈圈，进行展开：\"></a>然后点分类图右边的小圈圈，进行展开：</h3><p>如图：<img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-11_133912-150x107.png\" alt></p>\n<h4 id=\"然后想看哪方面，再点相应分类的小圈圈，再次进行展开-：\"><a href=\"#然后想看哪方面，再点相应分类的小圈圈，再次进行展开-：\" class=\"headerlink\" title=\"然后想看哪方面，再点相应分类的小圈圈，再次进行展开 ：\"></a>然后想看哪方面，再点相应分类的小圈圈，再次进行展开 ：</h4><p>如图：<img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-11_133931-150x90.png\" alt> <strong>所以大家别在盯着图片看 ，只能看概括 ，自己点点，记忆更深刻，当然如果你能直接看图就能理解，那就很666</strong>   软件有免费版，支持mac Windows Linux 手机。官网直接下载，无需激活直接就可以用。<a href=\"http://www.xmindchina.net/xiazai.html\" target=\"_blank\" rel=\"noopener\">链接点我</a> [/success]</p>\n"},{"title":"将数据归一化到任意区间范围的方法","date":"2019-01-15T07:18:39.000Z","_content":"-----\n*** 一般常见的数据归一化，是归一化到0~1，或者-1~1的区间，但在一些特殊场合下，我们需要根据实际情况归一化到其他任意区间，方法是： ***\n\n----\n    将数据归一化到[a,b]区间范围的方法：\n\n（1）首先找到样本数据Y的最小值Min及最大值Max\n（2）计算系数为：k=（b-a)/(Max-Min)\n（3）得到归一化到[a,b]区间的数据：newY=a+k(Y-Min)\n\n--------------------- \n","source":"_posts/将数据归一化到任意区间范围的方法.md","raw":"---\ntitle: 将数据归一化到任意区间范围的方法\ndate: 2019-01-15 15:18:39\ntags:\n       - 归一化\ncategories:\n       - 学习\n       - 算法\n       - 数据处理\n---\n-----\n*** 一般常见的数据归一化，是归一化到0~1，或者-1~1的区间，但在一些特殊场合下，我们需要根据实际情况归一化到其他任意区间，方法是： ***\n\n----\n    将数据归一化到[a,b]区间范围的方法：\n\n（1）首先找到样本数据Y的最小值Min及最大值Max\n（2）计算系数为：k=（b-a)/(Max-Min)\n（3）得到归一化到[a,b]区间的数据：newY=a+k(Y-Min)\n\n--------------------- \n","slug":"将数据归一化到任意区间范围的方法","published":1,"updated":"2021-07-26T09:58:02.580Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m2a0023igtamesrqd2c","content":"<hr>\n<p><strong><em> 一般常见的数据归一化，是归一化到0~1，或者-1~1的区间，但在一些特殊场合下，我们需要根据实际情况归一化到其他任意区间，方法是： </em></strong></p>\n<hr>\n<pre><code>将数据归一化到[a,b]区间范围的方法：\n</code></pre><p>（1）首先找到样本数据Y的最小值Min及最大值Max<br>（2）计算系数为：k=（b-a)/(Max-Min)<br>（3）得到归一化到[a,b]区间的数据：newY=a+k(Y-Min)</p>\n<hr>\n","site":{"data":{}},"excerpt":"","more":"<hr>\n<p><strong><em> 一般常见的数据归一化，是归一化到0~1，或者-1~1的区间，但在一些特殊场合下，我们需要根据实际情况归一化到其他任意区间，方法是： </em></strong></p>\n<hr>\n<pre><code>将数据归一化到[a,b]区间范围的方法：\n</code></pre><p>（1）首先找到样本数据Y的最小值Min及最大值Max<br>（2）计算系数为：k=（b-a)/(Max-Min)<br>（3）得到归一化到[a,b]区间的数据：newY=a+k(Y-Min)</p>\n<hr>\n"},{"title":"小玩具-VIP视频解析界面","date":"2018-12-13T18:21:38.000Z","_content":"\n## 需要下列工具:\n1. QT-designer(用于快速构造界面)\n2. QT-pyuic(用于把刚才界面转换成py文件,方便设计)\n3. main.py空文件(用于储存页面逻辑)\n4. url.txt(用于储存解析网址)\n5. 背景图一张(可选)\n****\n### 第一步:\n    直接打开QT-designer拖动组件设计出如下界面:\n    \n![](https://blog.mviai.com/images/小玩具-VIP视频解析界面/ui.png)\n    \n    \n### 第二步:\n    用Qt-pyuic (python文件里面的Scripts) 将设计好的转换成.py文件\n    如在生成.ui文件下 运行命令\n   ```\n    pyuic5 -o 文件名.py 文件名.ui\n    ```\n    \n 注: 如果找不到pyuic5 看是否将Scripts加入了环境变量\n \n \n 然后可以看到生成对应的.py文件\n 我是生成ui.py,如图:\n```python\nfrom PyQt5 import QtCore, QtGui, QtWidgets\nimport sys\nclass Ui_widget(object):\n    def setupUi(self, widget):\n        widget.setObjectName(\"widget\")\n        widget.setEnabled(True)\n        widget.resize(416, 667)\n        widget.setFixedSize(widget.width(), widget.height())\n        self.label = QtWidgets.QLabel(widget)\n        self.label.setGeometry(QtCore.QRect(30, 10, 191, 17))\n        self.label.setObjectName(\"label\")\n        self.lineEdit = QtWidgets.QLineEdit(widget)\n        self.lineEdit.setGeometry(QtCore.QRect(0, 35, 301, 21))\n        self.lineEdit.setObjectName(\"lineEdit\")\n        self.label_2 = QtWidgets.QLabel(widget)\n        self.label_2.setGeometry(QtCore.QRect(0, 60, 391, 21))\n        self.label_2.setObjectName(\"label_2\")\n        self.pushButton_run = QtWidgets.QPushButton(widget)\n        self.pushButton_run.setGeometry(QtCore.QRect(310, 30, 89, 31))\n        self.pushButton_run.setObjectName(\"pushButton_run\")\n        self.label_3 = QtWidgets.QLabel(widget)\n        self.label_3.setGeometry(QtCore.QRect(90, 170, 211, 20))\n        self.label_3.setObjectName(\"label_3\")\n\n\n        self.gridLayoutWidget = QtWidgets.QWidget(widget)\n        self.gridLayoutWidget.setGeometry(QtCore.QRect(10, 200, 401, 451))\n        self.gridLayoutWidget.setObjectName(\"gridLayoutWidget\")\n        self.gridLayout = QtWidgets.QGridLayout(self.gridLayoutWidget)\n        names=['优酷','土豆','爱奇艺','芒果','乐视','腾讯','搜狐','PPTV','360视','暴风影音','M1905','咪咕视频',\n        '音悦台','哔哩哔哩','华数TV','网易公开课','新浪视频','范特西','M3U8','私有云','韩国DAUM'\t,'品善网','开眼视频'\n        ,'优米网','好看视频','美拍','2MM','凤凰视频','Naver','糖豆网','秒拍','快手','17173','梨视频','中国蓝','第一视频'\n        ,'爱拍视频','汽车之家','ECHOMV','东方头条','今日头条','阳光宽频','西瓜视频','酷6视频','CCTV央视','27盘','91广场舞',\n        '爆米花','火猫直播','酷狗MV','酷狗MV','QQ音乐MV','酷狗直播','酷狗LIVE','天天看看','激动网','斗鱼视频','斗鱼直播',\n        '虎牙视频','虎牙直播','熊猫星颜','熊猫直播','战旗视频','战旗直播','龙珠视频','龙珠直播','来疯直播','触手视频','触手直播','花椒直播','花椒视频'\n        ,'全民直播','全民视频','CC直播','CC视频','印客直播','YY神曲','YY回放','YY小','一直播','NOW直播' ]\n\n        posittions=[(i,j)for  i in range(19) for j in range(5)]\n\n        for posittions,name in zip(posittions,names):\n            label=QtWidgets.QLabel(name)\n            label.setStyleSheet(\"font:10pt;color:rgb(0,0, 255);font-weight:40px;\")\n            self.gridLayout.addWidget(label,*posittions)\n        self.gridLayout.setContentsMargins(0, 1, 2, 0)\n        self.gridLayout.setObjectName(\"gridLayout\")\n\n\n\n        self.pushButton_switch = QtWidgets.QPushButton(widget)\n        self.pushButton_switch.setGeometry(QtCore.QRect(100, 110, 171, 31))\n        self.pushButton_switch.setObjectName(\"pushButton_switch\")\n\n        self.retranslateUi(widget)\n        QtCore.QMetaObject.connectSlotsByName(widget)\n\n    def retranslateUi(self, widget):\n        _translate = QtCore.QCoreApplication.translate\n        widget.setWindowTitle(_translate(\"widget\", \"VIP会员-新\"))\n        self.label.setText(_translate(\"widget\", \"视频网页最上面网址(链接):\"))\n        self.label_2.setText(_translate(\"widget\", \"复制VIP视频的地址到↑↑↑上栏中点击立即播放就行了\"))\n        self.pushButton_run.setText(_translate(\"widget\", \"开始播放\"))\n        self.pushButton_run.setStyleSheet(\"color:rgb(255,0,0)\")\n        self.label_3.setText(_translate(\"widget\", \"↓↓现支持以下免费播放↓↓\"))\n        self.pushButton_switch.setText(_translate(\"widget\", \"如果不能播放用力点我\"))\n        self.pushButton_switch.setStyleSheet(\"background: rgb(0,191,255);color:rgb(128,0,0)\")\n        self.pushButton_run.setStyleSheet (\"background: rgb(0,191,255);color:rgb(128,0,0)\")\n\n```\n\n\n##### 如果想看看界面,可以创建test.py,输入\n```python\n#继承窗口\nclass MainWindow(QMainWindow):\n    def __init__(self):\n        super(MainWindow, self).__init__()\n        self.ui = Ui_widget()\n        self.ui.setupUi(self)\n        \nif __name__ =='__main__':\n    app = QApplication (sys.argv)\n    win1 = MainWindow ()# 创建实例\n    win1.show ()\n    app.exec_ ()\n\n ```\n \n \n \n ## 第三步:\n 有了界面,还需要个播放窗口!\n 为了简单,直接使用了浏览器当窗口!\n \n ![](https://blog.mviai.com/images/小玩具-VIP视频解析界面/20181214031720070.png)\n 代码如下:\n ```python\n class ScreenWindow (QMainWindow):\n    def __init__ (self,url):\n        super (ScreenWindow, self).__init__ ()\n        self.setWindowTitle('vip视频影院')\n        self.setGeometry(5,30,1355,730)\n\n        self.browser=QWebEngineView()\n        self.browser.settings().setAttribute(QWebEngineSettings.PluginsEnabled, True)  # 支持视频播放\n        self.browser.settings().setAttribute(QWebEngineSettings.JavascriptEnabled, True)\n        self.browser.settings().setAttribute(QWebEngineSettings.FullScreenSupportEnabled, True)\n        # self.browser.page().fullScreenRequested.connect(self._fullScreenRequested)\n\n        self.browser.load (QUrl (url))\n\n        self.setCentralWidget(self.browser)\n    #\n    # def _fullScreenRequested(request):\n    #     request.accept()\n    #     w.showFullScreen()\n\n\n    def screendisplay(self):\n        if not self.isVisible ():\n            self.show ()\n\n \n ```\n \n \n ** 注:中间那三行,为了加载flash插件,不然播放不了视频\n 最后一行,为了让用户点击触发显示函数\n 传入参数`url` 是为了让用户切换解析接口\n url来自下面↓\n **\n \n ### 最后一步:\n \n ```python\n class MainWindow(QMainWindow):\n    def __init__(self):\n        super(MainWindow, self).__init__()\n        self.ui = Ui_widget()\n        self.ui.setupUi(self)\n        url=self.switch()\n        #print(url)\n\n\n        self.setIcon()\n        self.ui.pushButton_run.clicked.connect (self.TwoT)\n        self.ui.pushButton_switch.clicked.connect (self.TwoT)\n\n    def TwoT(self):\n        url = self.switch ()\n        self.win2 = ScreenWindow (url)\n        self.win2.screendisplay()\n\n    def setIcon (self):\n        palette1 = QPalette ()\n\n        # palette1.setColor(self.backgroundRole(), QColor(192,253,123))   # 设置背景颜色.scaled(self.width(), self.height()\n        palette1.setBrush (self.backgroundRole (), QBrush (QPixmap ('d.png')))  # 设置背景图片\n        self.setPalette (palette1)\n        self.setAutoFillBackground(True) # 不设置也可以\n\n\n        self.setWindowIcon (QIcon ('d.png'))\n\n\n    def addurl(self):\n        url = self.ui.lineEdit.text ()\n        return url\n\n    def switch(self):\n        countmax = len (open ('url', 'r').readlines ())\n        count=random.randint(0,countmax-1)\n        if count >= countmax-1:\n            count = random.randint(0,countmax-1)\n        else:\n            count += 1\n        with open ('url', 'r') as f:\n            vurl = f.readlines ()\n            vurl = vurl [count].replace ('\\n', '')\n            qurl = vurl + self.addurl()\n            #print(qurl)\n        return qurl\n\nif __name__ =='__main__':\n    #argvs = sys.argv\n    # 支援flash\n    #argvs.append('--ppapi-flash-path=./pepflashplayer.dll')\n    app = QApplication (sys.argv)\n    win1 = MainWindow ()\n    win1.show ()\n    app.exec_ ()\n```\n     \n \n **注: 初始化函数`__init__`中 :继承窗口界面,两个触发函数\n `TWoT`:触发函数触发事件(运行切换函数,生成播放窗口)\n `setIcon`:设置界面背景\n `addurl`:读取用户输入url\n `switch`:随机取url文件里的解析口和用户输入url组成新的url\n \n URL文件:\n ```\n https://jx.lache.me/cc/?url=\nHttps://al.lache.me/vip/?url=\nhttps://2wk.com/vip.php?url=\nhttp://api.bbbbbb.me/jx/?url=\nhttps://www.myxin.top/jx/api/?url=\nhttp://www.syhbyl.tw/jx/api/?url=\nhttps://vip.hackmg.com/jx/index.php?url=\nhttp://jx.wslmf.com/?url=\nhttp://api.52xmw.com/?url=\nhttp://yun.baiyug.cn/vip/index.php?url=\nhttps://jx.lache.me/cc/?url=\nHttps://al.lache.me/vip/?url=\nhttps://jx.lache.me/cc/?url=\nHttps://al.lache.me/vip/?url=\n\n```\n 最后创建窗口,启动!\n ![](https://blog.mviai.com/images/小玩具-VIP视频解析界面/20181214032135019.png)\n ****\n ***注:无法观看,请下载flashplay (虽然已被淘汰)\n over***\n ***\n \n ***想要一键运行:\n 创建run.bat文件\n 输入:\n```\npython main.py\n```\n保存   就可以点击运行\n***\n \n## github:  [项目地址点我](https://github.com/sindre97/PyQt5_Toy)\n\n\n","source":"_posts/小玩具-VIP视频解析界面.md","raw":"---\ntitle: 小玩具-VIP视频解析界面\ndate: 2018-12-14 02:21:38\ntags:\n    - pyqt5\ncategories:\n    - 界面\n    - pyqt\n\n---\n\n## 需要下列工具:\n1. QT-designer(用于快速构造界面)\n2. QT-pyuic(用于把刚才界面转换成py文件,方便设计)\n3. main.py空文件(用于储存页面逻辑)\n4. url.txt(用于储存解析网址)\n5. 背景图一张(可选)\n****\n### 第一步:\n    直接打开QT-designer拖动组件设计出如下界面:\n    \n![](https://blog.mviai.com/images/小玩具-VIP视频解析界面/ui.png)\n    \n    \n### 第二步:\n    用Qt-pyuic (python文件里面的Scripts) 将设计好的转换成.py文件\n    如在生成.ui文件下 运行命令\n   ```\n    pyuic5 -o 文件名.py 文件名.ui\n    ```\n    \n 注: 如果找不到pyuic5 看是否将Scripts加入了环境变量\n \n \n 然后可以看到生成对应的.py文件\n 我是生成ui.py,如图:\n```python\nfrom PyQt5 import QtCore, QtGui, QtWidgets\nimport sys\nclass Ui_widget(object):\n    def setupUi(self, widget):\n        widget.setObjectName(\"widget\")\n        widget.setEnabled(True)\n        widget.resize(416, 667)\n        widget.setFixedSize(widget.width(), widget.height())\n        self.label = QtWidgets.QLabel(widget)\n        self.label.setGeometry(QtCore.QRect(30, 10, 191, 17))\n        self.label.setObjectName(\"label\")\n        self.lineEdit = QtWidgets.QLineEdit(widget)\n        self.lineEdit.setGeometry(QtCore.QRect(0, 35, 301, 21))\n        self.lineEdit.setObjectName(\"lineEdit\")\n        self.label_2 = QtWidgets.QLabel(widget)\n        self.label_2.setGeometry(QtCore.QRect(0, 60, 391, 21))\n        self.label_2.setObjectName(\"label_2\")\n        self.pushButton_run = QtWidgets.QPushButton(widget)\n        self.pushButton_run.setGeometry(QtCore.QRect(310, 30, 89, 31))\n        self.pushButton_run.setObjectName(\"pushButton_run\")\n        self.label_3 = QtWidgets.QLabel(widget)\n        self.label_3.setGeometry(QtCore.QRect(90, 170, 211, 20))\n        self.label_3.setObjectName(\"label_3\")\n\n\n        self.gridLayoutWidget = QtWidgets.QWidget(widget)\n        self.gridLayoutWidget.setGeometry(QtCore.QRect(10, 200, 401, 451))\n        self.gridLayoutWidget.setObjectName(\"gridLayoutWidget\")\n        self.gridLayout = QtWidgets.QGridLayout(self.gridLayoutWidget)\n        names=['优酷','土豆','爱奇艺','芒果','乐视','腾讯','搜狐','PPTV','360视','暴风影音','M1905','咪咕视频',\n        '音悦台','哔哩哔哩','华数TV','网易公开课','新浪视频','范特西','M3U8','私有云','韩国DAUM'\t,'品善网','开眼视频'\n        ,'优米网','好看视频','美拍','2MM','凤凰视频','Naver','糖豆网','秒拍','快手','17173','梨视频','中国蓝','第一视频'\n        ,'爱拍视频','汽车之家','ECHOMV','东方头条','今日头条','阳光宽频','西瓜视频','酷6视频','CCTV央视','27盘','91广场舞',\n        '爆米花','火猫直播','酷狗MV','酷狗MV','QQ音乐MV','酷狗直播','酷狗LIVE','天天看看','激动网','斗鱼视频','斗鱼直播',\n        '虎牙视频','虎牙直播','熊猫星颜','熊猫直播','战旗视频','战旗直播','龙珠视频','龙珠直播','来疯直播','触手视频','触手直播','花椒直播','花椒视频'\n        ,'全民直播','全民视频','CC直播','CC视频','印客直播','YY神曲','YY回放','YY小','一直播','NOW直播' ]\n\n        posittions=[(i,j)for  i in range(19) for j in range(5)]\n\n        for posittions,name in zip(posittions,names):\n            label=QtWidgets.QLabel(name)\n            label.setStyleSheet(\"font:10pt;color:rgb(0,0, 255);font-weight:40px;\")\n            self.gridLayout.addWidget(label,*posittions)\n        self.gridLayout.setContentsMargins(0, 1, 2, 0)\n        self.gridLayout.setObjectName(\"gridLayout\")\n\n\n\n        self.pushButton_switch = QtWidgets.QPushButton(widget)\n        self.pushButton_switch.setGeometry(QtCore.QRect(100, 110, 171, 31))\n        self.pushButton_switch.setObjectName(\"pushButton_switch\")\n\n        self.retranslateUi(widget)\n        QtCore.QMetaObject.connectSlotsByName(widget)\n\n    def retranslateUi(self, widget):\n        _translate = QtCore.QCoreApplication.translate\n        widget.setWindowTitle(_translate(\"widget\", \"VIP会员-新\"))\n        self.label.setText(_translate(\"widget\", \"视频网页最上面网址(链接):\"))\n        self.label_2.setText(_translate(\"widget\", \"复制VIP视频的地址到↑↑↑上栏中点击立即播放就行了\"))\n        self.pushButton_run.setText(_translate(\"widget\", \"开始播放\"))\n        self.pushButton_run.setStyleSheet(\"color:rgb(255,0,0)\")\n        self.label_3.setText(_translate(\"widget\", \"↓↓现支持以下免费播放↓↓\"))\n        self.pushButton_switch.setText(_translate(\"widget\", \"如果不能播放用力点我\"))\n        self.pushButton_switch.setStyleSheet(\"background: rgb(0,191,255);color:rgb(128,0,0)\")\n        self.pushButton_run.setStyleSheet (\"background: rgb(0,191,255);color:rgb(128,0,0)\")\n\n```\n\n\n##### 如果想看看界面,可以创建test.py,输入\n```python\n#继承窗口\nclass MainWindow(QMainWindow):\n    def __init__(self):\n        super(MainWindow, self).__init__()\n        self.ui = Ui_widget()\n        self.ui.setupUi(self)\n        \nif __name__ =='__main__':\n    app = QApplication (sys.argv)\n    win1 = MainWindow ()# 创建实例\n    win1.show ()\n    app.exec_ ()\n\n ```\n \n \n \n ## 第三步:\n 有了界面,还需要个播放窗口!\n 为了简单,直接使用了浏览器当窗口!\n \n ![](https://blog.mviai.com/images/小玩具-VIP视频解析界面/20181214031720070.png)\n 代码如下:\n ```python\n class ScreenWindow (QMainWindow):\n    def __init__ (self,url):\n        super (ScreenWindow, self).__init__ ()\n        self.setWindowTitle('vip视频影院')\n        self.setGeometry(5,30,1355,730)\n\n        self.browser=QWebEngineView()\n        self.browser.settings().setAttribute(QWebEngineSettings.PluginsEnabled, True)  # 支持视频播放\n        self.browser.settings().setAttribute(QWebEngineSettings.JavascriptEnabled, True)\n        self.browser.settings().setAttribute(QWebEngineSettings.FullScreenSupportEnabled, True)\n        # self.browser.page().fullScreenRequested.connect(self._fullScreenRequested)\n\n        self.browser.load (QUrl (url))\n\n        self.setCentralWidget(self.browser)\n    #\n    # def _fullScreenRequested(request):\n    #     request.accept()\n    #     w.showFullScreen()\n\n\n    def screendisplay(self):\n        if not self.isVisible ():\n            self.show ()\n\n \n ```\n \n \n ** 注:中间那三行,为了加载flash插件,不然播放不了视频\n 最后一行,为了让用户点击触发显示函数\n 传入参数`url` 是为了让用户切换解析接口\n url来自下面↓\n **\n \n ### 最后一步:\n \n ```python\n class MainWindow(QMainWindow):\n    def __init__(self):\n        super(MainWindow, self).__init__()\n        self.ui = Ui_widget()\n        self.ui.setupUi(self)\n        url=self.switch()\n        #print(url)\n\n\n        self.setIcon()\n        self.ui.pushButton_run.clicked.connect (self.TwoT)\n        self.ui.pushButton_switch.clicked.connect (self.TwoT)\n\n    def TwoT(self):\n        url = self.switch ()\n        self.win2 = ScreenWindow (url)\n        self.win2.screendisplay()\n\n    def setIcon (self):\n        palette1 = QPalette ()\n\n        # palette1.setColor(self.backgroundRole(), QColor(192,253,123))   # 设置背景颜色.scaled(self.width(), self.height()\n        palette1.setBrush (self.backgroundRole (), QBrush (QPixmap ('d.png')))  # 设置背景图片\n        self.setPalette (palette1)\n        self.setAutoFillBackground(True) # 不设置也可以\n\n\n        self.setWindowIcon (QIcon ('d.png'))\n\n\n    def addurl(self):\n        url = self.ui.lineEdit.text ()\n        return url\n\n    def switch(self):\n        countmax = len (open ('url', 'r').readlines ())\n        count=random.randint(0,countmax-1)\n        if count >= countmax-1:\n            count = random.randint(0,countmax-1)\n        else:\n            count += 1\n        with open ('url', 'r') as f:\n            vurl = f.readlines ()\n            vurl = vurl [count].replace ('\\n', '')\n            qurl = vurl + self.addurl()\n            #print(qurl)\n        return qurl\n\nif __name__ =='__main__':\n    #argvs = sys.argv\n    # 支援flash\n    #argvs.append('--ppapi-flash-path=./pepflashplayer.dll')\n    app = QApplication (sys.argv)\n    win1 = MainWindow ()\n    win1.show ()\n    app.exec_ ()\n```\n     \n \n **注: 初始化函数`__init__`中 :继承窗口界面,两个触发函数\n `TWoT`:触发函数触发事件(运行切换函数,生成播放窗口)\n `setIcon`:设置界面背景\n `addurl`:读取用户输入url\n `switch`:随机取url文件里的解析口和用户输入url组成新的url\n \n URL文件:\n ```\n https://jx.lache.me/cc/?url=\nHttps://al.lache.me/vip/?url=\nhttps://2wk.com/vip.php?url=\nhttp://api.bbbbbb.me/jx/?url=\nhttps://www.myxin.top/jx/api/?url=\nhttp://www.syhbyl.tw/jx/api/?url=\nhttps://vip.hackmg.com/jx/index.php?url=\nhttp://jx.wslmf.com/?url=\nhttp://api.52xmw.com/?url=\nhttp://yun.baiyug.cn/vip/index.php?url=\nhttps://jx.lache.me/cc/?url=\nHttps://al.lache.me/vip/?url=\nhttps://jx.lache.me/cc/?url=\nHttps://al.lache.me/vip/?url=\n\n```\n 最后创建窗口,启动!\n ![](https://blog.mviai.com/images/小玩具-VIP视频解析界面/20181214032135019.png)\n ****\n ***注:无法观看,请下载flashplay (虽然已被淘汰)\n over***\n ***\n \n ***想要一键运行:\n 创建run.bat文件\n 输入:\n```\npython main.py\n```\n保存   就可以点击运行\n***\n \n## github:  [项目地址点我](https://github.com/sindre97/PyQt5_Toy)\n\n\n","slug":"小玩具-VIP视频解析界面","published":1,"updated":"2021-07-26T09:58:02.583Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m2c0028igta97y4ah0u","content":"<h2 id=\"需要下列工具\"><a href=\"#需要下列工具\" class=\"headerlink\" title=\"需要下列工具:\"></a>需要下列工具:</h2><ol>\n<li>QT-designer(用于快速构造界面)</li>\n<li>QT-pyuic(用于把刚才界面转换成py文件,方便设计)</li>\n<li>main.py空文件(用于储存页面逻辑)</li>\n<li>url.txt(用于储存解析网址)</li>\n<li>背景图一张(可选)</li>\n</ol>\n<hr>\n<h3 id=\"第一步\"><a href=\"#第一步\" class=\"headerlink\" title=\"第一步:\"></a>第一步:</h3><pre><code>直接打开QT-designer拖动组件设计出如下界面:\n</code></pre><p><img src=\"https://blog.mviai.com/images/小玩具-VIP视频解析界面/ui.png\" alt></p>\n<h3 id=\"第二步\"><a href=\"#第二步\" class=\"headerlink\" title=\"第二步:\"></a>第二步:</h3><pre><code>用Qt-pyuic (python文件里面的Scripts) 将设计好的转换成.py文件\n如在生成.ui文件下 运行命令\n</code></pre>   <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pyuic5 -o 文件名.py 文件名.ui</span><br></pre></td></tr></table></figure>\n<p> 注: 如果找不到pyuic5 看是否将Scripts加入了环境变量</p>\n<p> 然后可以看到生成对应的.py文件<br> 我是生成ui.py,如图:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> PyQt5 <span class=\"keyword\">import</span> QtCore, QtGui, QtWidgets</span><br><span class=\"line\"><span class=\"keyword\">import</span> sys</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Ui_widget</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">setupUi</span><span class=\"params\">(self, widget)</span>:</span></span><br><span class=\"line\">        widget.setObjectName(<span class=\"string\">\"widget\"</span>)</span><br><span class=\"line\">        widget.setEnabled(<span class=\"literal\">True</span>)</span><br><span class=\"line\">        widget.resize(<span class=\"number\">416</span>, <span class=\"number\">667</span>)</span><br><span class=\"line\">        widget.setFixedSize(widget.width(), widget.height())</span><br><span class=\"line\">        self.label = QtWidgets.QLabel(widget)</span><br><span class=\"line\">        self.label.setGeometry(QtCore.QRect(<span class=\"number\">30</span>, <span class=\"number\">10</span>, <span class=\"number\">191</span>, <span class=\"number\">17</span>))</span><br><span class=\"line\">        self.label.setObjectName(<span class=\"string\">\"label\"</span>)</span><br><span class=\"line\">        self.lineEdit = QtWidgets.QLineEdit(widget)</span><br><span class=\"line\">        self.lineEdit.setGeometry(QtCore.QRect(<span class=\"number\">0</span>, <span class=\"number\">35</span>, <span class=\"number\">301</span>, <span class=\"number\">21</span>))</span><br><span class=\"line\">        self.lineEdit.setObjectName(<span class=\"string\">\"lineEdit\"</span>)</span><br><span class=\"line\">        self.label_2 = QtWidgets.QLabel(widget)</span><br><span class=\"line\">        self.label_2.setGeometry(QtCore.QRect(<span class=\"number\">0</span>, <span class=\"number\">60</span>, <span class=\"number\">391</span>, <span class=\"number\">21</span>))</span><br><span class=\"line\">        self.label_2.setObjectName(<span class=\"string\">\"label_2\"</span>)</span><br><span class=\"line\">        self.pushButton_run = QtWidgets.QPushButton(widget)</span><br><span class=\"line\">        self.pushButton_run.setGeometry(QtCore.QRect(<span class=\"number\">310</span>, <span class=\"number\">30</span>, <span class=\"number\">89</span>, <span class=\"number\">31</span>))</span><br><span class=\"line\">        self.pushButton_run.setObjectName(<span class=\"string\">\"pushButton_run\"</span>)</span><br><span class=\"line\">        self.label_3 = QtWidgets.QLabel(widget)</span><br><span class=\"line\">        self.label_3.setGeometry(QtCore.QRect(<span class=\"number\">90</span>, <span class=\"number\">170</span>, <span class=\"number\">211</span>, <span class=\"number\">20</span>))</span><br><span class=\"line\">        self.label_3.setObjectName(<span class=\"string\">\"label_3\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">        self.gridLayoutWidget = QtWidgets.QWidget(widget)</span><br><span class=\"line\">        self.gridLayoutWidget.setGeometry(QtCore.QRect(<span class=\"number\">10</span>, <span class=\"number\">200</span>, <span class=\"number\">401</span>, <span class=\"number\">451</span>))</span><br><span class=\"line\">        self.gridLayoutWidget.setObjectName(<span class=\"string\">\"gridLayoutWidget\"</span>)</span><br><span class=\"line\">        self.gridLayout = QtWidgets.QGridLayout(self.gridLayoutWidget)</span><br><span class=\"line\">        names=[<span class=\"string\">'优酷'</span>,<span class=\"string\">'土豆'</span>,<span class=\"string\">'爱奇艺'</span>,<span class=\"string\">'芒果'</span>,<span class=\"string\">'乐视'</span>,<span class=\"string\">'腾讯'</span>,<span class=\"string\">'搜狐'</span>,<span class=\"string\">'PPTV'</span>,<span class=\"string\">'360视'</span>,<span class=\"string\">'暴风影音'</span>,<span class=\"string\">'M1905'</span>,<span class=\"string\">'咪咕视频'</span>,</span><br><span class=\"line\">        <span class=\"string\">'音悦台'</span>,<span class=\"string\">'哔哩哔哩'</span>,<span class=\"string\">'华数TV'</span>,<span class=\"string\">'网易公开课'</span>,<span class=\"string\">'新浪视频'</span>,<span class=\"string\">'范特西'</span>,<span class=\"string\">'M3U8'</span>,<span class=\"string\">'私有云'</span>,<span class=\"string\">'韩国DAUM'</span>\t,<span class=\"string\">'品善网'</span>,<span class=\"string\">'开眼视频'</span></span><br><span class=\"line\">        ,<span class=\"string\">'优米网'</span>,<span class=\"string\">'好看视频'</span>,<span class=\"string\">'美拍'</span>,<span class=\"string\">'2MM'</span>,<span class=\"string\">'凤凰视频'</span>,<span class=\"string\">'Naver'</span>,<span class=\"string\">'糖豆网'</span>,<span class=\"string\">'秒拍'</span>,<span class=\"string\">'快手'</span>,<span class=\"string\">'17173'</span>,<span class=\"string\">'梨视频'</span>,<span class=\"string\">'中国蓝'</span>,<span class=\"string\">'第一视频'</span></span><br><span class=\"line\">        ,<span class=\"string\">'爱拍视频'</span>,<span class=\"string\">'汽车之家'</span>,<span class=\"string\">'ECHOMV'</span>,<span class=\"string\">'东方头条'</span>,<span class=\"string\">'今日头条'</span>,<span class=\"string\">'阳光宽频'</span>,<span class=\"string\">'西瓜视频'</span>,<span class=\"string\">'酷6视频'</span>,<span class=\"string\">'CCTV央视'</span>,<span class=\"string\">'27盘'</span>,<span class=\"string\">'91广场舞'</span>,</span><br><span class=\"line\">        <span class=\"string\">'爆米花'</span>,<span class=\"string\">'火猫直播'</span>,<span class=\"string\">'酷狗MV'</span>,<span class=\"string\">'酷狗MV'</span>,<span class=\"string\">'QQ音乐MV'</span>,<span class=\"string\">'酷狗直播'</span>,<span class=\"string\">'酷狗LIVE'</span>,<span class=\"string\">'天天看看'</span>,<span class=\"string\">'激动网'</span>,<span class=\"string\">'斗鱼视频'</span>,<span class=\"string\">'斗鱼直播'</span>,</span><br><span class=\"line\">        <span class=\"string\">'虎牙视频'</span>,<span class=\"string\">'虎牙直播'</span>,<span class=\"string\">'熊猫星颜'</span>,<span class=\"string\">'熊猫直播'</span>,<span class=\"string\">'战旗视频'</span>,<span class=\"string\">'战旗直播'</span>,<span class=\"string\">'龙珠视频'</span>,<span class=\"string\">'龙珠直播'</span>,<span class=\"string\">'来疯直播'</span>,<span class=\"string\">'触手视频'</span>,<span class=\"string\">'触手直播'</span>,<span class=\"string\">'花椒直播'</span>,<span class=\"string\">'花椒视频'</span></span><br><span class=\"line\">        ,<span class=\"string\">'全民直播'</span>,<span class=\"string\">'全民视频'</span>,<span class=\"string\">'CC直播'</span>,<span class=\"string\">'CC视频'</span>,<span class=\"string\">'印客直播'</span>,<span class=\"string\">'YY神曲'</span>,<span class=\"string\">'YY回放'</span>,<span class=\"string\">'YY小'</span>,<span class=\"string\">'一直播'</span>,<span class=\"string\">'NOW直播'</span> ]</span><br><span class=\"line\"></span><br><span class=\"line\">        posittions=[(i,j)<span class=\"keyword\">for</span>  i <span class=\"keyword\">in</span> range(<span class=\"number\">19</span>) <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(<span class=\"number\">5</span>)]</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> posittions,name <span class=\"keyword\">in</span> zip(posittions,names):</span><br><span class=\"line\">            label=QtWidgets.QLabel(name)</span><br><span class=\"line\">            label.setStyleSheet(<span class=\"string\">\"font:10pt;color:rgb(0,0, 255);font-weight:40px;\"</span>)</span><br><span class=\"line\">            self.gridLayout.addWidget(label,*posittions)</span><br><span class=\"line\">        self.gridLayout.setContentsMargins(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>)</span><br><span class=\"line\">        self.gridLayout.setObjectName(<span class=\"string\">\"gridLayout\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">        self.pushButton_switch = QtWidgets.QPushButton(widget)</span><br><span class=\"line\">        self.pushButton_switch.setGeometry(QtCore.QRect(<span class=\"number\">100</span>, <span class=\"number\">110</span>, <span class=\"number\">171</span>, <span class=\"number\">31</span>))</span><br><span class=\"line\">        self.pushButton_switch.setObjectName(<span class=\"string\">\"pushButton_switch\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        self.retranslateUi(widget)</span><br><span class=\"line\">        QtCore.QMetaObject.connectSlotsByName(widget)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">retranslateUi</span><span class=\"params\">(self, widget)</span>:</span></span><br><span class=\"line\">        _translate = QtCore.QCoreApplication.translate</span><br><span class=\"line\">        widget.setWindowTitle(_translate(<span class=\"string\">\"widget\"</span>, <span class=\"string\">\"VIP会员-新\"</span>))</span><br><span class=\"line\">        self.label.setText(_translate(<span class=\"string\">\"widget\"</span>, <span class=\"string\">\"视频网页最上面网址(链接):\"</span>))</span><br><span class=\"line\">        self.label_2.setText(_translate(<span class=\"string\">\"widget\"</span>, <span class=\"string\">\"复制VIP视频的地址到↑↑↑上栏中点击立即播放就行了\"</span>))</span><br><span class=\"line\">        self.pushButton_run.setText(_translate(<span class=\"string\">\"widget\"</span>, <span class=\"string\">\"开始播放\"</span>))</span><br><span class=\"line\">        self.pushButton_run.setStyleSheet(<span class=\"string\">\"color:rgb(255,0,0)\"</span>)</span><br><span class=\"line\">        self.label_3.setText(_translate(<span class=\"string\">\"widget\"</span>, <span class=\"string\">\"↓↓现支持以下免费播放↓↓\"</span>))</span><br><span class=\"line\">        self.pushButton_switch.setText(_translate(<span class=\"string\">\"widget\"</span>, <span class=\"string\">\"如果不能播放用力点我\"</span>))</span><br><span class=\"line\">        self.pushButton_switch.setStyleSheet(<span class=\"string\">\"background: rgb(0,191,255);color:rgb(128,0,0)\"</span>)</span><br><span class=\"line\">        self.pushButton_run.setStyleSheet (<span class=\"string\">\"background: rgb(0,191,255);color:rgb(128,0,0)\"</span>)</span><br></pre></td></tr></table></figure></p>\n<h5 id=\"如果想看看界面-可以创建test-py-输入\"><a href=\"#如果想看看界面-可以创建test-py-输入\" class=\"headerlink\" title=\"如果想看看界面,可以创建test.py,输入\"></a>如果想看看界面,可以创建test.py,输入</h5><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#继承窗口</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MainWindow</span><span class=\"params\">(QMainWindow)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        super(MainWindow, self).__init__()</span><br><span class=\"line\">        self.ui = Ui_widget()</span><br><span class=\"line\">        self.ui.setupUi(self)</span><br><span class=\"line\">        </span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ ==<span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    app = QApplication (sys.argv)</span><br><span class=\"line\">    win1 = MainWindow ()<span class=\"comment\"># 创建实例</span></span><br><span class=\"line\">    win1.show ()</span><br><span class=\"line\">    app.exec_ ()</span><br></pre></td></tr></table></figure>\n<h2 id=\"第三步\"><a href=\"#第三步\" class=\"headerlink\" title=\"第三步:\"></a>第三步:</h2><p> 有了界面,还需要个播放窗口!<br> 为了简单,直接使用了浏览器当窗口!</p>\n<p> <img src=\"https://blog.mviai.com/images/小玩具-VIP视频解析界面/20181214031720070.png\" alt><br> 代码如下:<br> <figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ScreenWindow</span> <span class=\"params\">(QMainWindow)</span>:</span></span><br><span class=\"line\">   <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span> <span class=\"params\">(self,url)</span>:</span></span><br><span class=\"line\">       super (ScreenWindow, self).__init__ ()</span><br><span class=\"line\">       self.setWindowTitle(<span class=\"string\">'vip视频影院'</span>)</span><br><span class=\"line\">       self.setGeometry(<span class=\"number\">5</span>,<span class=\"number\">30</span>,<span class=\"number\">1355</span>,<span class=\"number\">730</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">       self.browser=QWebEngineView()</span><br><span class=\"line\">       self.browser.settings().setAttribute(QWebEngineSettings.PluginsEnabled, <span class=\"literal\">True</span>)  <span class=\"comment\"># 支持视频播放</span></span><br><span class=\"line\">       self.browser.settings().setAttribute(QWebEngineSettings.JavascriptEnabled, <span class=\"literal\">True</span>)</span><br><span class=\"line\">       self.browser.settings().setAttribute(QWebEngineSettings.FullScreenSupportEnabled, <span class=\"literal\">True</span>)</span><br><span class=\"line\">       <span class=\"comment\"># self.browser.page().fullScreenRequested.connect(self._fullScreenRequested)</span></span><br><span class=\"line\"></span><br><span class=\"line\">       self.browser.load (QUrl (url))</span><br><span class=\"line\"></span><br><span class=\"line\">       self.setCentralWidget(self.browser)</span><br><span class=\"line\">   <span class=\"comment\">#</span></span><br><span class=\"line\">   <span class=\"comment\"># def _fullScreenRequested(request):</span></span><br><span class=\"line\">   <span class=\"comment\">#     request.accept()</span></span><br><span class=\"line\">   <span class=\"comment\">#     w.showFullScreen()</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">screendisplay</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">       <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> self.isVisible ():</span><br><span class=\"line\">           self.show ()</span><br></pre></td></tr></table></figure></p>\n<p> <strong> 注:中间那三行,为了加载flash插件,不然播放不了视频<br> 最后一行,为了让用户点击触发显示函数<br> 传入参数<code>url</code> 是为了让用户切换解析接口<br> url来自下面↓\n </strong></p>\n<h3 id=\"最后一步\"><a href=\"#最后一步\" class=\"headerlink\" title=\"最后一步:\"></a>最后一步:</h3> <figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MainWindow</span><span class=\"params\">(QMainWindow)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        super(MainWindow, self).__init__()</span><br><span class=\"line\">        self.ui = Ui_widget()</span><br><span class=\"line\">        self.ui.setupUi(self)</span><br><span class=\"line\">        url=self.switch()</span><br><span class=\"line\">        <span class=\"comment\">#print(url)</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">        self.setIcon()</span><br><span class=\"line\">        self.ui.pushButton_run.clicked.connect (self.TwoT)</span><br><span class=\"line\">        self.ui.pushButton_switch.clicked.connect (self.TwoT)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">TwoT</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        url = self.switch ()</span><br><span class=\"line\">        self.win2 = ScreenWindow (url)</span><br><span class=\"line\">        self.win2.screendisplay()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">setIcon</span> <span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        palette1 = QPalette ()</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># palette1.setColor(self.backgroundRole(), QColor(192,253,123))   # 设置背景颜色.scaled(self.width(), self.height()</span></span><br><span class=\"line\">        palette1.setBrush (self.backgroundRole (), QBrush (QPixmap (<span class=\"string\">'d.png'</span>)))  <span class=\"comment\"># 设置背景图片</span></span><br><span class=\"line\">        self.setPalette (palette1)</span><br><span class=\"line\">        self.setAutoFillBackground(<span class=\"literal\">True</span>) <span class=\"comment\"># 不设置也可以</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">        self.setWindowIcon (QIcon (<span class=\"string\">'d.png'</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">addurl</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        url = self.ui.lineEdit.text ()</span><br><span class=\"line\">        <span class=\"keyword\">return</span> url</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">switch</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        countmax = len (open (<span class=\"string\">'url'</span>, <span class=\"string\">'r'</span>).readlines ())</span><br><span class=\"line\">        count=random.randint(<span class=\"number\">0</span>,countmax<span class=\"number\">-1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> count &gt;= countmax<span class=\"number\">-1</span>:</span><br><span class=\"line\">            count = random.randint(<span class=\"number\">0</span>,countmax<span class=\"number\">-1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            count += <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"keyword\">with</span> open (<span class=\"string\">'url'</span>, <span class=\"string\">'r'</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">            vurl = f.readlines ()</span><br><span class=\"line\">            vurl = vurl [count].replace (<span class=\"string\">'\\n'</span>, <span class=\"string\">''</span>)</span><br><span class=\"line\">            qurl = vurl + self.addurl()</span><br><span class=\"line\">            <span class=\"comment\">#print(qurl)</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> qurl</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ ==<span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    <span class=\"comment\">#argvs = sys.argv</span></span><br><span class=\"line\">    <span class=\"comment\"># 支援flash</span></span><br><span class=\"line\">    <span class=\"comment\">#argvs.append('--ppapi-flash-path=./pepflashplayer.dll')</span></span><br><span class=\"line\">    app = QApplication (sys.argv)</span><br><span class=\"line\">    win1 = MainWindow ()</span><br><span class=\"line\">    win1.show ()</span><br><span class=\"line\">    app.exec_ ()</span><br></pre></td></tr></table></figure>\n<p> **注: 初始化函数<code>__init__</code>中 :继承窗口界面,两个触发函数<br> <code>TWoT</code>:触发函数触发事件(运行切换函数,生成播放窗口)<br> <code>setIcon</code>:设置界面背景<br> <code>addurl</code>:读取用户输入url<br> <code>switch</code>:随机取url文件里的解析口和用户输入url组成新的url</p>\n<p> URL文件:<br> <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> https://jx.lache.me/cc/?url=</span><br><span class=\"line\">Https://al.lache.me/vip/?url=</span><br><span class=\"line\">https://2wk.com/vip.php?url=</span><br><span class=\"line\">http://api.bbbbbb.me/jx/?url=</span><br><span class=\"line\">https://www.myxin.top/jx/api/?url=</span><br><span class=\"line\">http://www.syhbyl.tw/jx/api/?url=</span><br><span class=\"line\">https://vip.hackmg.com/jx/index.php?url=</span><br><span class=\"line\">http://jx.wslmf.com/?url=</span><br><span class=\"line\">http://api.52xmw.com/?url=</span><br><span class=\"line\">http://yun.baiyug.cn/vip/index.php?url=</span><br><span class=\"line\">https://jx.lache.me/cc/?url=</span><br><span class=\"line\">Https://al.lache.me/vip/?url=</span><br><span class=\"line\">https://jx.lache.me/cc/?url=</span><br><span class=\"line\">Https://al.lache.me/vip/?url=</span><br></pre></td></tr></table></figure></p>\n<p> 最后创建窗口,启动!<br> <img src=\"https://blog.mviai.com/images/小玩具-VIP视频解析界面/20181214032135019.png\" alt></p>\n<hr>\n<p> <strong><em>注:无法观看,请下载flashplay (虽然已被淘汰)<br> over</em></strong></p>\n<hr>\n<p> ***想要一键运行:<br> 创建run.bat文件<br> 输入:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python main.py</span><br></pre></td></tr></table></figure></p>\n<p>保存   就可以点击运行</p>\n<hr>\n<h2 id=\"github-项目地址点我\"><a href=\"#github-项目地址点我\" class=\"headerlink\" title=\"github:  项目地址点我\"></a>github:  <a href=\"https://github.com/sindre97/PyQt5_Toy\" target=\"_blank\" rel=\"noopener\">项目地址点我</a></h2>","site":{"data":{}},"excerpt":"","more":"<h2 id=\"需要下列工具\"><a href=\"#需要下列工具\" class=\"headerlink\" title=\"需要下列工具:\"></a>需要下列工具:</h2><ol>\n<li>QT-designer(用于快速构造界面)</li>\n<li>QT-pyuic(用于把刚才界面转换成py文件,方便设计)</li>\n<li>main.py空文件(用于储存页面逻辑)</li>\n<li>url.txt(用于储存解析网址)</li>\n<li>背景图一张(可选)</li>\n</ol>\n<hr>\n<h3 id=\"第一步\"><a href=\"#第一步\" class=\"headerlink\" title=\"第一步:\"></a>第一步:</h3><pre><code>直接打开QT-designer拖动组件设计出如下界面:\n</code></pre><p><img src=\"https://blog.mviai.com/images/小玩具-VIP视频解析界面/ui.png\" alt></p>\n<h3 id=\"第二步\"><a href=\"#第二步\" class=\"headerlink\" title=\"第二步:\"></a>第二步:</h3><pre><code>用Qt-pyuic (python文件里面的Scripts) 将设计好的转换成.py文件\n如在生成.ui文件下 运行命令\n</code></pre>   <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">pyuic5 -o 文件名.py 文件名.ui</span><br></pre></td></tr></table></figure>\n<p> 注: 如果找不到pyuic5 看是否将Scripts加入了环境变量</p>\n<p> 然后可以看到生成对应的.py文件<br> 我是生成ui.py,如图:<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> PyQt5 <span class=\"keyword\">import</span> QtCore, QtGui, QtWidgets</span><br><span class=\"line\"><span class=\"keyword\">import</span> sys</span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">Ui_widget</span><span class=\"params\">(object)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">setupUi</span><span class=\"params\">(self, widget)</span>:</span></span><br><span class=\"line\">        widget.setObjectName(<span class=\"string\">\"widget\"</span>)</span><br><span class=\"line\">        widget.setEnabled(<span class=\"literal\">True</span>)</span><br><span class=\"line\">        widget.resize(<span class=\"number\">416</span>, <span class=\"number\">667</span>)</span><br><span class=\"line\">        widget.setFixedSize(widget.width(), widget.height())</span><br><span class=\"line\">        self.label = QtWidgets.QLabel(widget)</span><br><span class=\"line\">        self.label.setGeometry(QtCore.QRect(<span class=\"number\">30</span>, <span class=\"number\">10</span>, <span class=\"number\">191</span>, <span class=\"number\">17</span>))</span><br><span class=\"line\">        self.label.setObjectName(<span class=\"string\">\"label\"</span>)</span><br><span class=\"line\">        self.lineEdit = QtWidgets.QLineEdit(widget)</span><br><span class=\"line\">        self.lineEdit.setGeometry(QtCore.QRect(<span class=\"number\">0</span>, <span class=\"number\">35</span>, <span class=\"number\">301</span>, <span class=\"number\">21</span>))</span><br><span class=\"line\">        self.lineEdit.setObjectName(<span class=\"string\">\"lineEdit\"</span>)</span><br><span class=\"line\">        self.label_2 = QtWidgets.QLabel(widget)</span><br><span class=\"line\">        self.label_2.setGeometry(QtCore.QRect(<span class=\"number\">0</span>, <span class=\"number\">60</span>, <span class=\"number\">391</span>, <span class=\"number\">21</span>))</span><br><span class=\"line\">        self.label_2.setObjectName(<span class=\"string\">\"label_2\"</span>)</span><br><span class=\"line\">        self.pushButton_run = QtWidgets.QPushButton(widget)</span><br><span class=\"line\">        self.pushButton_run.setGeometry(QtCore.QRect(<span class=\"number\">310</span>, <span class=\"number\">30</span>, <span class=\"number\">89</span>, <span class=\"number\">31</span>))</span><br><span class=\"line\">        self.pushButton_run.setObjectName(<span class=\"string\">\"pushButton_run\"</span>)</span><br><span class=\"line\">        self.label_3 = QtWidgets.QLabel(widget)</span><br><span class=\"line\">        self.label_3.setGeometry(QtCore.QRect(<span class=\"number\">90</span>, <span class=\"number\">170</span>, <span class=\"number\">211</span>, <span class=\"number\">20</span>))</span><br><span class=\"line\">        self.label_3.setObjectName(<span class=\"string\">\"label_3\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">        self.gridLayoutWidget = QtWidgets.QWidget(widget)</span><br><span class=\"line\">        self.gridLayoutWidget.setGeometry(QtCore.QRect(<span class=\"number\">10</span>, <span class=\"number\">200</span>, <span class=\"number\">401</span>, <span class=\"number\">451</span>))</span><br><span class=\"line\">        self.gridLayoutWidget.setObjectName(<span class=\"string\">\"gridLayoutWidget\"</span>)</span><br><span class=\"line\">        self.gridLayout = QtWidgets.QGridLayout(self.gridLayoutWidget)</span><br><span class=\"line\">        names=[<span class=\"string\">'优酷'</span>,<span class=\"string\">'土豆'</span>,<span class=\"string\">'爱奇艺'</span>,<span class=\"string\">'芒果'</span>,<span class=\"string\">'乐视'</span>,<span class=\"string\">'腾讯'</span>,<span class=\"string\">'搜狐'</span>,<span class=\"string\">'PPTV'</span>,<span class=\"string\">'360视'</span>,<span class=\"string\">'暴风影音'</span>,<span class=\"string\">'M1905'</span>,<span class=\"string\">'咪咕视频'</span>,</span><br><span class=\"line\">        <span class=\"string\">'音悦台'</span>,<span class=\"string\">'哔哩哔哩'</span>,<span class=\"string\">'华数TV'</span>,<span class=\"string\">'网易公开课'</span>,<span class=\"string\">'新浪视频'</span>,<span class=\"string\">'范特西'</span>,<span class=\"string\">'M3U8'</span>,<span class=\"string\">'私有云'</span>,<span class=\"string\">'韩国DAUM'</span>\t,<span class=\"string\">'品善网'</span>,<span class=\"string\">'开眼视频'</span></span><br><span class=\"line\">        ,<span class=\"string\">'优米网'</span>,<span class=\"string\">'好看视频'</span>,<span class=\"string\">'美拍'</span>,<span class=\"string\">'2MM'</span>,<span class=\"string\">'凤凰视频'</span>,<span class=\"string\">'Naver'</span>,<span class=\"string\">'糖豆网'</span>,<span class=\"string\">'秒拍'</span>,<span class=\"string\">'快手'</span>,<span class=\"string\">'17173'</span>,<span class=\"string\">'梨视频'</span>,<span class=\"string\">'中国蓝'</span>,<span class=\"string\">'第一视频'</span></span><br><span class=\"line\">        ,<span class=\"string\">'爱拍视频'</span>,<span class=\"string\">'汽车之家'</span>,<span class=\"string\">'ECHOMV'</span>,<span class=\"string\">'东方头条'</span>,<span class=\"string\">'今日头条'</span>,<span class=\"string\">'阳光宽频'</span>,<span class=\"string\">'西瓜视频'</span>,<span class=\"string\">'酷6视频'</span>,<span class=\"string\">'CCTV央视'</span>,<span class=\"string\">'27盘'</span>,<span class=\"string\">'91广场舞'</span>,</span><br><span class=\"line\">        <span class=\"string\">'爆米花'</span>,<span class=\"string\">'火猫直播'</span>,<span class=\"string\">'酷狗MV'</span>,<span class=\"string\">'酷狗MV'</span>,<span class=\"string\">'QQ音乐MV'</span>,<span class=\"string\">'酷狗直播'</span>,<span class=\"string\">'酷狗LIVE'</span>,<span class=\"string\">'天天看看'</span>,<span class=\"string\">'激动网'</span>,<span class=\"string\">'斗鱼视频'</span>,<span class=\"string\">'斗鱼直播'</span>,</span><br><span class=\"line\">        <span class=\"string\">'虎牙视频'</span>,<span class=\"string\">'虎牙直播'</span>,<span class=\"string\">'熊猫星颜'</span>,<span class=\"string\">'熊猫直播'</span>,<span class=\"string\">'战旗视频'</span>,<span class=\"string\">'战旗直播'</span>,<span class=\"string\">'龙珠视频'</span>,<span class=\"string\">'龙珠直播'</span>,<span class=\"string\">'来疯直播'</span>,<span class=\"string\">'触手视频'</span>,<span class=\"string\">'触手直播'</span>,<span class=\"string\">'花椒直播'</span>,<span class=\"string\">'花椒视频'</span></span><br><span class=\"line\">        ,<span class=\"string\">'全民直播'</span>,<span class=\"string\">'全民视频'</span>,<span class=\"string\">'CC直播'</span>,<span class=\"string\">'CC视频'</span>,<span class=\"string\">'印客直播'</span>,<span class=\"string\">'YY神曲'</span>,<span class=\"string\">'YY回放'</span>,<span class=\"string\">'YY小'</span>,<span class=\"string\">'一直播'</span>,<span class=\"string\">'NOW直播'</span> ]</span><br><span class=\"line\"></span><br><span class=\"line\">        posittions=[(i,j)<span class=\"keyword\">for</span>  i <span class=\"keyword\">in</span> range(<span class=\"number\">19</span>) <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(<span class=\"number\">5</span>)]</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">for</span> posittions,name <span class=\"keyword\">in</span> zip(posittions,names):</span><br><span class=\"line\">            label=QtWidgets.QLabel(name)</span><br><span class=\"line\">            label.setStyleSheet(<span class=\"string\">\"font:10pt;color:rgb(0,0, 255);font-weight:40px;\"</span>)</span><br><span class=\"line\">            self.gridLayout.addWidget(label,*posittions)</span><br><span class=\"line\">        self.gridLayout.setContentsMargins(<span class=\"number\">0</span>, <span class=\"number\">1</span>, <span class=\"number\">2</span>, <span class=\"number\">0</span>)</span><br><span class=\"line\">        self.gridLayout.setObjectName(<span class=\"string\">\"gridLayout\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">        self.pushButton_switch = QtWidgets.QPushButton(widget)</span><br><span class=\"line\">        self.pushButton_switch.setGeometry(QtCore.QRect(<span class=\"number\">100</span>, <span class=\"number\">110</span>, <span class=\"number\">171</span>, <span class=\"number\">31</span>))</span><br><span class=\"line\">        self.pushButton_switch.setObjectName(<span class=\"string\">\"pushButton_switch\"</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">        self.retranslateUi(widget)</span><br><span class=\"line\">        QtCore.QMetaObject.connectSlotsByName(widget)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">retranslateUi</span><span class=\"params\">(self, widget)</span>:</span></span><br><span class=\"line\">        _translate = QtCore.QCoreApplication.translate</span><br><span class=\"line\">        widget.setWindowTitle(_translate(<span class=\"string\">\"widget\"</span>, <span class=\"string\">\"VIP会员-新\"</span>))</span><br><span class=\"line\">        self.label.setText(_translate(<span class=\"string\">\"widget\"</span>, <span class=\"string\">\"视频网页最上面网址(链接):\"</span>))</span><br><span class=\"line\">        self.label_2.setText(_translate(<span class=\"string\">\"widget\"</span>, <span class=\"string\">\"复制VIP视频的地址到↑↑↑上栏中点击立即播放就行了\"</span>))</span><br><span class=\"line\">        self.pushButton_run.setText(_translate(<span class=\"string\">\"widget\"</span>, <span class=\"string\">\"开始播放\"</span>))</span><br><span class=\"line\">        self.pushButton_run.setStyleSheet(<span class=\"string\">\"color:rgb(255,0,0)\"</span>)</span><br><span class=\"line\">        self.label_3.setText(_translate(<span class=\"string\">\"widget\"</span>, <span class=\"string\">\"↓↓现支持以下免费播放↓↓\"</span>))</span><br><span class=\"line\">        self.pushButton_switch.setText(_translate(<span class=\"string\">\"widget\"</span>, <span class=\"string\">\"如果不能播放用力点我\"</span>))</span><br><span class=\"line\">        self.pushButton_switch.setStyleSheet(<span class=\"string\">\"background: rgb(0,191,255);color:rgb(128,0,0)\"</span>)</span><br><span class=\"line\">        self.pushButton_run.setStyleSheet (<span class=\"string\">\"background: rgb(0,191,255);color:rgb(128,0,0)\"</span>)</span><br></pre></td></tr></table></figure></p>\n<h5 id=\"如果想看看界面-可以创建test-py-输入\"><a href=\"#如果想看看界面-可以创建test-py-输入\" class=\"headerlink\" title=\"如果想看看界面,可以创建test.py,输入\"></a>如果想看看界面,可以创建test.py,输入</h5><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">#继承窗口</span></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MainWindow</span><span class=\"params\">(QMainWindow)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        super(MainWindow, self).__init__()</span><br><span class=\"line\">        self.ui = Ui_widget()</span><br><span class=\"line\">        self.ui.setupUi(self)</span><br><span class=\"line\">        </span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ ==<span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    app = QApplication (sys.argv)</span><br><span class=\"line\">    win1 = MainWindow ()<span class=\"comment\"># 创建实例</span></span><br><span class=\"line\">    win1.show ()</span><br><span class=\"line\">    app.exec_ ()</span><br></pre></td></tr></table></figure>\n<h2 id=\"第三步\"><a href=\"#第三步\" class=\"headerlink\" title=\"第三步:\"></a>第三步:</h2><p> 有了界面,还需要个播放窗口!<br> 为了简单,直接使用了浏览器当窗口!</p>\n<p> <img src=\"https://blog.mviai.com/images/小玩具-VIP视频解析界面/20181214031720070.png\" alt><br> 代码如下:<br> <figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">ScreenWindow</span> <span class=\"params\">(QMainWindow)</span>:</span></span><br><span class=\"line\">   <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span> <span class=\"params\">(self,url)</span>:</span></span><br><span class=\"line\">       super (ScreenWindow, self).__init__ ()</span><br><span class=\"line\">       self.setWindowTitle(<span class=\"string\">'vip视频影院'</span>)</span><br><span class=\"line\">       self.setGeometry(<span class=\"number\">5</span>,<span class=\"number\">30</span>,<span class=\"number\">1355</span>,<span class=\"number\">730</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">       self.browser=QWebEngineView()</span><br><span class=\"line\">       self.browser.settings().setAttribute(QWebEngineSettings.PluginsEnabled, <span class=\"literal\">True</span>)  <span class=\"comment\"># 支持视频播放</span></span><br><span class=\"line\">       self.browser.settings().setAttribute(QWebEngineSettings.JavascriptEnabled, <span class=\"literal\">True</span>)</span><br><span class=\"line\">       self.browser.settings().setAttribute(QWebEngineSettings.FullScreenSupportEnabled, <span class=\"literal\">True</span>)</span><br><span class=\"line\">       <span class=\"comment\"># self.browser.page().fullScreenRequested.connect(self._fullScreenRequested)</span></span><br><span class=\"line\"></span><br><span class=\"line\">       self.browser.load (QUrl (url))</span><br><span class=\"line\"></span><br><span class=\"line\">       self.setCentralWidget(self.browser)</span><br><span class=\"line\">   <span class=\"comment\">#</span></span><br><span class=\"line\">   <span class=\"comment\"># def _fullScreenRequested(request):</span></span><br><span class=\"line\">   <span class=\"comment\">#     request.accept()</span></span><br><span class=\"line\">   <span class=\"comment\">#     w.showFullScreen()</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">   <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">screendisplay</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">       <span class=\"keyword\">if</span> <span class=\"keyword\">not</span> self.isVisible ():</span><br><span class=\"line\">           self.show ()</span><br></pre></td></tr></table></figure></p>\n<p> <strong> 注:中间那三行,为了加载flash插件,不然播放不了视频<br> 最后一行,为了让用户点击触发显示函数<br> 传入参数<code>url</code> 是为了让用户切换解析接口<br> url来自下面↓\n </strong></p>\n<h3 id=\"最后一步\"><a href=\"#最后一步\" class=\"headerlink\" title=\"最后一步:\"></a>最后一步:</h3> <figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> <span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MainWindow</span><span class=\"params\">(QMainWindow)</span>:</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        super(MainWindow, self).__init__()</span><br><span class=\"line\">        self.ui = Ui_widget()</span><br><span class=\"line\">        self.ui.setupUi(self)</span><br><span class=\"line\">        url=self.switch()</span><br><span class=\"line\">        <span class=\"comment\">#print(url)</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">        self.setIcon()</span><br><span class=\"line\">        self.ui.pushButton_run.clicked.connect (self.TwoT)</span><br><span class=\"line\">        self.ui.pushButton_switch.clicked.connect (self.TwoT)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">TwoT</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        url = self.switch ()</span><br><span class=\"line\">        self.win2 = ScreenWindow (url)</span><br><span class=\"line\">        self.win2.screendisplay()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">setIcon</span> <span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        palette1 = QPalette ()</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># palette1.setColor(self.backgroundRole(), QColor(192,253,123))   # 设置背景颜色.scaled(self.width(), self.height()</span></span><br><span class=\"line\">        palette1.setBrush (self.backgroundRole (), QBrush (QPixmap (<span class=\"string\">'d.png'</span>)))  <span class=\"comment\"># 设置背景图片</span></span><br><span class=\"line\">        self.setPalette (palette1)</span><br><span class=\"line\">        self.setAutoFillBackground(<span class=\"literal\">True</span>) <span class=\"comment\"># 不设置也可以</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">        self.setWindowIcon (QIcon (<span class=\"string\">'d.png'</span>))</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">addurl</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        url = self.ui.lineEdit.text ()</span><br><span class=\"line\">        <span class=\"keyword\">return</span> url</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">switch</span><span class=\"params\">(self)</span>:</span></span><br><span class=\"line\">        countmax = len (open (<span class=\"string\">'url'</span>, <span class=\"string\">'r'</span>).readlines ())</span><br><span class=\"line\">        count=random.randint(<span class=\"number\">0</span>,countmax<span class=\"number\">-1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">if</span> count &gt;= countmax<span class=\"number\">-1</span>:</span><br><span class=\"line\">            count = random.randint(<span class=\"number\">0</span>,countmax<span class=\"number\">-1</span>)</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            count += <span class=\"number\">1</span></span><br><span class=\"line\">        <span class=\"keyword\">with</span> open (<span class=\"string\">'url'</span>, <span class=\"string\">'r'</span>) <span class=\"keyword\">as</span> f:</span><br><span class=\"line\">            vurl = f.readlines ()</span><br><span class=\"line\">            vurl = vurl [count].replace (<span class=\"string\">'\\n'</span>, <span class=\"string\">''</span>)</span><br><span class=\"line\">            qurl = vurl + self.addurl()</span><br><span class=\"line\">            <span class=\"comment\">#print(qurl)</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> qurl</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__ ==<span class=\"string\">'__main__'</span>:</span><br><span class=\"line\">    <span class=\"comment\">#argvs = sys.argv</span></span><br><span class=\"line\">    <span class=\"comment\"># 支援flash</span></span><br><span class=\"line\">    <span class=\"comment\">#argvs.append('--ppapi-flash-path=./pepflashplayer.dll')</span></span><br><span class=\"line\">    app = QApplication (sys.argv)</span><br><span class=\"line\">    win1 = MainWindow ()</span><br><span class=\"line\">    win1.show ()</span><br><span class=\"line\">    app.exec_ ()</span><br></pre></td></tr></table></figure>\n<p> **注: 初始化函数<code>__init__</code>中 :继承窗口界面,两个触发函数<br> <code>TWoT</code>:触发函数触发事件(运行切换函数,生成播放窗口)<br> <code>setIcon</code>:设置界面背景<br> <code>addurl</code>:读取用户输入url<br> <code>switch</code>:随机取url文件里的解析口和用户输入url组成新的url</p>\n<p> URL文件:<br> <figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> https://jx.lache.me/cc/?url=</span><br><span class=\"line\">Https://al.lache.me/vip/?url=</span><br><span class=\"line\">https://2wk.com/vip.php?url=</span><br><span class=\"line\">http://api.bbbbbb.me/jx/?url=</span><br><span class=\"line\">https://www.myxin.top/jx/api/?url=</span><br><span class=\"line\">http://www.syhbyl.tw/jx/api/?url=</span><br><span class=\"line\">https://vip.hackmg.com/jx/index.php?url=</span><br><span class=\"line\">http://jx.wslmf.com/?url=</span><br><span class=\"line\">http://api.52xmw.com/?url=</span><br><span class=\"line\">http://yun.baiyug.cn/vip/index.php?url=</span><br><span class=\"line\">https://jx.lache.me/cc/?url=</span><br><span class=\"line\">Https://al.lache.me/vip/?url=</span><br><span class=\"line\">https://jx.lache.me/cc/?url=</span><br><span class=\"line\">Https://al.lache.me/vip/?url=</span><br></pre></td></tr></table></figure></p>\n<p> 最后创建窗口,启动!<br> <img src=\"https://blog.mviai.com/images/小玩具-VIP视频解析界面/20181214032135019.png\" alt></p>\n<hr>\n<p> <strong><em>注:无法观看,请下载flashplay (虽然已被淘汰)<br> over</em></strong></p>\n<hr>\n<p> ***想要一键运行:<br> 创建run.bat文件<br> 输入:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">python main.py</span><br></pre></td></tr></table></figure></p>\n<p>保存   就可以点击运行</p>\n<hr>\n<h2 id=\"github-项目地址点我\"><a href=\"#github-项目地址点我\" class=\"headerlink\" title=\"github:  项目地址点我\"></a>github:  <a href=\"https://github.com/sindre97/PyQt5_Toy\" target=\"_blank\" rel=\"noopener\">项目地址点我</a></h2>"},{"title":"教程1:OpenCV代码转换为Web API","toc":false,"date":"2020-03-08T15:59:03.000Z","_content":"\n\n# 目标:\n1. 我们将创建一个Web API，允许用户调用OpenCV代码。\n2. 快速建立一个简单的示例。\n3. 只需要一个Web浏览器，即可在所有平台上运行。\n4. 该项目将是免费的！将注册一个免费帐户，并使用一个开源框架。\n5. 将从一个非常基本的示例开始，在该示例中，用户将输入图像url传递到后端。后端读取图像并返回其宽度和高度。\n\n# 工具:\n1. [pythonanywhere](http://pythonanywhere.com/)\n-\tPythonAnywhere不仅仅是一个托管平台。这是用于编写python代码的功能强大的IDE。它使您可以通过Web浏览器访问带有语法高亮显示的代码编辑器，Unix终端，访问日志文件。当然，您可以轻松地从github转移现有代码，也可以根据需要在vi中转移代码。它还附带安装了OpenCV！ \n2. [web2py](http://www.web2py.com/)\n-\t免费的开源全栈框架，用于快速开发快速，可伸缩，安全和可移植的数据库驱动的基于Web的应用程序。用Python编写和编程\n\n\n# 步骤:\n## 注册\n1. 注册PythonAnywhere并安装web2py(初学者的帐户是免费的,记住您的用户名)\n2. 注册并登录后，转到“ Web”选项卡，然后添加一个新的Web应用程序。\n![image.png](https://blog.mviai.com/images/FtkXBQuiEWGkMdxevcEKmDn9CMtu)\n3. 选择web2py作为您的python框架\n![image.png](https://blog.mviai.com/images/Fn_6VoDczoUUyfrD8EXNl905_BN3)\n4. 选择web2py的管理员密码。(记住这是管理员密码,不是登录密码)\n![image.png](https://blog.mviai.com/images/Fnuaih8Gp2gs7Wk_U0c3xYhvkyd6)\n![image.png](https://blog.mviai.com/images/FhFWGHLwvkJIMXPlh2F_SQ2IDYQE)\n\n## 在web2py上创建Web应用\n1. 打开一个新标签，然后转到位于web2py的管理界面(https://你的用户名.pythonanywhere.com/admin/default/index)\n\n![image.png](https://blog.mviai.com/images/FiG0_2rlroCh3LksbPbVUJfzesrF)\n![image.png](https://blog.mviai.com/images/Fn5vKEq3PIUUt0npOq7uhUuX62cw)\n\n2. 登陆后,检查是否有如下文件:(出现sindre目录)\n![image.png](https://blog.mviai.com/images/FitcbVJmwkj5ONrpzEp2SvuIQj9P)\n\n\n## 将OpenCV代码添加到web2py\n\nweb2py目录结构:\n- 模型包含应用程序的所有数据和规则\n- 控制器包含用于处理数据的代码\n- 视图则显示基础数据的某些状态\n\n![image.png](https://blog.mviai.com/images/FvmAUQVa7r2anLef1CKARrVwICK0)\n\n\nTODO: 输入图像URL-->返回图像的宽度和高度\n\n在控制器 controllers / default.py最后添加以下代码\n![image.png](https://blog.mviai.com/images/FrZI70EK0hcjb3ff631SR0d8JvX2)\n\n\n```python\n# -*- coding: UTF-8 -*-\n'''\n=================================================\n@path   ：learnopencv -> web\n@IDE    ：CLion\n@Author ：sindre\n@Date   ：2020/3/8 下午7:41\n==================================================\n'''\n\n\n__author__ = 'sindre'\n\nimport cv2\nimport numpy as np\nimport urllib2\nimport json\n\ndef image_dimensions():\n    # 伪装成Mozilla，因为一些web服务器可能不喜欢python机器人\n    hdr = {'User-Agent': 'Mozilla/5.0'}\n    \n    # 设定要求\n    req = urllib2.Request(urllib2.request.vars.url, headers=hdr)\n\n    try:\n\n        # 获取URL的内容\n\n        con = urllib2.urlopen( req )\n\n        # 读取内容并将其转换为numpy数组\n\n        im_array = np.asarray(bytearray(con.read()), dtype=np.uint8)\n\n        #将numpy数组转换为图像。\n\n        im =  cv2.imdecode(im_array, cv2.IMREAD_GRAYSCALE)\n\n        # 获取图像的宽度和高度。\n\n        height, width = im.shape\n\n        #将宽度和高度封装在一个对象中，并返回经过编码的JSON\n\n        return json.dumps({\"width\" : width, \"height\" : height})\n\n\n\n    except urllib2.HTTPError as e:\n\n        return e.fp.read()\n\n\n\n```\n保存后就可以测试了(注意,点 save file旁的图标才是保存)\n\n## 测试\n随机找个图片地址\n如:https://home.yx1024.top/images/1.png\n\ncurl -F url=https://home.yx1024.top/images/1.png http://你的用户名.pythonanywhere.com/你的应用名/default/image_dimensions\n\n\n\n\n","source":"_posts/教程1-OpenCV代码转换为Web-API.md","raw":"---\ntitle: '教程1:OpenCV代码转换为Web API'\ntags:\n  - cv\ncategories:\n  - 框架\n  - opencv\ntoc: false\ndate: 2020-03-08 23:59:03\n---\n\n\n# 目标:\n1. 我们将创建一个Web API，允许用户调用OpenCV代码。\n2. 快速建立一个简单的示例。\n3. 只需要一个Web浏览器，即可在所有平台上运行。\n4. 该项目将是免费的！将注册一个免费帐户，并使用一个开源框架。\n5. 将从一个非常基本的示例开始，在该示例中，用户将输入图像url传递到后端。后端读取图像并返回其宽度和高度。\n\n# 工具:\n1. [pythonanywhere](http://pythonanywhere.com/)\n-\tPythonAnywhere不仅仅是一个托管平台。这是用于编写python代码的功能强大的IDE。它使您可以通过Web浏览器访问带有语法高亮显示的代码编辑器，Unix终端，访问日志文件。当然，您可以轻松地从github转移现有代码，也可以根据需要在vi中转移代码。它还附带安装了OpenCV！ \n2. [web2py](http://www.web2py.com/)\n-\t免费的开源全栈框架，用于快速开发快速，可伸缩，安全和可移植的数据库驱动的基于Web的应用程序。用Python编写和编程\n\n\n# 步骤:\n## 注册\n1. 注册PythonAnywhere并安装web2py(初学者的帐户是免费的,记住您的用户名)\n2. 注册并登录后，转到“ Web”选项卡，然后添加一个新的Web应用程序。\n![image.png](https://blog.mviai.com/images/FtkXBQuiEWGkMdxevcEKmDn9CMtu)\n3. 选择web2py作为您的python框架\n![image.png](https://blog.mviai.com/images/Fn_6VoDczoUUyfrD8EXNl905_BN3)\n4. 选择web2py的管理员密码。(记住这是管理员密码,不是登录密码)\n![image.png](https://blog.mviai.com/images/Fnuaih8Gp2gs7Wk_U0c3xYhvkyd6)\n![image.png](https://blog.mviai.com/images/FhFWGHLwvkJIMXPlh2F_SQ2IDYQE)\n\n## 在web2py上创建Web应用\n1. 打开一个新标签，然后转到位于web2py的管理界面(https://你的用户名.pythonanywhere.com/admin/default/index)\n\n![image.png](https://blog.mviai.com/images/FiG0_2rlroCh3LksbPbVUJfzesrF)\n![image.png](https://blog.mviai.com/images/Fn5vKEq3PIUUt0npOq7uhUuX62cw)\n\n2. 登陆后,检查是否有如下文件:(出现sindre目录)\n![image.png](https://blog.mviai.com/images/FitcbVJmwkj5ONrpzEp2SvuIQj9P)\n\n\n## 将OpenCV代码添加到web2py\n\nweb2py目录结构:\n- 模型包含应用程序的所有数据和规则\n- 控制器包含用于处理数据的代码\n- 视图则显示基础数据的某些状态\n\n![image.png](https://blog.mviai.com/images/FvmAUQVa7r2anLef1CKARrVwICK0)\n\n\nTODO: 输入图像URL-->返回图像的宽度和高度\n\n在控制器 controllers / default.py最后添加以下代码\n![image.png](https://blog.mviai.com/images/FrZI70EK0hcjb3ff631SR0d8JvX2)\n\n\n```python\n# -*- coding: UTF-8 -*-\n'''\n=================================================\n@path   ：learnopencv -> web\n@IDE    ：CLion\n@Author ：sindre\n@Date   ：2020/3/8 下午7:41\n==================================================\n'''\n\n\n__author__ = 'sindre'\n\nimport cv2\nimport numpy as np\nimport urllib2\nimport json\n\ndef image_dimensions():\n    # 伪装成Mozilla，因为一些web服务器可能不喜欢python机器人\n    hdr = {'User-Agent': 'Mozilla/5.0'}\n    \n    # 设定要求\n    req = urllib2.Request(urllib2.request.vars.url, headers=hdr)\n\n    try:\n\n        # 获取URL的内容\n\n        con = urllib2.urlopen( req )\n\n        # 读取内容并将其转换为numpy数组\n\n        im_array = np.asarray(bytearray(con.read()), dtype=np.uint8)\n\n        #将numpy数组转换为图像。\n\n        im =  cv2.imdecode(im_array, cv2.IMREAD_GRAYSCALE)\n\n        # 获取图像的宽度和高度。\n\n        height, width = im.shape\n\n        #将宽度和高度封装在一个对象中，并返回经过编码的JSON\n\n        return json.dumps({\"width\" : width, \"height\" : height})\n\n\n\n    except urllib2.HTTPError as e:\n\n        return e.fp.read()\n\n\n\n```\n保存后就可以测试了(注意,点 save file旁的图标才是保存)\n\n## 测试\n随机找个图片地址\n如:https://home.yx1024.top/images/1.png\n\ncurl -F url=https://home.yx1024.top/images/1.png http://你的用户名.pythonanywhere.com/你的应用名/default/image_dimensions\n\n\n\n\n","slug":"教程1-OpenCV代码转换为Web-API","published":1,"updated":"2021-07-26T09:58:59.348Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m2d002aigtav88kdgc9","content":"<h1 id=\"目标\"><a href=\"#目标\" class=\"headerlink\" title=\"目标:\"></a>目标:</h1><ol>\n<li>我们将创建一个Web API，允许用户调用OpenCV代码。</li>\n<li>快速建立一个简单的示例。</li>\n<li>只需要一个Web浏览器，即可在所有平台上运行。</li>\n<li>该项目将是免费的！将注册一个免费帐户，并使用一个开源框架。</li>\n<li>将从一个非常基本的示例开始，在该示例中，用户将输入图像url传递到后端。后端读取图像并返回其宽度和高度。</li>\n</ol>\n<h1 id=\"工具\"><a href=\"#工具\" class=\"headerlink\" title=\"工具:\"></a>工具:</h1><ol>\n<li><a href=\"http://pythonanywhere.com/\" target=\"_blank\" rel=\"noopener\">pythonanywhere</a></li>\n</ol>\n<ul>\n<li>PythonAnywhere不仅仅是一个托管平台。这是用于编写python代码的功能强大的IDE。它使您可以通过Web浏览器访问带有语法高亮显示的代码编辑器，Unix终端，访问日志文件。当然，您可以轻松地从github转移现有代码，也可以根据需要在vi中转移代码。它还附带安装了OpenCV！ </li>\n</ul>\n<ol start=\"2\">\n<li><a href=\"http://www.web2py.com/\" target=\"_blank\" rel=\"noopener\">web2py</a></li>\n</ol>\n<ul>\n<li>免费的开源全栈框架，用于快速开发快速，可伸缩，安全和可移植的数据库驱动的基于Web的应用程序。用Python编写和编程</li>\n</ul>\n<h1 id=\"步骤\"><a href=\"#步骤\" class=\"headerlink\" title=\"步骤:\"></a>步骤:</h1><h2 id=\"注册\"><a href=\"#注册\" class=\"headerlink\" title=\"注册\"></a>注册</h2><ol>\n<li>注册PythonAnywhere并安装web2py(初学者的帐户是免费的,记住您的用户名)</li>\n<li>注册并登录后，转到“ Web”选项卡，然后添加一个新的Web应用程序。<br><img src=\"https://blog.mviai.com/images/FtkXBQuiEWGkMdxevcEKmDn9CMtu\" alt=\"image.png\"></li>\n<li>选择web2py作为您的python框架<br><img src=\"https://blog.mviai.com/images/Fn_6VoDczoUUyfrD8EXNl905_BN3\" alt=\"image.png\"></li>\n<li>选择web2py的管理员密码。(记住这是管理员密码,不是登录密码)<br><img src=\"https://blog.mviai.com/images/Fnuaih8Gp2gs7Wk_U0c3xYhvkyd6\" alt=\"image.png\"><br><img src=\"https://blog.mviai.com/images/FhFWGHLwvkJIMXPlh2F_SQ2IDYQE\" alt=\"image.png\"></li>\n</ol>\n<h2 id=\"在web2py上创建Web应用\"><a href=\"#在web2py上创建Web应用\" class=\"headerlink\" title=\"在web2py上创建Web应用\"></a>在web2py上创建Web应用</h2><ol>\n<li>打开一个新标签，然后转到位于web2py的管理界面(https://你的用户名.pythonanywhere.com/admin/default/index)</li>\n</ol>\n<p><img src=\"https://blog.mviai.com/images/FiG0_2rlroCh3LksbPbVUJfzesrF\" alt=\"image.png\"><br><img src=\"https://blog.mviai.com/images/Fn5vKEq3PIUUt0npOq7uhUuX62cw\" alt=\"image.png\"></p>\n<ol start=\"2\">\n<li>登陆后,检查是否有如下文件:(出现sindre目录)<br><img src=\"https://blog.mviai.com/images/FitcbVJmwkj5ONrpzEp2SvuIQj9P\" alt=\"image.png\"></li>\n</ol>\n<h2 id=\"将OpenCV代码添加到web2py\"><a href=\"#将OpenCV代码添加到web2py\" class=\"headerlink\" title=\"将OpenCV代码添加到web2py\"></a>将OpenCV代码添加到web2py</h2><p>web2py目录结构:</p>\n<ul>\n<li>模型包含应用程序的所有数据和规则</li>\n<li>控制器包含用于处理数据的代码</li>\n<li>视图则显示基础数据的某些状态</li>\n</ul>\n<p><img src=\"https://blog.mviai.com/images/FvmAUQVa7r2anLef1CKARrVwICK0\" alt=\"image.png\"></p>\n<p>TODO: 输入图像URL–&gt;返回图像的宽度和高度</p>\n<p>在控制器 controllers / default.py最后添加以下代码<br><img src=\"https://blog.mviai.com/images/FrZI70EK0hcjb3ff631SR0d8JvX2\" alt=\"image.png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -*- coding: UTF-8 -*-</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">=================================================</span></span><br><span class=\"line\"><span class=\"string\">@path   ：learnopencv -&gt; web</span></span><br><span class=\"line\"><span class=\"string\">@IDE    ：CLion</span></span><br><span class=\"line\"><span class=\"string\">@Author ：sindre</span></span><br><span class=\"line\"><span class=\"string\">@Date   ：2020/3/8 下午7:41</span></span><br><span class=\"line\"><span class=\"string\">==================================================</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">__author__ = <span class=\"string\">'sindre'</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> urllib2</span><br><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">image_dimensions</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"comment\"># 伪装成Mozilla，因为一些web服务器可能不喜欢python机器人</span></span><br><span class=\"line\">    hdr = &#123;<span class=\"string\">'User-Agent'</span>: <span class=\"string\">'Mozilla/5.0'</span>&#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># 设定要求</span></span><br><span class=\"line\">    req = urllib2.Request(urllib2.request.vars.url, headers=hdr)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 获取URL的内容</span></span><br><span class=\"line\"></span><br><span class=\"line\">        con = urllib2.urlopen( req )</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 读取内容并将其转换为numpy数组</span></span><br><span class=\"line\"></span><br><span class=\"line\">        im_array = np.asarray(bytearray(con.read()), dtype=np.uint8)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">#将numpy数组转换为图像。</span></span><br><span class=\"line\"></span><br><span class=\"line\">        im =  cv2.imdecode(im_array, cv2.IMREAD_GRAYSCALE)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 获取图像的宽度和高度。</span></span><br><span class=\"line\"></span><br><span class=\"line\">        height, width = im.shape</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">#将宽度和高度封装在一个对象中，并返回经过编码的JSON</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> json.dumps(&#123;<span class=\"string\">\"width\"</span> : width, <span class=\"string\">\"height\"</span> : height&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">except</span> urllib2.HTTPError <span class=\"keyword\">as</span> e:</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> e.fp.read()</span><br></pre></td></tr></table></figure>\n<p>保存后就可以测试了(注意,点 save file旁的图标才是保存)</p>\n<h2 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h2><p>随机找个图片地址<br>如:<a href=\"https://home.yx1024.top/images/1.png\" target=\"_blank\" rel=\"noopener\">https://home.yx1024.top/images/1.png</a></p>\n<p>curl -F url=<a href=\"https://home.yx1024.top/images/1.png\" target=\"_blank\" rel=\"noopener\">https://home.yx1024.top/images/1.png</a> http://你的用户名.pythonanywhere.com/你的应用名/default/image_dimensions</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"目标\"><a href=\"#目标\" class=\"headerlink\" title=\"目标:\"></a>目标:</h1><ol>\n<li>我们将创建一个Web API，允许用户调用OpenCV代码。</li>\n<li>快速建立一个简单的示例。</li>\n<li>只需要一个Web浏览器，即可在所有平台上运行。</li>\n<li>该项目将是免费的！将注册一个免费帐户，并使用一个开源框架。</li>\n<li>将从一个非常基本的示例开始，在该示例中，用户将输入图像url传递到后端。后端读取图像并返回其宽度和高度。</li>\n</ol>\n<h1 id=\"工具\"><a href=\"#工具\" class=\"headerlink\" title=\"工具:\"></a>工具:</h1><ol>\n<li><a href=\"http://pythonanywhere.com/\" target=\"_blank\" rel=\"noopener\">pythonanywhere</a></li>\n</ol>\n<ul>\n<li>PythonAnywhere不仅仅是一个托管平台。这是用于编写python代码的功能强大的IDE。它使您可以通过Web浏览器访问带有语法高亮显示的代码编辑器，Unix终端，访问日志文件。当然，您可以轻松地从github转移现有代码，也可以根据需要在vi中转移代码。它还附带安装了OpenCV！ </li>\n</ul>\n<ol start=\"2\">\n<li><a href=\"http://www.web2py.com/\" target=\"_blank\" rel=\"noopener\">web2py</a></li>\n</ol>\n<ul>\n<li>免费的开源全栈框架，用于快速开发快速，可伸缩，安全和可移植的数据库驱动的基于Web的应用程序。用Python编写和编程</li>\n</ul>\n<h1 id=\"步骤\"><a href=\"#步骤\" class=\"headerlink\" title=\"步骤:\"></a>步骤:</h1><h2 id=\"注册\"><a href=\"#注册\" class=\"headerlink\" title=\"注册\"></a>注册</h2><ol>\n<li>注册PythonAnywhere并安装web2py(初学者的帐户是免费的,记住您的用户名)</li>\n<li>注册并登录后，转到“ Web”选项卡，然后添加一个新的Web应用程序。<br><img src=\"https://blog.mviai.com/images/FtkXBQuiEWGkMdxevcEKmDn9CMtu\" alt=\"image.png\"></li>\n<li>选择web2py作为您的python框架<br><img src=\"https://blog.mviai.com/images/Fn_6VoDczoUUyfrD8EXNl905_BN3\" alt=\"image.png\"></li>\n<li>选择web2py的管理员密码。(记住这是管理员密码,不是登录密码)<br><img src=\"https://blog.mviai.com/images/Fnuaih8Gp2gs7Wk_U0c3xYhvkyd6\" alt=\"image.png\"><br><img src=\"https://blog.mviai.com/images/FhFWGHLwvkJIMXPlh2F_SQ2IDYQE\" alt=\"image.png\"></li>\n</ol>\n<h2 id=\"在web2py上创建Web应用\"><a href=\"#在web2py上创建Web应用\" class=\"headerlink\" title=\"在web2py上创建Web应用\"></a>在web2py上创建Web应用</h2><ol>\n<li>打开一个新标签，然后转到位于web2py的管理界面(https://你的用户名.pythonanywhere.com/admin/default/index)</li>\n</ol>\n<p><img src=\"https://blog.mviai.com/images/FiG0_2rlroCh3LksbPbVUJfzesrF\" alt=\"image.png\"><br><img src=\"https://blog.mviai.com/images/Fn5vKEq3PIUUt0npOq7uhUuX62cw\" alt=\"image.png\"></p>\n<ol start=\"2\">\n<li>登陆后,检查是否有如下文件:(出现sindre目录)<br><img src=\"https://blog.mviai.com/images/FitcbVJmwkj5ONrpzEp2SvuIQj9P\" alt=\"image.png\"></li>\n</ol>\n<h2 id=\"将OpenCV代码添加到web2py\"><a href=\"#将OpenCV代码添加到web2py\" class=\"headerlink\" title=\"将OpenCV代码添加到web2py\"></a>将OpenCV代码添加到web2py</h2><p>web2py目录结构:</p>\n<ul>\n<li>模型包含应用程序的所有数据和规则</li>\n<li>控制器包含用于处理数据的代码</li>\n<li>视图则显示基础数据的某些状态</li>\n</ul>\n<p><img src=\"https://blog.mviai.com/images/FvmAUQVa7r2anLef1CKARrVwICK0\" alt=\"image.png\"></p>\n<p>TODO: 输入图像URL–&gt;返回图像的宽度和高度</p>\n<p>在控制器 controllers / default.py最后添加以下代码<br><img src=\"https://blog.mviai.com/images/FrZI70EK0hcjb3ff631SR0d8JvX2\" alt=\"image.png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># -*- coding: UTF-8 -*-</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"><span class=\"string\">=================================================</span></span><br><span class=\"line\"><span class=\"string\">@path   ：learnopencv -&gt; web</span></span><br><span class=\"line\"><span class=\"string\">@IDE    ：CLion</span></span><br><span class=\"line\"><span class=\"string\">@Author ：sindre</span></span><br><span class=\"line\"><span class=\"string\">@Date   ：2020/3/8 下午7:41</span></span><br><span class=\"line\"><span class=\"string\">==================================================</span></span><br><span class=\"line\"><span class=\"string\">'''</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">__author__ = <span class=\"string\">'sindre'</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"><span class=\"keyword\">import</span> urllib2</span><br><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">image_dimensions</span><span class=\"params\">()</span>:</span></span><br><span class=\"line\">    <span class=\"comment\"># 伪装成Mozilla，因为一些web服务器可能不喜欢python机器人</span></span><br><span class=\"line\">    hdr = &#123;<span class=\"string\">'User-Agent'</span>: <span class=\"string\">'Mozilla/5.0'</span>&#125;</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"comment\"># 设定要求</span></span><br><span class=\"line\">    req = urllib2.Request(urllib2.request.vars.url, headers=hdr)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">try</span>:</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 获取URL的内容</span></span><br><span class=\"line\"></span><br><span class=\"line\">        con = urllib2.urlopen( req )</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 读取内容并将其转换为numpy数组</span></span><br><span class=\"line\"></span><br><span class=\"line\">        im_array = np.asarray(bytearray(con.read()), dtype=np.uint8)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">#将numpy数组转换为图像。</span></span><br><span class=\"line\"></span><br><span class=\"line\">        im =  cv2.imdecode(im_array, cv2.IMREAD_GRAYSCALE)</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\"># 获取图像的宽度和高度。</span></span><br><span class=\"line\"></span><br><span class=\"line\">        height, width = im.shape</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"comment\">#将宽度和高度封装在一个对象中，并返回经过编码的JSON</span></span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> json.dumps(&#123;<span class=\"string\">\"width\"</span> : width, <span class=\"string\">\"height\"</span> : height&#125;)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"keyword\">except</span> urllib2.HTTPError <span class=\"keyword\">as</span> e:</span><br><span class=\"line\"></span><br><span class=\"line\">        <span class=\"keyword\">return</span> e.fp.read()</span><br></pre></td></tr></table></figure>\n<p>保存后就可以测试了(注意,点 save file旁的图标才是保存)</p>\n<h2 id=\"测试\"><a href=\"#测试\" class=\"headerlink\" title=\"测试\"></a>测试</h2><p>随机找个图片地址<br>如:<a href=\"https://home.yx1024.top/images/1.png\" target=\"_blank\" rel=\"noopener\">https://home.yx1024.top/images/1.png</a></p>\n<p>curl -F url=<a href=\"https://home.yx1024.top/images/1.png\" target=\"_blank\" rel=\"noopener\">https://home.yx1024.top/images/1.png</a> http://你的用户名.pythonanywhere.com/你的应用名/default/image_dimensions</p>\n"},{"title":"教程2:斑点检测(Blob检测)","toc":false,"date":"2020-03-08T16:52:33.000Z","_content":"\n# 什么是Blob？\nBlob是图像中一组共享的像素，它们具有某些共同的属性（例如灰度值）。在上图中，深色连接区域是斑点，斑点检测的目的是识别并标记这些区域。\n![image.png](https://blog.mviai.com/images/FpYRqbsn3CaJ-vf4IKRfKkChgVAW)\n\n# 如何检测？\n\n**顾名思义，SimpleBlobDetector基于以下描述的相当简单的算法。该算法由参数控制（下面以粗体显示），并具有以下步骤。**\n1. **阈值处理**：通过以minThreshold开始的阈值对源图像进行阈值处理，将源图像转换为多个二进制图像  。这些阈值以thresholdStep递增，  直到  maxThreshold。因此，第一个阈值为  minThreshold， 第二个阈值为  minThreshold  +  thresholdStep，第三个阈 值为  minThreshold  + 2 x thresholdStep，依此类推。\n2. **分组**： 在每个二进制图像中，连接的白色像素被分组在一起。让我们称这些二进制blob。\n3.** 合并**   ：计算二进制图像中二进制斑点的中心，并合并比minDistBetweenBlob 更近的斑点  。\n4. **中心和半径计算**： 计算并返回新合并的Blob的中心和半径。\n\n\n# 过滤方法?\n- **按颜色**：首先，您需要设置  filterByColor =1。设置  blobColor = 0以选择较暗的blob，将  blobColor =  255设置为较浅的blob。 \n- **按大小**：   可以通过设置参数filterByArea = 1以及minArea   和maxArea的适当值来基于大小过滤blob 。例如，设置  minArea   = 100将滤除所有少于100个像素的斑点。\n- 按形状： 现在形状具有三个不同的参数。\n\t- 圆度：  这只是测量斑点距圆的距离。例如，正六边形的圆度比正方形大。要按圆度过滤，请设置 filterByCircularity  =1。然后为minCircularity  和maxCircularity设置适当的值。 圆度定义为\n\t\t-\t\\ frac {4 * \\ pi * Area} {perimeter * perimeter}\n\t\t- 这意味着圆的圆度为1，正方形的圆度为0.785，依此类推。\n\n- 凸性： 凸度定义为（斑点的面积/凸包的面积）。现在，形状的凸包是完全封闭该形状的最紧密的凸形。由凸滤波器，首先设置filterByConvexity  = 1 ，然后设置0≤  minConvexity ≤1  和maxConvexity（≤1） 图为凹形与凸形\n![image.png](https://blog.mviai.com/images/FiddIYcg0MJx1eJ9NVoEqVqG8Gkz)\n\n- 惯性比： 不要让它吓到你。数学家经常使用容易混淆的单词来描述非常简单的事物。您只需要知道这可以衡量形状的伸长程度。例如，对于一个圆，该值是1，对于椭圆它是0和1之间，而对于线是0。要通过过滤器惯量比，设置  filterByInertia = 1 ， 并设置0≤  minInertiaRatio  ≤1  和  maxInertiaRatio  （≤ 1） 适当。 \n![image.png](https://blog.mviai.com/images/FmI9PxggIyccKESVr5kkeRpaxHj9)\n\n\n# SimpleBlobDetector\n```python\n\n\n# 导入相关的包\nimport cv2\nimport numpy as np\n\n# 读取图片\nim = cv2.imread(\"blob.jpg\", cv2.IMREAD_GRAYSCALE)\n\n# 设置SimpleBlobDetector参数\nparams = cv2.SimpleBlobDetector_Params()\n\n# 更改阈值\nparams.minThreshold = 10\nparams.maxThreshold = 200\n\n\n# 基于大小过滤\nparams.filterByArea = True\nparams.minArea = 1500\n\n# 基于圆度过滤\nparams.filterByCircularity = True\nparams.minCircularity = 0.1\n\n# 按凸性过滤\nparams.filterByConvexity = True\nparams.minConvexity = 0.87\n    \n# 按惯性过滤\nparams.filterByInertia = True\nparams.minInertiaRatio = 0.01\n\n# 通过参数创建检测器\nver = (cv2.__version__).split('.')\nif int(ver[0]) < 3 :\n\tdetector = cv2.SimpleBlobDetector(params)\nelse : \n\tdetector = cv2.SimpleBlobDetector_create(params)\n\n\n# 检测 blobs.\nkeypoints = detector.detect(im)\n\n# 将检测到的斑点绘制为红色圆圈\n# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n# 确保圆的大小对应blobs的大小\n\nim_with_keypoints = cv2.drawKeypoints(im, keypoints, np.array([]), (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n\n# 显示 blobs\ncv2.imshow(\"Keypoints\", im_with_keypoints)\ncv2.waitKey(0)\n\n\n\n```\n\n![image.png](https://blog.mviai.com/images/FmX70X4ma5-XzZTlRTTp23duG8DX)\n\n\n\n```c++\n// 导入相关包\n#include \"opencv2/opencv.hpp\"\n\nusing namespace cv;\nusing namespace std;\n\nint main( int argc, char** argv )\n{\n\n\t//读取图片\n\tMat im = imread( \"../blob.jpg\", IMREAD_GRAYSCALE );\n\n\t// 设置SimpleBlobDetector参数\n\tSimpleBlobDetector::Params params;\n\n\t// 设置阈值\n\tparams.minThreshold = 10;\n\tparams.maxThreshold = 200;\n\n\t// 按大小过滤\n\tparams.filterByArea = true;\n\tparams.minArea = 1500;\n\n\t// 按圆度过滤\n\tparams.filterByCircularity = true;\n\tparams.minCircularity = 0.1;\n\n\t// 按凸性过滤\n\tparams.filterByConvexity = true;\n\tparams.minConvexity = 0.87;\n\n\t// 按惯性过滤\n\tparams.filterByInertia = true;\n\tparams.minInertiaRatio = 0.01;\n\n\n\t// 创建保存特征点变量\n\tvector<KeyPoint> keypoints;\n\n\n#if CV_MAJOR_VERSION < 3   // 如果使用 OpenCV 2\n\n\t// 设置通过参数创建检测器\n\tSimpleBlobDetector detector(params);\n\n\t// 检测 blobs\n\tdetector.detect( im, keypoints);\n#else \n\n\t// 设置通过参数创建检测器\n\tPtr<SimpleBlobDetector> detector = SimpleBlobDetector::create(params);   \n\n\t// 检测 blobs\n\tdetector->detect( im, keypoints);\n#endif\n\n\n    //# 将检测到的斑点绘制为红色圆圈\n    //# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n    //# 确保圆的大小对应blobs的大小\n\n\tMat im_with_keypoints;\n\tdrawKeypoints( im, keypoints, im_with_keypoints, Scalar(0,0,255), DrawMatchesFlags::DRAW_RICH_KEYPOINTS );\n\n\t// 显示 blobs\n\timshow(\"keypoints\", im_with_keypoints );\n\twaitKey(0);\n\n}\n\n\n\n```\n\n\n**注:希望能调好参数,把所有的都识别到**","source":"_posts/教程2-斑点检测-Blob检测.md","raw":"---\ntitle: '教程2:斑点检测(Blob检测)'\ntags:\n  - cv\ncategories:\n  - 框架\n  - opencv\ntoc: false\ndate: 2020-03-09 00:52:33\n---\n\n# 什么是Blob？\nBlob是图像中一组共享的像素，它们具有某些共同的属性（例如灰度值）。在上图中，深色连接区域是斑点，斑点检测的目的是识别并标记这些区域。\n![image.png](https://blog.mviai.com/images/FpYRqbsn3CaJ-vf4IKRfKkChgVAW)\n\n# 如何检测？\n\n**顾名思义，SimpleBlobDetector基于以下描述的相当简单的算法。该算法由参数控制（下面以粗体显示），并具有以下步骤。**\n1. **阈值处理**：通过以minThreshold开始的阈值对源图像进行阈值处理，将源图像转换为多个二进制图像  。这些阈值以thresholdStep递增，  直到  maxThreshold。因此，第一个阈值为  minThreshold， 第二个阈值为  minThreshold  +  thresholdStep，第三个阈 值为  minThreshold  + 2 x thresholdStep，依此类推。\n2. **分组**： 在每个二进制图像中，连接的白色像素被分组在一起。让我们称这些二进制blob。\n3.** 合并**   ：计算二进制图像中二进制斑点的中心，并合并比minDistBetweenBlob 更近的斑点  。\n4. **中心和半径计算**： 计算并返回新合并的Blob的中心和半径。\n\n\n# 过滤方法?\n- **按颜色**：首先，您需要设置  filterByColor =1。设置  blobColor = 0以选择较暗的blob，将  blobColor =  255设置为较浅的blob。 \n- **按大小**：   可以通过设置参数filterByArea = 1以及minArea   和maxArea的适当值来基于大小过滤blob 。例如，设置  minArea   = 100将滤除所有少于100个像素的斑点。\n- 按形状： 现在形状具有三个不同的参数。\n\t- 圆度：  这只是测量斑点距圆的距离。例如，正六边形的圆度比正方形大。要按圆度过滤，请设置 filterByCircularity  =1。然后为minCircularity  和maxCircularity设置适当的值。 圆度定义为\n\t\t-\t\\ frac {4 * \\ pi * Area} {perimeter * perimeter}\n\t\t- 这意味着圆的圆度为1，正方形的圆度为0.785，依此类推。\n\n- 凸性： 凸度定义为（斑点的面积/凸包的面积）。现在，形状的凸包是完全封闭该形状的最紧密的凸形。由凸滤波器，首先设置filterByConvexity  = 1 ，然后设置0≤  minConvexity ≤1  和maxConvexity（≤1） 图为凹形与凸形\n![image.png](https://blog.mviai.com/images/FiddIYcg0MJx1eJ9NVoEqVqG8Gkz)\n\n- 惯性比： 不要让它吓到你。数学家经常使用容易混淆的单词来描述非常简单的事物。您只需要知道这可以衡量形状的伸长程度。例如，对于一个圆，该值是1，对于椭圆它是0和1之间，而对于线是0。要通过过滤器惯量比，设置  filterByInertia = 1 ， 并设置0≤  minInertiaRatio  ≤1  和  maxInertiaRatio  （≤ 1） 适当。 \n![image.png](https://blog.mviai.com/images/FmI9PxggIyccKESVr5kkeRpaxHj9)\n\n\n# SimpleBlobDetector\n```python\n\n\n# 导入相关的包\nimport cv2\nimport numpy as np\n\n# 读取图片\nim = cv2.imread(\"blob.jpg\", cv2.IMREAD_GRAYSCALE)\n\n# 设置SimpleBlobDetector参数\nparams = cv2.SimpleBlobDetector_Params()\n\n# 更改阈值\nparams.minThreshold = 10\nparams.maxThreshold = 200\n\n\n# 基于大小过滤\nparams.filterByArea = True\nparams.minArea = 1500\n\n# 基于圆度过滤\nparams.filterByCircularity = True\nparams.minCircularity = 0.1\n\n# 按凸性过滤\nparams.filterByConvexity = True\nparams.minConvexity = 0.87\n    \n# 按惯性过滤\nparams.filterByInertia = True\nparams.minInertiaRatio = 0.01\n\n# 通过参数创建检测器\nver = (cv2.__version__).split('.')\nif int(ver[0]) < 3 :\n\tdetector = cv2.SimpleBlobDetector(params)\nelse : \n\tdetector = cv2.SimpleBlobDetector_create(params)\n\n\n# 检测 blobs.\nkeypoints = detector.detect(im)\n\n# 将检测到的斑点绘制为红色圆圈\n# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n# 确保圆的大小对应blobs的大小\n\nim_with_keypoints = cv2.drawKeypoints(im, keypoints, np.array([]), (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)\n\n# 显示 blobs\ncv2.imshow(\"Keypoints\", im_with_keypoints)\ncv2.waitKey(0)\n\n\n\n```\n\n![image.png](https://blog.mviai.com/images/FmX70X4ma5-XzZTlRTTp23duG8DX)\n\n\n\n```c++\n// 导入相关包\n#include \"opencv2/opencv.hpp\"\n\nusing namespace cv;\nusing namespace std;\n\nint main( int argc, char** argv )\n{\n\n\t//读取图片\n\tMat im = imread( \"../blob.jpg\", IMREAD_GRAYSCALE );\n\n\t// 设置SimpleBlobDetector参数\n\tSimpleBlobDetector::Params params;\n\n\t// 设置阈值\n\tparams.minThreshold = 10;\n\tparams.maxThreshold = 200;\n\n\t// 按大小过滤\n\tparams.filterByArea = true;\n\tparams.minArea = 1500;\n\n\t// 按圆度过滤\n\tparams.filterByCircularity = true;\n\tparams.minCircularity = 0.1;\n\n\t// 按凸性过滤\n\tparams.filterByConvexity = true;\n\tparams.minConvexity = 0.87;\n\n\t// 按惯性过滤\n\tparams.filterByInertia = true;\n\tparams.minInertiaRatio = 0.01;\n\n\n\t// 创建保存特征点变量\n\tvector<KeyPoint> keypoints;\n\n\n#if CV_MAJOR_VERSION < 3   // 如果使用 OpenCV 2\n\n\t// 设置通过参数创建检测器\n\tSimpleBlobDetector detector(params);\n\n\t// 检测 blobs\n\tdetector.detect( im, keypoints);\n#else \n\n\t// 设置通过参数创建检测器\n\tPtr<SimpleBlobDetector> detector = SimpleBlobDetector::create(params);   \n\n\t// 检测 blobs\n\tdetector->detect( im, keypoints);\n#endif\n\n\n    //# 将检测到的斑点绘制为红色圆圈\n    //# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS\n    //# 确保圆的大小对应blobs的大小\n\n\tMat im_with_keypoints;\n\tdrawKeypoints( im, keypoints, im_with_keypoints, Scalar(0,0,255), DrawMatchesFlags::DRAW_RICH_KEYPOINTS );\n\n\t// 显示 blobs\n\timshow(\"keypoints\", im_with_keypoints );\n\twaitKey(0);\n\n}\n\n\n\n```\n\n\n**注:希望能调好参数,把所有的都识别到**","slug":"教程2-斑点检测-Blob检测","published":1,"updated":"2021-07-26T09:58:02.581Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m2f002figtahc8j02a2","content":"<h1 id=\"什么是Blob？\"><a href=\"#什么是Blob？\" class=\"headerlink\" title=\"什么是Blob？\"></a>什么是Blob？</h1><p>Blob是图像中一组共享的像素，它们具有某些共同的属性（例如灰度值）。在上图中，深色连接区域是斑点，斑点检测的目的是识别并标记这些区域。<br><img src=\"https://blog.mviai.com/images/FpYRqbsn3CaJ-vf4IKRfKkChgVAW\" alt=\"image.png\"></p>\n<h1 id=\"如何检测？\"><a href=\"#如何检测？\" class=\"headerlink\" title=\"如何检测？\"></a>如何检测？</h1><p><strong>顾名思义，SimpleBlobDetector基于以下描述的相当简单的算法。该算法由参数控制（下面以粗体显示），并具有以下步骤。</strong></p>\n<ol>\n<li><strong>阈值处理</strong>：通过以minThreshold开始的阈值对源图像进行阈值处理，将源图像转换为多个二进制图像  。这些阈值以thresholdStep递增，  直到  maxThreshold。因此，第一个阈值为  minThreshold， 第二个阈值为  minThreshold  +  thresholdStep，第三个阈 值为  minThreshold  + 2 x thresholdStep，依此类推。</li>\n<li><strong>分组</strong>： 在每个二进制图像中，连接的白色像素被分组在一起。让我们称这些二进制blob。<br>3.<strong> 合并</strong>   ：计算二进制图像中二进制斑点的中心，并合并比minDistBetweenBlob 更近的斑点  。</li>\n<li><strong>中心和半径计算</strong>： 计算并返回新合并的Blob的中心和半径。</li>\n</ol>\n<h1 id=\"过滤方法\"><a href=\"#过滤方法\" class=\"headerlink\" title=\"过滤方法?\"></a>过滤方法?</h1><ul>\n<li><strong>按颜色</strong>：首先，您需要设置  filterByColor =1。设置  blobColor = 0以选择较暗的blob，将  blobColor =  255设置为较浅的blob。 </li>\n<li><strong>按大小</strong>：   可以通过设置参数filterByArea = 1以及minArea   和maxArea的适当值来基于大小过滤blob 。例如，设置  minArea   = 100将滤除所有少于100个像素的斑点。</li>\n<li><p>按形状： 现在形状具有三个不同的参数。</p>\n<ul>\n<li>圆度：  这只是测量斑点距圆的距离。例如，正六边形的圆度比正方形大。要按圆度过滤，请设置 filterByCircularity  =1。然后为minCircularity  和maxCircularity设置适当的值。 圆度定义为<ul>\n<li>\\ frac {4 <em> \\ pi </em> Area} {perimeter * perimeter}</li>\n<li>这意味着圆的圆度为1，正方形的圆度为0.785，依此类推。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>凸性： 凸度定义为（斑点的面积/凸包的面积）。现在，形状的凸包是完全封闭该形状的最紧密的凸形。由凸滤波器，首先设置filterByConvexity  = 1 ，然后设置0≤  minConvexity ≤1  和maxConvexity（≤1） 图为凹形与凸形<br><img src=\"https://blog.mviai.com/images/FiddIYcg0MJx1eJ9NVoEqVqG8Gkz\" alt=\"image.png\"></p>\n</li>\n<li><p>惯性比： 不要让它吓到你。数学家经常使用容易混淆的单词来描述非常简单的事物。您只需要知道这可以衡量形状的伸长程度。例如，对于一个圆，该值是1，对于椭圆它是0和1之间，而对于线是0。要通过过滤器惯量比，设置  filterByInertia = 1 ， 并设置0≤  minInertiaRatio  ≤1  和  maxInertiaRatio  （≤ 1） 适当。<br><img src=\"https://blog.mviai.com/images/FmI9PxggIyccKESVr5kkeRpaxHj9\" alt=\"image.png\"></p>\n</li>\n</ul>\n<h1 id=\"SimpleBlobDetector\"><a href=\"#SimpleBlobDetector\" class=\"headerlink\" title=\"SimpleBlobDetector\"></a>SimpleBlobDetector</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 导入相关的包</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 读取图片</span></span><br><span class=\"line\">im = cv2.imread(<span class=\"string\">\"blob.jpg\"</span>, cv2.IMREAD_GRAYSCALE)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置SimpleBlobDetector参数</span></span><br><span class=\"line\">params = cv2.SimpleBlobDetector_Params()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 更改阈值</span></span><br><span class=\"line\">params.minThreshold = <span class=\"number\">10</span></span><br><span class=\"line\">params.maxThreshold = <span class=\"number\">200</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 基于大小过滤</span></span><br><span class=\"line\">params.filterByArea = <span class=\"literal\">True</span></span><br><span class=\"line\">params.minArea = <span class=\"number\">1500</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 基于圆度过滤</span></span><br><span class=\"line\">params.filterByCircularity = <span class=\"literal\">True</span></span><br><span class=\"line\">params.minCircularity = <span class=\"number\">0.1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 按凸性过滤</span></span><br><span class=\"line\">params.filterByConvexity = <span class=\"literal\">True</span></span><br><span class=\"line\">params.minConvexity = <span class=\"number\">0.87</span></span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\"># 按惯性过滤</span></span><br><span class=\"line\">params.filterByInertia = <span class=\"literal\">True</span></span><br><span class=\"line\">params.minInertiaRatio = <span class=\"number\">0.01</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 通过参数创建检测器</span></span><br><span class=\"line\">ver = (cv2.__version__).split(<span class=\"string\">'.'</span>)</span><br><span class=\"line\"><span class=\"keyword\">if</span> int(ver[<span class=\"number\">0</span>]) &lt; <span class=\"number\">3</span> :</span><br><span class=\"line\">\tdetector = cv2.SimpleBlobDetector(params)</span><br><span class=\"line\"><span class=\"keyword\">else</span> : </span><br><span class=\"line\">\tdetector = cv2.SimpleBlobDetector_create(params)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 检测 blobs.</span></span><br><span class=\"line\">keypoints = detector.detect(im)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 将检测到的斑点绘制为红色圆圈</span></span><br><span class=\"line\"><span class=\"comment\"># cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS</span></span><br><span class=\"line\"><span class=\"comment\"># 确保圆的大小对应blobs的大小</span></span><br><span class=\"line\"></span><br><span class=\"line\">im_with_keypoints = cv2.drawKeypoints(im, keypoints, np.array([]), (<span class=\"number\">0</span>,<span class=\"number\">0</span>,<span class=\"number\">255</span>), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 显示 blobs</span></span><br><span class=\"line\">cv2.imshow(<span class=\"string\">\"Keypoints\"</span>, im_with_keypoints)</span><br><span class=\"line\">cv2.waitKey(<span class=\"number\">0</span>)</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://blog.mviai.com/images/FmX70X4ma5-XzZTlRTTp23duG8DX\" alt=\"image.png\"></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 导入相关包</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"opencv2/opencv.hpp\"</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> cv;</span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">( <span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv )</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">//读取图片</span></span><br><span class=\"line\">\tMat im = imread( <span class=\"string\">\"../blob.jpg\"</span>, IMREAD_GRAYSCALE );</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 设置SimpleBlobDetector参数</span></span><br><span class=\"line\">\tSimpleBlobDetector::Params params;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 设置阈值</span></span><br><span class=\"line\">\tparams.minThreshold = <span class=\"number\">10</span>;</span><br><span class=\"line\">\tparams.maxThreshold = <span class=\"number\">200</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 按大小过滤</span></span><br><span class=\"line\">\tparams.filterByArea = <span class=\"literal\">true</span>;</span><br><span class=\"line\">\tparams.minArea = <span class=\"number\">1500</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 按圆度过滤</span></span><br><span class=\"line\">\tparams.filterByCircularity = <span class=\"literal\">true</span>;</span><br><span class=\"line\">\tparams.minCircularity = <span class=\"number\">0.1</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 按凸性过滤</span></span><br><span class=\"line\">\tparams.filterByConvexity = <span class=\"literal\">true</span>;</span><br><span class=\"line\">\tparams.minConvexity = <span class=\"number\">0.87</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 按惯性过滤</span></span><br><span class=\"line\">\tparams.filterByInertia = <span class=\"literal\">true</span>;</span><br><span class=\"line\">\tparams.minInertiaRatio = <span class=\"number\">0.01</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 创建保存特征点变量</span></span><br><span class=\"line\">\t<span class=\"built_in\">vector</span>&lt;KeyPoint&gt; keypoints;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">if</span> CV_MAJOR_VERSION &lt; 3   <span class=\"comment\">// 如果使用 OpenCV 2</span></span></span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 设置通过参数创建检测器</span></span><br><span class=\"line\">\t<span class=\"function\">SimpleBlobDetector <span class=\"title\">detector</span><span class=\"params\">(params)</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 检测 blobs</span></span><br><span class=\"line\">\tdetector.detect( im, keypoints);</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">else</span> </span></span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 设置通过参数创建检测器</span></span><br><span class=\"line\">\tPtr&lt;SimpleBlobDetector&gt; detector = SimpleBlobDetector::create(params);   </span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 检测 blobs</span></span><br><span class=\"line\">\tdetector-&gt;detect( im, keypoints);</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//# 将检测到的斑点绘制为红色圆圈</span></span><br><span class=\"line\">    <span class=\"comment\">//# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS</span></span><br><span class=\"line\">    <span class=\"comment\">//# 确保圆的大小对应blobs的大小</span></span><br><span class=\"line\"></span><br><span class=\"line\">\tMat im_with_keypoints;</span><br><span class=\"line\">\tdrawKeypoints( im, keypoints, im_with_keypoints, Scalar(<span class=\"number\">0</span>,<span class=\"number\">0</span>,<span class=\"number\">255</span>), DrawMatchesFlags::DRAW_RICH_KEYPOINTS );</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 显示 blobs</span></span><br><span class=\"line\">\timshow(<span class=\"string\">\"keypoints\"</span>, im_with_keypoints );</span><br><span class=\"line\">\twaitKey(<span class=\"number\">0</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><strong>注:希望能调好参数,把所有的都识别到</strong></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"什么是Blob？\"><a href=\"#什么是Blob？\" class=\"headerlink\" title=\"什么是Blob？\"></a>什么是Blob？</h1><p>Blob是图像中一组共享的像素，它们具有某些共同的属性（例如灰度值）。在上图中，深色连接区域是斑点，斑点检测的目的是识别并标记这些区域。<br><img src=\"https://blog.mviai.com/images/FpYRqbsn3CaJ-vf4IKRfKkChgVAW\" alt=\"image.png\"></p>\n<h1 id=\"如何检测？\"><a href=\"#如何检测？\" class=\"headerlink\" title=\"如何检测？\"></a>如何检测？</h1><p><strong>顾名思义，SimpleBlobDetector基于以下描述的相当简单的算法。该算法由参数控制（下面以粗体显示），并具有以下步骤。</strong></p>\n<ol>\n<li><strong>阈值处理</strong>：通过以minThreshold开始的阈值对源图像进行阈值处理，将源图像转换为多个二进制图像  。这些阈值以thresholdStep递增，  直到  maxThreshold。因此，第一个阈值为  minThreshold， 第二个阈值为  minThreshold  +  thresholdStep，第三个阈 值为  minThreshold  + 2 x thresholdStep，依此类推。</li>\n<li><strong>分组</strong>： 在每个二进制图像中，连接的白色像素被分组在一起。让我们称这些二进制blob。<br>3.<strong> 合并</strong>   ：计算二进制图像中二进制斑点的中心，并合并比minDistBetweenBlob 更近的斑点  。</li>\n<li><strong>中心和半径计算</strong>： 计算并返回新合并的Blob的中心和半径。</li>\n</ol>\n<h1 id=\"过滤方法\"><a href=\"#过滤方法\" class=\"headerlink\" title=\"过滤方法?\"></a>过滤方法?</h1><ul>\n<li><strong>按颜色</strong>：首先，您需要设置  filterByColor =1。设置  blobColor = 0以选择较暗的blob，将  blobColor =  255设置为较浅的blob。 </li>\n<li><strong>按大小</strong>：   可以通过设置参数filterByArea = 1以及minArea   和maxArea的适当值来基于大小过滤blob 。例如，设置  minArea   = 100将滤除所有少于100个像素的斑点。</li>\n<li><p>按形状： 现在形状具有三个不同的参数。</p>\n<ul>\n<li>圆度：  这只是测量斑点距圆的距离。例如，正六边形的圆度比正方形大。要按圆度过滤，请设置 filterByCircularity  =1。然后为minCircularity  和maxCircularity设置适当的值。 圆度定义为<ul>\n<li>\\ frac {4 <em> \\ pi </em> Area} {perimeter * perimeter}</li>\n<li>这意味着圆的圆度为1，正方形的圆度为0.785，依此类推。</li>\n</ul>\n</li>\n</ul>\n</li>\n<li><p>凸性： 凸度定义为（斑点的面积/凸包的面积）。现在，形状的凸包是完全封闭该形状的最紧密的凸形。由凸滤波器，首先设置filterByConvexity  = 1 ，然后设置0≤  minConvexity ≤1  和maxConvexity（≤1） 图为凹形与凸形<br><img src=\"https://blog.mviai.com/images/FiddIYcg0MJx1eJ9NVoEqVqG8Gkz\" alt=\"image.png\"></p>\n</li>\n<li><p>惯性比： 不要让它吓到你。数学家经常使用容易混淆的单词来描述非常简单的事物。您只需要知道这可以衡量形状的伸长程度。例如，对于一个圆，该值是1，对于椭圆它是0和1之间，而对于线是0。要通过过滤器惯量比，设置  filterByInertia = 1 ， 并设置0≤  minInertiaRatio  ≤1  和  maxInertiaRatio  （≤ 1） 适当。<br><img src=\"https://blog.mviai.com/images/FmI9PxggIyccKESVr5kkeRpaxHj9\" alt=\"image.png\"></p>\n</li>\n</ul>\n<h1 id=\"SimpleBlobDetector\"><a href=\"#SimpleBlobDetector\" class=\"headerlink\" title=\"SimpleBlobDetector\"></a>SimpleBlobDetector</h1><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 导入相关的包</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2</span><br><span class=\"line\"><span class=\"keyword\">import</span> numpy <span class=\"keyword\">as</span> np</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 读取图片</span></span><br><span class=\"line\">im = cv2.imread(<span class=\"string\">\"blob.jpg\"</span>, cv2.IMREAD_GRAYSCALE)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置SimpleBlobDetector参数</span></span><br><span class=\"line\">params = cv2.SimpleBlobDetector_Params()</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 更改阈值</span></span><br><span class=\"line\">params.minThreshold = <span class=\"number\">10</span></span><br><span class=\"line\">params.maxThreshold = <span class=\"number\">200</span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 基于大小过滤</span></span><br><span class=\"line\">params.filterByArea = <span class=\"literal\">True</span></span><br><span class=\"line\">params.minArea = <span class=\"number\">1500</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 基于圆度过滤</span></span><br><span class=\"line\">params.filterByCircularity = <span class=\"literal\">True</span></span><br><span class=\"line\">params.minCircularity = <span class=\"number\">0.1</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 按凸性过滤</span></span><br><span class=\"line\">params.filterByConvexity = <span class=\"literal\">True</span></span><br><span class=\"line\">params.minConvexity = <span class=\"number\">0.87</span></span><br><span class=\"line\">    </span><br><span class=\"line\"><span class=\"comment\"># 按惯性过滤</span></span><br><span class=\"line\">params.filterByInertia = <span class=\"literal\">True</span></span><br><span class=\"line\">params.minInertiaRatio = <span class=\"number\">0.01</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 通过参数创建检测器</span></span><br><span class=\"line\">ver = (cv2.__version__).split(<span class=\"string\">'.'</span>)</span><br><span class=\"line\"><span class=\"keyword\">if</span> int(ver[<span class=\"number\">0</span>]) &lt; <span class=\"number\">3</span> :</span><br><span class=\"line\">\tdetector = cv2.SimpleBlobDetector(params)</span><br><span class=\"line\"><span class=\"keyword\">else</span> : </span><br><span class=\"line\">\tdetector = cv2.SimpleBlobDetector_create(params)</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 检测 blobs.</span></span><br><span class=\"line\">keypoints = detector.detect(im)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 将检测到的斑点绘制为红色圆圈</span></span><br><span class=\"line\"><span class=\"comment\"># cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS</span></span><br><span class=\"line\"><span class=\"comment\"># 确保圆的大小对应blobs的大小</span></span><br><span class=\"line\"></span><br><span class=\"line\">im_with_keypoints = cv2.drawKeypoints(im, keypoints, np.array([]), (<span class=\"number\">0</span>,<span class=\"number\">0</span>,<span class=\"number\">255</span>), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 显示 blobs</span></span><br><span class=\"line\">cv2.imshow(<span class=\"string\">\"Keypoints\"</span>, im_with_keypoints)</span><br><span class=\"line\">cv2.waitKey(<span class=\"number\">0</span>)</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://blog.mviai.com/images/FmX70X4ma5-XzZTlRTTp23duG8DX\" alt=\"image.png\"></p>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br><span class=\"line\">49</span><br><span class=\"line\">50</span><br><span class=\"line\">51</span><br><span class=\"line\">52</span><br><span class=\"line\">53</span><br><span class=\"line\">54</span><br><span class=\"line\">55</span><br><span class=\"line\">56</span><br><span class=\"line\">57</span><br><span class=\"line\">58</span><br><span class=\"line\">59</span><br><span class=\"line\">60</span><br><span class=\"line\">61</span><br><span class=\"line\">62</span><br><span class=\"line\">63</span><br><span class=\"line\">64</span><br><span class=\"line\">65</span><br><span class=\"line\">66</span><br><span class=\"line\">67</span><br><span class=\"line\">68</span><br><span class=\"line\">69</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">// 导入相关包</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"opencv2/opencv.hpp\"</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> cv;</span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">( <span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv )</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">//读取图片</span></span><br><span class=\"line\">\tMat im = imread( <span class=\"string\">\"../blob.jpg\"</span>, IMREAD_GRAYSCALE );</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 设置SimpleBlobDetector参数</span></span><br><span class=\"line\">\tSimpleBlobDetector::Params params;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 设置阈值</span></span><br><span class=\"line\">\tparams.minThreshold = <span class=\"number\">10</span>;</span><br><span class=\"line\">\tparams.maxThreshold = <span class=\"number\">200</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 按大小过滤</span></span><br><span class=\"line\">\tparams.filterByArea = <span class=\"literal\">true</span>;</span><br><span class=\"line\">\tparams.minArea = <span class=\"number\">1500</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 按圆度过滤</span></span><br><span class=\"line\">\tparams.filterByCircularity = <span class=\"literal\">true</span>;</span><br><span class=\"line\">\tparams.minCircularity = <span class=\"number\">0.1</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 按凸性过滤</span></span><br><span class=\"line\">\tparams.filterByConvexity = <span class=\"literal\">true</span>;</span><br><span class=\"line\">\tparams.minConvexity = <span class=\"number\">0.87</span>;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 按惯性过滤</span></span><br><span class=\"line\">\tparams.filterByInertia = <span class=\"literal\">true</span>;</span><br><span class=\"line\">\tparams.minInertiaRatio = <span class=\"number\">0.01</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 创建保存特征点变量</span></span><br><span class=\"line\">\t<span class=\"built_in\">vector</span>&lt;KeyPoint&gt; keypoints;</span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">if</span> CV_MAJOR_VERSION &lt; 3   <span class=\"comment\">// 如果使用 OpenCV 2</span></span></span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 设置通过参数创建检测器</span></span><br><span class=\"line\">\t<span class=\"function\">SimpleBlobDetector <span class=\"title\">detector</span><span class=\"params\">(params)</span></span>;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 检测 blobs</span></span><br><span class=\"line\">\tdetector.detect( im, keypoints);</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">else</span> </span></span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 设置通过参数创建检测器</span></span><br><span class=\"line\">\tPtr&lt;SimpleBlobDetector&gt; detector = SimpleBlobDetector::create(params);   </span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 检测 blobs</span></span><br><span class=\"line\">\tdetector-&gt;detect( im, keypoints);</span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">endif</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"comment\">//# 将检测到的斑点绘制为红色圆圈</span></span><br><span class=\"line\">    <span class=\"comment\">//# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS</span></span><br><span class=\"line\">    <span class=\"comment\">//# 确保圆的大小对应blobs的大小</span></span><br><span class=\"line\"></span><br><span class=\"line\">\tMat im_with_keypoints;</span><br><span class=\"line\">\tdrawKeypoints( im, keypoints, im_with_keypoints, Scalar(<span class=\"number\">0</span>,<span class=\"number\">0</span>,<span class=\"number\">255</span>), DrawMatchesFlags::DRAW_RICH_KEYPOINTS );</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 显示 blobs</span></span><br><span class=\"line\">\timshow(<span class=\"string\">\"keypoints\"</span>, im_with_keypoints );</span><br><span class=\"line\">\twaitKey(<span class=\"number\">0</span>);</span><br><span class=\"line\"></span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>\n<p><strong>注:希望能调好参数,把所有的都识别到</strong></p>\n"},{"title":"数据链路层","url":"96.html","id":"96","date":"2018-04-05T13:06:21.000Z","_content":"\n\\[success\\]\n\n今天过生，把最难得数据链路层整理下：\n------------------\n\n#### 计算机网络学不好，说真的，确实是数据链路层没搞懂，以前忽视了，现在整理下：\n\n#### 数据链路层\n\n组帧方法\n\n  字符计数法\n\n    用个计数字段来表明帧内字符数\n\n  字符填充首尾定界法\n\n    用开始（DLE STX)和结束（DLE ETX)来控制首尾定界\n\n    他的透明传输表现\n\n        如果数据部分出现DLE ，发方则在数据部分在加个DLE， 以区别首尾定界，收方收到两个DLE,DLE则删除一个\n\n  常用组帧方法\n\n    比特填充法\n\n        首尾用01111110来标志一帧的开始与结束\n\n        他的透明传输表现\n\n                如果数据部分出现五个连续1，发方则在五个1后面插入一个0；接收方相反\n\n    违规编码法\n\n        在物理层编码时，曼切斯特编码用了高低电平表示0,1. 违规编码则是用高高，低低电平表示起始，因为在物理层完成定界，所以不需要要任何技术就能实现透明传输\n\n差错控制\n\n  ARQ（自动重传请求）\n\n  FEC（前向纠错）\n\n    检错编码\n\n        奇偶校检码\n\n                垂直奇偶校检\n\n                水平奇偶校检\n\n                水平垂直奇偶校检\n\n        CRC（循环冗余码）\n\n    纠错编码\n\n        海明码\n\n                M个信息位插入R个校检位组成m+r位码字 ，必须满足关系2^r>=m+r+1;\n\n流控与可靠传输\n\n  滑动窗口流控\n\n    发送窗口=1，接受窗口=1\n\n        停等流控\n\n                发方每发送一个帧，必须收到应答才发送下一个帧\n\n    发送窗口>1，接受窗口=1\n\n        回退N流控\n\n                1<=发送窗口<=2^n-1\n\n    发送窗口>1，接受窗口>1\n\n        选择重传流控\n\n                接收窗口+发送窗口<=2^n，接收窗口必须小于序列号范围的一半，接收窗口<=2^(n-1)，否则无意义。\n\n介质访问控制（MAC）\n\n  信道划分介质访问控制\n\n    频分多路复用（FDM)\n\n        将多路基带信号调制到不同频率载波，在进行叠加形成一个符合信号\n\n    时分多路复用(TDM)\n\n        将一条物理信道按时间分成若干时间片，理论刘分配给多个信号使用\n\n        升级版：统计(异步)时分多路复用（STDM)\n\n                区别：将固定分配时隙改进成按需动态分配时隙\n\n    波分多路复用（WDM）\n\n        就是光的频分多路复用：光纤中传输不同波长（频率）的光，通过频率不同分解合成\n\n    码分多路复用（cdm)\n\n        原理:靠不同编码来区分各路原始信号（共享频率，共享时间）\n\n        复用方式\n\n                码分多址（cdma）\n\n                优点：利用率高，保密强，语音通信好，成本低\n\n                应用：无线通信，特别是移动通信\n\n  随机访问介质访问控制\n\n    ALOHA协议\n\n        纯ALOHA\n\n                当网络任一站点需要发送数据，不检测就发，如果没收到确认，就等一段时间在发\n\n        升级版：时隙ALOHA\n\n                区别：把网络时间同步，将时间分成等段的时隙，规定只能在时隙开始时才能发送\n\n    csma协议\n\n        1-坚持协议（100%发送）\n\n                侦听-空闲就发 侦听-忙则等待，并继续侦听到空闲为止 冲突-随机等待一段时间-重新侦听\n\n        0-坚持（非坚持）协议\n\n                侦听-空闲就发 侦听-忙则放弃侦听，等待随机一段时间\n\n        p-坚持协议\n\n                侦听-空闲就以p的概率发 以1-p的概率推迟到下个时隙 侦听-忙则等待下个时隙侦听 冲突-随机等待一段时间-重新侦听\n\n    CDMA/CD协议\n\n        工作流程\n\n                先听后发，边听边发，冲突停发，随机重发\n\n        检测冲突\n\n                以太网端到端往返时间2t叫做争用期（冲突窗口或碰撞期）\n\n                最小帧长=总线传播时延（t)*数据传输率（C）*2\n\n        冲突后处理\n\n                二进制退避法\n\n                随着冲突重传次数增大而增大\n\n        使用范围\n\n                用于总线型网络或半双工网络\n\n    CDMA/ca协议\n\n        应用：局域网和无线局域网\n\n        区别：将cd（碰撞检测）改成ca（碰撞避免）\n\n  轮询访问介质访问控制\n\n    令牌传递协议\n\n        持令发，没持不准发\n\n局域网LAN\n\n  以太网(ieee802.3)\n\n    逻辑：总线 物理：星形\n\n    以太网MAC地址\n\n        使用6字节（48比特）地址\n\n    高速以太网\n\n        100dase-t以太网\n\n        吉比特以太网\n\n        10吉比特以太网\n\n    无线局域网（ieee802.11）\n\n        有基础设施\n\n                最小单位：基本服务集(BSS)\n\n                bss中基站也叫接入点（ap）\n\n        无基础设施（ad hoc）\n\n  令牌环网（IEEE802.5）\n\n    逻辑：环形 物理：星形\n\n  fddi（IEEE802.8）\n\n    逻辑：环形 物理：双环\n\n广域网\n\n  面向字节\n\n    ppp协议（点到点）\n\n        组成\n\n                链路控制协议（lcp）\n\n                网络控制协议（ncp）\n\n                将ip数据报封装在链路的方法\n\n        透明传输方法\n\n                ppp在异步线路（默认）\n\n                使用字节填充法\n\n                ppp在sonet/sdh同步线路\n\n                使用比特填充法（HDLC一样）\n\n  面向比特\n\n    hdlc协议\n\n        分类\n\n                非平衡配置\n\n                平衡配置\n\n        站的类型\n\n                主站\n\n                从站\n\n                复合站\n\n        操作方式\n\n                正常响应方式\n\n                主站向从站传输数据，从站要得到主站许可，才可以做事（响应）\n\n                异步平衡方式\n\n                每个复合站都可以向另一个站传输数据\n\n                异步响应方式\n\n                从站没接受主站许可就可以传输\n\n        帧结构\n\n                信息帧（i）第一位为0\n\n                监控帧（S) 第一二位为1,0\n\n                无编号帧（u）第一二位为1,1\n\n设备\n\n  网桥\n\n    网段概念\n\n        通过网桥连接起来的以太网，每个以太网就叫网段\n\n    工作层次\n\n        链路层的mac子层\n\n    路径选择算法\n\n        透明网桥\n\n                转发表建立方式\n\n                自学习算法：从某端口进来，一定能从相反端口出去\n\n                工作方式\n\n                源端口与目的端口一样，丢弃 源端口与目的端口不同，转发 目的端口未知，扩散\n\n        源路由网桥\n\n                工作方式\n\n                1.广播发送一个发现帧去探索。 2.每个目的站应答，然后发送应答帧 3.应答帧原路径返回，途径网桥把自己标志记录在应答帧中 4.源站确定最佳路由（路线/转发表），以后凡是从这个源发往该目的都要携带理由信息。\n\n  局域网交换机（多端口网桥）\n\n    交换模式\n\n        直通交换\n\n        存储转发交换\n\n    最大优点\n\n        用户独占带宽\n\n        加入vlan\n\n                可以隔离冲突域，广播域\n\n    原理\n\n        检测源目的mac地址，查找表，若没有在表中，则加入表，然后再转发\n\n功能\n\n  为网络层提供服务\n\n    无确认无连接\n\n        以太网\n\n    有确认无连接\n\n        无线网\n\n    有确认面向连接\n\n        通信要求（可靠性，实时性）较高的场合\n\n  链路管理\n\n  组帧\n\n    帧定界\n\n        确定帧的边界（界限）\n\n    帧同步\n\n        接收方能从比特流中分出帧的起止\n\n    透明传输\n\n        防止出现数据部分出现与帧定界一样的组合\n\n  流控\n\n    控制收发的速率，以及缓存空间（窗口）大小\n\n  差错控制\n\n    位错\n\n        ARQ（自动重传请求）\n\n        CRC（循环冗余校检）\n\n    帧错\n\n        定时器\n\n        编号机制\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/04/数据链路层.png) [**如何下载使用思维导图（点我）**](https://blog.mviai.com/images/archives/172) 思维导图下载  链接：https://pan.yangxin.com/s/1J1fkVM3qZEmjMmIydz9lmw \\[/success\\] \\[reply\\]密码：sml6 \\[/reply\\]\n","source":"_posts/数据链路层.md","raw":"---\ntitle: 数据链路层\ntags:\n  - 网络\nurl: 96.html\nid: 96\ncategories:\n  - 学习\n  - 计算机网络\n  - 数据链路层\ndate: 2018-04-05 21:06:21\n---\n\n\\[success\\]\n\n今天过生，把最难得数据链路层整理下：\n------------------\n\n#### 计算机网络学不好，说真的，确实是数据链路层没搞懂，以前忽视了，现在整理下：\n\n#### 数据链路层\n\n组帧方法\n\n  字符计数法\n\n    用个计数字段来表明帧内字符数\n\n  字符填充首尾定界法\n\n    用开始（DLE STX)和结束（DLE ETX)来控制首尾定界\n\n    他的透明传输表现\n\n        如果数据部分出现DLE ，发方则在数据部分在加个DLE， 以区别首尾定界，收方收到两个DLE,DLE则删除一个\n\n  常用组帧方法\n\n    比特填充法\n\n        首尾用01111110来标志一帧的开始与结束\n\n        他的透明传输表现\n\n                如果数据部分出现五个连续1，发方则在五个1后面插入一个0；接收方相反\n\n    违规编码法\n\n        在物理层编码时，曼切斯特编码用了高低电平表示0,1. 违规编码则是用高高，低低电平表示起始，因为在物理层完成定界，所以不需要要任何技术就能实现透明传输\n\n差错控制\n\n  ARQ（自动重传请求）\n\n  FEC（前向纠错）\n\n    检错编码\n\n        奇偶校检码\n\n                垂直奇偶校检\n\n                水平奇偶校检\n\n                水平垂直奇偶校检\n\n        CRC（循环冗余码）\n\n    纠错编码\n\n        海明码\n\n                M个信息位插入R个校检位组成m+r位码字 ，必须满足关系2^r>=m+r+1;\n\n流控与可靠传输\n\n  滑动窗口流控\n\n    发送窗口=1，接受窗口=1\n\n        停等流控\n\n                发方每发送一个帧，必须收到应答才发送下一个帧\n\n    发送窗口>1，接受窗口=1\n\n        回退N流控\n\n                1<=发送窗口<=2^n-1\n\n    发送窗口>1，接受窗口>1\n\n        选择重传流控\n\n                接收窗口+发送窗口<=2^n，接收窗口必须小于序列号范围的一半，接收窗口<=2^(n-1)，否则无意义。\n\n介质访问控制（MAC）\n\n  信道划分介质访问控制\n\n    频分多路复用（FDM)\n\n        将多路基带信号调制到不同频率载波，在进行叠加形成一个符合信号\n\n    时分多路复用(TDM)\n\n        将一条物理信道按时间分成若干时间片，理论刘分配给多个信号使用\n\n        升级版：统计(异步)时分多路复用（STDM)\n\n                区别：将固定分配时隙改进成按需动态分配时隙\n\n    波分多路复用（WDM）\n\n        就是光的频分多路复用：光纤中传输不同波长（频率）的光，通过频率不同分解合成\n\n    码分多路复用（cdm)\n\n        原理:靠不同编码来区分各路原始信号（共享频率，共享时间）\n\n        复用方式\n\n                码分多址（cdma）\n\n                优点：利用率高，保密强，语音通信好，成本低\n\n                应用：无线通信，特别是移动通信\n\n  随机访问介质访问控制\n\n    ALOHA协议\n\n        纯ALOHA\n\n                当网络任一站点需要发送数据，不检测就发，如果没收到确认，就等一段时间在发\n\n        升级版：时隙ALOHA\n\n                区别：把网络时间同步，将时间分成等段的时隙，规定只能在时隙开始时才能发送\n\n    csma协议\n\n        1-坚持协议（100%发送）\n\n                侦听-空闲就发 侦听-忙则等待，并继续侦听到空闲为止 冲突-随机等待一段时间-重新侦听\n\n        0-坚持（非坚持）协议\n\n                侦听-空闲就发 侦听-忙则放弃侦听，等待随机一段时间\n\n        p-坚持协议\n\n                侦听-空闲就以p的概率发 以1-p的概率推迟到下个时隙 侦听-忙则等待下个时隙侦听 冲突-随机等待一段时间-重新侦听\n\n    CDMA/CD协议\n\n        工作流程\n\n                先听后发，边听边发，冲突停发，随机重发\n\n        检测冲突\n\n                以太网端到端往返时间2t叫做争用期（冲突窗口或碰撞期）\n\n                最小帧长=总线传播时延（t)*数据传输率（C）*2\n\n        冲突后处理\n\n                二进制退避法\n\n                随着冲突重传次数增大而增大\n\n        使用范围\n\n                用于总线型网络或半双工网络\n\n    CDMA/ca协议\n\n        应用：局域网和无线局域网\n\n        区别：将cd（碰撞检测）改成ca（碰撞避免）\n\n  轮询访问介质访问控制\n\n    令牌传递协议\n\n        持令发，没持不准发\n\n局域网LAN\n\n  以太网(ieee802.3)\n\n    逻辑：总线 物理：星形\n\n    以太网MAC地址\n\n        使用6字节（48比特）地址\n\n    高速以太网\n\n        100dase-t以太网\n\n        吉比特以太网\n\n        10吉比特以太网\n\n    无线局域网（ieee802.11）\n\n        有基础设施\n\n                最小单位：基本服务集(BSS)\n\n                bss中基站也叫接入点（ap）\n\n        无基础设施（ad hoc）\n\n  令牌环网（IEEE802.5）\n\n    逻辑：环形 物理：星形\n\n  fddi（IEEE802.8）\n\n    逻辑：环形 物理：双环\n\n广域网\n\n  面向字节\n\n    ppp协议（点到点）\n\n        组成\n\n                链路控制协议（lcp）\n\n                网络控制协议（ncp）\n\n                将ip数据报封装在链路的方法\n\n        透明传输方法\n\n                ppp在异步线路（默认）\n\n                使用字节填充法\n\n                ppp在sonet/sdh同步线路\n\n                使用比特填充法（HDLC一样）\n\n  面向比特\n\n    hdlc协议\n\n        分类\n\n                非平衡配置\n\n                平衡配置\n\n        站的类型\n\n                主站\n\n                从站\n\n                复合站\n\n        操作方式\n\n                正常响应方式\n\n                主站向从站传输数据，从站要得到主站许可，才可以做事（响应）\n\n                异步平衡方式\n\n                每个复合站都可以向另一个站传输数据\n\n                异步响应方式\n\n                从站没接受主站许可就可以传输\n\n        帧结构\n\n                信息帧（i）第一位为0\n\n                监控帧（S) 第一二位为1,0\n\n                无编号帧（u）第一二位为1,1\n\n设备\n\n  网桥\n\n    网段概念\n\n        通过网桥连接起来的以太网，每个以太网就叫网段\n\n    工作层次\n\n        链路层的mac子层\n\n    路径选择算法\n\n        透明网桥\n\n                转发表建立方式\n\n                自学习算法：从某端口进来，一定能从相反端口出去\n\n                工作方式\n\n                源端口与目的端口一样，丢弃 源端口与目的端口不同，转发 目的端口未知，扩散\n\n        源路由网桥\n\n                工作方式\n\n                1.广播发送一个发现帧去探索。 2.每个目的站应答，然后发送应答帧 3.应答帧原路径返回，途径网桥把自己标志记录在应答帧中 4.源站确定最佳路由（路线/转发表），以后凡是从这个源发往该目的都要携带理由信息。\n\n  局域网交换机（多端口网桥）\n\n    交换模式\n\n        直通交换\n\n        存储转发交换\n\n    最大优点\n\n        用户独占带宽\n\n        加入vlan\n\n                可以隔离冲突域，广播域\n\n    原理\n\n        检测源目的mac地址，查找表，若没有在表中，则加入表，然后再转发\n\n功能\n\n  为网络层提供服务\n\n    无确认无连接\n\n        以太网\n\n    有确认无连接\n\n        无线网\n\n    有确认面向连接\n\n        通信要求（可靠性，实时性）较高的场合\n\n  链路管理\n\n  组帧\n\n    帧定界\n\n        确定帧的边界（界限）\n\n    帧同步\n\n        接收方能从比特流中分出帧的起止\n\n    透明传输\n\n        防止出现数据部分出现与帧定界一样的组合\n\n  流控\n\n    控制收发的速率，以及缓存空间（窗口）大小\n\n  差错控制\n\n    位错\n\n        ARQ（自动重传请求）\n\n        CRC（循环冗余校检）\n\n    帧错\n\n        定时器\n\n        编号机制\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/04/数据链路层.png) [**如何下载使用思维导图（点我）**](https://blog.mviai.com/images/archives/172) 思维导图下载  链接：https://pan.yangxin.com/s/1J1fkVM3qZEmjMmIydz9lmw \\[/success\\] \\[reply\\]密码：sml6 \\[/reply\\]\n","slug":"数据链路层","published":1,"updated":"2021-07-26T09:58:02.582Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m2g002iigtad99tyutg","content":"<p>[success]</p>\n<h2 id=\"今天过生，把最难得数据链路层整理下：\"><a href=\"#今天过生，把最难得数据链路层整理下：\" class=\"headerlink\" title=\"今天过生，把最难得数据链路层整理下：\"></a>今天过生，把最难得数据链路层整理下：</h2><h4 id=\"计算机网络学不好，说真的，确实是数据链路层没搞懂，以前忽视了，现在整理下：\"><a href=\"#计算机网络学不好，说真的，确实是数据链路层没搞懂，以前忽视了，现在整理下：\" class=\"headerlink\" title=\"计算机网络学不好，说真的，确实是数据链路层没搞懂，以前忽视了，现在整理下：\"></a>计算机网络学不好，说真的，确实是数据链路层没搞懂，以前忽视了，现在整理下：</h4><h4 id=\"数据链路层\"><a href=\"#数据链路层\" class=\"headerlink\" title=\"数据链路层\"></a>数据链路层</h4><p>组帧方法</p>\n<p>  字符计数法</p>\n<pre><code>用个计数字段来表明帧内字符数\n</code></pre><p>  字符填充首尾定界法</p>\n<pre><code>用开始（DLE STX)和结束（DLE ETX)来控制首尾定界\n\n他的透明传输表现\n\n    如果数据部分出现DLE ，发方则在数据部分在加个DLE， 以区别首尾定界，收方收到两个DLE,DLE则删除一个\n</code></pre><p>  常用组帧方法</p>\n<pre><code>比特填充法\n\n    首尾用01111110来标志一帧的开始与结束\n\n    他的透明传输表现\n\n            如果数据部分出现五个连续1，发方则在五个1后面插入一个0；接收方相反\n\n违规编码法\n\n    在物理层编码时，曼切斯特编码用了高低电平表示0,1. 违规编码则是用高高，低低电平表示起始，因为在物理层完成定界，所以不需要要任何技术就能实现透明传输\n</code></pre><p>差错控制</p>\n<p>  ARQ（自动重传请求）</p>\n<p>  FEC（前向纠错）</p>\n<pre><code>检错编码\n\n    奇偶校检码\n\n            垂直奇偶校检\n\n            水平奇偶校检\n\n            水平垂直奇偶校检\n\n    CRC（循环冗余码）\n\n纠错编码\n\n    海明码\n\n            M个信息位插入R个校检位组成m+r位码字 ，必须满足关系2^r&gt;=m+r+1;\n</code></pre><p>流控与可靠传输</p>\n<p>  滑动窗口流控</p>\n<pre><code>发送窗口=1，接受窗口=1\n\n    停等流控\n\n            发方每发送一个帧，必须收到应答才发送下一个帧\n\n发送窗口&gt;1，接受窗口=1\n\n    回退N流控\n\n            1&lt;=发送窗口&lt;=2^n-1\n\n发送窗口&gt;1，接受窗口&gt;1\n\n    选择重传流控\n\n            接收窗口+发送窗口&lt;=2^n，接收窗口必须小于序列号范围的一半，接收窗口&lt;=2^(n-1)，否则无意义。\n</code></pre><p>介质访问控制（MAC）</p>\n<p>  信道划分介质访问控制</p>\n<pre><code>频分多路复用（FDM)\n\n    将多路基带信号调制到不同频率载波，在进行叠加形成一个符合信号\n\n时分多路复用(TDM)\n\n    将一条物理信道按时间分成若干时间片，理论刘分配给多个信号使用\n\n    升级版：统计(异步)时分多路复用（STDM)\n\n            区别：将固定分配时隙改进成按需动态分配时隙\n\n波分多路复用（WDM）\n\n    就是光的频分多路复用：光纤中传输不同波长（频率）的光，通过频率不同分解合成\n\n码分多路复用（cdm)\n\n    原理:靠不同编码来区分各路原始信号（共享频率，共享时间）\n\n    复用方式\n\n            码分多址（cdma）\n\n            优点：利用率高，保密强，语音通信好，成本低\n\n            应用：无线通信，特别是移动通信\n</code></pre><p>  随机访问介质访问控制</p>\n<pre><code>ALOHA协议\n\n    纯ALOHA\n\n            当网络任一站点需要发送数据，不检测就发，如果没收到确认，就等一段时间在发\n\n    升级版：时隙ALOHA\n\n            区别：把网络时间同步，将时间分成等段的时隙，规定只能在时隙开始时才能发送\n\ncsma协议\n\n    1-坚持协议（100%发送）\n\n            侦听-空闲就发 侦听-忙则等待，并继续侦听到空闲为止 冲突-随机等待一段时间-重新侦听\n\n    0-坚持（非坚持）协议\n\n            侦听-空闲就发 侦听-忙则放弃侦听，等待随机一段时间\n\n    p-坚持协议\n\n            侦听-空闲就以p的概率发 以1-p的概率推迟到下个时隙 侦听-忙则等待下个时隙侦听 冲突-随机等待一段时间-重新侦听\n\nCDMA/CD协议\n\n    工作流程\n\n            先听后发，边听边发，冲突停发，随机重发\n\n    检测冲突\n\n            以太网端到端往返时间2t叫做争用期（冲突窗口或碰撞期）\n\n            最小帧长=总线传播时延（t)*数据传输率（C）*2\n\n    冲突后处理\n\n            二进制退避法\n\n            随着冲突重传次数增大而增大\n\n    使用范围\n\n            用于总线型网络或半双工网络\n\nCDMA/ca协议\n\n    应用：局域网和无线局域网\n\n    区别：将cd（碰撞检测）改成ca（碰撞避免）\n</code></pre><p>  轮询访问介质访问控制</p>\n<pre><code>令牌传递协议\n\n    持令发，没持不准发\n</code></pre><p>局域网LAN</p>\n<p>  以太网(ieee802.3)</p>\n<pre><code>逻辑：总线 物理：星形\n\n以太网MAC地址\n\n    使用6字节（48比特）地址\n\n高速以太网\n\n    100dase-t以太网\n\n    吉比特以太网\n\n    10吉比特以太网\n\n无线局域网（ieee802.11）\n\n    有基础设施\n\n            最小单位：基本服务集(BSS)\n\n            bss中基站也叫接入点（ap）\n\n    无基础设施（ad hoc）\n</code></pre><p>  令牌环网（IEEE802.5）</p>\n<pre><code>逻辑：环形 物理：星形\n</code></pre><p>  fddi（IEEE802.8）</p>\n<pre><code>逻辑：环形 物理：双环\n</code></pre><p>广域网</p>\n<p>  面向字节</p>\n<pre><code>ppp协议（点到点）\n\n    组成\n\n            链路控制协议（lcp）\n\n            网络控制协议（ncp）\n\n            将ip数据报封装在链路的方法\n\n    透明传输方法\n\n            ppp在异步线路（默认）\n\n            使用字节填充法\n\n            ppp在sonet/sdh同步线路\n\n            使用比特填充法（HDLC一样）\n</code></pre><p>  面向比特</p>\n<pre><code>hdlc协议\n\n    分类\n\n            非平衡配置\n\n            平衡配置\n\n    站的类型\n\n            主站\n\n            从站\n\n            复合站\n\n    操作方式\n\n            正常响应方式\n\n            主站向从站传输数据，从站要得到主站许可，才可以做事（响应）\n\n            异步平衡方式\n\n            每个复合站都可以向另一个站传输数据\n\n            异步响应方式\n\n            从站没接受主站许可就可以传输\n\n    帧结构\n\n            信息帧（i）第一位为0\n\n            监控帧（S) 第一二位为1,0\n\n            无编号帧（u）第一二位为1,1\n</code></pre><p>设备</p>\n<p>  网桥</p>\n<pre><code>网段概念\n\n    通过网桥连接起来的以太网，每个以太网就叫网段\n\n工作层次\n\n    链路层的mac子层\n\n路径选择算法\n\n    透明网桥\n\n            转发表建立方式\n\n            自学习算法：从某端口进来，一定能从相反端口出去\n\n            工作方式\n\n            源端口与目的端口一样，丢弃 源端口与目的端口不同，转发 目的端口未知，扩散\n\n    源路由网桥\n\n            工作方式\n\n            1.广播发送一个发现帧去探索。 2.每个目的站应答，然后发送应答帧 3.应答帧原路径返回，途径网桥把自己标志记录在应答帧中 4.源站确定最佳路由（路线/转发表），以后凡是从这个源发往该目的都要携带理由信息。\n</code></pre><p>  局域网交换机（多端口网桥）</p>\n<pre><code>交换模式\n\n    直通交换\n\n    存储转发交换\n\n最大优点\n\n    用户独占带宽\n\n    加入vlan\n\n            可以隔离冲突域，广播域\n\n原理\n\n    检测源目的mac地址，查找表，若没有在表中，则加入表，然后再转发\n</code></pre><p>功能</p>\n<p>  为网络层提供服务</p>\n<pre><code>无确认无连接\n\n    以太网\n\n有确认无连接\n\n    无线网\n\n有确认面向连接\n\n    通信要求（可靠性，实时性）较高的场合\n</code></pre><p>  链路管理</p>\n<p>  组帧</p>\n<pre><code>帧定界\n\n    确定帧的边界（界限）\n\n帧同步\n\n    接收方能从比特流中分出帧的起止\n\n透明传输\n\n    防止出现数据部分出现与帧定界一样的组合\n</code></pre><p>  流控</p>\n<pre><code>控制收发的速率，以及缓存空间（窗口）大小\n</code></pre><p>  差错控制</p>\n<pre><code>位错\n\n    ARQ（自动重传请求）\n\n    CRC（循环冗余校检）\n\n帧错\n\n    定时器\n\n    编号机制\n</code></pre><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/数据链路层.png\" alt> <a href=\"https://blog.mviai.com/images/archives/172\" target=\"_blank\" rel=\"noopener\"><strong>如何下载使用思维导图（点我）</strong></a> 思维导图下载  链接：<a href=\"https://pan.yangxin.com/s/1J1fkVM3qZEmjMmIydz9lmw\" target=\"_blank\" rel=\"noopener\">https://pan.yangxin.com/s/1J1fkVM3qZEmjMmIydz9lmw</a> [/success] [reply]密码：sml6 [/reply]</p>\n","site":{"data":{}},"excerpt":"","more":"<p>[success]</p>\n<h2 id=\"今天过生，把最难得数据链路层整理下：\"><a href=\"#今天过生，把最难得数据链路层整理下：\" class=\"headerlink\" title=\"今天过生，把最难得数据链路层整理下：\"></a>今天过生，把最难得数据链路层整理下：</h2><h4 id=\"计算机网络学不好，说真的，确实是数据链路层没搞懂，以前忽视了，现在整理下：\"><a href=\"#计算机网络学不好，说真的，确实是数据链路层没搞懂，以前忽视了，现在整理下：\" class=\"headerlink\" title=\"计算机网络学不好，说真的，确实是数据链路层没搞懂，以前忽视了，现在整理下：\"></a>计算机网络学不好，说真的，确实是数据链路层没搞懂，以前忽视了，现在整理下：</h4><h4 id=\"数据链路层\"><a href=\"#数据链路层\" class=\"headerlink\" title=\"数据链路层\"></a>数据链路层</h4><p>组帧方法</p>\n<p>  字符计数法</p>\n<pre><code>用个计数字段来表明帧内字符数\n</code></pre><p>  字符填充首尾定界法</p>\n<pre><code>用开始（DLE STX)和结束（DLE ETX)来控制首尾定界\n\n他的透明传输表现\n\n    如果数据部分出现DLE ，发方则在数据部分在加个DLE， 以区别首尾定界，收方收到两个DLE,DLE则删除一个\n</code></pre><p>  常用组帧方法</p>\n<pre><code>比特填充法\n\n    首尾用01111110来标志一帧的开始与结束\n\n    他的透明传输表现\n\n            如果数据部分出现五个连续1，发方则在五个1后面插入一个0；接收方相反\n\n违规编码法\n\n    在物理层编码时，曼切斯特编码用了高低电平表示0,1. 违规编码则是用高高，低低电平表示起始，因为在物理层完成定界，所以不需要要任何技术就能实现透明传输\n</code></pre><p>差错控制</p>\n<p>  ARQ（自动重传请求）</p>\n<p>  FEC（前向纠错）</p>\n<pre><code>检错编码\n\n    奇偶校检码\n\n            垂直奇偶校检\n\n            水平奇偶校检\n\n            水平垂直奇偶校检\n\n    CRC（循环冗余码）\n\n纠错编码\n\n    海明码\n\n            M个信息位插入R个校检位组成m+r位码字 ，必须满足关系2^r&gt;=m+r+1;\n</code></pre><p>流控与可靠传输</p>\n<p>  滑动窗口流控</p>\n<pre><code>发送窗口=1，接受窗口=1\n\n    停等流控\n\n            发方每发送一个帧，必须收到应答才发送下一个帧\n\n发送窗口&gt;1，接受窗口=1\n\n    回退N流控\n\n            1&lt;=发送窗口&lt;=2^n-1\n\n发送窗口&gt;1，接受窗口&gt;1\n\n    选择重传流控\n\n            接收窗口+发送窗口&lt;=2^n，接收窗口必须小于序列号范围的一半，接收窗口&lt;=2^(n-1)，否则无意义。\n</code></pre><p>介质访问控制（MAC）</p>\n<p>  信道划分介质访问控制</p>\n<pre><code>频分多路复用（FDM)\n\n    将多路基带信号调制到不同频率载波，在进行叠加形成一个符合信号\n\n时分多路复用(TDM)\n\n    将一条物理信道按时间分成若干时间片，理论刘分配给多个信号使用\n\n    升级版：统计(异步)时分多路复用（STDM)\n\n            区别：将固定分配时隙改进成按需动态分配时隙\n\n波分多路复用（WDM）\n\n    就是光的频分多路复用：光纤中传输不同波长（频率）的光，通过频率不同分解合成\n\n码分多路复用（cdm)\n\n    原理:靠不同编码来区分各路原始信号（共享频率，共享时间）\n\n    复用方式\n\n            码分多址（cdma）\n\n            优点：利用率高，保密强，语音通信好，成本低\n\n            应用：无线通信，特别是移动通信\n</code></pre><p>  随机访问介质访问控制</p>\n<pre><code>ALOHA协议\n\n    纯ALOHA\n\n            当网络任一站点需要发送数据，不检测就发，如果没收到确认，就等一段时间在发\n\n    升级版：时隙ALOHA\n\n            区别：把网络时间同步，将时间分成等段的时隙，规定只能在时隙开始时才能发送\n\ncsma协议\n\n    1-坚持协议（100%发送）\n\n            侦听-空闲就发 侦听-忙则等待，并继续侦听到空闲为止 冲突-随机等待一段时间-重新侦听\n\n    0-坚持（非坚持）协议\n\n            侦听-空闲就发 侦听-忙则放弃侦听，等待随机一段时间\n\n    p-坚持协议\n\n            侦听-空闲就以p的概率发 以1-p的概率推迟到下个时隙 侦听-忙则等待下个时隙侦听 冲突-随机等待一段时间-重新侦听\n\nCDMA/CD协议\n\n    工作流程\n\n            先听后发，边听边发，冲突停发，随机重发\n\n    检测冲突\n\n            以太网端到端往返时间2t叫做争用期（冲突窗口或碰撞期）\n\n            最小帧长=总线传播时延（t)*数据传输率（C）*2\n\n    冲突后处理\n\n            二进制退避法\n\n            随着冲突重传次数增大而增大\n\n    使用范围\n\n            用于总线型网络或半双工网络\n\nCDMA/ca协议\n\n    应用：局域网和无线局域网\n\n    区别：将cd（碰撞检测）改成ca（碰撞避免）\n</code></pre><p>  轮询访问介质访问控制</p>\n<pre><code>令牌传递协议\n\n    持令发，没持不准发\n</code></pre><p>局域网LAN</p>\n<p>  以太网(ieee802.3)</p>\n<pre><code>逻辑：总线 物理：星形\n\n以太网MAC地址\n\n    使用6字节（48比特）地址\n\n高速以太网\n\n    100dase-t以太网\n\n    吉比特以太网\n\n    10吉比特以太网\n\n无线局域网（ieee802.11）\n\n    有基础设施\n\n            最小单位：基本服务集(BSS)\n\n            bss中基站也叫接入点（ap）\n\n    无基础设施（ad hoc）\n</code></pre><p>  令牌环网（IEEE802.5）</p>\n<pre><code>逻辑：环形 物理：星形\n</code></pre><p>  fddi（IEEE802.8）</p>\n<pre><code>逻辑：环形 物理：双环\n</code></pre><p>广域网</p>\n<p>  面向字节</p>\n<pre><code>ppp协议（点到点）\n\n    组成\n\n            链路控制协议（lcp）\n\n            网络控制协议（ncp）\n\n            将ip数据报封装在链路的方法\n\n    透明传输方法\n\n            ppp在异步线路（默认）\n\n            使用字节填充法\n\n            ppp在sonet/sdh同步线路\n\n            使用比特填充法（HDLC一样）\n</code></pre><p>  面向比特</p>\n<pre><code>hdlc协议\n\n    分类\n\n            非平衡配置\n\n            平衡配置\n\n    站的类型\n\n            主站\n\n            从站\n\n            复合站\n\n    操作方式\n\n            正常响应方式\n\n            主站向从站传输数据，从站要得到主站许可，才可以做事（响应）\n\n            异步平衡方式\n\n            每个复合站都可以向另一个站传输数据\n\n            异步响应方式\n\n            从站没接受主站许可就可以传输\n\n    帧结构\n\n            信息帧（i）第一位为0\n\n            监控帧（S) 第一二位为1,0\n\n            无编号帧（u）第一二位为1,1\n</code></pre><p>设备</p>\n<p>  网桥</p>\n<pre><code>网段概念\n\n    通过网桥连接起来的以太网，每个以太网就叫网段\n\n工作层次\n\n    链路层的mac子层\n\n路径选择算法\n\n    透明网桥\n\n            转发表建立方式\n\n            自学习算法：从某端口进来，一定能从相反端口出去\n\n            工作方式\n\n            源端口与目的端口一样，丢弃 源端口与目的端口不同，转发 目的端口未知，扩散\n\n    源路由网桥\n\n            工作方式\n\n            1.广播发送一个发现帧去探索。 2.每个目的站应答，然后发送应答帧 3.应答帧原路径返回，途径网桥把自己标志记录在应答帧中 4.源站确定最佳路由（路线/转发表），以后凡是从这个源发往该目的都要携带理由信息。\n</code></pre><p>  局域网交换机（多端口网桥）</p>\n<pre><code>交换模式\n\n    直通交换\n\n    存储转发交换\n\n最大优点\n\n    用户独占带宽\n\n    加入vlan\n\n            可以隔离冲突域，广播域\n\n原理\n\n    检测源目的mac地址，查找表，若没有在表中，则加入表，然后再转发\n</code></pre><p>功能</p>\n<p>  为网络层提供服务</p>\n<pre><code>无确认无连接\n\n    以太网\n\n有确认无连接\n\n    无线网\n\n有确认面向连接\n\n    通信要求（可靠性，实时性）较高的场合\n</code></pre><p>  链路管理</p>\n<p>  组帧</p>\n<pre><code>帧定界\n\n    确定帧的边界（界限）\n\n帧同步\n\n    接收方能从比特流中分出帧的起止\n\n透明传输\n\n    防止出现数据部分出现与帧定界一样的组合\n</code></pre><p>  流控</p>\n<pre><code>控制收发的速率，以及缓存空间（窗口）大小\n</code></pre><p>  差错控制</p>\n<pre><code>位错\n\n    ARQ（自动重传请求）\n\n    CRC（循环冗余校检）\n\n帧错\n\n    定时器\n\n    编号机制\n</code></pre><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/数据链路层.png\" alt> <a href=\"https://blog.mviai.com/images/archives/172\" target=\"_blank\" rel=\"noopener\"><strong>如何下载使用思维导图（点我）</strong></a> 思维导图下载  链接：<a href=\"https://pan.yangxin.com/s/1J1fkVM3qZEmjMmIydz9lmw\" target=\"_blank\" rel=\"noopener\">https://pan.yangxin.com/s/1J1fkVM3qZEmjMmIydz9lmw</a> [/success] [reply]密码：sml6 [/reply]</p>\n"},{"title":"最小二乘推导","url":"199.html","id":"199","date":"2018-05-09T05:52:39.000Z","_content":"\n![](https://blog.mviai.com/images/wp-content/uploads/2018/05/TIM图片20180509134753.jpg)![](https://blog.mviai.com/images/wp-content/uploads/2018/05/TIM图片20180509134805.jpg)![](https://blog.mviai.com/images/wp-content/uploads/2018/05/TIM图片20180509134700.jpg)\n","source":"_posts/最小二乘推导.md","raw":"---\ntitle: 最小二乘推导\ntags:\n  - 推导\nurl: 199.html\nid: 199\ncategories:\n  - 学习\n  - 算法\ndate: 2018-05-09 13:52:39\n---\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/05/TIM图片20180509134753.jpg)![](https://blog.mviai.com/images/wp-content/uploads/2018/05/TIM图片20180509134805.jpg)![](https://blog.mviai.com/images/wp-content/uploads/2018/05/TIM图片20180509134700.jpg)\n","slug":"最小二乘推导","published":1,"updated":"2021-07-26T09:58:02.584Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m2i002migtaalic8oly","content":"<p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/TIM图片20180509134753.jpg\" alt><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/TIM图片20180509134805.jpg\" alt><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/TIM图片20180509134700.jpg\" alt></p>\n","site":{"data":{}},"excerpt":"","more":"<p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/TIM图片20180509134753.jpg\" alt><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/TIM图片20180509134805.jpg\" alt><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/TIM图片20180509134700.jpg\" alt></p>\n"},{"title":"构建简单社交推荐系统——绪论","url":"181.html","id":"181","date":"2018-04-17T06:23:59.000Z","_content":"\n\n\n1.兴趣来源\n------\n\n推荐系统的研究和应用从90年代开始兴起，到现在己经有近30年的历史。GroupLens最初研究推荐Usenet上的新闻给可能感兴趣的用户。用户只需要提供对一些新闻的评分或者网站上行为数据,系统就会结合其他用户的评分和行为给出个性化推荐。在这个系统中用户可以在对其他用户或者新闻一无所知的情况下获得推荐。随后推荐系统在机器学习信息检索等领域迅速掀起热潮,众多领域开始引入推荐系统。 最有影响力的推荐应用当属亚马逊购物推荐系统，系统根据用户购买，浏览和评价历史和当前的查看的产品，推荐用户可能购买的其他产品。 在当今网络社交高涨的年代，人人都不易出门交友，导致大部分人朋友圈狭隘。假设有个好友推荐系统，能让用户匹配到性格相似，话语投机的网友，或许可以让冷漠的网络成为一方心灵疏导的乐土。\n\n2.面临难题。\n-------\n\n### 1.数据收集\n\n社会加速发展，人的观念也在加速变化，无法花费大量成本收集到最新数据。\n\n### 2.数据稀疏\n\n用户之间评分，评价非常少。\n\n### 3.冷启动问题\n\n新用户无历史数据无法推荐。\n\n### 4.如何制定评分标准\n\n一个好的评分标准直接关系到推荐系统的性能。\n\n### 5.如何计算推荐效果\n\n一个好的推荐系统应该具有健壮性，让大多数人信赖。  \n\n3.协同过滤推荐算法\n----------\n\n协同过滤是从当前过去的行为和其他用户对当前用户评分来构建模型。 因为写过简单的电影推荐，所以继续采用K-最近邻（KNN）算法构建推荐系统。 KNN是用k个最近邻的训练数据集来寻找位置对象分类的算法（多数表决法）。 一般分为三个步骤：定义相似度，选择近邻，预测。  \n\n### 4.用户关系网络图\n\n用户-标签 ，用户-评分等等之间联系组成一个网络图，每个用户都是一张图，用户-用户间又是一张图，为了简化复杂的网络图， 将一个评价赋予权重，然后将每个用户的评价构成向量C=(V,D)，评价与评价间做余弦定理，计算余弦值，大于阈值，则说明评价对用户无关， 小于阈值，则说明有关。如此迭代，最后将整个网络看成整体，将用户看成一个向量，计算用户与用户间相似性。     待续。。。。。\n","source":"_posts/构建简单社交推荐系统——绪论.md","raw":"---\ntitle: 构建简单社交推荐系统——绪论\nurl: 181.html\nid: 181\ncategories:\n  - 感悟\ndate: 2018-04-17 14:23:59\ntags:\n---\n\n\n\n1.兴趣来源\n------\n\n推荐系统的研究和应用从90年代开始兴起，到现在己经有近30年的历史。GroupLens最初研究推荐Usenet上的新闻给可能感兴趣的用户。用户只需要提供对一些新闻的评分或者网站上行为数据,系统就会结合其他用户的评分和行为给出个性化推荐。在这个系统中用户可以在对其他用户或者新闻一无所知的情况下获得推荐。随后推荐系统在机器学习信息检索等领域迅速掀起热潮,众多领域开始引入推荐系统。 最有影响力的推荐应用当属亚马逊购物推荐系统，系统根据用户购买，浏览和评价历史和当前的查看的产品，推荐用户可能购买的其他产品。 在当今网络社交高涨的年代，人人都不易出门交友，导致大部分人朋友圈狭隘。假设有个好友推荐系统，能让用户匹配到性格相似，话语投机的网友，或许可以让冷漠的网络成为一方心灵疏导的乐土。\n\n2.面临难题。\n-------\n\n### 1.数据收集\n\n社会加速发展，人的观念也在加速变化，无法花费大量成本收集到最新数据。\n\n### 2.数据稀疏\n\n用户之间评分，评价非常少。\n\n### 3.冷启动问题\n\n新用户无历史数据无法推荐。\n\n### 4.如何制定评分标准\n\n一个好的评分标准直接关系到推荐系统的性能。\n\n### 5.如何计算推荐效果\n\n一个好的推荐系统应该具有健壮性，让大多数人信赖。  \n\n3.协同过滤推荐算法\n----------\n\n协同过滤是从当前过去的行为和其他用户对当前用户评分来构建模型。 因为写过简单的电影推荐，所以继续采用K-最近邻（KNN）算法构建推荐系统。 KNN是用k个最近邻的训练数据集来寻找位置对象分类的算法（多数表决法）。 一般分为三个步骤：定义相似度，选择近邻，预测。  \n\n### 4.用户关系网络图\n\n用户-标签 ，用户-评分等等之间联系组成一个网络图，每个用户都是一张图，用户-用户间又是一张图，为了简化复杂的网络图， 将一个评价赋予权重，然后将每个用户的评价构成向量C=(V,D)，评价与评价间做余弦定理，计算余弦值，大于阈值，则说明评价对用户无关， 小于阈值，则说明有关。如此迭代，最后将整个网络看成整体，将用户看成一个向量，计算用户与用户间相似性。     待续。。。。。\n","slug":"构建简单社交推荐系统——绪论","published":1,"updated":"2021-07-26T09:58:02.575Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m2j002qigtarrhskwb5","content":"<h2 id=\"1-兴趣来源\"><a href=\"#1-兴趣来源\" class=\"headerlink\" title=\"1.兴趣来源\"></a>1.兴趣来源</h2><p>推荐系统的研究和应用从90年代开始兴起，到现在己经有近30年的历史。GroupLens最初研究推荐Usenet上的新闻给可能感兴趣的用户。用户只需要提供对一些新闻的评分或者网站上行为数据,系统就会结合其他用户的评分和行为给出个性化推荐。在这个系统中用户可以在对其他用户或者新闻一无所知的情况下获得推荐。随后推荐系统在机器学习信息检索等领域迅速掀起热潮,众多领域开始引入推荐系统。 最有影响力的推荐应用当属亚马逊购物推荐系统，系统根据用户购买，浏览和评价历史和当前的查看的产品，推荐用户可能购买的其他产品。 在当今网络社交高涨的年代，人人都不易出门交友，导致大部分人朋友圈狭隘。假设有个好友推荐系统，能让用户匹配到性格相似，话语投机的网友，或许可以让冷漠的网络成为一方心灵疏导的乐土。</p>\n<h2 id=\"2-面临难题。\"><a href=\"#2-面临难题。\" class=\"headerlink\" title=\"2.面临难题。\"></a>2.面临难题。</h2><h3 id=\"1-数据收集\"><a href=\"#1-数据收集\" class=\"headerlink\" title=\"1.数据收集\"></a>1.数据收集</h3><p>社会加速发展，人的观念也在加速变化，无法花费大量成本收集到最新数据。</p>\n<h3 id=\"2-数据稀疏\"><a href=\"#2-数据稀疏\" class=\"headerlink\" title=\"2.数据稀疏\"></a>2.数据稀疏</h3><p>用户之间评分，评价非常少。</p>\n<h3 id=\"3-冷启动问题\"><a href=\"#3-冷启动问题\" class=\"headerlink\" title=\"3.冷启动问题\"></a>3.冷启动问题</h3><p>新用户无历史数据无法推荐。</p>\n<h3 id=\"4-如何制定评分标准\"><a href=\"#4-如何制定评分标准\" class=\"headerlink\" title=\"4.如何制定评分标准\"></a>4.如何制定评分标准</h3><p>一个好的评分标准直接关系到推荐系统的性能。</p>\n<h3 id=\"5-如何计算推荐效果\"><a href=\"#5-如何计算推荐效果\" class=\"headerlink\" title=\"5.如何计算推荐效果\"></a>5.如何计算推荐效果</h3><p>一个好的推荐系统应该具有健壮性，让大多数人信赖。  </p>\n<h2 id=\"3-协同过滤推荐算法\"><a href=\"#3-协同过滤推荐算法\" class=\"headerlink\" title=\"3.协同过滤推荐算法\"></a>3.协同过滤推荐算法</h2><p>协同过滤是从当前过去的行为和其他用户对当前用户评分来构建模型。 因为写过简单的电影推荐，所以继续采用K-最近邻（KNN）算法构建推荐系统。 KNN是用k个最近邻的训练数据集来寻找位置对象分类的算法（多数表决法）。 一般分为三个步骤：定义相似度，选择近邻，预测。  </p>\n<h3 id=\"4-用户关系网络图\"><a href=\"#4-用户关系网络图\" class=\"headerlink\" title=\"4.用户关系网络图\"></a>4.用户关系网络图</h3><p>用户-标签 ，用户-评分等等之间联系组成一个网络图，每个用户都是一张图，用户-用户间又是一张图，为了简化复杂的网络图， 将一个评价赋予权重，然后将每个用户的评价构成向量C=(V,D)，评价与评价间做余弦定理，计算余弦值，大于阈值，则说明评价对用户无关， 小于阈值，则说明有关。如此迭代，最后将整个网络看成整体，将用户看成一个向量，计算用户与用户间相似性。     待续。。。。。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"1-兴趣来源\"><a href=\"#1-兴趣来源\" class=\"headerlink\" title=\"1.兴趣来源\"></a>1.兴趣来源</h2><p>推荐系统的研究和应用从90年代开始兴起，到现在己经有近30年的历史。GroupLens最初研究推荐Usenet上的新闻给可能感兴趣的用户。用户只需要提供对一些新闻的评分或者网站上行为数据,系统就会结合其他用户的评分和行为给出个性化推荐。在这个系统中用户可以在对其他用户或者新闻一无所知的情况下获得推荐。随后推荐系统在机器学习信息检索等领域迅速掀起热潮,众多领域开始引入推荐系统。 最有影响力的推荐应用当属亚马逊购物推荐系统，系统根据用户购买，浏览和评价历史和当前的查看的产品，推荐用户可能购买的其他产品。 在当今网络社交高涨的年代，人人都不易出门交友，导致大部分人朋友圈狭隘。假设有个好友推荐系统，能让用户匹配到性格相似，话语投机的网友，或许可以让冷漠的网络成为一方心灵疏导的乐土。</p>\n<h2 id=\"2-面临难题。\"><a href=\"#2-面临难题。\" class=\"headerlink\" title=\"2.面临难题。\"></a>2.面临难题。</h2><h3 id=\"1-数据收集\"><a href=\"#1-数据收集\" class=\"headerlink\" title=\"1.数据收集\"></a>1.数据收集</h3><p>社会加速发展，人的观念也在加速变化，无法花费大量成本收集到最新数据。</p>\n<h3 id=\"2-数据稀疏\"><a href=\"#2-数据稀疏\" class=\"headerlink\" title=\"2.数据稀疏\"></a>2.数据稀疏</h3><p>用户之间评分，评价非常少。</p>\n<h3 id=\"3-冷启动问题\"><a href=\"#3-冷启动问题\" class=\"headerlink\" title=\"3.冷启动问题\"></a>3.冷启动问题</h3><p>新用户无历史数据无法推荐。</p>\n<h3 id=\"4-如何制定评分标准\"><a href=\"#4-如何制定评分标准\" class=\"headerlink\" title=\"4.如何制定评分标准\"></a>4.如何制定评分标准</h3><p>一个好的评分标准直接关系到推荐系统的性能。</p>\n<h3 id=\"5-如何计算推荐效果\"><a href=\"#5-如何计算推荐效果\" class=\"headerlink\" title=\"5.如何计算推荐效果\"></a>5.如何计算推荐效果</h3><p>一个好的推荐系统应该具有健壮性，让大多数人信赖。  </p>\n<h2 id=\"3-协同过滤推荐算法\"><a href=\"#3-协同过滤推荐算法\" class=\"headerlink\" title=\"3.协同过滤推荐算法\"></a>3.协同过滤推荐算法</h2><p>协同过滤是从当前过去的行为和其他用户对当前用户评分来构建模型。 因为写过简单的电影推荐，所以继续采用K-最近邻（KNN）算法构建推荐系统。 KNN是用k个最近邻的训练数据集来寻找位置对象分类的算法（多数表决法）。 一般分为三个步骤：定义相似度，选择近邻，预测。  </p>\n<h3 id=\"4-用户关系网络图\"><a href=\"#4-用户关系网络图\" class=\"headerlink\" title=\"4.用户关系网络图\"></a>4.用户关系网络图</h3><p>用户-标签 ，用户-评分等等之间联系组成一个网络图，每个用户都是一张图，用户-用户间又是一张图，为了简化复杂的网络图， 将一个评价赋予权重，然后将每个用户的评价构成向量C=(V,D)，评价与评价间做余弦定理，计算余弦值，大于阈值，则说明评价对用户无关， 小于阈值，则说明有关。如此迭代，最后将整个网络看成整体，将用户看成一个向量，计算用户与用户间相似性。     待续。。。。。</p>\n"},{"title":"漂亮又简洁的hexo编辑器hexoEditor","date":"2018-11-05T13:05:48.000Z","_content":"\n# 地址：\n* 项目地址 ：[点我](https://github.com/zhuzhuyule/HexoEditor)\n\n\n# 功能\n* HexoEditor \n  * 预览内容与 Hexo 生成页面内容高度相似\n  * 支持 Hexo 原生 Tag/Filter/Renderer\n  * 支持使用 Hexo 配置文件 `_config.yml`\n  * 快速生成 **新Post** 到项目资源路径下\n  * 快速修改文件名(在Hexo编辑模式中)\n  * 快速部署\n  * 快速执行Hexo命令 `hexo d`,`hexo g`,`hexo s`,`hexo clean`\n  * 图片自动转换为Markdown格式\n    * 支持拖拽图片\n    * 支持剪贴板粘贴\n  * 图床支持(一键上传)\n    * 支持 [SM.MS](https://sm.ms) \n    * 支持 [QiNiu](https://portal.qiniu.com) \n    * 支持 [Tencent](https://console.cloud.tencent.com) \n  * 快速启动（常用目录，常用地址）\n  * 滚动条启用/取消同步滚动\n* HexoEditor (继承 [Moeditor](https://github.com/Moeditor/Moeditor) 原有功能)\n  * GitHub 风格 Markdown 显示\n  * TeX math 表达式\n  * UML 设计图\n  * 编辑框代码高亮显示\n  * 只读/只写/预览多模式切换\n  * 用户自定义 字体，行高，字体大小\n  * 用户自定义主题（文件名：main.csss）\n  * 高亮代码块皮肤切换(由 [highlight.js](https://highlightjs.org/) 提供支持)\n  * 自动重载文件\n  * 本地化\n  * 专注模式\n\n# 截图\n\n![HexoEditor Main](https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/main.png)\n\n![HexoEditor side](https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/side-menu.png)\n\n![HexoEditor menu](https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/menu.png)\n\n![HexoEditor About](https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/about.png)\n\n# 动态截图\n![HexoEditor settings](https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/gif-settings.gif)\n\n![HexoEditor tag](https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/gif-tag.gif)\n\n![HexoEditor Mode](https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/gif-mode.gif)\n\n![HexoEditor Upload Image](https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/gif-uploadImage.gif)\n\n![HexoEditor New Post](https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/gif-newpost.gif)\n\n![HexoEditor Hexo](https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/gif-hexo.gif)\n\n\n# 计划要做的\n- [ ] 添加目录\n- [x] 添加标题头设置(100%)\n- [x] 添加基本语法快捷键\n- [ ] 添加历史文件树木\n.....\n- [x] 快速部署\n- [ ] 多标签编辑显示\n\n# 快捷键\n| 按键                    | 方法              | 说明            |\n| :--------------------: | :------------------ | :-------------- |\n| `Tab`                  | tabAdd              | 添加缩进        |\n| `Shift` - `Tab`        | tabSubtract         | 减少缩进        |\n| `Ctrl` - `B`           | toggleBlod          | 切换粗体        |\n| `Ctrl` - `I`           | toggleItalic        | 切换斜体        |\n| `Ctrl` - `D`           | toggleDelete        | 删除当前行       |\n| `Ctrl` - <code>\\`</code>         | toggleComment       | 切换注解        |\n| `Ctrl` - `L`           | toggleUnOrderedList | 切换无序列表    |\n| `Ctrl` - `Alt` - `L`   | toggleOrderedList   | 切换有序列表    |\n| `Ctrl` - `]`           | toggleHeader        | 降级标题        |\n| `Ctrl` - `[`           | toggleUnHeader      | 升级标题        |\n| `Ctrl` - `=`           | toggleBlockquote    | 增加引用        |\n| `Ctrl` - ` - `         | toggleUnBlockquote  | 减少引用        |\n| `Ctrl` - `U`           | drawLink            | 添加超级链接    |\n| `Ctrl` - `Alt` - `U`   | drawImageLink       | 添加图片       |\n| `Ctrl` - `T`           | drawTable(row col)  | 添加表格(行 列) |\n| `Ctrl` - `V`           | pasteOriginContent  |源内容粘贴       |\n| `Shift` - `Ctrl` - `V` | pasteContent        |  智能粘贴      |\n| `Alt` - `F`            | formatTables        | 格式化表格      |\n| `Ctrl` - `N`            |         | 新建md文档      |\n| `Ctrl` - `H`            |         | 新建Hexo文档      |\n| `Ctrl` - `O`            |         | 打开md文件      |\n| `Ctrl` - `S`            |         | 保存文档      |\n| `Shift` - `Ctrl` - `S`            |         | 另存为      |\n| `Alt` - `Ctrl` - `S`            |         | 打开设置      |\n| `Ctrl` - `W`            |         | 切换写作模式      |\n| `Ctrl` - `P`            |         | 切换预览模式      |\n| `Ctrl` - `R`            |         | 切换阅读模式      |\n\n* **提示**: 在 Mac OS下, 请使用 `Cmd` 来代替 `Ctrl` .\n\n# 安装\n```c\n//如果使用 Windows:\nnpm config set prefix \"C:/Program Files/nodejs/npm_global\"\nnpm config set cache \"C:/Program Files/nodejs/npm_cache\" \n\n//如果使用 Linux\\Mac:\nnpm config set prefix \"~/nodejs/npm_global\"\nnpm config set cache \"~/nodejs/npm_cache\" \n\n//在中国，中国，中国，你应该设置淘宝镜像来加速下载。\nnpm config set registry \"https://registry.npm.taobao.org/\"\nnpm config set electron_mirror \"https://npm.taobao.org/mirrors/electron/\"\n\ngit clone https://github.com/zhuzhuyule/HexoEditor.git\ncd HexoEditor\nnpm install\nnpm start\n```\n这里是 [详细安装方式](https://github.com/zhuzhuyule/HexoEditor/blob/master/doc/en/Building.md)\n\n国内，如果想要提高下载速度，请使用 `cnpm` 来代替 `npm`，命令如下 。\n\n# 调试模式\n这里有三种方法打开 [Chrome开发者工具](https://developer.chrome.com/devtools).\n\n1. 启动命令行添加参数 `--debug` :\n```bash\nnpm start -- --debug\n```\n2. 使用快捷键：  \nLinux / Windows： `Ctrl` + `Shift` + `I`   \nOS X / macOS   ： `Command` + `Option` + `I` \n3. 在 config 设置 `debug: true`。 配置文件在缓存中，路径：\n```plain\nwindows: %USERPROFILE%\\.config\\configstore\\HexoEditor.json\nlinux  : ~/.config/configstore/HexoEditor.json\nmac    : ~/.config/configstore/HexoEditor.json( 待确认)\n```\n\n# 本地化\nHexoEditor将自动识别系统语言并使用对应语言包。\n\n你也可以通过设置手动设置语言包。\n\n目前支持：简体中文，英语，法语，德语，西班牙语，俄语 和 不完整的葡萄牙语。\n\n**帮助** 如果你可以帮助翻译，请修改 `app/moe-l10n.js`.\n\n# 许可证\nHexoEditor 使用许可证为 **GPL v3** 许可.\n\n一些Node模块使用其他的免费许可证书。\n\n`Raleway` 字体许可证书为 OFL(Open Font License)。\n\n# 提示\n1. 请修改插件 codemirror，文件路径 :\n\n> ./node_modules/codemirror/lib/codemirror.js (line: `3104`)\n\n\n> ./node_modules/codemirror/src/display/selection.js (line: `56`)\n\n```js \n//var rightSide = Math.max(display.sizerWidth, displayWidth(cm) - display.sizer.offsetLeft) - padding.right;\nvar rightSide = display.lineDiv.offsetWidth - padding.right;\n```\n\n# 兼容性\n\n* :triangular_flag_on_post: <a href=\"https://github.com/theme-next/hexo-theme-next\" target=\"_blank\">NexT theme</a>\n","source":"_posts/漂亮又简洁的hexo编辑器hexoEditor.md","raw":"---\ntitle: 漂亮又简洁的hexo编辑器hexoEditor\ntags:\n  - hexo\ncategories:\n  - 网站\n  - hexo\ndate: 2018-11-05 21:05:48\n---\n\n# 地址：\n* 项目地址 ：[点我](https://github.com/zhuzhuyule/HexoEditor)\n\n\n# 功能\n* HexoEditor \n  * 预览内容与 Hexo 生成页面内容高度相似\n  * 支持 Hexo 原生 Tag/Filter/Renderer\n  * 支持使用 Hexo 配置文件 `_config.yml`\n  * 快速生成 **新Post** 到项目资源路径下\n  * 快速修改文件名(在Hexo编辑模式中)\n  * 快速部署\n  * 快速执行Hexo命令 `hexo d`,`hexo g`,`hexo s`,`hexo clean`\n  * 图片自动转换为Markdown格式\n    * 支持拖拽图片\n    * 支持剪贴板粘贴\n  * 图床支持(一键上传)\n    * 支持 [SM.MS](https://sm.ms) \n    * 支持 [QiNiu](https://portal.qiniu.com) \n    * 支持 [Tencent](https://console.cloud.tencent.com) \n  * 快速启动（常用目录，常用地址）\n  * 滚动条启用/取消同步滚动\n* HexoEditor (继承 [Moeditor](https://github.com/Moeditor/Moeditor) 原有功能)\n  * GitHub 风格 Markdown 显示\n  * TeX math 表达式\n  * UML 设计图\n  * 编辑框代码高亮显示\n  * 只读/只写/预览多模式切换\n  * 用户自定义 字体，行高，字体大小\n  * 用户自定义主题（文件名：main.csss）\n  * 高亮代码块皮肤切换(由 [highlight.js](https://highlightjs.org/) 提供支持)\n  * 自动重载文件\n  * 本地化\n  * 专注模式\n\n# 截图\n\n![HexoEditor Main](https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/main.png)\n\n![HexoEditor side](https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/side-menu.png)\n\n![HexoEditor menu](https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/menu.png)\n\n![HexoEditor About](https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/about.png)\n\n# 动态截图\n![HexoEditor settings](https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/gif-settings.gif)\n\n![HexoEditor tag](https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/gif-tag.gif)\n\n![HexoEditor Mode](https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/gif-mode.gif)\n\n![HexoEditor Upload Image](https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/gif-uploadImage.gif)\n\n![HexoEditor New Post](https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/gif-newpost.gif)\n\n![HexoEditor Hexo](https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/gif-hexo.gif)\n\n\n# 计划要做的\n- [ ] 添加目录\n- [x] 添加标题头设置(100%)\n- [x] 添加基本语法快捷键\n- [ ] 添加历史文件树木\n.....\n- [x] 快速部署\n- [ ] 多标签编辑显示\n\n# 快捷键\n| 按键                    | 方法              | 说明            |\n| :--------------------: | :------------------ | :-------------- |\n| `Tab`                  | tabAdd              | 添加缩进        |\n| `Shift` - `Tab`        | tabSubtract         | 减少缩进        |\n| `Ctrl` - `B`           | toggleBlod          | 切换粗体        |\n| `Ctrl` - `I`           | toggleItalic        | 切换斜体        |\n| `Ctrl` - `D`           | toggleDelete        | 删除当前行       |\n| `Ctrl` - <code>\\`</code>         | toggleComment       | 切换注解        |\n| `Ctrl` - `L`           | toggleUnOrderedList | 切换无序列表    |\n| `Ctrl` - `Alt` - `L`   | toggleOrderedList   | 切换有序列表    |\n| `Ctrl` - `]`           | toggleHeader        | 降级标题        |\n| `Ctrl` - `[`           | toggleUnHeader      | 升级标题        |\n| `Ctrl` - `=`           | toggleBlockquote    | 增加引用        |\n| `Ctrl` - ` - `         | toggleUnBlockquote  | 减少引用        |\n| `Ctrl` - `U`           | drawLink            | 添加超级链接    |\n| `Ctrl` - `Alt` - `U`   | drawImageLink       | 添加图片       |\n| `Ctrl` - `T`           | drawTable(row col)  | 添加表格(行 列) |\n| `Ctrl` - `V`           | pasteOriginContent  |源内容粘贴       |\n| `Shift` - `Ctrl` - `V` | pasteContent        |  智能粘贴      |\n| `Alt` - `F`            | formatTables        | 格式化表格      |\n| `Ctrl` - `N`            |         | 新建md文档      |\n| `Ctrl` - `H`            |         | 新建Hexo文档      |\n| `Ctrl` - `O`            |         | 打开md文件      |\n| `Ctrl` - `S`            |         | 保存文档      |\n| `Shift` - `Ctrl` - `S`            |         | 另存为      |\n| `Alt` - `Ctrl` - `S`            |         | 打开设置      |\n| `Ctrl` - `W`            |         | 切换写作模式      |\n| `Ctrl` - `P`            |         | 切换预览模式      |\n| `Ctrl` - `R`            |         | 切换阅读模式      |\n\n* **提示**: 在 Mac OS下, 请使用 `Cmd` 来代替 `Ctrl` .\n\n# 安装\n```c\n//如果使用 Windows:\nnpm config set prefix \"C:/Program Files/nodejs/npm_global\"\nnpm config set cache \"C:/Program Files/nodejs/npm_cache\" \n\n//如果使用 Linux\\Mac:\nnpm config set prefix \"~/nodejs/npm_global\"\nnpm config set cache \"~/nodejs/npm_cache\" \n\n//在中国，中国，中国，你应该设置淘宝镜像来加速下载。\nnpm config set registry \"https://registry.npm.taobao.org/\"\nnpm config set electron_mirror \"https://npm.taobao.org/mirrors/electron/\"\n\ngit clone https://github.com/zhuzhuyule/HexoEditor.git\ncd HexoEditor\nnpm install\nnpm start\n```\n这里是 [详细安装方式](https://github.com/zhuzhuyule/HexoEditor/blob/master/doc/en/Building.md)\n\n国内，如果想要提高下载速度，请使用 `cnpm` 来代替 `npm`，命令如下 。\n\n# 调试模式\n这里有三种方法打开 [Chrome开发者工具](https://developer.chrome.com/devtools).\n\n1. 启动命令行添加参数 `--debug` :\n```bash\nnpm start -- --debug\n```\n2. 使用快捷键：  \nLinux / Windows： `Ctrl` + `Shift` + `I`   \nOS X / macOS   ： `Command` + `Option` + `I` \n3. 在 config 设置 `debug: true`。 配置文件在缓存中，路径：\n```plain\nwindows: %USERPROFILE%\\.config\\configstore\\HexoEditor.json\nlinux  : ~/.config/configstore/HexoEditor.json\nmac    : ~/.config/configstore/HexoEditor.json( 待确认)\n```\n\n# 本地化\nHexoEditor将自动识别系统语言并使用对应语言包。\n\n你也可以通过设置手动设置语言包。\n\n目前支持：简体中文，英语，法语，德语，西班牙语，俄语 和 不完整的葡萄牙语。\n\n**帮助** 如果你可以帮助翻译，请修改 `app/moe-l10n.js`.\n\n# 许可证\nHexoEditor 使用许可证为 **GPL v3** 许可.\n\n一些Node模块使用其他的免费许可证书。\n\n`Raleway` 字体许可证书为 OFL(Open Font License)。\n\n# 提示\n1. 请修改插件 codemirror，文件路径 :\n\n> ./node_modules/codemirror/lib/codemirror.js (line: `3104`)\n\n\n> ./node_modules/codemirror/src/display/selection.js (line: `56`)\n\n```js \n//var rightSide = Math.max(display.sizerWidth, displayWidth(cm) - display.sizer.offsetLeft) - padding.right;\nvar rightSide = display.lineDiv.offsetWidth - padding.right;\n```\n\n# 兼容性\n\n* :triangular_flag_on_post: <a href=\"https://github.com/theme-next/hexo-theme-next\" target=\"_blank\">NexT theme</a>\n","slug":"漂亮又简洁的hexo编辑器hexoEditor","published":1,"updated":"2021-07-26T09:58:02.581Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m2m002tigtabvmrtv1l","content":"<h1 id=\"地址：\"><a href=\"#地址：\" class=\"headerlink\" title=\"地址：\"></a>地址：</h1><ul>\n<li>项目地址 ：<a href=\"https://github.com/zhuzhuyule/HexoEditor\" target=\"_blank\" rel=\"noopener\">点我</a></li>\n</ul>\n<h1 id=\"功能\"><a href=\"#功能\" class=\"headerlink\" title=\"功能\"></a>功能</h1><ul>\n<li>HexoEditor <ul>\n<li>预览内容与 Hexo 生成页面内容高度相似</li>\n<li>支持 Hexo 原生 Tag/Filter/Renderer</li>\n<li>支持使用 Hexo 配置文件 <code>_config.yml</code></li>\n<li>快速生成 <strong>新Post</strong> 到项目资源路径下</li>\n<li>快速修改文件名(在Hexo编辑模式中)</li>\n<li>快速部署</li>\n<li>快速执行Hexo命令 <code>hexo d</code>,<code>hexo g</code>,<code>hexo s</code>,<code>hexo clean</code></li>\n<li>图片自动转换为Markdown格式<ul>\n<li>支持拖拽图片</li>\n<li>支持剪贴板粘贴</li>\n</ul>\n</li>\n<li>图床支持(一键上传)<ul>\n<li>支持 <a href=\"https://sm.ms\" target=\"_blank\" rel=\"noopener\">SM.MS</a> </li>\n<li>支持 <a href=\"https://portal.qiniu.com\" target=\"_blank\" rel=\"noopener\">QiNiu</a> </li>\n<li>支持 <a href=\"https://console.cloud.tencent.com\" target=\"_blank\" rel=\"noopener\">Tencent</a> </li>\n</ul>\n</li>\n<li>快速启动（常用目录，常用地址）</li>\n<li>滚动条启用/取消同步滚动</li>\n</ul>\n</li>\n<li>HexoEditor (继承 <a href=\"https://github.com/Moeditor/Moeditor\" target=\"_blank\" rel=\"noopener\">Moeditor</a> 原有功能)<ul>\n<li>GitHub 风格 Markdown 显示</li>\n<li>TeX math 表达式</li>\n<li>UML 设计图</li>\n<li>编辑框代码高亮显示</li>\n<li>只读/只写/预览多模式切换</li>\n<li>用户自定义 字体，行高，字体大小</li>\n<li>用户自定义主题（文件名：main.csss）</li>\n<li>高亮代码块皮肤切换(由 <a href=\"https://highlightjs.org/\" target=\"_blank\" rel=\"noopener\">highlight.js</a> 提供支持)</li>\n<li>自动重载文件</li>\n<li>本地化</li>\n<li>专注模式</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"截图\"><a href=\"#截图\" class=\"headerlink\" title=\"截图\"></a>截图</h1><p><img src=\"https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/main.png\" alt=\"HexoEditor Main\"></p>\n<p><img src=\"https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/side-menu.png\" alt=\"HexoEditor side\"></p>\n<p><img src=\"https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/menu.png\" alt=\"HexoEditor menu\"></p>\n<p><img src=\"https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/about.png\" alt=\"HexoEditor About\"></p>\n<h1 id=\"动态截图\"><a href=\"#动态截图\" class=\"headerlink\" title=\"动态截图\"></a>动态截图</h1><p><img src=\"https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/gif-settings.gif\" alt=\"HexoEditor settings\"></p>\n<p><img src=\"https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/gif-tag.gif\" alt=\"HexoEditor tag\"></p>\n<p><img src=\"https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/gif-mode.gif\" alt=\"HexoEditor Mode\"></p>\n<p><img src=\"https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/gif-uploadImage.gif\" alt=\"HexoEditor Upload Image\"></p>\n<p><img src=\"https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/gif-newpost.gif\" alt=\"HexoEditor New Post\"></p>\n<p><img src=\"https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/gif-hexo.gif\" alt=\"HexoEditor Hexo\"></p>\n<h1 id=\"计划要做的\"><a href=\"#计划要做的\" class=\"headerlink\" title=\"计划要做的\"></a>计划要做的</h1><ul>\n<li style=\"list-style: none\"><input type=\"checkbox\"> 添加目录</li>\n<li style=\"list-style: none\"><input type=\"checkbox\" checked> 添加标题头设置(100%)</li>\n<li style=\"list-style: none\"><input type=\"checkbox\" checked> 添加基本语法快捷键</li>\n<li style=\"list-style: none\"><input type=\"checkbox\"> 添加历史文件树木<br>…..</li>\n<li style=\"list-style: none\"><input type=\"checkbox\" checked> 快速部署</li>\n<li style=\"list-style: none\"><input type=\"checkbox\"> 多标签编辑显示</li>\n</ul>\n<h1 id=\"快捷键\"><a href=\"#快捷键\" class=\"headerlink\" title=\"快捷键\"></a>快捷键</h1><table>\n<thead>\n<tr>\n<th style=\"text-align:center\">按键</th>\n<th style=\"text-align:left\">方法</th>\n<th style=\"text-align:left\">说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\"><code>Tab</code></td>\n<td style=\"text-align:left\">tabAdd</td>\n<td style=\"text-align:left\">添加缩进</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Shift</code> - <code>Tab</code></td>\n<td style=\"text-align:left\">tabSubtract</td>\n<td style=\"text-align:left\">减少缩进</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>B</code></td>\n<td style=\"text-align:left\">toggleBlod</td>\n<td style=\"text-align:left\">切换粗体</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>I</code></td>\n<td style=\"text-align:left\">toggleItalic</td>\n<td style=\"text-align:left\">切换斜体</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>D</code></td>\n<td style=\"text-align:left\">toggleDelete</td>\n<td style=\"text-align:left\">删除当前行</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>`</code></td>\n<td style=\"text-align:left\">toggleComment</td>\n<td style=\"text-align:left\">切换注解</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>L</code></td>\n<td style=\"text-align:left\">toggleUnOrderedList</td>\n<td style=\"text-align:left\">切换无序列表</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>Alt</code> - <code>L</code></td>\n<td style=\"text-align:left\">toggleOrderedList</td>\n<td style=\"text-align:left\">切换有序列表</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>]</code></td>\n<td style=\"text-align:left\">toggleHeader</td>\n<td style=\"text-align:left\">降级标题</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>[</code></td>\n<td style=\"text-align:left\">toggleUnHeader</td>\n<td style=\"text-align:left\">升级标题</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>=</code></td>\n<td style=\"text-align:left\">toggleBlockquote</td>\n<td style=\"text-align:left\">增加引用</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>-</code></td>\n<td style=\"text-align:left\">toggleUnBlockquote</td>\n<td style=\"text-align:left\">减少引用</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>U</code></td>\n<td style=\"text-align:left\">drawLink</td>\n<td style=\"text-align:left\">添加超级链接</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>Alt</code> - <code>U</code></td>\n<td style=\"text-align:left\">drawImageLink</td>\n<td style=\"text-align:left\">添加图片</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>T</code></td>\n<td style=\"text-align:left\">drawTable(row col)</td>\n<td style=\"text-align:left\">添加表格(行 列)</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>V</code></td>\n<td style=\"text-align:left\">pasteOriginContent</td>\n<td style=\"text-align:left\">源内容粘贴</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Shift</code> - <code>Ctrl</code> - <code>V</code></td>\n<td style=\"text-align:left\">pasteContent</td>\n<td style=\"text-align:left\">智能粘贴</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Alt</code> - <code>F</code></td>\n<td style=\"text-align:left\">formatTables</td>\n<td style=\"text-align:left\">格式化表格</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>N</code></td>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">新建md文档</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>H</code></td>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">新建Hexo文档</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>O</code></td>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">打开md文件</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>S</code></td>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">保存文档</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Shift</code> - <code>Ctrl</code> - <code>S</code></td>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">另存为</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Alt</code> - <code>Ctrl</code> - <code>S</code></td>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">打开设置</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>W</code></td>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">切换写作模式</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>P</code></td>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">切换预览模式</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>R</code></td>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">切换阅读模式</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li><strong>提示</strong>: 在 Mac OS下, 请使用 <code>Cmd</code> 来代替 <code>Ctrl</code> .</li>\n</ul>\n<h1 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h1><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//如果使用 Windows:</span></span><br><span class=\"line\">npm config <span class=\"built_in\">set</span> prefix <span class=\"string\">\"C:/Program Files/nodejs/npm_global\"</span></span><br><span class=\"line\">npm config <span class=\"built_in\">set</span> cache <span class=\"string\">\"C:/Program Files/nodejs/npm_cache\"</span> </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//如果使用 Linux\\Mac:</span></span><br><span class=\"line\">npm config <span class=\"built_in\">set</span> prefix <span class=\"string\">\"~/nodejs/npm_global\"</span></span><br><span class=\"line\">npm config <span class=\"built_in\">set</span> cache <span class=\"string\">\"~/nodejs/npm_cache\"</span> </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//在中国，中国，中国，你应该设置淘宝镜像来加速下载。</span></span><br><span class=\"line\">npm config <span class=\"built_in\">set</span> registry <span class=\"string\">\"https://registry.npm.taobao.org/\"</span></span><br><span class=\"line\">npm config <span class=\"built_in\">set</span> electron_mirror <span class=\"string\">\"https://npm.taobao.org/mirrors/electron/\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">git clone https:<span class=\"comment\">//github.com/zhuzhuyule/HexoEditor.git</span></span><br><span class=\"line\">cd HexoEditor</span><br><span class=\"line\">npm install</span><br><span class=\"line\">npm start</span><br></pre></td></tr></table></figure>\n<p>这里是 <a href=\"https://github.com/zhuzhuyule/HexoEditor/blob/master/doc/en/Building.md\" target=\"_blank\" rel=\"noopener\">详细安装方式</a></p>\n<p>国内，如果想要提高下载速度，请使用 <code>cnpm</code> 来代替 <code>npm</code>，命令如下 。</p>\n<h1 id=\"调试模式\"><a href=\"#调试模式\" class=\"headerlink\" title=\"调试模式\"></a>调试模式</h1><p>这里有三种方法打开 <a href=\"https://developer.chrome.com/devtools\" target=\"_blank\" rel=\"noopener\">Chrome开发者工具</a>.</p>\n<ol>\n<li><p>启动命令行添加参数 <code>--debug</code> :</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm start -- --debug</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>使用快捷键：<br>Linux / Windows： <code>Ctrl</code> + <code>Shift</code> + <code>I</code><br>OS X / macOS   ： <code>Command</code> + <code>Option</code> + <code>I</code> </p>\n</li>\n<li>在 config 设置 <code>debug: true</code>。 配置文件在缓存中，路径：<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">windows: %USERPROFILE%\\.config\\configstore\\HexoEditor.json</span><br><span class=\"line\">linux  : ~/.config/configstore/HexoEditor.json</span><br><span class=\"line\">mac    : ~/.config/configstore/HexoEditor.json( 待确认)</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<h1 id=\"本地化\"><a href=\"#本地化\" class=\"headerlink\" title=\"本地化\"></a>本地化</h1><p>HexoEditor将自动识别系统语言并使用对应语言包。</p>\n<p>你也可以通过设置手动设置语言包。</p>\n<p>目前支持：简体中文，英语，法语，德语，西班牙语，俄语 和 不完整的葡萄牙语。</p>\n<p><strong>帮助</strong> 如果你可以帮助翻译，请修改 <code>app/moe-l10n.js</code>.</p>\n<h1 id=\"许可证\"><a href=\"#许可证\" class=\"headerlink\" title=\"许可证\"></a>许可证</h1><p>HexoEditor 使用许可证为 <strong>GPL v3</strong> 许可.</p>\n<p>一些Node模块使用其他的免费许可证书。</p>\n<p><code>Raleway</code> 字体许可证书为 OFL(Open Font License)。</p>\n<h1 id=\"提示\"><a href=\"#提示\" class=\"headerlink\" title=\"提示\"></a>提示</h1><ol>\n<li>请修改插件 codemirror，文件路径 :</li>\n</ol>\n<blockquote>\n<p>./node_modules/codemirror/lib/codemirror.js (line: <code>3104</code>)</p>\n</blockquote>\n<blockquote>\n<p>./node_modules/codemirror/src/display/selection.js (line: <code>56</code>)</p>\n</blockquote>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//var rightSide = Math.max(display.sizerWidth, displayWidth(cm) - display.sizer.offsetLeft) - padding.right;</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> rightSide = display.lineDiv.offsetWidth - padding.right;</span><br></pre></td></tr></table></figure>\n<h1 id=\"兼容性\"><a href=\"#兼容性\" class=\"headerlink\" title=\"兼容性\"></a>兼容性</h1><ul>\n<li>:triangular_flag_on_post: <a href=\"https://github.com/theme-next/hexo-theme-next\" target=\"_blank\">NexT theme</a></li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"地址：\"><a href=\"#地址：\" class=\"headerlink\" title=\"地址：\"></a>地址：</h1><ul>\n<li>项目地址 ：<a href=\"https://github.com/zhuzhuyule/HexoEditor\" target=\"_blank\" rel=\"noopener\">点我</a></li>\n</ul>\n<h1 id=\"功能\"><a href=\"#功能\" class=\"headerlink\" title=\"功能\"></a>功能</h1><ul>\n<li>HexoEditor <ul>\n<li>预览内容与 Hexo 生成页面内容高度相似</li>\n<li>支持 Hexo 原生 Tag/Filter/Renderer</li>\n<li>支持使用 Hexo 配置文件 <code>_config.yml</code></li>\n<li>快速生成 <strong>新Post</strong> 到项目资源路径下</li>\n<li>快速修改文件名(在Hexo编辑模式中)</li>\n<li>快速部署</li>\n<li>快速执行Hexo命令 <code>hexo d</code>,<code>hexo g</code>,<code>hexo s</code>,<code>hexo clean</code></li>\n<li>图片自动转换为Markdown格式<ul>\n<li>支持拖拽图片</li>\n<li>支持剪贴板粘贴</li>\n</ul>\n</li>\n<li>图床支持(一键上传)<ul>\n<li>支持 <a href=\"https://sm.ms\" target=\"_blank\" rel=\"noopener\">SM.MS</a> </li>\n<li>支持 <a href=\"https://portal.qiniu.com\" target=\"_blank\" rel=\"noopener\">QiNiu</a> </li>\n<li>支持 <a href=\"https://console.cloud.tencent.com\" target=\"_blank\" rel=\"noopener\">Tencent</a> </li>\n</ul>\n</li>\n<li>快速启动（常用目录，常用地址）</li>\n<li>滚动条启用/取消同步滚动</li>\n</ul>\n</li>\n<li>HexoEditor (继承 <a href=\"https://github.com/Moeditor/Moeditor\" target=\"_blank\" rel=\"noopener\">Moeditor</a> 原有功能)<ul>\n<li>GitHub 风格 Markdown 显示</li>\n<li>TeX math 表达式</li>\n<li>UML 设计图</li>\n<li>编辑框代码高亮显示</li>\n<li>只读/只写/预览多模式切换</li>\n<li>用户自定义 字体，行高，字体大小</li>\n<li>用户自定义主题（文件名：main.csss）</li>\n<li>高亮代码块皮肤切换(由 <a href=\"https://highlightjs.org/\" target=\"_blank\" rel=\"noopener\">highlight.js</a> 提供支持)</li>\n<li>自动重载文件</li>\n<li>本地化</li>\n<li>专注模式</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"截图\"><a href=\"#截图\" class=\"headerlink\" title=\"截图\"></a>截图</h1><p><img src=\"https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/main.png\" alt=\"HexoEditor Main\"></p>\n<p><img src=\"https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/side-menu.png\" alt=\"HexoEditor side\"></p>\n<p><img src=\"https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/menu.png\" alt=\"HexoEditor menu\"></p>\n<p><img src=\"https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/about.png\" alt=\"HexoEditor About\"></p>\n<h1 id=\"动态截图\"><a href=\"#动态截图\" class=\"headerlink\" title=\"动态截图\"></a>动态截图</h1><p><img src=\"https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/gif-settings.gif\" alt=\"HexoEditor settings\"></p>\n<p><img src=\"https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/gif-tag.gif\" alt=\"HexoEditor tag\"></p>\n<p><img src=\"https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/gif-mode.gif\" alt=\"HexoEditor Mode\"></p>\n<p><img src=\"https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/gif-uploadImage.gif\" alt=\"HexoEditor Upload Image\"></p>\n<p><img src=\"https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/gif-newpost.gif\" alt=\"HexoEditor New Post\"></p>\n<p><img src=\"https://raw.githubusercontent.com/zhuzhuyule/HexoEditor/master/screenshots/gif-hexo.gif\" alt=\"HexoEditor Hexo\"></p>\n<h1 id=\"计划要做的\"><a href=\"#计划要做的\" class=\"headerlink\" title=\"计划要做的\"></a>计划要做的</h1><ul>\n<li style=\"list-style: none\"><input type=\"checkbox\"> 添加目录</li>\n<li style=\"list-style: none\"><input type=\"checkbox\" checked> 添加标题头设置(100%)</li>\n<li style=\"list-style: none\"><input type=\"checkbox\" checked> 添加基本语法快捷键</li>\n<li style=\"list-style: none\"><input type=\"checkbox\"> 添加历史文件树木<br>…..</li>\n<li style=\"list-style: none\"><input type=\"checkbox\" checked> 快速部署</li>\n<li style=\"list-style: none\"><input type=\"checkbox\"> 多标签编辑显示</li>\n</ul>\n<h1 id=\"快捷键\"><a href=\"#快捷键\" class=\"headerlink\" title=\"快捷键\"></a>快捷键</h1><table>\n<thead>\n<tr>\n<th style=\"text-align:center\">按键</th>\n<th style=\"text-align:left\">方法</th>\n<th style=\"text-align:left\">说明</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td style=\"text-align:center\"><code>Tab</code></td>\n<td style=\"text-align:left\">tabAdd</td>\n<td style=\"text-align:left\">添加缩进</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Shift</code> - <code>Tab</code></td>\n<td style=\"text-align:left\">tabSubtract</td>\n<td style=\"text-align:left\">减少缩进</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>B</code></td>\n<td style=\"text-align:left\">toggleBlod</td>\n<td style=\"text-align:left\">切换粗体</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>I</code></td>\n<td style=\"text-align:left\">toggleItalic</td>\n<td style=\"text-align:left\">切换斜体</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>D</code></td>\n<td style=\"text-align:left\">toggleDelete</td>\n<td style=\"text-align:left\">删除当前行</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>`</code></td>\n<td style=\"text-align:left\">toggleComment</td>\n<td style=\"text-align:left\">切换注解</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>L</code></td>\n<td style=\"text-align:left\">toggleUnOrderedList</td>\n<td style=\"text-align:left\">切换无序列表</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>Alt</code> - <code>L</code></td>\n<td style=\"text-align:left\">toggleOrderedList</td>\n<td style=\"text-align:left\">切换有序列表</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>]</code></td>\n<td style=\"text-align:left\">toggleHeader</td>\n<td style=\"text-align:left\">降级标题</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>[</code></td>\n<td style=\"text-align:left\">toggleUnHeader</td>\n<td style=\"text-align:left\">升级标题</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>=</code></td>\n<td style=\"text-align:left\">toggleBlockquote</td>\n<td style=\"text-align:left\">增加引用</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>-</code></td>\n<td style=\"text-align:left\">toggleUnBlockquote</td>\n<td style=\"text-align:left\">减少引用</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>U</code></td>\n<td style=\"text-align:left\">drawLink</td>\n<td style=\"text-align:left\">添加超级链接</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>Alt</code> - <code>U</code></td>\n<td style=\"text-align:left\">drawImageLink</td>\n<td style=\"text-align:left\">添加图片</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>T</code></td>\n<td style=\"text-align:left\">drawTable(row col)</td>\n<td style=\"text-align:left\">添加表格(行 列)</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>V</code></td>\n<td style=\"text-align:left\">pasteOriginContent</td>\n<td style=\"text-align:left\">源内容粘贴</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Shift</code> - <code>Ctrl</code> - <code>V</code></td>\n<td style=\"text-align:left\">pasteContent</td>\n<td style=\"text-align:left\">智能粘贴</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Alt</code> - <code>F</code></td>\n<td style=\"text-align:left\">formatTables</td>\n<td style=\"text-align:left\">格式化表格</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>N</code></td>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">新建md文档</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>H</code></td>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">新建Hexo文档</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>O</code></td>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">打开md文件</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>S</code></td>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">保存文档</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Shift</code> - <code>Ctrl</code> - <code>S</code></td>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">另存为</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Alt</code> - <code>Ctrl</code> - <code>S</code></td>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">打开设置</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>W</code></td>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">切换写作模式</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>P</code></td>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">切换预览模式</td>\n</tr>\n<tr>\n<td style=\"text-align:center\"><code>Ctrl</code> - <code>R</code></td>\n<td style=\"text-align:left\"></td>\n<td style=\"text-align:left\">切换阅读模式</td>\n</tr>\n</tbody>\n</table>\n<ul>\n<li><strong>提示</strong>: 在 Mac OS下, 请使用 <code>Cmd</code> 来代替 <code>Ctrl</code> .</li>\n</ul>\n<h1 id=\"安装\"><a href=\"#安装\" class=\"headerlink\" title=\"安装\"></a>安装</h1><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//如果使用 Windows:</span></span><br><span class=\"line\">npm config <span class=\"built_in\">set</span> prefix <span class=\"string\">\"C:/Program Files/nodejs/npm_global\"</span></span><br><span class=\"line\">npm config <span class=\"built_in\">set</span> cache <span class=\"string\">\"C:/Program Files/nodejs/npm_cache\"</span> </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//如果使用 Linux\\Mac:</span></span><br><span class=\"line\">npm config <span class=\"built_in\">set</span> prefix <span class=\"string\">\"~/nodejs/npm_global\"</span></span><br><span class=\"line\">npm config <span class=\"built_in\">set</span> cache <span class=\"string\">\"~/nodejs/npm_cache\"</span> </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">//在中国，中国，中国，你应该设置淘宝镜像来加速下载。</span></span><br><span class=\"line\">npm config <span class=\"built_in\">set</span> registry <span class=\"string\">\"https://registry.npm.taobao.org/\"</span></span><br><span class=\"line\">npm config <span class=\"built_in\">set</span> electron_mirror <span class=\"string\">\"https://npm.taobao.org/mirrors/electron/\"</span></span><br><span class=\"line\"></span><br><span class=\"line\">git clone https:<span class=\"comment\">//github.com/zhuzhuyule/HexoEditor.git</span></span><br><span class=\"line\">cd HexoEditor</span><br><span class=\"line\">npm install</span><br><span class=\"line\">npm start</span><br></pre></td></tr></table></figure>\n<p>这里是 <a href=\"https://github.com/zhuzhuyule/HexoEditor/blob/master/doc/en/Building.md\" target=\"_blank\" rel=\"noopener\">详细安装方式</a></p>\n<p>国内，如果想要提高下载速度，请使用 <code>cnpm</code> 来代替 <code>npm</code>，命令如下 。</p>\n<h1 id=\"调试模式\"><a href=\"#调试模式\" class=\"headerlink\" title=\"调试模式\"></a>调试模式</h1><p>这里有三种方法打开 <a href=\"https://developer.chrome.com/devtools\" target=\"_blank\" rel=\"noopener\">Chrome开发者工具</a>.</p>\n<ol>\n<li><p>启动命令行添加参数 <code>--debug</code> :</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">npm start -- --debug</span><br></pre></td></tr></table></figure>\n</li>\n<li><p>使用快捷键：<br>Linux / Windows： <code>Ctrl</code> + <code>Shift</code> + <code>I</code><br>OS X / macOS   ： <code>Command</code> + <code>Option</code> + <code>I</code> </p>\n</li>\n<li>在 config 设置 <code>debug: true</code>。 配置文件在缓存中，路径：<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">windows: %USERPROFILE%\\.config\\configstore\\HexoEditor.json</span><br><span class=\"line\">linux  : ~/.config/configstore/HexoEditor.json</span><br><span class=\"line\">mac    : ~/.config/configstore/HexoEditor.json( 待确认)</span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<h1 id=\"本地化\"><a href=\"#本地化\" class=\"headerlink\" title=\"本地化\"></a>本地化</h1><p>HexoEditor将自动识别系统语言并使用对应语言包。</p>\n<p>你也可以通过设置手动设置语言包。</p>\n<p>目前支持：简体中文，英语，法语，德语，西班牙语，俄语 和 不完整的葡萄牙语。</p>\n<p><strong>帮助</strong> 如果你可以帮助翻译，请修改 <code>app/moe-l10n.js</code>.</p>\n<h1 id=\"许可证\"><a href=\"#许可证\" class=\"headerlink\" title=\"许可证\"></a>许可证</h1><p>HexoEditor 使用许可证为 <strong>GPL v3</strong> 许可.</p>\n<p>一些Node模块使用其他的免费许可证书。</p>\n<p><code>Raleway</code> 字体许可证书为 OFL(Open Font License)。</p>\n<h1 id=\"提示\"><a href=\"#提示\" class=\"headerlink\" title=\"提示\"></a>提示</h1><ol>\n<li>请修改插件 codemirror，文件路径 :</li>\n</ol>\n<blockquote>\n<p>./node_modules/codemirror/lib/codemirror.js (line: <code>3104</code>)</p>\n</blockquote>\n<blockquote>\n<p>./node_modules/codemirror/src/display/selection.js (line: <code>56</code>)</p>\n</blockquote>\n<figure class=\"highlight js\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\">//var rightSide = Math.max(display.sizerWidth, displayWidth(cm) - display.sizer.offsetLeft) - padding.right;</span></span><br><span class=\"line\"><span class=\"keyword\">var</span> rightSide = display.lineDiv.offsetWidth - padding.right;</span><br></pre></td></tr></table></figure>\n<h1 id=\"兼容性\"><a href=\"#兼容性\" class=\"headerlink\" title=\"兼容性\"></a>兼容性</h1><ul>\n<li>:triangular_flag_on_post: <a href=\"https://github.com/theme-next/hexo-theme-next\" target=\"_blank\">NexT theme</a></li>\n</ul>\n"},{"title":"模型评估与选择","url":"217.html","id":"217","date":"2018-05-09T13:29:54.000Z","_content":"\n![](https://blog.mviai.com/images/wp-content/uploads/2018/05/two.jpg)\n","source":"_posts/模型评估与选择.md","raw":"---\ntitle: 模型评估与选择\nurl: 217.html\nid: 217\ncategories:\n  - 学习\n  - 算法\ndate: 2018-05-09 21:29:54\ntags:\n---\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/05/two.jpg)\n","slug":"模型评估与选择","published":1,"updated":"2021-07-26T09:58:02.581Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m2o002xigtaqit8u6o9","content":"<p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/two.jpg\" alt></p>\n","site":{"data":{}},"excerpt":"","more":"<p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/two.jpg\" alt></p>\n"},{"title":"物理层","url":"97.html","id":"97","date":"2018-04-05T13:06:32.000Z","_content":"\n\n\n#### 物理层\n\n基本概念\n\n  数据\n\n    信号\n\n  码元\n\n  数据通信组成\n\n    信源\n\n    信宿\n\n    信道\n\n        基带传输\n\n                宽带传输\n\n    通信交互方式\n\n        单工通信\n\n        半双工通信\n\n        全双工通信\n\n  传输性能指标\n\n    码元速率\n\n    信息速率（比特率,带宽）\n\n  两大定理\n\n    奈奎斯特定理\n\n        得出任何信道码元传输速率都是有上限，超出则会出现码间串扰问题\n\n                采样定理\n\n        得出 带宽越高，速率越高\n\n        给出了码元传输率限制，并没有对信息速率限制\n\n    香农定理\n\n        得出带宽或信道中信噪比越大，信息传输率越高\n\n        得出只要有确定带宽和信噪比确定，信息传输率上限确定\n\n        只要信息传输率低于信道极限传输率，就一定有方法实现无差错传输\n\n        实际信道传输率比香农的传输率低\n\n  编码与调制\n\n    编码\n\n        数字数据转数字信号\n\n                非归零编码\n\n                曼切斯特编码\n\n                差分曼切斯特编码\n\n                4B/5B,8B/10B编码\n\n        模拟数据转数字信号\n\n                采用抽样定理\n\n                抽样\n\n                量化\n\n                编码\n\n    调制\n\n        数字数据调制为模拟信号\n\n                ASK（只改变振幅来表示0,1）\n\n                FSK（只改变频率来表示1,0）\n\n                PSK(只改变相位来表示1，0）\n\n                QAM（正交振幅调制）频率相同条件下，将ASK,PSK（就是冷门的方法）结合\n\n        模拟数据装模拟信号\n\n                FDM（频分复用技术）\n\n  交换技术\n\n    电路交换\n\n        重要优点\n\n                延迟小，数据直达\n\n        缺点\n\n                复杂，利用率低，建立时间太长\n\n    报文交换\n\n    分组交换\n\n        网络层提供服务\n\n                数据报（无连接）\n\n                就是想发就发，哪里线路好，往哪里走\n\n                虚电路（面向连接）\n\n                先修路，然后开车送货\n\n传输介质与设备\n\n  传输介质\n\n    双绞线\n\n        屏蔽双绞线STP\n\n        非屏蔽双绞线UTP\n\n    同轴电缆\n\n        50欧姆（基带同轴电缆）\n\n        75欧姆（宽带同轴电缆）\n\n    光纤\n\n        光源：发光二极管\n\n                光的折射（多模光纤\n\n        光源：激光二极管\n\n                光的直射（单模光纤）\n\n    无线传输\n\n        无线电波\n\n        微波，红外线，激光\n\n  接口特性\n\n    机械特性\n\n    电气特性\n\n    功能特性\n\n    规程特性\n\n  设备\n\n    中继器（转发器）\n\n        个数不能超过四个 5-4-3规则\n\n        不整形的中继器\n\n                放大器\n\n    集线器（多端口中继器）HUB\n\n        逻辑上还是个总线型网络，只能在半双工工作\n\n#### 疑难解答：\n\n1.集线器连接的网络是**星形**，但逻辑上仍然是个**总线网** 2传输媒介是物理层吗？\n 传输媒介不是物理层，可以说是**0层，**但不能说他属于物理层 3.同步？异步？同步通信？异步通信？\n 同步：指某个函数的执行方式 ，函数调用者等待函数执行完后进行下一步 异步：就是不同步 \n 同步通信：通信双方时钟调整到同一个频率，通信双方不停发送接受**比特流**。分为全网同步（北京时间），\n 准同步（四川时间，结点之间允许有误差） 异步通信：发送**字符**时，发送端字符间可以有时间间隔（所以出现帧格式有**开始位，停止位**），\n 接收端时刻准备接收（有点像c/s模型）\n  \n","source":"_posts/物理层.md","raw":"---\ntitle: 物理层\ntags:\n  - 计算机网络\nurl: 97.html\nid: 97\ncategories:\n  - 学习\n  - 计算机网络\n  - 物理层\ndate: 2018-04-05 21:06:32\n---\n\n\n\n#### 物理层\n\n基本概念\n\n  数据\n\n    信号\n\n  码元\n\n  数据通信组成\n\n    信源\n\n    信宿\n\n    信道\n\n        基带传输\n\n                宽带传输\n\n    通信交互方式\n\n        单工通信\n\n        半双工通信\n\n        全双工通信\n\n  传输性能指标\n\n    码元速率\n\n    信息速率（比特率,带宽）\n\n  两大定理\n\n    奈奎斯特定理\n\n        得出任何信道码元传输速率都是有上限，超出则会出现码间串扰问题\n\n                采样定理\n\n        得出 带宽越高，速率越高\n\n        给出了码元传输率限制，并没有对信息速率限制\n\n    香农定理\n\n        得出带宽或信道中信噪比越大，信息传输率越高\n\n        得出只要有确定带宽和信噪比确定，信息传输率上限确定\n\n        只要信息传输率低于信道极限传输率，就一定有方法实现无差错传输\n\n        实际信道传输率比香农的传输率低\n\n  编码与调制\n\n    编码\n\n        数字数据转数字信号\n\n                非归零编码\n\n                曼切斯特编码\n\n                差分曼切斯特编码\n\n                4B/5B,8B/10B编码\n\n        模拟数据转数字信号\n\n                采用抽样定理\n\n                抽样\n\n                量化\n\n                编码\n\n    调制\n\n        数字数据调制为模拟信号\n\n                ASK（只改变振幅来表示0,1）\n\n                FSK（只改变频率来表示1,0）\n\n                PSK(只改变相位来表示1，0）\n\n                QAM（正交振幅调制）频率相同条件下，将ASK,PSK（就是冷门的方法）结合\n\n        模拟数据装模拟信号\n\n                FDM（频分复用技术）\n\n  交换技术\n\n    电路交换\n\n        重要优点\n\n                延迟小，数据直达\n\n        缺点\n\n                复杂，利用率低，建立时间太长\n\n    报文交换\n\n    分组交换\n\n        网络层提供服务\n\n                数据报（无连接）\n\n                就是想发就发，哪里线路好，往哪里走\n\n                虚电路（面向连接）\n\n                先修路，然后开车送货\n\n传输介质与设备\n\n  传输介质\n\n    双绞线\n\n        屏蔽双绞线STP\n\n        非屏蔽双绞线UTP\n\n    同轴电缆\n\n        50欧姆（基带同轴电缆）\n\n        75欧姆（宽带同轴电缆）\n\n    光纤\n\n        光源：发光二极管\n\n                光的折射（多模光纤\n\n        光源：激光二极管\n\n                光的直射（单模光纤）\n\n    无线传输\n\n        无线电波\n\n        微波，红外线，激光\n\n  接口特性\n\n    机械特性\n\n    电气特性\n\n    功能特性\n\n    规程特性\n\n  设备\n\n    中继器（转发器）\n\n        个数不能超过四个 5-4-3规则\n\n        不整形的中继器\n\n                放大器\n\n    集线器（多端口中继器）HUB\n\n        逻辑上还是个总线型网络，只能在半双工工作\n\n#### 疑难解答：\n\n1.集线器连接的网络是**星形**，但逻辑上仍然是个**总线网** 2传输媒介是物理层吗？\n 传输媒介不是物理层，可以说是**0层，**但不能说他属于物理层 3.同步？异步？同步通信？异步通信？\n 同步：指某个函数的执行方式 ，函数调用者等待函数执行完后进行下一步 异步：就是不同步 \n 同步通信：通信双方时钟调整到同一个频率，通信双方不停发送接受**比特流**。分为全网同步（北京时间），\n 准同步（四川时间，结点之间允许有误差） 异步通信：发送**字符**时，发送端字符间可以有时间间隔（所以出现帧格式有**开始位，停止位**），\n 接收端时刻准备接收（有点像c/s模型）\n  \n","slug":"物理层","published":1,"updated":"2021-07-26T09:58:02.583Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m2p0030igtam0nyt1r5","content":"<h4 id=\"物理层\"><a href=\"#物理层\" class=\"headerlink\" title=\"物理层\"></a>物理层</h4><p>基本概念</p>\n<p>  数据</p>\n<pre><code>信号\n</code></pre><p>  码元</p>\n<p>  数据通信组成</p>\n<pre><code>信源\n\n信宿\n\n信道\n\n    基带传输\n\n            宽带传输\n\n通信交互方式\n\n    单工通信\n\n    半双工通信\n\n    全双工通信\n</code></pre><p>  传输性能指标</p>\n<pre><code>码元速率\n\n信息速率（比特率,带宽）\n</code></pre><p>  两大定理</p>\n<pre><code>奈奎斯特定理\n\n    得出任何信道码元传输速率都是有上限，超出则会出现码间串扰问题\n\n            采样定理\n\n    得出 带宽越高，速率越高\n\n    给出了码元传输率限制，并没有对信息速率限制\n\n香农定理\n\n    得出带宽或信道中信噪比越大，信息传输率越高\n\n    得出只要有确定带宽和信噪比确定，信息传输率上限确定\n\n    只要信息传输率低于信道极限传输率，就一定有方法实现无差错传输\n\n    实际信道传输率比香农的传输率低\n</code></pre><p>  编码与调制</p>\n<pre><code>编码\n\n    数字数据转数字信号\n\n            非归零编码\n\n            曼切斯特编码\n\n            差分曼切斯特编码\n\n            4B/5B,8B/10B编码\n\n    模拟数据转数字信号\n\n            采用抽样定理\n\n            抽样\n\n            量化\n\n            编码\n\n调制\n\n    数字数据调制为模拟信号\n\n            ASK（只改变振幅来表示0,1）\n\n            FSK（只改变频率来表示1,0）\n\n            PSK(只改变相位来表示1，0）\n\n            QAM（正交振幅调制）频率相同条件下，将ASK,PSK（就是冷门的方法）结合\n\n    模拟数据装模拟信号\n\n            FDM（频分复用技术）\n</code></pre><p>  交换技术</p>\n<pre><code>电路交换\n\n    重要优点\n\n            延迟小，数据直达\n\n    缺点\n\n            复杂，利用率低，建立时间太长\n\n报文交换\n\n分组交换\n\n    网络层提供服务\n\n            数据报（无连接）\n\n            就是想发就发，哪里线路好，往哪里走\n\n            虚电路（面向连接）\n\n            先修路，然后开车送货\n</code></pre><p>传输介质与设备</p>\n<p>  传输介质</p>\n<pre><code>双绞线\n\n    屏蔽双绞线STP\n\n    非屏蔽双绞线UTP\n\n同轴电缆\n\n    50欧姆（基带同轴电缆）\n\n    75欧姆（宽带同轴电缆）\n\n光纤\n\n    光源：发光二极管\n\n            光的折射（多模光纤\n\n    光源：激光二极管\n\n            光的直射（单模光纤）\n\n无线传输\n\n    无线电波\n\n    微波，红外线，激光\n</code></pre><p>  接口特性</p>\n<pre><code>机械特性\n\n电气特性\n\n功能特性\n\n规程特性\n</code></pre><p>  设备</p>\n<pre><code>中继器（转发器）\n\n    个数不能超过四个 5-4-3规则\n\n    不整形的中继器\n\n            放大器\n\n集线器（多端口中继器）HUB\n\n    逻辑上还是个总线型网络，只能在半双工工作\n</code></pre><h4 id=\"疑难解答：\"><a href=\"#疑难解答：\" class=\"headerlink\" title=\"疑难解答：\"></a>疑难解答：</h4><p>1.集线器连接的网络是<strong>星形</strong>，但逻辑上仍然是个<strong>总线网</strong> 2传输媒介是物理层吗？<br> 传输媒介不是物理层，可以说是<strong>0层，</strong>但不能说他属于物理层 3.同步？异步？同步通信？异步通信？<br> 同步：指某个函数的执行方式 ，函数调用者等待函数执行完后进行下一步 异步：就是不同步<br> 同步通信：通信双方时钟调整到同一个频率，通信双方不停发送接受<strong>比特流</strong>。分为全网同步（北京时间），<br> 准同步（四川时间，结点之间允许有误差） 异步通信：发送<strong>字符</strong>时，发送端字符间可以有时间间隔（所以出现帧格式有<strong>开始位，停止位</strong>），<br> 接收端时刻准备接收（有点像c/s模型）</p>\n","site":{"data":{}},"excerpt":"","more":"<h4 id=\"物理层\"><a href=\"#物理层\" class=\"headerlink\" title=\"物理层\"></a>物理层</h4><p>基本概念</p>\n<p>  数据</p>\n<pre><code>信号\n</code></pre><p>  码元</p>\n<p>  数据通信组成</p>\n<pre><code>信源\n\n信宿\n\n信道\n\n    基带传输\n\n            宽带传输\n\n通信交互方式\n\n    单工通信\n\n    半双工通信\n\n    全双工通信\n</code></pre><p>  传输性能指标</p>\n<pre><code>码元速率\n\n信息速率（比特率,带宽）\n</code></pre><p>  两大定理</p>\n<pre><code>奈奎斯特定理\n\n    得出任何信道码元传输速率都是有上限，超出则会出现码间串扰问题\n\n            采样定理\n\n    得出 带宽越高，速率越高\n\n    给出了码元传输率限制，并没有对信息速率限制\n\n香农定理\n\n    得出带宽或信道中信噪比越大，信息传输率越高\n\n    得出只要有确定带宽和信噪比确定，信息传输率上限确定\n\n    只要信息传输率低于信道极限传输率，就一定有方法实现无差错传输\n\n    实际信道传输率比香农的传输率低\n</code></pre><p>  编码与调制</p>\n<pre><code>编码\n\n    数字数据转数字信号\n\n            非归零编码\n\n            曼切斯特编码\n\n            差分曼切斯特编码\n\n            4B/5B,8B/10B编码\n\n    模拟数据转数字信号\n\n            采用抽样定理\n\n            抽样\n\n            量化\n\n            编码\n\n调制\n\n    数字数据调制为模拟信号\n\n            ASK（只改变振幅来表示0,1）\n\n            FSK（只改变频率来表示1,0）\n\n            PSK(只改变相位来表示1，0）\n\n            QAM（正交振幅调制）频率相同条件下，将ASK,PSK（就是冷门的方法）结合\n\n    模拟数据装模拟信号\n\n            FDM（频分复用技术）\n</code></pre><p>  交换技术</p>\n<pre><code>电路交换\n\n    重要优点\n\n            延迟小，数据直达\n\n    缺点\n\n            复杂，利用率低，建立时间太长\n\n报文交换\n\n分组交换\n\n    网络层提供服务\n\n            数据报（无连接）\n\n            就是想发就发，哪里线路好，往哪里走\n\n            虚电路（面向连接）\n\n            先修路，然后开车送货\n</code></pre><p>传输介质与设备</p>\n<p>  传输介质</p>\n<pre><code>双绞线\n\n    屏蔽双绞线STP\n\n    非屏蔽双绞线UTP\n\n同轴电缆\n\n    50欧姆（基带同轴电缆）\n\n    75欧姆（宽带同轴电缆）\n\n光纤\n\n    光源：发光二极管\n\n            光的折射（多模光纤\n\n    光源：激光二极管\n\n            光的直射（单模光纤）\n\n无线传输\n\n    无线电波\n\n    微波，红外线，激光\n</code></pre><p>  接口特性</p>\n<pre><code>机械特性\n\n电气特性\n\n功能特性\n\n规程特性\n</code></pre><p>  设备</p>\n<pre><code>中继器（转发器）\n\n    个数不能超过四个 5-4-3规则\n\n    不整形的中继器\n\n            放大器\n\n集线器（多端口中继器）HUB\n\n    逻辑上还是个总线型网络，只能在半双工工作\n</code></pre><h4 id=\"疑难解答：\"><a href=\"#疑难解答：\" class=\"headerlink\" title=\"疑难解答：\"></a>疑难解答：</h4><p>1.集线器连接的网络是<strong>星形</strong>，但逻辑上仍然是个<strong>总线网</strong> 2传输媒介是物理层吗？<br> 传输媒介不是物理层，可以说是<strong>0层，</strong>但不能说他属于物理层 3.同步？异步？同步通信？异步通信？<br> 同步：指某个函数的执行方式 ，函数调用者等待函数执行完后进行下一步 异步：就是不同步<br> 同步通信：通信双方时钟调整到同一个频率，通信双方不停发送接受<strong>比特流</strong>。分为全网同步（北京时间），<br> 准同步（四川时间，结点之间允许有误差） 异步通信：发送<strong>字符</strong>时，发送端字符间可以有时间间隔（所以出现帧格式有<strong>开始位，停止位</strong>），<br> 接收端时刻准备接收（有点像c/s模型）</p>\n"},{"title":"破解MathType-方法","date":"2018-12-23T19:38:57.000Z","categoies":["工具","日常工具"],"_content":"# 流程：\n1.首先打开运行，快捷键 win+R\n2.输入regedit。\n3.打开注册表\n4.在HKEY_CURRENT_USER项右键 点击查找\n5.输入Install Options\n6.删除键值对\n\n# 快捷方式：\n新建记事本：\n输入\n```\n@echo on\n\nreg delete \"HKEY_CURRENT_USER\\Software\\Install Options\\Options7.2\" /f\n\npause\n\n```\n注意： reg delete后面 路径每个电脑不同\n\n保存 新建文档.txt(没有txt，请打开后缀）  重命名 为刷新mathtype.bat  每次到期 运行下就可以了\n","source":"_posts/破解MathType-方法.md","raw":"---\n\ntitle: 破解MathType-方法\ndate: 2018-12-24 03:38:57\ntags:\n    - 破解MathType\ncategoies:\n    - 工具\n    - 日常工具\n\n---\n# 流程：\n1.首先打开运行，快捷键 win+R\n2.输入regedit。\n3.打开注册表\n4.在HKEY_CURRENT_USER项右键 点击查找\n5.输入Install Options\n6.删除键值对\n\n# 快捷方式：\n新建记事本：\n输入\n```\n@echo on\n\nreg delete \"HKEY_CURRENT_USER\\Software\\Install Options\\Options7.2\" /f\n\npause\n\n```\n注意： reg delete后面 路径每个电脑不同\n\n保存 新建文档.txt(没有txt，请打开后缀）  重命名 为刷新mathtype.bat  每次到期 运行下就可以了\n","slug":"破解MathType-方法","published":1,"updated":"2021-07-26T09:58:02.582Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m2r0034igtajkb8xgjt","content":"<h1 id=\"流程：\"><a href=\"#流程：\" class=\"headerlink\" title=\"流程：\"></a>流程：</h1><p>1.首先打开运行，快捷键 win+R<br>2.输入regedit。<br>3.打开注册表<br>4.在HKEY_CURRENT_USER项右键 点击查找<br>5.输入Install Options<br>6.删除键值对</p>\n<h1 id=\"快捷方式：\"><a href=\"#快捷方式：\" class=\"headerlink\" title=\"快捷方式：\"></a>快捷方式：</h1><p>新建记事本：<br>输入<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@echo on</span><br><span class=\"line\"></span><br><span class=\"line\">reg delete &quot;HKEY_CURRENT_USER\\Software\\Install Options\\Options7.2&quot; /f</span><br><span class=\"line\"></span><br><span class=\"line\">pause</span><br></pre></td></tr></table></figure></p>\n<p>注意： reg delete后面 路径每个电脑不同</p>\n<p>保存 新建文档.txt(没有txt，请打开后缀）  重命名 为刷新mathtype.bat  每次到期 运行下就可以了</p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"流程：\"><a href=\"#流程：\" class=\"headerlink\" title=\"流程：\"></a>流程：</h1><p>1.首先打开运行，快捷键 win+R<br>2.输入regedit。<br>3.打开注册表<br>4.在HKEY_CURRENT_USER项右键 点击查找<br>5.输入Install Options<br>6.删除键值对</p>\n<h1 id=\"快捷方式：\"><a href=\"#快捷方式：\" class=\"headerlink\" title=\"快捷方式：\"></a>快捷方式：</h1><p>新建记事本：<br>输入<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">@echo on</span><br><span class=\"line\"></span><br><span class=\"line\">reg delete &quot;HKEY_CURRENT_USER\\Software\\Install Options\\Options7.2&quot; /f</span><br><span class=\"line\"></span><br><span class=\"line\">pause</span><br></pre></td></tr></table></figure></p>\n<p>注意： reg delete后面 路径每个电脑不同</p>\n<p>保存 新建文档.txt(没有txt，请打开后缀）  重命名 为刷新mathtype.bat  每次到期 运行下就可以了</p>\n"},{"title":"第七节：函数基础和函数参数","url":"193.html","id":"193","date":"2018-05-08T06:41:12.000Z","_content":"\n\\[danger\\]\n\n函数定义（一段代码表示）：\n-------------\n\n函数是一段具有特定功能的，可重复使用的语句组 函数其实就是“功能” 有什么用呢？ 以后方便使用，模块化，代码简洁，可重复调用  \n\n### 书写格式：\n\ndef  (函数名）（参数（0个或者多个））**：** 函数体 return （返回值）   **注：函数不调用，它是不会去执行**   当函数调用时 分了四种参数：必选参数（在函数体参数项没有赋值），可选参数（默认参数）（在函数体参数项赋了值），可变参数（函数体参数项*a表示），关键字参数（函数体参数项**b） \\*args是可变参数，args接收的是一个tuple（元组--一种特殊的列表）； \\*\\*kw是关键字参数，kw接收的是一个dict（字典）。 注意，参数定义的顺序必须是：必选参数、默认参数、可变参数和关键字参数。(星星越多，约往后） 如：def  fun(a, b, c=0, \\*args, \\*\\*kw): 返回值return 可以直接使用return 表示返回保留字。 return可以传递0个返回值，也可以返回多个返回值    \n\n局部变量与全局变量区别：\n------------\n\n简单来说就是 函数体外定义的就是全局变量 函数体内定义的就是局部变量 区别： 1.局部变量在函数体运行完了就释放了 2.基本数据类型，无论重不重名，局部变量与全局变量不同 3.如果硬要在函数内部去声明全局变量，可以通过global声明\n\nPython内置函数：\n-----------\n\n如果记不住，记住方法，善用help（）----查看帮助   比如看数学运算类的方法  import math dir(math)  help(math) 查看所有内置函数：可以在idle里面使用命令dir(\\_\\_builtins\\_\\_)查看python的所有你内置函数\n\n### 数学类:\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/05/math.png)\n\n### 集合类：\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/05/集合.png)\n\n### io操作类：\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/05/io.png)\n\n### 函数操作类：\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/05/反射1.png) ![](https://blog.mviai.com/images/wp-content/uploads/2018/05/反射2-1.png) 详情链接：[点我](https://www.cnblogs.com/MrFiona/p/5958896.html) \\[/danger\\]\n","source":"_posts/第七节：函数基础和函数参数.md","raw":"---\ntitle: 第七节：函数基础和函数参数\ntags:\n  - 课后解答\nurl: 193.html\nid: 193\ncategories:\n  - 学习\n  - 教学\ndate: 2018-05-08 14:41:12\n---\n\n\\[danger\\]\n\n函数定义（一段代码表示）：\n-------------\n\n函数是一段具有特定功能的，可重复使用的语句组 函数其实就是“功能” 有什么用呢？ 以后方便使用，模块化，代码简洁，可重复调用  \n\n### 书写格式：\n\ndef  (函数名）（参数（0个或者多个））**：** 函数体 return （返回值）   **注：函数不调用，它是不会去执行**   当函数调用时 分了四种参数：必选参数（在函数体参数项没有赋值），可选参数（默认参数）（在函数体参数项赋了值），可变参数（函数体参数项*a表示），关键字参数（函数体参数项**b） \\*args是可变参数，args接收的是一个tuple（元组--一种特殊的列表）； \\*\\*kw是关键字参数，kw接收的是一个dict（字典）。 注意，参数定义的顺序必须是：必选参数、默认参数、可变参数和关键字参数。(星星越多，约往后） 如：def  fun(a, b, c=0, \\*args, \\*\\*kw): 返回值return 可以直接使用return 表示返回保留字。 return可以传递0个返回值，也可以返回多个返回值    \n\n局部变量与全局变量区别：\n------------\n\n简单来说就是 函数体外定义的就是全局变量 函数体内定义的就是局部变量 区别： 1.局部变量在函数体运行完了就释放了 2.基本数据类型，无论重不重名，局部变量与全局变量不同 3.如果硬要在函数内部去声明全局变量，可以通过global声明\n\nPython内置函数：\n-----------\n\n如果记不住，记住方法，善用help（）----查看帮助   比如看数学运算类的方法  import math dir(math)  help(math) 查看所有内置函数：可以在idle里面使用命令dir(\\_\\_builtins\\_\\_)查看python的所有你内置函数\n\n### 数学类:\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/05/math.png)\n\n### 集合类：\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/05/集合.png)\n\n### io操作类：\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/05/io.png)\n\n### 函数操作类：\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/05/反射1.png) ![](https://blog.mviai.com/images/wp-content/uploads/2018/05/反射2-1.png) 详情链接：[点我](https://www.cnblogs.com/MrFiona/p/5958896.html) \\[/danger\\]\n","slug":"第七节：函数基础和函数参数","published":1,"updated":"2021-07-26T09:58:02.570Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m2s0036igtaefs1tou6","content":"<p>[danger]</p>\n<h2 id=\"函数定义（一段代码表示）：\"><a href=\"#函数定义（一段代码表示）：\" class=\"headerlink\" title=\"函数定义（一段代码表示）：\"></a>函数定义（一段代码表示）：</h2><p>函数是一段具有特定功能的，可重复使用的语句组 函数其实就是“功能” 有什么用呢？ 以后方便使用，模块化，代码简洁，可重复调用  </p>\n<h3 id=\"书写格式：\"><a href=\"#书写格式：\" class=\"headerlink\" title=\"书写格式：\"></a>书写格式：</h3><p>def  (函数名）（参数（0个或者多个））<strong>：</strong> 函数体 return （返回值）   <strong>注：函数不调用，它是不会去执行</strong>   当函数调用时 分了四种参数：必选参数（在函数体参数项没有赋值），可选参数（默认参数）（在函数体参数项赋了值），可变参数（函数体参数项<em>a表示），关键字参数（函数体参数项**b） \\</em>args是可变参数，args接收的是一个tuple（元组–一种特殊的列表）； **kw是关键字参数，kw接收的是一个dict（字典）。 注意，参数定义的顺序必须是：必选参数、默认参数、可变参数和关键字参数。(星星越多，约往后） 如：def  fun(a, b, c=0, *args, **kw): 返回值return 可以直接使用return 表示返回保留字。 return可以传递0个返回值，也可以返回多个返回值    </p>\n<h2 id=\"局部变量与全局变量区别：\"><a href=\"#局部变量与全局变量区别：\" class=\"headerlink\" title=\"局部变量与全局变量区别：\"></a>局部变量与全局变量区别：</h2><p>简单来说就是 函数体外定义的就是全局变量 函数体内定义的就是局部变量 区别： 1.局部变量在函数体运行完了就释放了 2.基本数据类型，无论重不重名，局部变量与全局变量不同 3.如果硬要在函数内部去声明全局变量，可以通过global声明</p>\n<h2 id=\"Python内置函数：\"><a href=\"#Python内置函数：\" class=\"headerlink\" title=\"Python内置函数：\"></a>Python内置函数：</h2><p>如果记不住，记住方法，善用help（）—-查看帮助   比如看数学运算类的方法  import math dir(math)  help(math) 查看所有内置函数：可以在idle里面使用命令dir(__builtins__)查看python的所有你内置函数</p>\n<h3 id=\"数学类\"><a href=\"#数学类\" class=\"headerlink\" title=\"数学类:\"></a>数学类:</h3><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/math.png\" alt></p>\n<h3 id=\"集合类：\"><a href=\"#集合类：\" class=\"headerlink\" title=\"集合类：\"></a>集合类：</h3><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/集合.png\" alt></p>\n<h3 id=\"io操作类：\"><a href=\"#io操作类：\" class=\"headerlink\" title=\"io操作类：\"></a>io操作类：</h3><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/io.png\" alt></p>\n<h3 id=\"函数操作类：\"><a href=\"#函数操作类：\" class=\"headerlink\" title=\"函数操作类：\"></a>函数操作类：</h3><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/反射1.png\" alt> <img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/反射2-1.png\" alt> 详情链接：<a href=\"https://www.cnblogs.com/MrFiona/p/5958896.html\" target=\"_blank\" rel=\"noopener\">点我</a> [/danger]</p>\n","site":{"data":{}},"excerpt":"","more":"<p>[danger]</p>\n<h2 id=\"函数定义（一段代码表示）：\"><a href=\"#函数定义（一段代码表示）：\" class=\"headerlink\" title=\"函数定义（一段代码表示）：\"></a>函数定义（一段代码表示）：</h2><p>函数是一段具有特定功能的，可重复使用的语句组 函数其实就是“功能” 有什么用呢？ 以后方便使用，模块化，代码简洁，可重复调用  </p>\n<h3 id=\"书写格式：\"><a href=\"#书写格式：\" class=\"headerlink\" title=\"书写格式：\"></a>书写格式：</h3><p>def  (函数名）（参数（0个或者多个））<strong>：</strong> 函数体 return （返回值）   <strong>注：函数不调用，它是不会去执行</strong>   当函数调用时 分了四种参数：必选参数（在函数体参数项没有赋值），可选参数（默认参数）（在函数体参数项赋了值），可变参数（函数体参数项<em>a表示），关键字参数（函数体参数项**b） \\</em>args是可变参数，args接收的是一个tuple（元组–一种特殊的列表）； **kw是关键字参数，kw接收的是一个dict（字典）。 注意，参数定义的顺序必须是：必选参数、默认参数、可变参数和关键字参数。(星星越多，约往后） 如：def  fun(a, b, c=0, *args, **kw): 返回值return 可以直接使用return 表示返回保留字。 return可以传递0个返回值，也可以返回多个返回值    </p>\n<h2 id=\"局部变量与全局变量区别：\"><a href=\"#局部变量与全局变量区别：\" class=\"headerlink\" title=\"局部变量与全局变量区别：\"></a>局部变量与全局变量区别：</h2><p>简单来说就是 函数体外定义的就是全局变量 函数体内定义的就是局部变量 区别： 1.局部变量在函数体运行完了就释放了 2.基本数据类型，无论重不重名，局部变量与全局变量不同 3.如果硬要在函数内部去声明全局变量，可以通过global声明</p>\n<h2 id=\"Python内置函数：\"><a href=\"#Python内置函数：\" class=\"headerlink\" title=\"Python内置函数：\"></a>Python内置函数：</h2><p>如果记不住，记住方法，善用help（）—-查看帮助   比如看数学运算类的方法  import math dir(math)  help(math) 查看所有内置函数：可以在idle里面使用命令dir(__builtins__)查看python的所有你内置函数</p>\n<h3 id=\"数学类\"><a href=\"#数学类\" class=\"headerlink\" title=\"数学类:\"></a>数学类:</h3><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/math.png\" alt></p>\n<h3 id=\"集合类：\"><a href=\"#集合类：\" class=\"headerlink\" title=\"集合类：\"></a>集合类：</h3><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/集合.png\" alt></p>\n<h3 id=\"io操作类：\"><a href=\"#io操作类：\" class=\"headerlink\" title=\"io操作类：\"></a>io操作类：</h3><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/io.png\" alt></p>\n<h3 id=\"函数操作类：\"><a href=\"#函数操作类：\" class=\"headerlink\" title=\"函数操作类：\"></a>函数操作类：</h3><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/反射1.png\" alt> <img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/反射2-1.png\" alt> 详情链接：<a href=\"https://www.cnblogs.com/MrFiona/p/5958896.html\" target=\"_blank\" rel=\"noopener\">点我</a> [/danger]</p>\n"},{"title":"第一节：开班典礼","url":"186.html","id":"186","date":"2018-05-08T06:32:42.000Z","_content":"\n\\[success\\]\n\n一：下载网速过慢解决方案：\n-------------\n\n将下载源换成国内清华源：https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/ ![](https://blog.mviai.com/images/wp-content/uploads/2018/05/2018-05-08-15-55-33屏幕截图.png)\n\n二：Linux常用命令：\n------------\n\n　cd 路径                   （进入一个路径，比如 /usr/local/lib） 　　cd ..　　  　　　　  （返回上一个文件夹） 　　ls　　　　　　　　 （显示当前文件夹下的所有文件，Linux独有哦，dir 也有相同功能） 　　sudo 命令　　　　 （获取超级管理权限，需要输入密码）  \n\n### 　　常用新建、删除、拷贝命令：\n\n　　mkdir 目录名        （新建一个文件夹，文件夹在Linux系统中叫做“目录”） 　　touch 文件名        （新建一个空文件）   　　rmdir 目录名        （删除一个空文件夹，文件夹里有内容则不可用） 　　rm -rf 非空目录名 （删除一个包含文件的文件夹） 　　rm 文件名 文件名 （删除多个文件）  　　cp 文件名 目标路径（拷贝一个文件到目标路径，如cp hserver /opt/hqueue） 　　cp -i　　　　　　  （拷贝，同名文件存在时，输出 \\[yes/no\\] 询问是否执行） 　　cp -f　　　　　　  （强制复制文件，如有同名不询问）  \n\n### 　　常用解压、安装程序、文件更新命令：deb格式双击即可安装\n\ntar -zxvf *.tar.gz　     ( 解压 tar.gz格式的文件 ) 　　source *.install　　　 （安装install格式的安装包） 　　sh 路径/×.sh　　    　 （安装sh格式的文件，如 sudo sh /home/hp/Downloads/*.sh） 　　sudo apt-get upgrade（更新已安装的包） 　　sudo apt-get update  （更新源）         chmod +x *.sh 这个命令是为sh文件增加可执行权限； 　　chmod +R 777 *.*  对当前目录下的所有子目录和子文件进行 777权限的变更；通在安装软件时复制相关文件。  \n\n三：疑难解答：\n-------\n\n一：Linux与**Ubuntu，CentOS等的区别：** 其实Ubuntu等是Linux的发行版，就像小米系统，华为系统也是属于安卓系统。 二,使用Linux的好处：\n\n1.  可以增加就业机会，因为Linux是开源免费的。\n2.  可以改掉使用电脑坏习惯，让自己真正接触计算机。\n3.  开源软件越来约丰富，如ROS，Hadoop等\n4.  对配置要求很低，反正我08年笔记本电脑完美运行（新手最好拿使用双系统或者用台不常用的笔记本\n\n\\[/success\\]）\n","source":"_posts/第一节：开班典礼.md","raw":"---\ntitle: 第一节：开班典礼\ntags:\n  - 课后解答\nurl: 186.html\nid: 186\ncategories:\n  - 学习\n  - 教学\ndate: 2018-05-08 14:32:42\n---\n\n\\[success\\]\n\n一：下载网速过慢解决方案：\n-------------\n\n将下载源换成国内清华源：https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/ ![](https://blog.mviai.com/images/wp-content/uploads/2018/05/2018-05-08-15-55-33屏幕截图.png)\n\n二：Linux常用命令：\n------------\n\n　cd 路径                   （进入一个路径，比如 /usr/local/lib） 　　cd ..　　  　　　　  （返回上一个文件夹） 　　ls　　　　　　　　 （显示当前文件夹下的所有文件，Linux独有哦，dir 也有相同功能） 　　sudo 命令　　　　 （获取超级管理权限，需要输入密码）  \n\n### 　　常用新建、删除、拷贝命令：\n\n　　mkdir 目录名        （新建一个文件夹，文件夹在Linux系统中叫做“目录”） 　　touch 文件名        （新建一个空文件）   　　rmdir 目录名        （删除一个空文件夹，文件夹里有内容则不可用） 　　rm -rf 非空目录名 （删除一个包含文件的文件夹） 　　rm 文件名 文件名 （删除多个文件）  　　cp 文件名 目标路径（拷贝一个文件到目标路径，如cp hserver /opt/hqueue） 　　cp -i　　　　　　  （拷贝，同名文件存在时，输出 \\[yes/no\\] 询问是否执行） 　　cp -f　　　　　　  （强制复制文件，如有同名不询问）  \n\n### 　　常用解压、安装程序、文件更新命令：deb格式双击即可安装\n\ntar -zxvf *.tar.gz　     ( 解压 tar.gz格式的文件 ) 　　source *.install　　　 （安装install格式的安装包） 　　sh 路径/×.sh　　    　 （安装sh格式的文件，如 sudo sh /home/hp/Downloads/*.sh） 　　sudo apt-get upgrade（更新已安装的包） 　　sudo apt-get update  （更新源）         chmod +x *.sh 这个命令是为sh文件增加可执行权限； 　　chmod +R 777 *.*  对当前目录下的所有子目录和子文件进行 777权限的变更；通在安装软件时复制相关文件。  \n\n三：疑难解答：\n-------\n\n一：Linux与**Ubuntu，CentOS等的区别：** 其实Ubuntu等是Linux的发行版，就像小米系统，华为系统也是属于安卓系统。 二,使用Linux的好处：\n\n1.  可以增加就业机会，因为Linux是开源免费的。\n2.  可以改掉使用电脑坏习惯，让自己真正接触计算机。\n3.  开源软件越来约丰富，如ROS，Hadoop等\n4.  对配置要求很低，反正我08年笔记本电脑完美运行（新手最好拿使用双系统或者用台不常用的笔记本\n\n\\[/success\\]）\n","slug":"第一节：开班典礼","published":1,"updated":"2021-07-26T09:58:02.575Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m2t003bigtacrpg397s","content":"<p>[success]</p>\n<h2 id=\"一：下载网速过慢解决方案：\"><a href=\"#一：下载网速过慢解决方案：\" class=\"headerlink\" title=\"一：下载网速过慢解决方案：\"></a>一：下载网速过慢解决方案：</h2><p>将下载源换成国内清华源：<a href=\"https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/\" target=\"_blank\" rel=\"noopener\">https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/</a> <img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/2018-05-08-15-55-33屏幕截图.png\" alt></p>\n<h2 id=\"二：Linux常用命令：\"><a href=\"#二：Linux常用命令：\" class=\"headerlink\" title=\"二：Linux常用命令：\"></a>二：Linux常用命令：</h2><p>　cd 路径                   （进入一个路径，比如 /usr/local/lib） 　　cd ..　　  　　　　  （返回上一个文件夹） 　　ls　　　　　　　　 （显示当前文件夹下的所有文件，Linux独有哦，dir 也有相同功能） 　　sudo 命令　　　　 （获取超级管理权限，需要输入密码）  </p>\n<h3 id=\"常用新建、删除、拷贝命令：\"><a href=\"#常用新建、删除、拷贝命令：\" class=\"headerlink\" title=\"　　常用新建、删除、拷贝命令：\"></a>　　常用新建、删除、拷贝命令：</h3><p>　　mkdir 目录名        （新建一个文件夹，文件夹在Linux系统中叫做“目录”） 　　touch 文件名        （新建一个空文件）   　　rmdir 目录名        （删除一个空文件夹，文件夹里有内容则不可用） 　　rm -rf 非空目录名 （删除一个包含文件的文件夹） 　　rm 文件名 文件名 （删除多个文件）  　　cp 文件名 目标路径（拷贝一个文件到目标路径，如cp hserver /opt/hqueue） 　　cp -i　　　　　　  （拷贝，同名文件存在时，输出 [yes/no] 询问是否执行） 　　cp -f　　　　　　  （强制复制文件，如有同名不询问）  </p>\n<h3 id=\"常用解压、安装程序、文件更新命令：deb格式双击即可安装\"><a href=\"#常用解压、安装程序、文件更新命令：deb格式双击即可安装\" class=\"headerlink\" title=\"　　常用解压、安装程序、文件更新命令：deb格式双击即可安装\"></a>　　常用解压、安装程序、文件更新命令：deb格式双击即可安装</h3><p>tar -zxvf <em>.tar.gz　     ( 解压 tar.gz格式的文件 ) 　　source </em>.install　　　 （安装install格式的安装包） 　　sh 路径/×.sh　　    　 （安装sh格式的文件，如 sudo sh /home/hp/Downloads/<em>.sh） 　　sudo apt-get upgrade（更新已安装的包） 　　sudo apt-get update  （更新源）         chmod +x </em>.sh 这个命令是为sh文件增加可执行权限； 　　chmod +R 777 <em>.</em>  对当前目录下的所有子目录和子文件进行 777权限的变更；通在安装软件时复制相关文件。  </p>\n<h2 id=\"三：疑难解答：\"><a href=\"#三：疑难解答：\" class=\"headerlink\" title=\"三：疑难解答：\"></a>三：疑难解答：</h2><p>一：Linux与<strong>Ubuntu，CentOS等的区别：</strong> 其实Ubuntu等是Linux的发行版，就像小米系统，华为系统也是属于安卓系统。 二,使用Linux的好处：</p>\n<ol>\n<li>可以增加就业机会，因为Linux是开源免费的。</li>\n<li>可以改掉使用电脑坏习惯，让自己真正接触计算机。</li>\n<li>开源软件越来约丰富，如ROS，Hadoop等</li>\n<li>对配置要求很低，反正我08年笔记本电脑完美运行（新手最好拿使用双系统或者用台不常用的笔记本</li>\n</ol>\n<p>[/success]）</p>\n","site":{"data":{}},"excerpt":"","more":"<p>[success]</p>\n<h2 id=\"一：下载网速过慢解决方案：\"><a href=\"#一：下载网速过慢解决方案：\" class=\"headerlink\" title=\"一：下载网速过慢解决方案：\"></a>一：下载网速过慢解决方案：</h2><p>将下载源换成国内清华源：<a href=\"https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/\" target=\"_blank\" rel=\"noopener\">https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/</a> <img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/2018-05-08-15-55-33屏幕截图.png\" alt></p>\n<h2 id=\"二：Linux常用命令：\"><a href=\"#二：Linux常用命令：\" class=\"headerlink\" title=\"二：Linux常用命令：\"></a>二：Linux常用命令：</h2><p>　cd 路径                   （进入一个路径，比如 /usr/local/lib） 　　cd ..　　  　　　　  （返回上一个文件夹） 　　ls　　　　　　　　 （显示当前文件夹下的所有文件，Linux独有哦，dir 也有相同功能） 　　sudo 命令　　　　 （获取超级管理权限，需要输入密码）  </p>\n<h3 id=\"常用新建、删除、拷贝命令：\"><a href=\"#常用新建、删除、拷贝命令：\" class=\"headerlink\" title=\"　　常用新建、删除、拷贝命令：\"></a>　　常用新建、删除、拷贝命令：</h3><p>　　mkdir 目录名        （新建一个文件夹，文件夹在Linux系统中叫做“目录”） 　　touch 文件名        （新建一个空文件）   　　rmdir 目录名        （删除一个空文件夹，文件夹里有内容则不可用） 　　rm -rf 非空目录名 （删除一个包含文件的文件夹） 　　rm 文件名 文件名 （删除多个文件）  　　cp 文件名 目标路径（拷贝一个文件到目标路径，如cp hserver /opt/hqueue） 　　cp -i　　　　　　  （拷贝，同名文件存在时，输出 [yes/no] 询问是否执行） 　　cp -f　　　　　　  （强制复制文件，如有同名不询问）  </p>\n<h3 id=\"常用解压、安装程序、文件更新命令：deb格式双击即可安装\"><a href=\"#常用解压、安装程序、文件更新命令：deb格式双击即可安装\" class=\"headerlink\" title=\"　　常用解压、安装程序、文件更新命令：deb格式双击即可安装\"></a>　　常用解压、安装程序、文件更新命令：deb格式双击即可安装</h3><p>tar -zxvf <em>.tar.gz　     ( 解压 tar.gz格式的文件 ) 　　source </em>.install　　　 （安装install格式的安装包） 　　sh 路径/×.sh　　    　 （安装sh格式的文件，如 sudo sh /home/hp/Downloads/<em>.sh） 　　sudo apt-get upgrade（更新已安装的包） 　　sudo apt-get update  （更新源）         chmod +x </em>.sh 这个命令是为sh文件增加可执行权限； 　　chmod +R 777 <em>.</em>  对当前目录下的所有子目录和子文件进行 777权限的变更；通在安装软件时复制相关文件。  </p>\n<h2 id=\"三：疑难解答：\"><a href=\"#三：疑难解答：\" class=\"headerlink\" title=\"三：疑难解答：\"></a>三：疑难解答：</h2><p>一：Linux与<strong>Ubuntu，CentOS等的区别：</strong> 其实Ubuntu等是Linux的发行版，就像小米系统，华为系统也是属于安卓系统。 二,使用Linux的好处：</p>\n<ol>\n<li>可以增加就业机会，因为Linux是开源免费的。</li>\n<li>可以改掉使用电脑坏习惯，让自己真正接触计算机。</li>\n<li>开源软件越来约丰富，如ROS，Hadoop等</li>\n<li>对配置要求很低，反正我08年笔记本电脑完美运行（新手最好拿使用双系统或者用台不常用的笔记本</li>\n</ol>\n<p>[/success]）</p>\n"},{"title":"第一部分:GitKraken破解及教程","toc":false,"date":"2020-03-01T11:35:41.000Z","_content":"\n# 1.GItKraken介绍\ngitKraken，这款工具操作比较方便，UI也是我喜欢的风格，对没有太多git使用经验的新手比较友好，学习成本相对较低。尤其喜欢的一点就是它的分支和提交非常清晰。\n![image.png](https://blog.mviai.com/images/Fs9HOjVYzYWRDsUM1XmDcoq7LKc7)\n**优点:**\n1.            可以在不切换分支的情况下，操作其他的分支\n2.     \t   多平台(Windows,liunx,mac)\n\n\n**缺点:**\n1.\t       启动慢,占用资源多\n2.    \t   收费\n\n\n# 2.下载\n[官网下载](https://www.gitkraken.com/download)\n\n\n# 3.汉化\n虽然都能认识,但是第一次接触,汉化亲切些;\n\n## 下载\n```\ngit clone https://github.com/k-skye/gitkraken-chinese.git\n\n```\n\n## 原理\n\n通过修改软件目录下english语言对应的一个json文件内容来完成汉化目的\n\n## 操作步骤\n**(注意备份英文文件,备份为strings.json.bak,习惯了操作就改回来)**\n1. 将项目中的 `strings.json` 替换到 GitKraken 语言目录下的 `strings.json`.  \n(实际目录可能会不一样,但文件名一定是strings.json)\n  \n   - Windows: `%程序安装目录%\\gitkraken\\app-x.x.x\\resources\\app\\src\\strings.json` (x.x.x 是你的GitKraken版本)\n   - Mac: `/Applications/GitKraken.app/Contents/Resources/app/src/strings.json`\n   - Linux: `/usr/share/gitkraken/resources/app.asar.unpacked/src` (感谢lyydhy 10.31补充 Gitkraken是deepin 通过deb 安装的)\n     \n2. 重启GitKraken.\n\n\n# 4.破解\n1.安装完成后(sudo dpkg -i xx.deb),打开软件\n2.打开网址[破解器](https://github.com/KillWolfVlad/GitKraken-AUR),查看是否版本对应,否则查看问题回答最多(里面有解决方案)\n3.我下载的更新分支(github.com/BoGnY/GitCracken)的,它支持6.5\n4.看说明:如下\n-\t\tGNU/Linux不要用snap安装\n-\t        macOS必须开启后在破解(实测liunx也需要)\n- \t        node.js 版本需要12及其以上(sudo n 选择)\n-  \t\tyarn必须安装\t\t\n \t\t完成上述几条,执行\n```c\nyarn install\n yarn build\nnode dist/bin/gitcracken.js --help\n\t\t\n\n```\n **  如遇到下载问题,首先查看是否默认换到淘宝源,如遇到报错,点击下载链接是否可以远程下载,如无法,打开yarn.lock文件修改地址(可以尝试本地地址 file://xxxxx) **\n\n\t\n-\t完成后开始破解\n```c\t\n\t\tyarn run gitcracken patcher\n\t\tyarn run gitcracken patcher --asar ~/Downloads/gitkraken/resources/app.asar(修改为你的安装地址)\n\t\tyarn run gitcracken patcher backup unpack patch\n\n```\n\n\t\t\n**注意:如果报错,用yarn run gitcracken patcher remove 删除,然后到sudo rm gitkraken/resources/app.asar.*(如果破解后启动不了,也用这个方法)**\n\n### 提示:防止更新\n\t**更新后还要收费,修改hosts文件**\n\tvim etc/hosts\n\t然后在文件最后加入\n```c\n0.0.0.0 release.gitkraken.com#屏蔽官方地址\n\n```\n\n![image.png](https://blog.mviai.com/images/Fia7aodyxl3vw3G3WU151wVAl2dH)\n","source":"_posts/第一部分-GitKraken破解及教程.md","raw":"---\ntitle: '第一部分:GitKraken破解及教程'\ntags:\n  - GItKraken\ncategories:\n  - 工具\n  - 日常工具\n  \ntoc: false\ndate: 2020-03-01 19:35:41\n---\n\n# 1.GItKraken介绍\ngitKraken，这款工具操作比较方便，UI也是我喜欢的风格，对没有太多git使用经验的新手比较友好，学习成本相对较低。尤其喜欢的一点就是它的分支和提交非常清晰。\n![image.png](https://blog.mviai.com/images/Fs9HOjVYzYWRDsUM1XmDcoq7LKc7)\n**优点:**\n1.            可以在不切换分支的情况下，操作其他的分支\n2.     \t   多平台(Windows,liunx,mac)\n\n\n**缺点:**\n1.\t       启动慢,占用资源多\n2.    \t   收费\n\n\n# 2.下载\n[官网下载](https://www.gitkraken.com/download)\n\n\n# 3.汉化\n虽然都能认识,但是第一次接触,汉化亲切些;\n\n## 下载\n```\ngit clone https://github.com/k-skye/gitkraken-chinese.git\n\n```\n\n## 原理\n\n通过修改软件目录下english语言对应的一个json文件内容来完成汉化目的\n\n## 操作步骤\n**(注意备份英文文件,备份为strings.json.bak,习惯了操作就改回来)**\n1. 将项目中的 `strings.json` 替换到 GitKraken 语言目录下的 `strings.json`.  \n(实际目录可能会不一样,但文件名一定是strings.json)\n  \n   - Windows: `%程序安装目录%\\gitkraken\\app-x.x.x\\resources\\app\\src\\strings.json` (x.x.x 是你的GitKraken版本)\n   - Mac: `/Applications/GitKraken.app/Contents/Resources/app/src/strings.json`\n   - Linux: `/usr/share/gitkraken/resources/app.asar.unpacked/src` (感谢lyydhy 10.31补充 Gitkraken是deepin 通过deb 安装的)\n     \n2. 重启GitKraken.\n\n\n# 4.破解\n1.安装完成后(sudo dpkg -i xx.deb),打开软件\n2.打开网址[破解器](https://github.com/KillWolfVlad/GitKraken-AUR),查看是否版本对应,否则查看问题回答最多(里面有解决方案)\n3.我下载的更新分支(github.com/BoGnY/GitCracken)的,它支持6.5\n4.看说明:如下\n-\t\tGNU/Linux不要用snap安装\n-\t        macOS必须开启后在破解(实测liunx也需要)\n- \t        node.js 版本需要12及其以上(sudo n 选择)\n-  \t\tyarn必须安装\t\t\n \t\t完成上述几条,执行\n```c\nyarn install\n yarn build\nnode dist/bin/gitcracken.js --help\n\t\t\n\n```\n **  如遇到下载问题,首先查看是否默认换到淘宝源,如遇到报错,点击下载链接是否可以远程下载,如无法,打开yarn.lock文件修改地址(可以尝试本地地址 file://xxxxx) **\n\n\t\n-\t完成后开始破解\n```c\t\n\t\tyarn run gitcracken patcher\n\t\tyarn run gitcracken patcher --asar ~/Downloads/gitkraken/resources/app.asar(修改为你的安装地址)\n\t\tyarn run gitcracken patcher backup unpack patch\n\n```\n\n\t\t\n**注意:如果报错,用yarn run gitcracken patcher remove 删除,然后到sudo rm gitkraken/resources/app.asar.*(如果破解后启动不了,也用这个方法)**\n\n### 提示:防止更新\n\t**更新后还要收费,修改hosts文件**\n\tvim etc/hosts\n\t然后在文件最后加入\n```c\n0.0.0.0 release.gitkraken.com#屏蔽官方地址\n\n```\n\n![image.png](https://blog.mviai.com/images/Fia7aodyxl3vw3G3WU151wVAl2dH)\n","slug":"第一部分-GitKraken破解及教程","published":1,"updated":"2021-07-26T09:58:02.575Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m2u003digtap6wwkwfq","content":"<h1 id=\"1-GItKraken介绍\"><a href=\"#1-GItKraken介绍\" class=\"headerlink\" title=\"1.GItKraken介绍\"></a>1.GItKraken介绍</h1><p>gitKraken，这款工具操作比较方便，UI也是我喜欢的风格，对没有太多git使用经验的新手比较友好，学习成本相对较低。尤其喜欢的一点就是它的分支和提交非常清晰。<br><img src=\"https://blog.mviai.com/images/Fs9HOjVYzYWRDsUM1XmDcoq7LKc7\" alt=\"image.png\"><br><strong>优点:</strong></p>\n<ol>\n<li>可以在不切换分支的情况下，操作其他的分支</li>\n<li>多平台(Windows,liunx,mac)</li>\n</ol>\n<p><strong>缺点:</strong></p>\n<ol>\n<li>启动慢,占用资源多</li>\n<li>收费</li>\n</ol>\n<h1 id=\"2-下载\"><a href=\"#2-下载\" class=\"headerlink\" title=\"2.下载\"></a>2.下载</h1><p><a href=\"https://www.gitkraken.com/download\" target=\"_blank\" rel=\"noopener\">官网下载</a></p>\n<h1 id=\"3-汉化\"><a href=\"#3-汉化\" class=\"headerlink\" title=\"3.汉化\"></a>3.汉化</h1><p>虽然都能认识,但是第一次接触,汉化亲切些;</p>\n<h2 id=\"下载\"><a href=\"#下载\" class=\"headerlink\" title=\"下载\"></a>下载</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/k-skye/gitkraken-chinese.git</span><br></pre></td></tr></table></figure>\n<h2 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h2><p>通过修改软件目录下english语言对应的一个json文件内容来完成汉化目的</p>\n<h2 id=\"操作步骤\"><a href=\"#操作步骤\" class=\"headerlink\" title=\"操作步骤\"></a>操作步骤</h2><p><strong>(注意备份英文文件,备份为strings.json.bak,习惯了操作就改回来)</strong></p>\n<ol>\n<li><p>将项目中的 <code>strings.json</code> 替换到 GitKraken 语言目录下的 <code>strings.json</code>.<br>(实际目录可能会不一样,但文件名一定是strings.json)</p>\n<ul>\n<li>Windows: <code>%程序安装目录%\\gitkraken\\app-x.x.x\\resources\\app\\src\\strings.json</code> (x.x.x 是你的GitKraken版本)</li>\n<li>Mac: <code>/Applications/GitKraken.app/Contents/Resources/app/src/strings.json</code></li>\n<li>Linux: <code>/usr/share/gitkraken/resources/app.asar.unpacked/src</code> (感谢lyydhy 10.31补充 Gitkraken是deepin 通过deb 安装的)</li>\n</ul>\n</li>\n<li><p>重启GitKraken.</p>\n</li>\n</ol>\n<h1 id=\"4-破解\"><a href=\"#4-破解\" class=\"headerlink\" title=\"4.破解\"></a>4.破解</h1><p>1.安装完成后(sudo dpkg -i xx.deb),打开软件<br>2.打开网址<a href=\"https://github.com/KillWolfVlad/GitKraken-AUR\" target=\"_blank\" rel=\"noopener\">破解器</a>,查看是否版本对应,否则查看问题回答最多(里面有解决方案)<br>3.我下载的更新分支(github.com/BoGnY/GitCracken)的,它支持6.5<br>4.看说明:如下</p>\n<ul>\n<li>GNU/Linux不要用snap安装</li>\n<li>macOS必须开启后在破解(实测liunx也需要)</li>\n<li>node.js 版本需要12及其以上(sudo n 选择)</li>\n<li><p>yarn必须安装<br>完成上述几条,执行</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yarn install</span><br><span class=\"line\"> yarn build</span><br><span class=\"line\">node dist/bin/gitcracken.js --help</span><br></pre></td></tr></table></figure>\n<p><strong>  如遇到下载问题,首先查看是否默认换到淘宝源,如遇到报错,点击下载链接是否可以远程下载,如无法,打开yarn.lock文件修改地址(可以尝试本地地址 file://xxxxx) </strong></p>\n</li>\n</ul>\n<ul>\n<li>完成后开始破解<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yarn run gitcracken patcher</span><br><span class=\"line\">yarn run gitcracken patcher --asar ~/Downloads/gitkraken/resources/app.asar(修改为你的安装地址)</span><br><span class=\"line\">yarn run gitcracken patcher backup unpack patch</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p><strong>注意:如果报错,用yarn run gitcracken patcher remove 删除,然后到sudo rm gitkraken/resources/app.asar.*(如果破解后启动不了,也用这个方法)</strong></p>\n<h3 id=\"提示-防止更新\"><a href=\"#提示-防止更新\" class=\"headerlink\" title=\"提示:防止更新\"></a>提示:防止更新</h3><pre><code>**更新后还要收费,修改hosts文件**\nvim etc/hosts\n然后在文件最后加入\n</code></pre><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">0.0</span><span class=\"number\">.0</span><span class=\"number\">.0</span> release.gitkraken.com#屏蔽官方地址</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://blog.mviai.com/images/Fia7aodyxl3vw3G3WU151wVAl2dH\" alt=\"image.png\"></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"1-GItKraken介绍\"><a href=\"#1-GItKraken介绍\" class=\"headerlink\" title=\"1.GItKraken介绍\"></a>1.GItKraken介绍</h1><p>gitKraken，这款工具操作比较方便，UI也是我喜欢的风格，对没有太多git使用经验的新手比较友好，学习成本相对较低。尤其喜欢的一点就是它的分支和提交非常清晰。<br><img src=\"https://blog.mviai.com/images/Fs9HOjVYzYWRDsUM1XmDcoq7LKc7\" alt=\"image.png\"><br><strong>优点:</strong></p>\n<ol>\n<li>可以在不切换分支的情况下，操作其他的分支</li>\n<li>多平台(Windows,liunx,mac)</li>\n</ol>\n<p><strong>缺点:</strong></p>\n<ol>\n<li>启动慢,占用资源多</li>\n<li>收费</li>\n</ol>\n<h1 id=\"2-下载\"><a href=\"#2-下载\" class=\"headerlink\" title=\"2.下载\"></a>2.下载</h1><p><a href=\"https://www.gitkraken.com/download\" target=\"_blank\" rel=\"noopener\">官网下载</a></p>\n<h1 id=\"3-汉化\"><a href=\"#3-汉化\" class=\"headerlink\" title=\"3.汉化\"></a>3.汉化</h1><p>虽然都能认识,但是第一次接触,汉化亲切些;</p>\n<h2 id=\"下载\"><a href=\"#下载\" class=\"headerlink\" title=\"下载\"></a>下载</h2><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git clone https://github.com/k-skye/gitkraken-chinese.git</span><br></pre></td></tr></table></figure>\n<h2 id=\"原理\"><a href=\"#原理\" class=\"headerlink\" title=\"原理\"></a>原理</h2><p>通过修改软件目录下english语言对应的一个json文件内容来完成汉化目的</p>\n<h2 id=\"操作步骤\"><a href=\"#操作步骤\" class=\"headerlink\" title=\"操作步骤\"></a>操作步骤</h2><p><strong>(注意备份英文文件,备份为strings.json.bak,习惯了操作就改回来)</strong></p>\n<ol>\n<li><p>将项目中的 <code>strings.json</code> 替换到 GitKraken 语言目录下的 <code>strings.json</code>.<br>(实际目录可能会不一样,但文件名一定是strings.json)</p>\n<ul>\n<li>Windows: <code>%程序安装目录%\\gitkraken\\app-x.x.x\\resources\\app\\src\\strings.json</code> (x.x.x 是你的GitKraken版本)</li>\n<li>Mac: <code>/Applications/GitKraken.app/Contents/Resources/app/src/strings.json</code></li>\n<li>Linux: <code>/usr/share/gitkraken/resources/app.asar.unpacked/src</code> (感谢lyydhy 10.31补充 Gitkraken是deepin 通过deb 安装的)</li>\n</ul>\n</li>\n<li><p>重启GitKraken.</p>\n</li>\n</ol>\n<h1 id=\"4-破解\"><a href=\"#4-破解\" class=\"headerlink\" title=\"4.破解\"></a>4.破解</h1><p>1.安装完成后(sudo dpkg -i xx.deb),打开软件<br>2.打开网址<a href=\"https://github.com/KillWolfVlad/GitKraken-AUR\" target=\"_blank\" rel=\"noopener\">破解器</a>,查看是否版本对应,否则查看问题回答最多(里面有解决方案)<br>3.我下载的更新分支(github.com/BoGnY/GitCracken)的,它支持6.5<br>4.看说明:如下</p>\n<ul>\n<li>GNU/Linux不要用snap安装</li>\n<li>macOS必须开启后在破解(实测liunx也需要)</li>\n<li>node.js 版本需要12及其以上(sudo n 选择)</li>\n<li><p>yarn必须安装<br>完成上述几条,执行</p>\n<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yarn install</span><br><span class=\"line\"> yarn build</span><br><span class=\"line\">node dist/bin/gitcracken.js --help</span><br></pre></td></tr></table></figure>\n<p><strong>  如遇到下载问题,首先查看是否默认换到淘宝源,如遇到报错,点击下载链接是否可以远程下载,如无法,打开yarn.lock文件修改地址(可以尝试本地地址 file://xxxxx) </strong></p>\n</li>\n</ul>\n<ul>\n<li>完成后开始破解<figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">yarn run gitcracken patcher</span><br><span class=\"line\">yarn run gitcracken patcher --asar ~/Downloads/gitkraken/resources/app.asar(修改为你的安装地址)</span><br><span class=\"line\">yarn run gitcracken patcher backup unpack patch</span><br></pre></td></tr></table></figure>\n</li>\n</ul>\n<p><strong>注意:如果报错,用yarn run gitcracken patcher remove 删除,然后到sudo rm gitkraken/resources/app.asar.*(如果破解后启动不了,也用这个方法)</strong></p>\n<h3 id=\"提示-防止更新\"><a href=\"#提示-防止更新\" class=\"headerlink\" title=\"提示:防止更新\"></a>提示:防止更新</h3><pre><code>**更新后还要收费,修改hosts文件**\nvim etc/hosts\n然后在文件最后加入\n</code></pre><figure class=\"highlight c\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">0.0</span><span class=\"number\">.0</span><span class=\"number\">.0</span> release.gitkraken.com#屏蔽官方地址</span><br></pre></td></tr></table></figure>\n<p><img src=\"https://blog.mviai.com/images/Fia7aodyxl3vw3G3WU151wVAl2dH\" alt=\"image.png\"></p>\n"},{"title":"第三节：序列类型的方法","url":"188.html","id":"188","date":"2018-05-08T06:34:56.000Z","_content":"\n **1.创建列表。只要把逗号分隔的不同的数据项使用方括号括起来即可** List = \\['wade','james','bosh','haslem'\\] 与字符串的索引一样，列表索引从0开始。列表可以进行截取、组合等 **2.添加新的元素**\n\n[?](http://www.jb51.net/article/84754.htm#)\n\n\n`List``.append(``'allen'``)` `#方式一：向list结尾添加 参数object`\n\n`>>> a``=``[``1``,``2``,``3``,``4``]`\n\n`>>> a.append(``5``)`\n\n`>>>` `print``(a)`\n\n`[``1``,` `2``,` `3``,` `4``,` `5``]`\n\n`List``.insert(``4``,``'lewis'``)` `#方式二：插入一个元素 参数一：index位置 参数二：object`\n\n`>>> a``=``[``1``,``2``,``4``]`\n\n`>>> a.insert(``2``,``3``)`\n\n`>>>` `print``(a)`\n\n`[``1``,` `2``,` `3``,` `4``]`\n\n`List``.extend(tableList)` `#方式三：扩展列表，参数：iterable参数`\n\n`>>> a``=``[``1``,``2``,``3``]`\n\n`>>> b``=``[``4``,``5``,``6``]`\n\n`>>> a.extend(b)`\n\n`>>>` `print``(a)`\n\n`[``1``,` `2``,` `3``,` `4``,` `5``,` `6``]`\n\n**3.遍历列表**\n\n[?](http://www.jb51.net/article/84754.htm#)\n\n1\n\n2\n\n`for` `i` `in` `List``:`\n\n`print` `i,`\n\n**4.访问列表中的值** 使用下标索引来访问列表中的值，同样你也可以使用方括号的形式截取字符，如下所示：\n\n[?](http://www.jb51.net/article/84754.htm#)\n\n1\n\n2\n\n3\n\n`>>>` `List` `=` `[``1``,` `2``,` `3``,` `4``,` `5``,` `6``,` `7` `]`\n\n`>>>` `print``(``List``[``3``])`\n\n`4`\n\n**5.从list删除元素**\n\n[?](http://www.jb51.net/article/84754.htm#)\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n9\n\n10\n\n11\n\n12\n\n13\n\n14\n\n15\n\n16\n\n17\n\n18\n\n19\n\n20\n\n21\n\n22\n\n23\n\n24\n\n`List``.remove()` `#删除方式一：参数object 如有重复元素，只会删除最靠前的`\n\n`>>> a``=``[``1``,``2``,``3``]`\n\n`>>> a.remove(``2``)`\n\n`>>>` `print``(a)`\n\n`[``1``,` `3``]`\n\n`List``.pop()` `#删除方式二：pop 可选参数index删除指定位置的元素 默认为最后一个元素`\n\n`>>> a``=``[``1``,` `2``,` `3``,` `4``,` `5``,` `6``]`\n\n`>>> a.pop()`\n\n`6`\n\n`>>>` `print``(a)`\n\n`[``1``,` `2``,` `3``,` `4``,` `5``]`\n\n`del` `List` `#删除方式三：可以删除整个列表或指定元素或者列表切片，list删除后无法访问。`\n\n`>>> a``=``[``1``,` `2``,` `3``,` `4``,` `5``,` `6``]`\n\n`>>>` `del` `a[``5``]`\n\n`>>>` `print``(a)`\n\n`[``1``,` `2``,` `3``,` `4``,` `5``]`\n\n`>>>` `del` `a`\n\n`>>>` `print``(a)`\n\n`Traceback (most recent call last):`\n\n`File` `\"<pyshell#93>\"``, line` `1``,` `in` `<module>`\n\n`print``(a)`\n\n**6.排序和反转代码**\n\n[?](http://www.jb51.net/article/84754.htm#)\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n9\n\n10\n\n11\n\n12\n\n13\n\n14\n\n15\n\n16\n\n17\n\n18\n\n19\n\n`List``.reverse()`\n\n`>>> a``=``[``1``,` `2``,` `3``,` `4``,` `5``,` `6``]`\n\n`>>> a.reverse()`\n\n`>>>` `print``(a)`\n\n`[``6``,` `5``,` `4``,` `3``,` `2``,` `1``]`\n\n`List``.sort()` `#sort有三个默认参数 cmp=None,key=None,reverse=False 因此可以制定排序参数`\n\n`>>> a``=``[``2``,``4``,``6``,``7``,``3``,``1``,``5``]`\n\n`>>> a.sort()`\n\n`>>>` `print``(a)`\n\n`[``1``,` `2``,` `3``,` `4``,` `5``,` `6``,` `7``]`\n\n`#python3X中，不能将数字和字符一起排序，会出现此报错`\n\n`>>> a``=``[``2``,``4``,``6``,``7``,``3``,``1``,``5``,``'a'``]`\n\n`>>> a.sort()`\n\n`Traceback (most recent call last):`\n\n`File` `\"<pyshell#104>\"``, line` `1``,` `in` `<module>`\n\n`a.sort()`\n\n`TypeError: unorderable types:` `str``() <` `int``()`\n\n**7.Python列表截取** Python的列表截取与字符串操作类型相同，如下所示： L = \\['spam', 'Spam', 'SPAM!'\\] 操作：\n\n[?](http://www.jb51.net/article/84754.htm#)\n\n1\n\n2\n\n3\n\n4\n\n`Python 表达式 结果 描述`\n\n`L[``2``]` `'SPAM!'` `读取列表中第三个元素`\n\n`L[``-``2``]` `'Spam'` `读取列表中倒数第二个元素`\n\n`L[``1``:] [``'Spam'``,` `'SPAM!'``] 从第二个元素开始截取列表`\n\n**8.Python列表操作的函数和方法** 列表操作包含以下**函数**: 1、cmp(list1, list2)：比较两个列表的元素 (python3已丢弃) 2、len(list)：列表元素个数 3、max(list)：返回列表元素最大值 4、min(list)：返回列表元素最小值 5、list(seq)：将元组转换为列表 列表操作常用操作包含以下**方法**: 1、list.append(obj)：在列表末尾添加新的对象 2、list.count(obj)：统计某个元素在列表中出现的次数 3、list.extend(seq)：在列表末尾一次性追加另一个序列中的多个值（用新列表扩展原来的列表） 4、list.index(obj)：从列表中找出某个值第一个匹配项的索引位置 5、list.insert(index, obj)：将对象插入列表 6、list.pop(obj=list\\[-1\\])：移除列表中的一个元素（默认最后一个元素），并且返回该元素的值 7、list.remove(obj)：移除列表中某个值的第一个匹配项 8、list.reverse()：反向列表中元素 9、list.sort(\\[func\\])：对原列表进行排序\n\n#### **注意：与字符串的方法不同，所有对列表操作的方法均会改变原有列表的值，而不是创建一个新的列表！！！**\n\n   \n\n**修改列表元素的方法**\n-------------\n\n**修改元素的方法用索引以及切片的方法，如：** **▷ 索引：** **list_name\\[0\\] = '修改后的值'** **▷ 切片：** **l****ist_name\\[0:3\\] = \\[a,b,c\\]   ** **注意：后面需要修改的值的总数可以不与切片的长度相对应，比如说\\[0:3\\]这个切片长度为3，后面可以传一个有2个或者4个元素的列表，此时，只是将切片所对应的值剔除，然后将后面列表依次插入** **后面也可以赋值一个字符串，此时，只是将切片所对应的值剔除，然后将后面字符串拆开然后依次插入** **list_name\\[0:3\\] = 'fuyong'**\n\n![复制代码](https://common.cnblogs.com/images/copycode.gif)\n\nname_list = \\['赵','钱','孙','李','周',\\]\nname_list\\[2\\]= 'sun'\nprint(name_list)\n#结果为：\\['赵', '钱', 'sun', '李', '周'\\]\n\nname\\_list\\[2\\]= name\\_list\\[2\\].title()\nprint(name_list)\n\\# 结果为：\\['赵', '钱', 'Sun', '李', '周'\\]\n\nname_list\\[0:2\\] = \\['zhao','qian'\\]\nprint(name_list)\n#结果为：\\['zhao', 'qian', 'Sun', '李', '周'\\]\n\nname_list\\[0:2\\] = \\['zhao','qian','zheng'\\]\nprint(name_list)\n#结果为：\\['zhao', 'qian', 'zheng', 'Sun', '李', '周'\\]\n\nname_list\\[0:2\\] = \\['zhao'\\]\nprint(name_list)\n#结果为：\\['zhao', 'zheng', 'Sun', '李', '周'\\]\n\nname_list\\[0:3\\] = 'fuyong'\nprint(name_list)\n#结果为：\\['f', 'u', 'y', 'o', 'n', 'g', '李', '周'\\]\n\n![复制代码](https://common.cnblogs.com/images/copycode.gif)\n\n \n\n**五、查询列表元素的方法**\n---------------\n\n**查询元素的方法用索引以及切片的方法，如：** **▷ 索引：** **list_name\\[0\\] ** **▷ 切片：** **l****ist_name\\[0:3\\]** **list_name\\[0:3:2\\] **\n\n![复制代码](https://common.cnblogs.com/images/copycode.gif)\n\n 1 name_list = \\['赵','钱','孙','李','周',\\]\n 2 print(name_list\\[0\\])   # 赵\n 3 print(name_list\\[2\\])   # 孙\n 4 \n 5 print(name_list\\[0:2\\])   # \\['赵', '钱'\\]\n 6 print(name_list\\[1:\\])    # \\['钱', '孙', '李', '周'\\]\n 7 \n 8 print(name_list\\[0:4:2\\]) # \\['赵', '孙'\\]\n 9 print(name_list\\[:4:2\\])  # \\['赵', '孙'\\] 10 \n11 print(name_list\\[4:0:-1\\]) #\\['周', '李', '孙', '钱'\\] 12 print(name_list\\[-2:0:-1\\]) #\\['李', '孙', '钱'\\]\n\n![复制代码](https://common.cnblogs.com/images/copycode.gif)\n\n#### 另外，如果需要查询列表中所有的元素，可以用for循环来实现，如：\n\n![复制代码](https://common.cnblogs.com/images/copycode.gif)\n\n1 name_list = \\['赵','钱','孙','李','周',\\] 2 for name in name_list: 3     print(name)\n\n'''\n输出结果如下：\n\n赵 钱 孙 李 周 '''\n\n![复制代码](https://common.cnblogs.com/images/copycode.gif)\n\n \n\n**六、列表的其他方法**\n-------------\n\n**▷ len(list)方法：** **此方法可以用来计算列表的长度，如下：**\n\n1 name_list = \\['赵','钱','孙','李','周',\\] 2 print(len(name_list)) 3 #输出结果为5\n\n### ▷count()方法:\n\n**此方法用来计算列表中一个元素出现的次数，如下：**\n\n1 name_list = \\['赵','钱','孙','李','周','赵'\\] 2 print(name_list.count('赵')) 3 # 输出结果为2\n\n** ▷sort()方法：** **次方法是对列表进行排序（列表里的元素要为数字类型），默认是正序，可以指定倒序（reverse = True）**\n\n![复制代码](https://common.cnblogs.com/images/copycode.gif)\n\n1 num_list = \\[1,3,6,2,5,0,8\\] 2 num_list.sort() #默认为正序排列 3 print(num_list) 4 #输出结果为：\\[0, 1, 2, 3, 5, 6, 8\\] 5 \n6 num_list.sort(reverse=True)  #指定reverse为True 则为倒序 7 print(num_list) 8 #输出结果为\\[8, 6, 5, 3, 2, 1, 0\\]\n\n![复制代码](https://common.cnblogs.com/images/copycode.gif)\n\n**▷reverse():** **此方法是将列表里所有元素进行翻转，注意，不是排序，是将所有元素倒过来 ，如：**\n\n1 name_list = \\['赵','钱','孙','李','周'\\] 2 name_list.reverse() 3 print(name_list) 4 #结果为：\\['周', '李', '孙', '钱', '赵'\\]\n\n  **▷join()方法：** **此方法用法与字符串的join方法一样，就是将列表里的元素用指定字符连接起来，字符可以是空格，可以是空字符，可以是下划线以及任意字符，如下：**\n\n1 name_list = \\['赵','钱','孙','李','周'\\] 2 print('*'.join(name_list))   # 结果：赵*钱*孙*李*周\n3 print(' '.join(name_list))   # 结果：赵 钱 孙 李 周\n4 print(''.join(name_list))    # 结果：赵钱孙李周\n5 print('__'.join(name_list))  # 结果：赵__钱__孙__李__周\n\n注：可以利用这种方法将一个列表转为字符串格式\n\n**七、列表的嵌套**\n-----------\n\n**上面说过，列表里可以放一切元素，所以，当然也可以嵌套列表：** **如果需要对列表里的列表进行增删改查，只需先索引到里面的列表，然后再进行操作即可，如下：**\n\n![复制代码](https://common.cnblogs.com/images/copycode.gif)\n\nname_list = \\['赵','钱','孙',\\['付','傅','符'\\],'李','周','赵'\\]\n\nprint(name_list\\[3\\]\\[1\\]) # 傅\nprint(name_list\\[3\\]\\[0:2\\]) #\\['付', '傅'\\]\n\nname_list\\[3\\]\\[1\\]= 'fu'\nprint(name_list)\n\\# 结果为：\\['赵', '钱', '孙', \\['付', 'fu', '符'\\], '李', '周', '赵'\\]\n\nname_list\\[3\\].pop(1)\nprint(name_list)\n#结果为\\['赵', '钱', '孙', \\['付', '符'\\], '李', '周', '赵'\\]\n\nname_list\\[3\\].remove('符')\nprint(name_list)\n#结果为：\\['赵', '钱', '孙', \\['付'\\], '李', '周', '赵'\\]\n\n![复制代码](https://common.cnblogs.com/images/copycode.gif)\n\n#### **强调：与字符串的方法不同，所有对列表操作的方法均会改变原有列表的值，而不是创建一个新的列表！！！**\n\n\n","source":"_posts/第三节：序列类型的方法.md","raw":"---\ntitle: 第三节：序列类型的方法\ntags:\n  - 课后解答\nurl: 188.html\nid: 188\ncategories:\n  - 学习\n  - 教学\ndate: 2018-05-08 14:34:56\n---\n\n **1.创建列表。只要把逗号分隔的不同的数据项使用方括号括起来即可** List = \\['wade','james','bosh','haslem'\\] 与字符串的索引一样，列表索引从0开始。列表可以进行截取、组合等 **2.添加新的元素**\n\n[?](http://www.jb51.net/article/84754.htm#)\n\n\n`List``.append(``'allen'``)` `#方式一：向list结尾添加 参数object`\n\n`>>> a``=``[``1``,``2``,``3``,``4``]`\n\n`>>> a.append(``5``)`\n\n`>>>` `print``(a)`\n\n`[``1``,` `2``,` `3``,` `4``,` `5``]`\n\n`List``.insert(``4``,``'lewis'``)` `#方式二：插入一个元素 参数一：index位置 参数二：object`\n\n`>>> a``=``[``1``,``2``,``4``]`\n\n`>>> a.insert(``2``,``3``)`\n\n`>>>` `print``(a)`\n\n`[``1``,` `2``,` `3``,` `4``]`\n\n`List``.extend(tableList)` `#方式三：扩展列表，参数：iterable参数`\n\n`>>> a``=``[``1``,``2``,``3``]`\n\n`>>> b``=``[``4``,``5``,``6``]`\n\n`>>> a.extend(b)`\n\n`>>>` `print``(a)`\n\n`[``1``,` `2``,` `3``,` `4``,` `5``,` `6``]`\n\n**3.遍历列表**\n\n[?](http://www.jb51.net/article/84754.htm#)\n\n1\n\n2\n\n`for` `i` `in` `List``:`\n\n`print` `i,`\n\n**4.访问列表中的值** 使用下标索引来访问列表中的值，同样你也可以使用方括号的形式截取字符，如下所示：\n\n[?](http://www.jb51.net/article/84754.htm#)\n\n1\n\n2\n\n3\n\n`>>>` `List` `=` `[``1``,` `2``,` `3``,` `4``,` `5``,` `6``,` `7` `]`\n\n`>>>` `print``(``List``[``3``])`\n\n`4`\n\n**5.从list删除元素**\n\n[?](http://www.jb51.net/article/84754.htm#)\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n9\n\n10\n\n11\n\n12\n\n13\n\n14\n\n15\n\n16\n\n17\n\n18\n\n19\n\n20\n\n21\n\n22\n\n23\n\n24\n\n`List``.remove()` `#删除方式一：参数object 如有重复元素，只会删除最靠前的`\n\n`>>> a``=``[``1``,``2``,``3``]`\n\n`>>> a.remove(``2``)`\n\n`>>>` `print``(a)`\n\n`[``1``,` `3``]`\n\n`List``.pop()` `#删除方式二：pop 可选参数index删除指定位置的元素 默认为最后一个元素`\n\n`>>> a``=``[``1``,` `2``,` `3``,` `4``,` `5``,` `6``]`\n\n`>>> a.pop()`\n\n`6`\n\n`>>>` `print``(a)`\n\n`[``1``,` `2``,` `3``,` `4``,` `5``]`\n\n`del` `List` `#删除方式三：可以删除整个列表或指定元素或者列表切片，list删除后无法访问。`\n\n`>>> a``=``[``1``,` `2``,` `3``,` `4``,` `5``,` `6``]`\n\n`>>>` `del` `a[``5``]`\n\n`>>>` `print``(a)`\n\n`[``1``,` `2``,` `3``,` `4``,` `5``]`\n\n`>>>` `del` `a`\n\n`>>>` `print``(a)`\n\n`Traceback (most recent call last):`\n\n`File` `\"<pyshell#93>\"``, line` `1``,` `in` `<module>`\n\n`print``(a)`\n\n**6.排序和反转代码**\n\n[?](http://www.jb51.net/article/84754.htm#)\n\n1\n\n2\n\n3\n\n4\n\n5\n\n6\n\n7\n\n8\n\n9\n\n10\n\n11\n\n12\n\n13\n\n14\n\n15\n\n16\n\n17\n\n18\n\n19\n\n`List``.reverse()`\n\n`>>> a``=``[``1``,` `2``,` `3``,` `4``,` `5``,` `6``]`\n\n`>>> a.reverse()`\n\n`>>>` `print``(a)`\n\n`[``6``,` `5``,` `4``,` `3``,` `2``,` `1``]`\n\n`List``.sort()` `#sort有三个默认参数 cmp=None,key=None,reverse=False 因此可以制定排序参数`\n\n`>>> a``=``[``2``,``4``,``6``,``7``,``3``,``1``,``5``]`\n\n`>>> a.sort()`\n\n`>>>` `print``(a)`\n\n`[``1``,` `2``,` `3``,` `4``,` `5``,` `6``,` `7``]`\n\n`#python3X中，不能将数字和字符一起排序，会出现此报错`\n\n`>>> a``=``[``2``,``4``,``6``,``7``,``3``,``1``,``5``,``'a'``]`\n\n`>>> a.sort()`\n\n`Traceback (most recent call last):`\n\n`File` `\"<pyshell#104>\"``, line` `1``,` `in` `<module>`\n\n`a.sort()`\n\n`TypeError: unorderable types:` `str``() <` `int``()`\n\n**7.Python列表截取** Python的列表截取与字符串操作类型相同，如下所示： L = \\['spam', 'Spam', 'SPAM!'\\] 操作：\n\n[?](http://www.jb51.net/article/84754.htm#)\n\n1\n\n2\n\n3\n\n4\n\n`Python 表达式 结果 描述`\n\n`L[``2``]` `'SPAM!'` `读取列表中第三个元素`\n\n`L[``-``2``]` `'Spam'` `读取列表中倒数第二个元素`\n\n`L[``1``:] [``'Spam'``,` `'SPAM!'``] 从第二个元素开始截取列表`\n\n**8.Python列表操作的函数和方法** 列表操作包含以下**函数**: 1、cmp(list1, list2)：比较两个列表的元素 (python3已丢弃) 2、len(list)：列表元素个数 3、max(list)：返回列表元素最大值 4、min(list)：返回列表元素最小值 5、list(seq)：将元组转换为列表 列表操作常用操作包含以下**方法**: 1、list.append(obj)：在列表末尾添加新的对象 2、list.count(obj)：统计某个元素在列表中出现的次数 3、list.extend(seq)：在列表末尾一次性追加另一个序列中的多个值（用新列表扩展原来的列表） 4、list.index(obj)：从列表中找出某个值第一个匹配项的索引位置 5、list.insert(index, obj)：将对象插入列表 6、list.pop(obj=list\\[-1\\])：移除列表中的一个元素（默认最后一个元素），并且返回该元素的值 7、list.remove(obj)：移除列表中某个值的第一个匹配项 8、list.reverse()：反向列表中元素 9、list.sort(\\[func\\])：对原列表进行排序\n\n#### **注意：与字符串的方法不同，所有对列表操作的方法均会改变原有列表的值，而不是创建一个新的列表！！！**\n\n   \n\n**修改列表元素的方法**\n-------------\n\n**修改元素的方法用索引以及切片的方法，如：** **▷ 索引：** **list_name\\[0\\] = '修改后的值'** **▷ 切片：** **l****ist_name\\[0:3\\] = \\[a,b,c\\]   ** **注意：后面需要修改的值的总数可以不与切片的长度相对应，比如说\\[0:3\\]这个切片长度为3，后面可以传一个有2个或者4个元素的列表，此时，只是将切片所对应的值剔除，然后将后面列表依次插入** **后面也可以赋值一个字符串，此时，只是将切片所对应的值剔除，然后将后面字符串拆开然后依次插入** **list_name\\[0:3\\] = 'fuyong'**\n\n![复制代码](https://common.cnblogs.com/images/copycode.gif)\n\nname_list = \\['赵','钱','孙','李','周',\\]\nname_list\\[2\\]= 'sun'\nprint(name_list)\n#结果为：\\['赵', '钱', 'sun', '李', '周'\\]\n\nname\\_list\\[2\\]= name\\_list\\[2\\].title()\nprint(name_list)\n\\# 结果为：\\['赵', '钱', 'Sun', '李', '周'\\]\n\nname_list\\[0:2\\] = \\['zhao','qian'\\]\nprint(name_list)\n#结果为：\\['zhao', 'qian', 'Sun', '李', '周'\\]\n\nname_list\\[0:2\\] = \\['zhao','qian','zheng'\\]\nprint(name_list)\n#结果为：\\['zhao', 'qian', 'zheng', 'Sun', '李', '周'\\]\n\nname_list\\[0:2\\] = \\['zhao'\\]\nprint(name_list)\n#结果为：\\['zhao', 'zheng', 'Sun', '李', '周'\\]\n\nname_list\\[0:3\\] = 'fuyong'\nprint(name_list)\n#结果为：\\['f', 'u', 'y', 'o', 'n', 'g', '李', '周'\\]\n\n![复制代码](https://common.cnblogs.com/images/copycode.gif)\n\n \n\n**五、查询列表元素的方法**\n---------------\n\n**查询元素的方法用索引以及切片的方法，如：** **▷ 索引：** **list_name\\[0\\] ** **▷ 切片：** **l****ist_name\\[0:3\\]** **list_name\\[0:3:2\\] **\n\n![复制代码](https://common.cnblogs.com/images/copycode.gif)\n\n 1 name_list = \\['赵','钱','孙','李','周',\\]\n 2 print(name_list\\[0\\])   # 赵\n 3 print(name_list\\[2\\])   # 孙\n 4 \n 5 print(name_list\\[0:2\\])   # \\['赵', '钱'\\]\n 6 print(name_list\\[1:\\])    # \\['钱', '孙', '李', '周'\\]\n 7 \n 8 print(name_list\\[0:4:2\\]) # \\['赵', '孙'\\]\n 9 print(name_list\\[:4:2\\])  # \\['赵', '孙'\\] 10 \n11 print(name_list\\[4:0:-1\\]) #\\['周', '李', '孙', '钱'\\] 12 print(name_list\\[-2:0:-1\\]) #\\['李', '孙', '钱'\\]\n\n![复制代码](https://common.cnblogs.com/images/copycode.gif)\n\n#### 另外，如果需要查询列表中所有的元素，可以用for循环来实现，如：\n\n![复制代码](https://common.cnblogs.com/images/copycode.gif)\n\n1 name_list = \\['赵','钱','孙','李','周',\\] 2 for name in name_list: 3     print(name)\n\n'''\n输出结果如下：\n\n赵 钱 孙 李 周 '''\n\n![复制代码](https://common.cnblogs.com/images/copycode.gif)\n\n \n\n**六、列表的其他方法**\n-------------\n\n**▷ len(list)方法：** **此方法可以用来计算列表的长度，如下：**\n\n1 name_list = \\['赵','钱','孙','李','周',\\] 2 print(len(name_list)) 3 #输出结果为5\n\n### ▷count()方法:\n\n**此方法用来计算列表中一个元素出现的次数，如下：**\n\n1 name_list = \\['赵','钱','孙','李','周','赵'\\] 2 print(name_list.count('赵')) 3 # 输出结果为2\n\n** ▷sort()方法：** **次方法是对列表进行排序（列表里的元素要为数字类型），默认是正序，可以指定倒序（reverse = True）**\n\n![复制代码](https://common.cnblogs.com/images/copycode.gif)\n\n1 num_list = \\[1,3,6,2,5,0,8\\] 2 num_list.sort() #默认为正序排列 3 print(num_list) 4 #输出结果为：\\[0, 1, 2, 3, 5, 6, 8\\] 5 \n6 num_list.sort(reverse=True)  #指定reverse为True 则为倒序 7 print(num_list) 8 #输出结果为\\[8, 6, 5, 3, 2, 1, 0\\]\n\n![复制代码](https://common.cnblogs.com/images/copycode.gif)\n\n**▷reverse():** **此方法是将列表里所有元素进行翻转，注意，不是排序，是将所有元素倒过来 ，如：**\n\n1 name_list = \\['赵','钱','孙','李','周'\\] 2 name_list.reverse() 3 print(name_list) 4 #结果为：\\['周', '李', '孙', '钱', '赵'\\]\n\n  **▷join()方法：** **此方法用法与字符串的join方法一样，就是将列表里的元素用指定字符连接起来，字符可以是空格，可以是空字符，可以是下划线以及任意字符，如下：**\n\n1 name_list = \\['赵','钱','孙','李','周'\\] 2 print('*'.join(name_list))   # 结果：赵*钱*孙*李*周\n3 print(' '.join(name_list))   # 结果：赵 钱 孙 李 周\n4 print(''.join(name_list))    # 结果：赵钱孙李周\n5 print('__'.join(name_list))  # 结果：赵__钱__孙__李__周\n\n注：可以利用这种方法将一个列表转为字符串格式\n\n**七、列表的嵌套**\n-----------\n\n**上面说过，列表里可以放一切元素，所以，当然也可以嵌套列表：** **如果需要对列表里的列表进行增删改查，只需先索引到里面的列表，然后再进行操作即可，如下：**\n\n![复制代码](https://common.cnblogs.com/images/copycode.gif)\n\nname_list = \\['赵','钱','孙',\\['付','傅','符'\\],'李','周','赵'\\]\n\nprint(name_list\\[3\\]\\[1\\]) # 傅\nprint(name_list\\[3\\]\\[0:2\\]) #\\['付', '傅'\\]\n\nname_list\\[3\\]\\[1\\]= 'fu'\nprint(name_list)\n\\# 结果为：\\['赵', '钱', '孙', \\['付', 'fu', '符'\\], '李', '周', '赵'\\]\n\nname_list\\[3\\].pop(1)\nprint(name_list)\n#结果为\\['赵', '钱', '孙', \\['付', '符'\\], '李', '周', '赵'\\]\n\nname_list\\[3\\].remove('符')\nprint(name_list)\n#结果为：\\['赵', '钱', '孙', \\['付'\\], '李', '周', '赵'\\]\n\n![复制代码](https://common.cnblogs.com/images/copycode.gif)\n\n#### **强调：与字符串的方法不同，所有对列表操作的方法均会改变原有列表的值，而不是创建一个新的列表！！！**\n\n\n","slug":"第三节：序列类型的方法","published":1,"updated":"2021-07-26T09:58:02.571Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m2v003higtatcp123au","content":"<p> <strong>1.创建列表。只要把逗号分隔的不同的数据项使用方括号括起来即可</strong> List = [‘wade’,’james’,’bosh’,’haslem’] 与字符串的索引一样，列表索引从0开始。列表可以进行截取、组合等 <strong>2.添加新的元素</strong></p>\n<p><a href=\"http://www.jb51.net/article/84754.htm#\" target=\"_blank\" rel=\"noopener\">?</a></p>\n<p><code>List`</code>.append(<code>&#39;allen&#39;</code>)<code></code>#方式一：向list结尾添加 参数object`</p>\n<p><code>&gt;&gt;&gt; a`</code>=<code>[</code>1<code>,</code>2<code>,</code>3<code>,</code>4<code></code>]`</p>\n<p><code>&gt;&gt;&gt; a.append(`</code>5<code></code>)`</p>\n<p><code>&gt;&gt;&gt;</code> <code>print`</code>(a)`</p>\n<p><code>[`</code>1<code>,` `2</code>,<code></code>3<code>,` `4</code>,<code></code>5<code></code>]`</p>\n<p><code>List`</code>.insert(<code>4</code>,<code>&#39;lewis&#39;</code>)<code></code>#方式二：插入一个元素 参数一：index位置 参数二：object`</p>\n<p><code>&gt;&gt;&gt; a`</code>=<code>[</code>1<code>,</code>2<code>,</code>4<code></code>]`</p>\n<p><code>&gt;&gt;&gt; a.insert(`</code>2<code>,</code>3<code></code>)`</p>\n<p><code>&gt;&gt;&gt;</code> <code>print`</code>(a)`</p>\n<p><code>[`</code>1<code>,` `2</code>,<code></code>3<code>,` `4</code>]`</p>\n<p><code>List`</code>.extend(tableList)<code></code>#方式三：扩展列表，参数：iterable参数`</p>\n<p><code>&gt;&gt;&gt; a`</code>=<code>[</code>1<code>,</code>2<code>,</code>3<code></code>]`</p>\n<p><code>&gt;&gt;&gt; b`</code>=<code>[</code>4<code>,</code>5<code>,</code>6<code></code>]`</p>\n<p><code>&gt;&gt;&gt; a.extend(b)</code></p>\n<p><code>&gt;&gt;&gt;</code> <code>print`</code>(a)`</p>\n<p><code>[`</code>1<code>,` `2</code>,<code></code>3<code>,` `4</code>,<code></code>5<code>,` `6</code>]`</p>\n<p><strong>3.遍历列表</strong></p>\n<p><a href=\"http://www.jb51.net/article/84754.htm#\" target=\"_blank\" rel=\"noopener\">?</a></p>\n<p>1</p>\n<p>2</p>\n<p><code>for</code> <code>i</code> <code>in</code> <code>List`</code>:`</p>\n<p><code>print</code> <code>i,</code></p>\n<p><strong>4.访问列表中的值</strong> 使用下标索引来访问列表中的值，同样你也可以使用方括号的形式截取字符，如下所示：</p>\n<p><a href=\"http://www.jb51.net/article/84754.htm#\" target=\"_blank\" rel=\"noopener\">?</a></p>\n<p>1</p>\n<p>2</p>\n<p>3</p>\n<p><code>&gt;&gt;&gt;</code> <code>List</code> <code>=</code> <code>[`</code>1<code>,` `2</code>,<code></code>3<code>,` `4</code>,<code></code>5<code>,` `6</code>,<code></code>7<code></code>]`</p>\n<p><code>&gt;&gt;&gt;</code> <code>print`</code>(<code>List</code>[<code>3</code>])`</p>\n<p><code>4</code></p>\n<p><strong>5.从list删除元素</strong></p>\n<p><a href=\"http://www.jb51.net/article/84754.htm#\" target=\"_blank\" rel=\"noopener\">?</a></p>\n<p>1</p>\n<p>2</p>\n<p>3</p>\n<p>4</p>\n<p>5</p>\n<p>6</p>\n<p>7</p>\n<p>8</p>\n<p>9</p>\n<p>10</p>\n<p>11</p>\n<p>12</p>\n<p>13</p>\n<p>14</p>\n<p>15</p>\n<p>16</p>\n<p>17</p>\n<p>18</p>\n<p>19</p>\n<p>20</p>\n<p>21</p>\n<p>22</p>\n<p>23</p>\n<p>24</p>\n<p><code>List`</code>.remove()<code></code>#删除方式一：参数object 如有重复元素，只会删除最靠前的`</p>\n<p><code>&gt;&gt;&gt; a`</code>=<code>[</code>1<code>,</code>2<code>,</code>3<code></code>]`</p>\n<p><code>&gt;&gt;&gt; a.remove(`</code>2<code></code>)`</p>\n<p><code>&gt;&gt;&gt;</code> <code>print`</code>(a)`</p>\n<p><code>[`</code>1<code>,` `3</code>]`</p>\n<p><code>List`</code>.pop()<code></code>#删除方式二：pop 可选参数index删除指定位置的元素 默认为最后一个元素`</p>\n<p><code>&gt;&gt;&gt; a`</code>=<code>[</code>1<code>,` `2</code>,<code></code>3<code>,` `4</code>,<code></code>5<code>,` `6</code>]`</p>\n<p><code>&gt;&gt;&gt; a.pop()</code></p>\n<p><code>6</code></p>\n<p><code>&gt;&gt;&gt;</code> <code>print`</code>(a)`</p>\n<p><code>[`</code>1<code>,` `2</code>,<code></code>3<code>,` `4</code>,<code></code>5<code></code>]`</p>\n<p><code>del</code> <code>List</code> <code>#删除方式三：可以删除整个列表或指定元素或者列表切片，list删除后无法访问。</code></p>\n<p><code>&gt;&gt;&gt; a`</code>=<code>[</code>1<code>,` `2</code>,<code></code>3<code>,` `4</code>,<code></code>5<code>,` `6</code>]`</p>\n<p><code>&gt;&gt;&gt;</code> <code>del</code> <code>a[`</code>5<code></code>]`</p>\n<p><code>&gt;&gt;&gt;</code> <code>print`</code>(a)`</p>\n<p><code>[`</code>1<code>,` `2</code>,<code></code>3<code>,` `4</code>,<code></code>5<code></code>]`</p>\n<p><code>&gt;&gt;&gt;</code> <code>del</code> <code>a</code></p>\n<p><code>&gt;&gt;&gt;</code> <code>print`</code>(a)`</p>\n<p><code>Traceback (most recent call last):</code></p>\n<p><code>File</code> <code>&quot;&lt;pyshell#93&gt;&quot;`</code>, line<code></code>1<code></code>,<code></code>in<code></code><module>`</module></p>\n<p><code>print`</code>(a)`</p>\n<p><strong>6.排序和反转代码</strong></p>\n<p><a href=\"http://www.jb51.net/article/84754.htm#\" target=\"_blank\" rel=\"noopener\">?</a></p>\n<p>1</p>\n<p>2</p>\n<p>3</p>\n<p>4</p>\n<p>5</p>\n<p>6</p>\n<p>7</p>\n<p>8</p>\n<p>9</p>\n<p>10</p>\n<p>11</p>\n<p>12</p>\n<p>13</p>\n<p>14</p>\n<p>15</p>\n<p>16</p>\n<p>17</p>\n<p>18</p>\n<p>19</p>\n<p><code>List`</code>.reverse()`</p>\n<p><code>&gt;&gt;&gt; a`</code>=<code>[</code>1<code>,` `2</code>,<code></code>3<code>,` `4</code>,<code></code>5<code>,` `6</code>]`</p>\n<p><code>&gt;&gt;&gt; a.reverse()</code></p>\n<p><code>&gt;&gt;&gt;</code> <code>print`</code>(a)`</p>\n<p><code>[`</code>6<code>,` `5</code>,<code></code>4<code>,` `3</code>,<code></code>2<code>,` `1</code>]`</p>\n<p><code>List`</code>.sort()<code></code>#sort有三个默认参数 cmp=None,key=None,reverse=False 因此可以制定排序参数`</p>\n<p><code>&gt;&gt;&gt; a`</code>=<code>[</code>2<code>,</code>4<code>,</code>6<code>,</code>7<code>,</code>3<code>,</code>1<code>,</code>5<code></code>]`</p>\n<p><code>&gt;&gt;&gt; a.sort()</code></p>\n<p><code>&gt;&gt;&gt;</code> <code>print`</code>(a)`</p>\n<p><code>[`</code>1<code>,` `2</code>,<code></code>3<code>,` `4</code>,<code></code>5<code>,` `6</code>,<code></code>7<code></code>]`</p>\n<p><code>#python3X中，不能将数字和字符一起排序，会出现此报错</code></p>\n<p><code>&gt;&gt;&gt; a`</code>=<code>[</code>2<code>,</code>4<code>,</code>6<code>,</code>7<code>,</code>3<code>,</code>1<code>,</code>5<code>,</code>‘a’<code></code>]`</p>\n<p><code>&gt;&gt;&gt; a.sort()</code></p>\n<p><code>Traceback (most recent call last):</code></p>\n<p><code>File</code> <code>&quot;&lt;pyshell#104&gt;&quot;`</code>, line<code></code>1<code></code>,<code></code>in<code></code><module>`</module></p>\n<p><code>a.sort()</code></p>\n<p><code>TypeError: unorderable types:</code> <code>str`</code>() &lt;<code></code>int<code></code>()`</p>\n<p><strong>7.Python列表截取</strong> Python的列表截取与字符串操作类型相同，如下所示： L = [‘spam’, ‘Spam’, ‘SPAM!’] 操作：</p>\n<p><a href=\"http://www.jb51.net/article/84754.htm#\" target=\"_blank\" rel=\"noopener\">?</a></p>\n<p>1</p>\n<p>2</p>\n<p>3</p>\n<p>4</p>\n<p><code>Python 表达式 结果 描述</code></p>\n<p><code>L[`</code>2<code></code>]<code></code>‘SPAM!’<code></code>读取列表中第三个元素`</p>\n<p><code>L[`</code>-<code>2</code>]<code></code>‘Spam’<code></code>读取列表中倒数第二个元素`</p>\n<p><code>L[`</code>1<code>:] [</code>‘Spam’<code>,` `&#39;SPAM!&#39;</code>] 从第二个元素开始截取列表`</p>\n<p><strong>8.Python列表操作的函数和方法</strong> 列表操作包含以下<strong>函数</strong>: 1、cmp(list1, list2)：比较两个列表的元素 (python3已丢弃) 2、len(list)：列表元素个数 3、max(list)：返回列表元素最大值 4、min(list)：返回列表元素最小值 5、list(seq)：将元组转换为列表 列表操作常用操作包含以下<strong>方法</strong>: 1、list.append(obj)：在列表末尾添加新的对象 2、list.count(obj)：统计某个元素在列表中出现的次数 3、list.extend(seq)：在列表末尾一次性追加另一个序列中的多个值（用新列表扩展原来的列表） 4、list.index(obj)：从列表中找出某个值第一个匹配项的索引位置 5、list.insert(index, obj)：将对象插入列表 6、list.pop(obj=list[-1])：移除列表中的一个元素（默认最后一个元素），并且返回该元素的值 7、list.remove(obj)：移除列表中某个值的第一个匹配项 8、list.reverse()：反向列表中元素 9、list.sort([func])：对原列表进行排序</p>\n<h4 id=\"注意：与字符串的方法不同，所有对列表操作的方法均会改变原有列表的值，而不是创建一个新的列表！！！\"><a href=\"#注意：与字符串的方法不同，所有对列表操作的方法均会改变原有列表的值，而不是创建一个新的列表！！！\" class=\"headerlink\" title=\"注意：与字符串的方法不同，所有对列表操作的方法均会改变原有列表的值，而不是创建一个新的列表！！！\"></a><strong>注意：与字符串的方法不同，所有对列表操作的方法均会改变原有列表的值，而不是创建一个新的列表！！！</strong></h4><h2 id=\"修改列表元素的方法\"><a href=\"#修改列表元素的方法\" class=\"headerlink\" title=\"修改列表元素的方法\"></a><strong>修改列表元素的方法</strong></h2><p><strong>修改元素的方法用索引以及切片的方法，如：</strong> <strong>▷ 索引：</strong> <strong>list_name[0] = ‘修改后的值’</strong> <strong>▷ 切片：</strong> <strong>l**</strong>ist_name[0:3] = [a,b,c]   <strong> </strong>注意：后面需要修改的值的总数可以不与切片的长度相对应，比如说[0:3]这个切片长度为3，后面可以传一个有2个或者4个元素的列表，此时，只是将切片所对应的值剔除，然后将后面列表依次插入<strong> </strong>后面也可以赋值一个字符串，此时，只是将切片所对应的值剔除，然后将后面字符串拆开然后依次插入<strong> </strong>list_name[0:3] = ‘fuyong’**</p>\n<p><img src=\"https://common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></p>\n<p>name_list = [‘赵’,’钱’,’孙’,’李’,’周’,]<br>name_list[2]= ‘sun’<br>print(name_list)</p>\n<p>#结果为：[‘赵’, ‘钱’, ‘sun’, ‘李’, ‘周’]</p>\n<p>name_list[2]= name_list[2].title()<br>print(name_list)<br># 结果为：[‘赵’, ‘钱’, ‘Sun’, ‘李’, ‘周’]</p>\n<p>name_list[0:2] = [‘zhao’,’qian’]<br>print(name_list)</p>\n<p>#结果为：[‘zhao’, ‘qian’, ‘Sun’, ‘李’, ‘周’]</p>\n<p>name_list[0:2] = [‘zhao’,’qian’,’zheng’]<br>print(name_list)</p>\n<p>#结果为：[‘zhao’, ‘qian’, ‘zheng’, ‘Sun’, ‘李’, ‘周’]</p>\n<p>name_list[0:2] = [‘zhao’]<br>print(name_list)</p>\n<p>#结果为：[‘zhao’, ‘zheng’, ‘Sun’, ‘李’, ‘周’]</p>\n<p>name_list[0:3] = ‘fuyong’<br>print(name_list)</p>\n<p>#结果为：[‘f’, ‘u’, ‘y’, ‘o’, ‘n’, ‘g’, ‘李’, ‘周’]</p>\n<p><img src=\"https://common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></p>\n<h2 id=\"五、查询列表元素的方法\"><a href=\"#五、查询列表元素的方法\" class=\"headerlink\" title=\"五、查询列表元素的方法\"></a><strong>五、查询列表元素的方法</strong></h2><p><strong>查询元素的方法用索引以及切片的方法，如：</strong> <strong>▷ 索引：</strong> <strong>list_name[0] </strong> <strong>▷ 切片：</strong> <strong>l**</strong>ist_name[0:3]<strong> </strong>list_name[0:3:2] **</p>\n<p><img src=\"https://common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></p>\n<p> 1 name_list = [‘赵’,’钱’,’孙’,’李’,’周’,]<br> 2 print(name_list[0])   # 赵<br> 3 print(name_list[2])   # 孙<br> 4<br> 5 print(name_list[0:2])   # [‘赵’, ‘钱’]<br> 6 print(name_list[1:])    # [‘钱’, ‘孙’, ‘李’, ‘周’]<br> 7<br> 8 print(name_list[0:4:2]) # [‘赵’, ‘孙’]<br> 9 print(name_list[:4:2])  # [‘赵’, ‘孙’] 10<br>11 print(name_list[4:0:-1]) #[‘周’, ‘李’, ‘孙’, ‘钱’] 12 print(name_list[-2:0:-1]) #[‘李’, ‘孙’, ‘钱’]</p>\n<p><img src=\"https://common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></p>\n<h4 id=\"另外，如果需要查询列表中所有的元素，可以用for循环来实现，如：\"><a href=\"#另外，如果需要查询列表中所有的元素，可以用for循环来实现，如：\" class=\"headerlink\" title=\"另外，如果需要查询列表中所有的元素，可以用for循环来实现，如：\"></a>另外，如果需要查询列表中所有的元素，可以用for循环来实现，如：</h4><p><img src=\"https://common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></p>\n<p>1 name_list = [‘赵’,’钱’,’孙’,’李’,’周’,] 2 for name in name_list: 3     print(name)</p>\n<p>‘’’<br>输出结果如下：</p>\n<p>赵 钱 孙 李 周 ‘’’</p>\n<p><img src=\"https://common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></p>\n<h2 id=\"六、列表的其他方法\"><a href=\"#六、列表的其他方法\" class=\"headerlink\" title=\"六、列表的其他方法\"></a><strong>六、列表的其他方法</strong></h2><p><strong>▷ len(list)方法：</strong> <strong>此方法可以用来计算列表的长度，如下：</strong></p>\n<p>1 name_list = [‘赵’,’钱’,’孙’,’李’,’周’,] 2 print(len(name_list)) 3 #输出结果为5</p>\n<h3 id=\"▷count-方法\"><a href=\"#▷count-方法\" class=\"headerlink\" title=\"▷count()方法:\"></a>▷count()方法:</h3><p><strong>此方法用来计算列表中一个元素出现的次数，如下：</strong></p>\n<p>1 name_list = [‘赵’,’钱’,’孙’,’李’,’周’,’赵’] 2 print(name_list.count(‘赵’)) 3 # 输出结果为2</p>\n<p><strong> ▷sort()方法：</strong> <strong>次方法是对列表进行排序（列表里的元素要为数字类型），默认是正序，可以指定倒序（reverse = True）</strong></p>\n<p><img src=\"https://common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></p>\n<p>1 num_list = [1,3,6,2,5,0,8] 2 num_list.sort() #默认为正序排列 3 print(num_list) 4 #输出结果为：[0, 1, 2, 3, 5, 6, 8] 5<br>6 num_list.sort(reverse=True)  #指定reverse为True 则为倒序 7 print(num_list) 8 #输出结果为[8, 6, 5, 3, 2, 1, 0]</p>\n<p><img src=\"https://common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></p>\n<p><strong>▷reverse():</strong> <strong>此方法是将列表里所有元素进行翻转，注意，不是排序，是将所有元素倒过来 ，如：</strong></p>\n<p>1 name_list = [‘赵’,’钱’,’孙’,’李’,’周’] 2 name_list.reverse() 3 print(name_list) 4 #结果为：[‘周’, ‘李’, ‘孙’, ‘钱’, ‘赵’]</p>\n<p>  <strong>▷join()方法：</strong> <strong>此方法用法与字符串的join方法一样，就是将列表里的元素用指定字符连接起来，字符可以是空格，可以是空字符，可以是下划线以及任意字符，如下：</strong></p>\n<p>1 name_list = [‘赵’,’钱’,’孙’,’李’,’周’] 2 print(‘<em>‘.join(name_list))   # 结果：赵</em>钱<em>孙</em>李*周<br>3 print(‘ ‘.join(name_list))   # 结果：赵 钱 孙 李 周<br>4 print(‘’.join(name_list))    # 结果：赵钱孙李周<br>5 print(‘<strong>‘.join(name_list))  # 结果：赵</strong>钱<strong>孙</strong>李__周</p>\n<p>注：可以利用这种方法将一个列表转为字符串格式</p>\n<h2 id=\"七、列表的嵌套\"><a href=\"#七、列表的嵌套\" class=\"headerlink\" title=\"七、列表的嵌套\"></a><strong>七、列表的嵌套</strong></h2><p><strong>上面说过，列表里可以放一切元素，所以，当然也可以嵌套列表：</strong> <strong>如果需要对列表里的列表进行增删改查，只需先索引到里面的列表，然后再进行操作即可，如下：</strong></p>\n<p><img src=\"https://common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></p>\n<p>name_list = [‘赵’,’钱’,’孙’,[‘付’,’傅’,’符’],’李’,’周’,’赵’]</p>\n<p>print(name_list[3][1]) # 傅<br>print(name_list[3][0:2]) #[‘付’, ‘傅’]</p>\n<p>name_list[3][1]= ‘fu’<br>print(name_list)<br># 结果为：[‘赵’, ‘钱’, ‘孙’, [‘付’, ‘fu’, ‘符’], ‘李’, ‘周’, ‘赵’]</p>\n<p>name_list[3].pop(1)<br>print(name_list)</p>\n<p>#结果为[‘赵’, ‘钱’, ‘孙’, [‘付’, ‘符’], ‘李’, ‘周’, ‘赵’]</p>\n<p>name_list[3].remove(‘符’)<br>print(name_list)</p>\n<p>#结果为：[‘赵’, ‘钱’, ‘孙’, [‘付’], ‘李’, ‘周’, ‘赵’]</p>\n<p><img src=\"https://common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></p>\n<h4 id=\"强调：与字符串的方法不同，所有对列表操作的方法均会改变原有列表的值，而不是创建一个新的列表！！！\"><a href=\"#强调：与字符串的方法不同，所有对列表操作的方法均会改变原有列表的值，而不是创建一个新的列表！！！\" class=\"headerlink\" title=\"强调：与字符串的方法不同，所有对列表操作的方法均会改变原有列表的值，而不是创建一个新的列表！！！\"></a><strong>强调：与字符串的方法不同，所有对列表操作的方法均会改变原有列表的值，而不是创建一个新的列表！！！</strong></h4>","site":{"data":{}},"excerpt":"","more":"<p> <strong>1.创建列表。只要把逗号分隔的不同的数据项使用方括号括起来即可</strong> List = [‘wade’,’james’,’bosh’,’haslem’] 与字符串的索引一样，列表索引从0开始。列表可以进行截取、组合等 <strong>2.添加新的元素</strong></p>\n<p><a href=\"http://www.jb51.net/article/84754.htm#\" target=\"_blank\" rel=\"noopener\">?</a></p>\n<p><code>List`</code>.append(<code>&#39;allen&#39;</code>)<code></code>#方式一：向list结尾添加 参数object`</p>\n<p><code>&gt;&gt;&gt; a`</code>=<code>[</code>1<code>,</code>2<code>,</code>3<code>,</code>4<code></code>]`</p>\n<p><code>&gt;&gt;&gt; a.append(`</code>5<code></code>)`</p>\n<p><code>&gt;&gt;&gt;</code> <code>print`</code>(a)`</p>\n<p><code>[`</code>1<code>,` `2</code>,<code></code>3<code>,` `4</code>,<code></code>5<code></code>]`</p>\n<p><code>List`</code>.insert(<code>4</code>,<code>&#39;lewis&#39;</code>)<code></code>#方式二：插入一个元素 参数一：index位置 参数二：object`</p>\n<p><code>&gt;&gt;&gt; a`</code>=<code>[</code>1<code>,</code>2<code>,</code>4<code></code>]`</p>\n<p><code>&gt;&gt;&gt; a.insert(`</code>2<code>,</code>3<code></code>)`</p>\n<p><code>&gt;&gt;&gt;</code> <code>print`</code>(a)`</p>\n<p><code>[`</code>1<code>,` `2</code>,<code></code>3<code>,` `4</code>]`</p>\n<p><code>List`</code>.extend(tableList)<code></code>#方式三：扩展列表，参数：iterable参数`</p>\n<p><code>&gt;&gt;&gt; a`</code>=<code>[</code>1<code>,</code>2<code>,</code>3<code></code>]`</p>\n<p><code>&gt;&gt;&gt; b`</code>=<code>[</code>4<code>,</code>5<code>,</code>6<code></code>]`</p>\n<p><code>&gt;&gt;&gt; a.extend(b)</code></p>\n<p><code>&gt;&gt;&gt;</code> <code>print`</code>(a)`</p>\n<p><code>[`</code>1<code>,` `2</code>,<code></code>3<code>,` `4</code>,<code></code>5<code>,` `6</code>]`</p>\n<p><strong>3.遍历列表</strong></p>\n<p><a href=\"http://www.jb51.net/article/84754.htm#\" target=\"_blank\" rel=\"noopener\">?</a></p>\n<p>1</p>\n<p>2</p>\n<p><code>for</code> <code>i</code> <code>in</code> <code>List`</code>:`</p>\n<p><code>print</code> <code>i,</code></p>\n<p><strong>4.访问列表中的值</strong> 使用下标索引来访问列表中的值，同样你也可以使用方括号的形式截取字符，如下所示：</p>\n<p><a href=\"http://www.jb51.net/article/84754.htm#\" target=\"_blank\" rel=\"noopener\">?</a></p>\n<p>1</p>\n<p>2</p>\n<p>3</p>\n<p><code>&gt;&gt;&gt;</code> <code>List</code> <code>=</code> <code>[`</code>1<code>,` `2</code>,<code></code>3<code>,` `4</code>,<code></code>5<code>,` `6</code>,<code></code>7<code></code>]`</p>\n<p><code>&gt;&gt;&gt;</code> <code>print`</code>(<code>List</code>[<code>3</code>])`</p>\n<p><code>4</code></p>\n<p><strong>5.从list删除元素</strong></p>\n<p><a href=\"http://www.jb51.net/article/84754.htm#\" target=\"_blank\" rel=\"noopener\">?</a></p>\n<p>1</p>\n<p>2</p>\n<p>3</p>\n<p>4</p>\n<p>5</p>\n<p>6</p>\n<p>7</p>\n<p>8</p>\n<p>9</p>\n<p>10</p>\n<p>11</p>\n<p>12</p>\n<p>13</p>\n<p>14</p>\n<p>15</p>\n<p>16</p>\n<p>17</p>\n<p>18</p>\n<p>19</p>\n<p>20</p>\n<p>21</p>\n<p>22</p>\n<p>23</p>\n<p>24</p>\n<p><code>List`</code>.remove()<code></code>#删除方式一：参数object 如有重复元素，只会删除最靠前的`</p>\n<p><code>&gt;&gt;&gt; a`</code>=<code>[</code>1<code>,</code>2<code>,</code>3<code></code>]`</p>\n<p><code>&gt;&gt;&gt; a.remove(`</code>2<code></code>)`</p>\n<p><code>&gt;&gt;&gt;</code> <code>print`</code>(a)`</p>\n<p><code>[`</code>1<code>,` `3</code>]`</p>\n<p><code>List`</code>.pop()<code></code>#删除方式二：pop 可选参数index删除指定位置的元素 默认为最后一个元素`</p>\n<p><code>&gt;&gt;&gt; a`</code>=<code>[</code>1<code>,` `2</code>,<code></code>3<code>,` `4</code>,<code></code>5<code>,` `6</code>]`</p>\n<p><code>&gt;&gt;&gt; a.pop()</code></p>\n<p><code>6</code></p>\n<p><code>&gt;&gt;&gt;</code> <code>print`</code>(a)`</p>\n<p><code>[`</code>1<code>,` `2</code>,<code></code>3<code>,` `4</code>,<code></code>5<code></code>]`</p>\n<p><code>del</code> <code>List</code> <code>#删除方式三：可以删除整个列表或指定元素或者列表切片，list删除后无法访问。</code></p>\n<p><code>&gt;&gt;&gt; a`</code>=<code>[</code>1<code>,` `2</code>,<code></code>3<code>,` `4</code>,<code></code>5<code>,` `6</code>]`</p>\n<p><code>&gt;&gt;&gt;</code> <code>del</code> <code>a[`</code>5<code></code>]`</p>\n<p><code>&gt;&gt;&gt;</code> <code>print`</code>(a)`</p>\n<p><code>[`</code>1<code>,` `2</code>,<code></code>3<code>,` `4</code>,<code></code>5<code></code>]`</p>\n<p><code>&gt;&gt;&gt;</code> <code>del</code> <code>a</code></p>\n<p><code>&gt;&gt;&gt;</code> <code>print`</code>(a)`</p>\n<p><code>Traceback (most recent call last):</code></p>\n<p><code>File</code> <code>&quot;&lt;pyshell#93&gt;&quot;`</code>, line<code></code>1<code></code>,<code></code>in<code></code><module>`</module></p>\n<p><code>print`</code>(a)`</p>\n<p><strong>6.排序和反转代码</strong></p>\n<p><a href=\"http://www.jb51.net/article/84754.htm#\" target=\"_blank\" rel=\"noopener\">?</a></p>\n<p>1</p>\n<p>2</p>\n<p>3</p>\n<p>4</p>\n<p>5</p>\n<p>6</p>\n<p>7</p>\n<p>8</p>\n<p>9</p>\n<p>10</p>\n<p>11</p>\n<p>12</p>\n<p>13</p>\n<p>14</p>\n<p>15</p>\n<p>16</p>\n<p>17</p>\n<p>18</p>\n<p>19</p>\n<p><code>List`</code>.reverse()`</p>\n<p><code>&gt;&gt;&gt; a`</code>=<code>[</code>1<code>,` `2</code>,<code></code>3<code>,` `4</code>,<code></code>5<code>,` `6</code>]`</p>\n<p><code>&gt;&gt;&gt; a.reverse()</code></p>\n<p><code>&gt;&gt;&gt;</code> <code>print`</code>(a)`</p>\n<p><code>[`</code>6<code>,` `5</code>,<code></code>4<code>,` `3</code>,<code></code>2<code>,` `1</code>]`</p>\n<p><code>List`</code>.sort()<code></code>#sort有三个默认参数 cmp=None,key=None,reverse=False 因此可以制定排序参数`</p>\n<p><code>&gt;&gt;&gt; a`</code>=<code>[</code>2<code>,</code>4<code>,</code>6<code>,</code>7<code>,</code>3<code>,</code>1<code>,</code>5<code></code>]`</p>\n<p><code>&gt;&gt;&gt; a.sort()</code></p>\n<p><code>&gt;&gt;&gt;</code> <code>print`</code>(a)`</p>\n<p><code>[`</code>1<code>,` `2</code>,<code></code>3<code>,` `4</code>,<code></code>5<code>,` `6</code>,<code></code>7<code></code>]`</p>\n<p><code>#python3X中，不能将数字和字符一起排序，会出现此报错</code></p>\n<p><code>&gt;&gt;&gt; a`</code>=<code>[</code>2<code>,</code>4<code>,</code>6<code>,</code>7<code>,</code>3<code>,</code>1<code>,</code>5<code>,</code>‘a’<code></code>]`</p>\n<p><code>&gt;&gt;&gt; a.sort()</code></p>\n<p><code>Traceback (most recent call last):</code></p>\n<p><code>File</code> <code>&quot;&lt;pyshell#104&gt;&quot;`</code>, line<code></code>1<code></code>,<code></code>in<code></code><module>`</module></p>\n<p><code>a.sort()</code></p>\n<p><code>TypeError: unorderable types:</code> <code>str`</code>() &lt;<code></code>int<code></code>()`</p>\n<p><strong>7.Python列表截取</strong> Python的列表截取与字符串操作类型相同，如下所示： L = [‘spam’, ‘Spam’, ‘SPAM!’] 操作：</p>\n<p><a href=\"http://www.jb51.net/article/84754.htm#\" target=\"_blank\" rel=\"noopener\">?</a></p>\n<p>1</p>\n<p>2</p>\n<p>3</p>\n<p>4</p>\n<p><code>Python 表达式 结果 描述</code></p>\n<p><code>L[`</code>2<code></code>]<code></code>‘SPAM!’<code></code>读取列表中第三个元素`</p>\n<p><code>L[`</code>-<code>2</code>]<code></code>‘Spam’<code></code>读取列表中倒数第二个元素`</p>\n<p><code>L[`</code>1<code>:] [</code>‘Spam’<code>,` `&#39;SPAM!&#39;</code>] 从第二个元素开始截取列表`</p>\n<p><strong>8.Python列表操作的函数和方法</strong> 列表操作包含以下<strong>函数</strong>: 1、cmp(list1, list2)：比较两个列表的元素 (python3已丢弃) 2、len(list)：列表元素个数 3、max(list)：返回列表元素最大值 4、min(list)：返回列表元素最小值 5、list(seq)：将元组转换为列表 列表操作常用操作包含以下<strong>方法</strong>: 1、list.append(obj)：在列表末尾添加新的对象 2、list.count(obj)：统计某个元素在列表中出现的次数 3、list.extend(seq)：在列表末尾一次性追加另一个序列中的多个值（用新列表扩展原来的列表） 4、list.index(obj)：从列表中找出某个值第一个匹配项的索引位置 5、list.insert(index, obj)：将对象插入列表 6、list.pop(obj=list[-1])：移除列表中的一个元素（默认最后一个元素），并且返回该元素的值 7、list.remove(obj)：移除列表中某个值的第一个匹配项 8、list.reverse()：反向列表中元素 9、list.sort([func])：对原列表进行排序</p>\n<h4 id=\"注意：与字符串的方法不同，所有对列表操作的方法均会改变原有列表的值，而不是创建一个新的列表！！！\"><a href=\"#注意：与字符串的方法不同，所有对列表操作的方法均会改变原有列表的值，而不是创建一个新的列表！！！\" class=\"headerlink\" title=\"注意：与字符串的方法不同，所有对列表操作的方法均会改变原有列表的值，而不是创建一个新的列表！！！\"></a><strong>注意：与字符串的方法不同，所有对列表操作的方法均会改变原有列表的值，而不是创建一个新的列表！！！</strong></h4><h2 id=\"修改列表元素的方法\"><a href=\"#修改列表元素的方法\" class=\"headerlink\" title=\"修改列表元素的方法\"></a><strong>修改列表元素的方法</strong></h2><p><strong>修改元素的方法用索引以及切片的方法，如：</strong> <strong>▷ 索引：</strong> <strong>list_name[0] = ‘修改后的值’</strong> <strong>▷ 切片：</strong> <strong>l**</strong>ist_name[0:3] = [a,b,c]   <strong> </strong>注意：后面需要修改的值的总数可以不与切片的长度相对应，比如说[0:3]这个切片长度为3，后面可以传一个有2个或者4个元素的列表，此时，只是将切片所对应的值剔除，然后将后面列表依次插入<strong> </strong>后面也可以赋值一个字符串，此时，只是将切片所对应的值剔除，然后将后面字符串拆开然后依次插入<strong> </strong>list_name[0:3] = ‘fuyong’**</p>\n<p><img src=\"https://common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></p>\n<p>name_list = [‘赵’,’钱’,’孙’,’李’,’周’,]<br>name_list[2]= ‘sun’<br>print(name_list)</p>\n<p>#结果为：[‘赵’, ‘钱’, ‘sun’, ‘李’, ‘周’]</p>\n<p>name_list[2]= name_list[2].title()<br>print(name_list)<br># 结果为：[‘赵’, ‘钱’, ‘Sun’, ‘李’, ‘周’]</p>\n<p>name_list[0:2] = [‘zhao’,’qian’]<br>print(name_list)</p>\n<p>#结果为：[‘zhao’, ‘qian’, ‘Sun’, ‘李’, ‘周’]</p>\n<p>name_list[0:2] = [‘zhao’,’qian’,’zheng’]<br>print(name_list)</p>\n<p>#结果为：[‘zhao’, ‘qian’, ‘zheng’, ‘Sun’, ‘李’, ‘周’]</p>\n<p>name_list[0:2] = [‘zhao’]<br>print(name_list)</p>\n<p>#结果为：[‘zhao’, ‘zheng’, ‘Sun’, ‘李’, ‘周’]</p>\n<p>name_list[0:3] = ‘fuyong’<br>print(name_list)</p>\n<p>#结果为：[‘f’, ‘u’, ‘y’, ‘o’, ‘n’, ‘g’, ‘李’, ‘周’]</p>\n<p><img src=\"https://common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></p>\n<h2 id=\"五、查询列表元素的方法\"><a href=\"#五、查询列表元素的方法\" class=\"headerlink\" title=\"五、查询列表元素的方法\"></a><strong>五、查询列表元素的方法</strong></h2><p><strong>查询元素的方法用索引以及切片的方法，如：</strong> <strong>▷ 索引：</strong> <strong>list_name[0] </strong> <strong>▷ 切片：</strong> <strong>l**</strong>ist_name[0:3]<strong> </strong>list_name[0:3:2] **</p>\n<p><img src=\"https://common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></p>\n<p> 1 name_list = [‘赵’,’钱’,’孙’,’李’,’周’,]<br> 2 print(name_list[0])   # 赵<br> 3 print(name_list[2])   # 孙<br> 4<br> 5 print(name_list[0:2])   # [‘赵’, ‘钱’]<br> 6 print(name_list[1:])    # [‘钱’, ‘孙’, ‘李’, ‘周’]<br> 7<br> 8 print(name_list[0:4:2]) # [‘赵’, ‘孙’]<br> 9 print(name_list[:4:2])  # [‘赵’, ‘孙’] 10<br>11 print(name_list[4:0:-1]) #[‘周’, ‘李’, ‘孙’, ‘钱’] 12 print(name_list[-2:0:-1]) #[‘李’, ‘孙’, ‘钱’]</p>\n<p><img src=\"https://common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></p>\n<h4 id=\"另外，如果需要查询列表中所有的元素，可以用for循环来实现，如：\"><a href=\"#另外，如果需要查询列表中所有的元素，可以用for循环来实现，如：\" class=\"headerlink\" title=\"另外，如果需要查询列表中所有的元素，可以用for循环来实现，如：\"></a>另外，如果需要查询列表中所有的元素，可以用for循环来实现，如：</h4><p><img src=\"https://common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></p>\n<p>1 name_list = [‘赵’,’钱’,’孙’,’李’,’周’,] 2 for name in name_list: 3     print(name)</p>\n<p>‘’’<br>输出结果如下：</p>\n<p>赵 钱 孙 李 周 ‘’’</p>\n<p><img src=\"https://common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></p>\n<h2 id=\"六、列表的其他方法\"><a href=\"#六、列表的其他方法\" class=\"headerlink\" title=\"六、列表的其他方法\"></a><strong>六、列表的其他方法</strong></h2><p><strong>▷ len(list)方法：</strong> <strong>此方法可以用来计算列表的长度，如下：</strong></p>\n<p>1 name_list = [‘赵’,’钱’,’孙’,’李’,’周’,] 2 print(len(name_list)) 3 #输出结果为5</p>\n<h3 id=\"▷count-方法\"><a href=\"#▷count-方法\" class=\"headerlink\" title=\"▷count()方法:\"></a>▷count()方法:</h3><p><strong>此方法用来计算列表中一个元素出现的次数，如下：</strong></p>\n<p>1 name_list = [‘赵’,’钱’,’孙’,’李’,’周’,’赵’] 2 print(name_list.count(‘赵’)) 3 # 输出结果为2</p>\n<p><strong> ▷sort()方法：</strong> <strong>次方法是对列表进行排序（列表里的元素要为数字类型），默认是正序，可以指定倒序（reverse = True）</strong></p>\n<p><img src=\"https://common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></p>\n<p>1 num_list = [1,3,6,2,5,0,8] 2 num_list.sort() #默认为正序排列 3 print(num_list) 4 #输出结果为：[0, 1, 2, 3, 5, 6, 8] 5<br>6 num_list.sort(reverse=True)  #指定reverse为True 则为倒序 7 print(num_list) 8 #输出结果为[8, 6, 5, 3, 2, 1, 0]</p>\n<p><img src=\"https://common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></p>\n<p><strong>▷reverse():</strong> <strong>此方法是将列表里所有元素进行翻转，注意，不是排序，是将所有元素倒过来 ，如：</strong></p>\n<p>1 name_list = [‘赵’,’钱’,’孙’,’李’,’周’] 2 name_list.reverse() 3 print(name_list) 4 #结果为：[‘周’, ‘李’, ‘孙’, ‘钱’, ‘赵’]</p>\n<p>  <strong>▷join()方法：</strong> <strong>此方法用法与字符串的join方法一样，就是将列表里的元素用指定字符连接起来，字符可以是空格，可以是空字符，可以是下划线以及任意字符，如下：</strong></p>\n<p>1 name_list = [‘赵’,’钱’,’孙’,’李’,’周’] 2 print(‘<em>‘.join(name_list))   # 结果：赵</em>钱<em>孙</em>李*周<br>3 print(‘ ‘.join(name_list))   # 结果：赵 钱 孙 李 周<br>4 print(‘’.join(name_list))    # 结果：赵钱孙李周<br>5 print(‘<strong>‘.join(name_list))  # 结果：赵</strong>钱<strong>孙</strong>李__周</p>\n<p>注：可以利用这种方法将一个列表转为字符串格式</p>\n<h2 id=\"七、列表的嵌套\"><a href=\"#七、列表的嵌套\" class=\"headerlink\" title=\"七、列表的嵌套\"></a><strong>七、列表的嵌套</strong></h2><p><strong>上面说过，列表里可以放一切元素，所以，当然也可以嵌套列表：</strong> <strong>如果需要对列表里的列表进行增删改查，只需先索引到里面的列表，然后再进行操作即可，如下：</strong></p>\n<p><img src=\"https://common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></p>\n<p>name_list = [‘赵’,’钱’,’孙’,[‘付’,’傅’,’符’],’李’,’周’,’赵’]</p>\n<p>print(name_list[3][1]) # 傅<br>print(name_list[3][0:2]) #[‘付’, ‘傅’]</p>\n<p>name_list[3][1]= ‘fu’<br>print(name_list)<br># 结果为：[‘赵’, ‘钱’, ‘孙’, [‘付’, ‘fu’, ‘符’], ‘李’, ‘周’, ‘赵’]</p>\n<p>name_list[3].pop(1)<br>print(name_list)</p>\n<p>#结果为[‘赵’, ‘钱’, ‘孙’, [‘付’, ‘符’], ‘李’, ‘周’, ‘赵’]</p>\n<p>name_list[3].remove(‘符’)<br>print(name_list)</p>\n<p>#结果为：[‘赵’, ‘钱’, ‘孙’, [‘付’], ‘李’, ‘周’, ‘赵’]</p>\n<p><img src=\"https://common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></p>\n<h4 id=\"强调：与字符串的方法不同，所有对列表操作的方法均会改变原有列表的值，而不是创建一个新的列表！！！\"><a href=\"#强调：与字符串的方法不同，所有对列表操作的方法均会改变原有列表的值，而不是创建一个新的列表！！！\" class=\"headerlink\" title=\"强调：与字符串的方法不同，所有对列表操作的方法均会改变原有列表的值，而不是创建一个新的列表！！！\"></a><strong>强调：与字符串的方法不同，所有对列表操作的方法均会改变原有列表的值，而不是创建一个新的列表！！！</strong></h4>"},{"title":"第九节：类","url":"230.html","id":"230","date":"2018-05-12T14:15:10.000Z","_content":"\n\n\n类定义：\n----\n\n**用来描述具体相同的属性和方法的对象的集合。定义了该集合中每个对象所共有的属性和方法。对象是类的示例** `类 Class`: 用来描述具体相同的属性和方法的对象的集合。定义了该集合中每个对象所共有的属性和方法。对象是类的示例。 `类变量`：类变量在整个实例化的对象中是公用的。类变量定义在类中且在函数体之外。类变量通常不作为实例变量使用。 `数据成员`：类变量或者实例变量用于处理类及其实例对象的相关数据。 `方法重写`：如果从父类继承的方法不能满足子类的需求，可以对其 进行改写，这个过程叫方法的覆盖（override），也称为方法的重写。 `实例变量`：定义在方法中的变量，只作用于当前实例的类。 `继承`：即一个派生类（derived class）继承基类（base class）的字段和方法。继承也允许把一个派生类的对象作为一个基类对象对待。例如，有这样一个设计：一个Dog类型的对象派生自Animal类，这是模拟”是一个（is-a）”关系（例图，Dog是一个Animal）。 `实例化`：创建一个类的实例，类的具体对象。就是将创建的类赋值给另一个变量。理解为赋值即可，a = class()，这个过程，就叫做实例化 `方法`：类中定义的函数。 `对象`：通过类定义的数据结构实例。对象包括两个数据成员（类变量和实例变量）和方法。\n\n类有这样一些的优点\n---------\n\n1 ) 、类对象是多态的：也就是多种形态，这意味着我们可以对不同的类对象使用同样的操作方法，而不需要额外写代码。 2 ) 、类的封装：封装之后，可以直接调用类的对象，来操作内部的一些类方法，不需要让使用者看到代码工作的细节。 3 ) 、类的继承：类可以从其它类或者元类中继承它们的方法，直接使用。\n\n属性:\n---\n\n1：实例属性： 在\\_\\_init\\_\\_(self,…)中初始化 内部调用时都需要加上self. 外部调用时用**实例化对象.属性名** 2:类属性： 在\\_\\_init\\_\\_()外初始化 在内部用**类名.类属性名**调用 外部既可以用**类名.类属性名**又可以用**实例化对象.类属性名**来调用 3：私有属性： 1）：单下划线_开头：只是告诉别人这是私有属性，外部依然可以访问更改 2）：双下划线__开头：外部不可通过**实例化对象.属性名**来访问或者更改  实际将其转化为了**_类名__属性名_**，只是在内部将变量名修改了，我们仍让可以通过._类名_属性名访问\n\n类属性的修改\n------\n\n字典为**可变类型**，而数字是**不可变类型**，因此无法通过这种方式修改。所以在实际开发中应该避免通过实例对象去修改类属 性。  \n\n类的继承：\n-----\n\n继承类的构造方法： 1.经典类的写法： 父类名称.\\_\\_init\\_\\_(self,参数1，参数2，...) 2. 新式类的写法：super(子类，self).\\_\\_init\\_\\_(参数1，参数2，....)\n\n`class``Person(``object``):`\n\n`def``__init__(``self``, name, age):`\n\n`self``.name``=``name`\n\n`self``.age``=``age`\n\n`self``.weight``=``'weight'`\n\n`      def``talk(``self``):`\n\n`print``(``\"person is talking....\"``)`\n\n`class``Chinese(Person):`\n\n`def``__init__(``self``, name, age, language): ``# 先继承，在重构`\n\n`Person.__init__(``self``, name, age) ``#继承父类的构造方法，`\n\n`也可以写成：super(Chinese,self).__init__(name,age)`\n\n`self``.language``=``language   ``# 定义类的本身属性`\n\n`      def``talk(``self``): ``# 子类 重构方法`\n\n`print``(``'%s is speaking chinese'``%``self``.name)`\n\n方法： \\# -*-coding:utf-8-*-  \\# 普通方法,类方法,静态方法的区别 \\_\\_metaclass\\_\\_ = type class Tst:  name = 'tst' data = 'this is data'  \\# 普通方法  def normalMethod(self, name):                   print self.data, name \\# 类方法,可以访问类属性  @classmethod  def classMethod(cls, name):                        print cls.data, name \\# 静态方法,不可以访问类属性  @staticmethod def staticMethod(name):                          print name\n\n*   三种方法都可以通过实例来调用，但是静态方法和类方法无法访问实例属性，所以更改了tst.data仅对普通方法起了作用\n*   普通方法不能通过类名调用，但是静态方法和类方法是可以的\n*   普通方法,可以通过self访问实例属性\n*   类方法,可以通过cls访问类属性\n*   静态方法,不可以访问,通过传值的方式\n\n","source":"_posts/第九节：类.md","raw":"---\ntitle: 第九节：类\ntags:\n  - 课后解答\nurl: 230.html\nid: 230\ncategories:\n  - 学习\n  - 教学\ndate: 2018-05-12 22:15:10\n---\n\n\n\n类定义：\n----\n\n**用来描述具体相同的属性和方法的对象的集合。定义了该集合中每个对象所共有的属性和方法。对象是类的示例** `类 Class`: 用来描述具体相同的属性和方法的对象的集合。定义了该集合中每个对象所共有的属性和方法。对象是类的示例。 `类变量`：类变量在整个实例化的对象中是公用的。类变量定义在类中且在函数体之外。类变量通常不作为实例变量使用。 `数据成员`：类变量或者实例变量用于处理类及其实例对象的相关数据。 `方法重写`：如果从父类继承的方法不能满足子类的需求，可以对其 进行改写，这个过程叫方法的覆盖（override），也称为方法的重写。 `实例变量`：定义在方法中的变量，只作用于当前实例的类。 `继承`：即一个派生类（derived class）继承基类（base class）的字段和方法。继承也允许把一个派生类的对象作为一个基类对象对待。例如，有这样一个设计：一个Dog类型的对象派生自Animal类，这是模拟”是一个（is-a）”关系（例图，Dog是一个Animal）。 `实例化`：创建一个类的实例，类的具体对象。就是将创建的类赋值给另一个变量。理解为赋值即可，a = class()，这个过程，就叫做实例化 `方法`：类中定义的函数。 `对象`：通过类定义的数据结构实例。对象包括两个数据成员（类变量和实例变量）和方法。\n\n类有这样一些的优点\n---------\n\n1 ) 、类对象是多态的：也就是多种形态，这意味着我们可以对不同的类对象使用同样的操作方法，而不需要额外写代码。 2 ) 、类的封装：封装之后，可以直接调用类的对象，来操作内部的一些类方法，不需要让使用者看到代码工作的细节。 3 ) 、类的继承：类可以从其它类或者元类中继承它们的方法，直接使用。\n\n属性:\n---\n\n1：实例属性： 在\\_\\_init\\_\\_(self,…)中初始化 内部调用时都需要加上self. 外部调用时用**实例化对象.属性名** 2:类属性： 在\\_\\_init\\_\\_()外初始化 在内部用**类名.类属性名**调用 外部既可以用**类名.类属性名**又可以用**实例化对象.类属性名**来调用 3：私有属性： 1）：单下划线_开头：只是告诉别人这是私有属性，外部依然可以访问更改 2）：双下划线__开头：外部不可通过**实例化对象.属性名**来访问或者更改  实际将其转化为了**_类名__属性名_**，只是在内部将变量名修改了，我们仍让可以通过._类名_属性名访问\n\n类属性的修改\n------\n\n字典为**可变类型**，而数字是**不可变类型**，因此无法通过这种方式修改。所以在实际开发中应该避免通过实例对象去修改类属 性。  \n\n类的继承：\n-----\n\n继承类的构造方法： 1.经典类的写法： 父类名称.\\_\\_init\\_\\_(self,参数1，参数2，...) 2. 新式类的写法：super(子类，self).\\_\\_init\\_\\_(参数1，参数2，....)\n\n`class``Person(``object``):`\n\n`def``__init__(``self``, name, age):`\n\n`self``.name``=``name`\n\n`self``.age``=``age`\n\n`self``.weight``=``'weight'`\n\n`      def``talk(``self``):`\n\n`print``(``\"person is talking....\"``)`\n\n`class``Chinese(Person):`\n\n`def``__init__(``self``, name, age, language): ``# 先继承，在重构`\n\n`Person.__init__(``self``, name, age) ``#继承父类的构造方法，`\n\n`也可以写成：super(Chinese,self).__init__(name,age)`\n\n`self``.language``=``language   ``# 定义类的本身属性`\n\n`      def``talk(``self``): ``# 子类 重构方法`\n\n`print``(``'%s is speaking chinese'``%``self``.name)`\n\n方法： \\# -*-coding:utf-8-*-  \\# 普通方法,类方法,静态方法的区别 \\_\\_metaclass\\_\\_ = type class Tst:  name = 'tst' data = 'this is data'  \\# 普通方法  def normalMethod(self, name):                   print self.data, name \\# 类方法,可以访问类属性  @classmethod  def classMethod(cls, name):                        print cls.data, name \\# 静态方法,不可以访问类属性  @staticmethod def staticMethod(name):                          print name\n\n*   三种方法都可以通过实例来调用，但是静态方法和类方法无法访问实例属性，所以更改了tst.data仅对普通方法起了作用\n*   普通方法不能通过类名调用，但是静态方法和类方法是可以的\n*   普通方法,可以通过self访问实例属性\n*   类方法,可以通过cls访问类属性\n*   静态方法,不可以访问,通过传值的方式\n\n","slug":"第九节：类","published":1,"updated":"2021-07-26T09:58:02.570Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m2w003kigtap5gwoyxl","content":"<h2 id=\"类定义：\"><a href=\"#类定义：\" class=\"headerlink\" title=\"类定义：\"></a>类定义：</h2><p><strong>用来描述具体相同的属性和方法的对象的集合。定义了该集合中每个对象所共有的属性和方法。对象是类的示例</strong> <code>类 Class</code>: 用来描述具体相同的属性和方法的对象的集合。定义了该集合中每个对象所共有的属性和方法。对象是类的示例。 <code>类变量</code>：类变量在整个实例化的对象中是公用的。类变量定义在类中且在函数体之外。类变量通常不作为实例变量使用。 <code>数据成员</code>：类变量或者实例变量用于处理类及其实例对象的相关数据。 <code>方法重写</code>：如果从父类继承的方法不能满足子类的需求，可以对其 进行改写，这个过程叫方法的覆盖（override），也称为方法的重写。 <code>实例变量</code>：定义在方法中的变量，只作用于当前实例的类。 <code>继承</code>：即一个派生类（derived class）继承基类（base class）的字段和方法。继承也允许把一个派生类的对象作为一个基类对象对待。例如，有这样一个设计：一个Dog类型的对象派生自Animal类，这是模拟”是一个（is-a）”关系（例图，Dog是一个Animal）。 <code>实例化</code>：创建一个类的实例，类的具体对象。就是将创建的类赋值给另一个变量。理解为赋值即可，a = class()，这个过程，就叫做实例化 <code>方法</code>：类中定义的函数。 <code>对象</code>：通过类定义的数据结构实例。对象包括两个数据成员（类变量和实例变量）和方法。</p>\n<h2 id=\"类有这样一些的优点\"><a href=\"#类有这样一些的优点\" class=\"headerlink\" title=\"类有这样一些的优点\"></a>类有这样一些的优点</h2><p>1 ) 、类对象是多态的：也就是多种形态，这意味着我们可以对不同的类对象使用同样的操作方法，而不需要额外写代码。 2 ) 、类的封装：封装之后，可以直接调用类的对象，来操作内部的一些类方法，不需要让使用者看到代码工作的细节。 3 ) 、类的继承：类可以从其它类或者元类中继承它们的方法，直接使用。</p>\n<h2 id=\"属性\"><a href=\"#属性\" class=\"headerlink\" title=\"属性:\"></a>属性:</h2><p>1：实例属性： 在__init__(self,…)中初始化 内部调用时都需要加上self. 外部调用时用<strong>实例化对象.属性名</strong> 2:类属性： 在__init__()外初始化 在内部用<strong>类名.类属性名</strong>调用 外部既可以用<strong>类名.类属性名</strong>又可以用<strong>实例化对象.类属性名</strong>来调用 3：私有属性： 1）：单下划线<em>开头：只是告诉别人这是私有属性，外部依然可以访问更改 2）：双下划线__开头：外部不可通过<strong>实例化对象.属性名</strong>来访问或者更改  实际将其转化为了**</em>类名__属性名<em>**，只是在内部将变量名修改了，我们仍让可以通过.</em>类名_属性名访问</p>\n<h2 id=\"类属性的修改\"><a href=\"#类属性的修改\" class=\"headerlink\" title=\"类属性的修改\"></a>类属性的修改</h2><p>字典为<strong>可变类型</strong>，而数字是<strong>不可变类型</strong>，因此无法通过这种方式修改。所以在实际开发中应该避免通过实例对象去修改类属 性。  </p>\n<h2 id=\"类的继承：\"><a href=\"#类的继承：\" class=\"headerlink\" title=\"类的继承：\"></a>类的继承：</h2><p>继承类的构造方法： 1.经典类的写法： 父类名称.__init__(self,参数1，参数2，…) 2. 新式类的写法：super(子类，self).__init__(参数1，参数2，….)</p>\n<p><code>class`</code>Person(<code>object</code>):`</p>\n<p><code>def`</code><strong>init</strong>(<code>self</code>, name, age):`</p>\n<p><code>self`</code>.name<code>=</code>name`</p>\n<p><code>self`</code>.age<code>=</code>age`</p>\n<p><code>self`</code>.weight<code>=</code>‘weight’`</p>\n<p><code>def`</code>talk(<code>self</code>):`</p>\n<p><code>print`</code>(<code>&quot;person is talking....&quot;</code>)`</p>\n<p><code>class`</code>Chinese(Person):`</p>\n<p><code>def`</code><strong>init</strong>(<code>self</code>, name, age, language): <code></code># 先继承，在重构`</p>\n<p><code>Person.__init__(`</code>self<code>, name, age)</code>#继承父类的构造方法，`</p>\n<p><code>也可以写成：super(Chinese,self).__init__(name,age)</code></p>\n<p><code>self`</code>.language<code>=</code>language   <code></code># 定义类的本身属性`</p>\n<p><code>def`</code>talk(<code>self</code>): <code></code># 子类 重构方法`</p>\n<p><code>print`</code>(<code>&#39;%s is speaking chinese&#39;</code>%<code>self</code>.name)`</p>\n<p>方法： # -<em>-coding:utf-8-</em>-  # 普通方法,类方法,静态方法的区别 __metaclass__ = type class Tst:  name = ‘tst’ data = ‘this is data’  # 普通方法  def normalMethod(self, name):                   print self.data, name # 类方法,可以访问类属性  @classmethod  def classMethod(cls, name):                        print cls.data, name # 静态方法,不可以访问类属性  @staticmethod def staticMethod(name):                          print name</p>\n<ul>\n<li>三种方法都可以通过实例来调用，但是静态方法和类方法无法访问实例属性，所以更改了tst.data仅对普通方法起了作用</li>\n<li>普通方法不能通过类名调用，但是静态方法和类方法是可以的</li>\n<li>普通方法,可以通过self访问实例属性</li>\n<li>类方法,可以通过cls访问类属性</li>\n<li>静态方法,不可以访问,通过传值的方式</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"类定义：\"><a href=\"#类定义：\" class=\"headerlink\" title=\"类定义：\"></a>类定义：</h2><p><strong>用来描述具体相同的属性和方法的对象的集合。定义了该集合中每个对象所共有的属性和方法。对象是类的示例</strong> <code>类 Class</code>: 用来描述具体相同的属性和方法的对象的集合。定义了该集合中每个对象所共有的属性和方法。对象是类的示例。 <code>类变量</code>：类变量在整个实例化的对象中是公用的。类变量定义在类中且在函数体之外。类变量通常不作为实例变量使用。 <code>数据成员</code>：类变量或者实例变量用于处理类及其实例对象的相关数据。 <code>方法重写</code>：如果从父类继承的方法不能满足子类的需求，可以对其 进行改写，这个过程叫方法的覆盖（override），也称为方法的重写。 <code>实例变量</code>：定义在方法中的变量，只作用于当前实例的类。 <code>继承</code>：即一个派生类（derived class）继承基类（base class）的字段和方法。继承也允许把一个派生类的对象作为一个基类对象对待。例如，有这样一个设计：一个Dog类型的对象派生自Animal类，这是模拟”是一个（is-a）”关系（例图，Dog是一个Animal）。 <code>实例化</code>：创建一个类的实例，类的具体对象。就是将创建的类赋值给另一个变量。理解为赋值即可，a = class()，这个过程，就叫做实例化 <code>方法</code>：类中定义的函数。 <code>对象</code>：通过类定义的数据结构实例。对象包括两个数据成员（类变量和实例变量）和方法。</p>\n<h2 id=\"类有这样一些的优点\"><a href=\"#类有这样一些的优点\" class=\"headerlink\" title=\"类有这样一些的优点\"></a>类有这样一些的优点</h2><p>1 ) 、类对象是多态的：也就是多种形态，这意味着我们可以对不同的类对象使用同样的操作方法，而不需要额外写代码。 2 ) 、类的封装：封装之后，可以直接调用类的对象，来操作内部的一些类方法，不需要让使用者看到代码工作的细节。 3 ) 、类的继承：类可以从其它类或者元类中继承它们的方法，直接使用。</p>\n<h2 id=\"属性\"><a href=\"#属性\" class=\"headerlink\" title=\"属性:\"></a>属性:</h2><p>1：实例属性： 在__init__(self,…)中初始化 内部调用时都需要加上self. 外部调用时用<strong>实例化对象.属性名</strong> 2:类属性： 在__init__()外初始化 在内部用<strong>类名.类属性名</strong>调用 外部既可以用<strong>类名.类属性名</strong>又可以用<strong>实例化对象.类属性名</strong>来调用 3：私有属性： 1）：单下划线<em>开头：只是告诉别人这是私有属性，外部依然可以访问更改 2）：双下划线__开头：外部不可通过<strong>实例化对象.属性名</strong>来访问或者更改  实际将其转化为了**</em>类名__属性名<em>**，只是在内部将变量名修改了，我们仍让可以通过.</em>类名_属性名访问</p>\n<h2 id=\"类属性的修改\"><a href=\"#类属性的修改\" class=\"headerlink\" title=\"类属性的修改\"></a>类属性的修改</h2><p>字典为<strong>可变类型</strong>，而数字是<strong>不可变类型</strong>，因此无法通过这种方式修改。所以在实际开发中应该避免通过实例对象去修改类属 性。  </p>\n<h2 id=\"类的继承：\"><a href=\"#类的继承：\" class=\"headerlink\" title=\"类的继承：\"></a>类的继承：</h2><p>继承类的构造方法： 1.经典类的写法： 父类名称.__init__(self,参数1，参数2，…) 2. 新式类的写法：super(子类，self).__init__(参数1，参数2，….)</p>\n<p><code>class`</code>Person(<code>object</code>):`</p>\n<p><code>def`</code><strong>init</strong>(<code>self</code>, name, age):`</p>\n<p><code>self`</code>.name<code>=</code>name`</p>\n<p><code>self`</code>.age<code>=</code>age`</p>\n<p><code>self`</code>.weight<code>=</code>‘weight’`</p>\n<p><code>def`</code>talk(<code>self</code>):`</p>\n<p><code>print`</code>(<code>&quot;person is talking....&quot;</code>)`</p>\n<p><code>class`</code>Chinese(Person):`</p>\n<p><code>def`</code><strong>init</strong>(<code>self</code>, name, age, language): <code></code># 先继承，在重构`</p>\n<p><code>Person.__init__(`</code>self<code>, name, age)</code>#继承父类的构造方法，`</p>\n<p><code>也可以写成：super(Chinese,self).__init__(name,age)</code></p>\n<p><code>self`</code>.language<code>=</code>language   <code></code># 定义类的本身属性`</p>\n<p><code>def`</code>talk(<code>self</code>): <code></code># 子类 重构方法`</p>\n<p><code>print`</code>(<code>&#39;%s is speaking chinese&#39;</code>%<code>self</code>.name)`</p>\n<p>方法： # -<em>-coding:utf-8-</em>-  # 普通方法,类方法,静态方法的区别 __metaclass__ = type class Tst:  name = ‘tst’ data = ‘this is data’  # 普通方法  def normalMethod(self, name):                   print self.data, name # 类方法,可以访问类属性  @classmethod  def classMethod(cls, name):                        print cls.data, name # 静态方法,不可以访问类属性  @staticmethod def staticMethod(name):                          print name</p>\n<ul>\n<li>三种方法都可以通过实例来调用，但是静态方法和类方法无法访问实例属性，所以更改了tst.data仅对普通方法起了作用</li>\n<li>普通方法不能通过类名调用，但是静态方法和类方法是可以的</li>\n<li>普通方法,可以通过self访问实例属性</li>\n<li>类方法,可以通过cls访问类属性</li>\n<li>静态方法,不可以访问,通过传值的方式</li>\n</ul>\n"},{"title":"第二节：数值类型和序列类型","url":"187.html","id":"187","date":"2018-05-08T06:33:44.000Z","_content":"\n\\[success\\]\n\n一：注意事项：\n-------\n\n###### **###Python严格缩进，严格大小写##############**\n\n### 数值类型解释：\n\n#### 一：整数类型（跟数学一样，可正，可负，没有取值限制）\n\n有四种表示方式： 1.十进制：110,520,991 2.二进制：以0b或0B开头：0b110,0B110 3.八进制：以0o或 0O开头：0o110,0O725 4.十六进制:以0x或0X开头：0x1A，0X78 注：第一个都是以小键盘数字0。\n\n#### 二：浮点型（数学中的实数）\n\n带有小数点及小数的数字 浮点数间运算尾数存在不确定性 》》》0.2+0.1 0.30000000006 》》》0.2+0.1 0.3 都是一样的，Python就这样   浮点数可以采用科学计数法 2.5e-2就是0.025 2.1E5就是210000.0    \n\n#### 三，复数型（数学中概念一致）\n\n形如A +Bx就是复数 A 是实部，B是虚部 有什么用呢？？ Y=52+12X Y.real就可以直接获取实部 Y.imag就可以直接获取虚部     二：数值运算操作 >>>10/3 3.3333333333335\n\n> >10//3 (双斜线表整除）\n\n3\n\n> >10%3(%取余运算符）  \n\n1 》》》10\\*\\*2（10的平方） 》》》25\\*\\*0.5（10的开方）  \n\n三种存在老大，老小的关系\n------------\n\n——————————》》 整数————》浮点数————》复数 大包小 如10+1.0=11.0（整数+浮点数=浮点数）  \n\n#### 四，字符串：\n\n字符串由单引号（‘ ’）或双引号(\"   \")表示 如‘A’    ， “收到” 字符串是有序序列，从0开始 “收到”的第0个字符是“收”   三引号' ' ' 可表示多行字符串，也可以来注释 如' ' '  abc sss ' ' ' ** 三引号可以同时包含 双单引号** **单可以包双，双可以包单**   字符串序号： 0   1  2  3  4  5 6 口口口口口口口 -7 -6 -5-4-3-2-1   索引：返回单个字符， 字符串【字符序号】  如s\\[0\\] 切片：返回字符子串，字符串【开始序号：结束序号】 缺开头序号表示到开头，缺结尾序号表到结尾 跳跃式切片：字符串【开始序号：结尾序号：步长大小】   字符串的特殊字符“ \\\\” 为了防止冲突表示本意 如 “等等（\\\\\"）” 输出  等等（”） 特定组合表示特定功能 如 \\\\b(回退） \\\\n(换行） \\\\r(回车） \\[/success\\]\n","source":"_posts/第二节：数值类型和序列类型.md","raw":"---\ntitle: 第二节：数值类型和序列类型\ntags:\n  - 课后解答\nurl: 187.html\nid: 187\ncategories:\n  - 学习\n  - 教学\ndate: 2018-05-08 14:33:44\n---\n\n\\[success\\]\n\n一：注意事项：\n-------\n\n###### **###Python严格缩进，严格大小写##############**\n\n### 数值类型解释：\n\n#### 一：整数类型（跟数学一样，可正，可负，没有取值限制）\n\n有四种表示方式： 1.十进制：110,520,991 2.二进制：以0b或0B开头：0b110,0B110 3.八进制：以0o或 0O开头：0o110,0O725 4.十六进制:以0x或0X开头：0x1A，0X78 注：第一个都是以小键盘数字0。\n\n#### 二：浮点型（数学中的实数）\n\n带有小数点及小数的数字 浮点数间运算尾数存在不确定性 》》》0.2+0.1 0.30000000006 》》》0.2+0.1 0.3 都是一样的，Python就这样   浮点数可以采用科学计数法 2.5e-2就是0.025 2.1E5就是210000.0    \n\n#### 三，复数型（数学中概念一致）\n\n形如A +Bx就是复数 A 是实部，B是虚部 有什么用呢？？ Y=52+12X Y.real就可以直接获取实部 Y.imag就可以直接获取虚部     二：数值运算操作 >>>10/3 3.3333333333335\n\n> >10//3 (双斜线表整除）\n\n3\n\n> >10%3(%取余运算符）  \n\n1 》》》10\\*\\*2（10的平方） 》》》25\\*\\*0.5（10的开方）  \n\n三种存在老大，老小的关系\n------------\n\n——————————》》 整数————》浮点数————》复数 大包小 如10+1.0=11.0（整数+浮点数=浮点数）  \n\n#### 四，字符串：\n\n字符串由单引号（‘ ’）或双引号(\"   \")表示 如‘A’    ， “收到” 字符串是有序序列，从0开始 “收到”的第0个字符是“收”   三引号' ' ' 可表示多行字符串，也可以来注释 如' ' '  abc sss ' ' ' ** 三引号可以同时包含 双单引号** **单可以包双，双可以包单**   字符串序号： 0   1  2  3  4  5 6 口口口口口口口 -7 -6 -5-4-3-2-1   索引：返回单个字符， 字符串【字符序号】  如s\\[0\\] 切片：返回字符子串，字符串【开始序号：结束序号】 缺开头序号表示到开头，缺结尾序号表到结尾 跳跃式切片：字符串【开始序号：结尾序号：步长大小】   字符串的特殊字符“ \\\\” 为了防止冲突表示本意 如 “等等（\\\\\"）” 输出  等等（”） 特定组合表示特定功能 如 \\\\b(回退） \\\\n(换行） \\\\r(回车） \\[/success\\]\n","slug":"第二节：数值类型和序列类型","published":1,"updated":"2021-07-26T09:58:02.569Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m2x003oigta2nasqjp4","content":"<p>[success]</p>\n<h2 id=\"一：注意事项：\"><a href=\"#一：注意事项：\" class=\"headerlink\" title=\"一：注意事项：\"></a>一：注意事项：</h2><h6 id=\"Python严格缩进，严格大小写\"><a href=\"#Python严格缩进，严格大小写\" class=\"headerlink\" title=\"###Python严格缩进，严格大小写##############\"></a><strong>###Python严格缩进，严格大小写##############</strong></h6><h3 id=\"数值类型解释：\"><a href=\"#数值类型解释：\" class=\"headerlink\" title=\"数值类型解释：\"></a>数值类型解释：</h3><h4 id=\"一：整数类型（跟数学一样，可正，可负，没有取值限制）\"><a href=\"#一：整数类型（跟数学一样，可正，可负，没有取值限制）\" class=\"headerlink\" title=\"一：整数类型（跟数学一样，可正，可负，没有取值限制）\"></a>一：整数类型（跟数学一样，可正，可负，没有取值限制）</h4><p>有四种表示方式： 1.十进制：110,520,991 2.二进制：以0b或0B开头：0b110,0B110 3.八进制：以0o或 0O开头：0o110,0O725 4.十六进制:以0x或0X开头：0x1A，0X78 注：第一个都是以小键盘数字0。</p>\n<h4 id=\"二：浮点型（数学中的实数）\"><a href=\"#二：浮点型（数学中的实数）\" class=\"headerlink\" title=\"二：浮点型（数学中的实数）\"></a>二：浮点型（数学中的实数）</h4><p>带有小数点及小数的数字 浮点数间运算尾数存在不确定性 》》》0.2+0.1 0.30000000006 》》》0.2+0.1 0.3 都是一样的，Python就这样   浮点数可以采用科学计数法 2.5e-2就是0.025 2.1E5就是210000.0    </p>\n<h4 id=\"三，复数型（数学中概念一致）\"><a href=\"#三，复数型（数学中概念一致）\" class=\"headerlink\" title=\"三，复数型（数学中概念一致）\"></a>三，复数型（数学中概念一致）</h4><p>形如A +Bx就是复数 A 是实部，B是虚部 有什么用呢？？ Y=52+12X Y.real就可以直接获取实部 Y.imag就可以直接获取虚部     二：数值运算操作 &gt;&gt;&gt;10/3 3.3333333333335</p>\n<blockquote>\n<blockquote>\n<p>10//3 (双斜线表整除）</p>\n</blockquote>\n</blockquote>\n<p>3</p>\n<blockquote>\n<blockquote>\n<p>10%3(%取余运算符）  </p>\n</blockquote>\n</blockquote>\n<p>1 》》》10**2（10的平方） 》》》25**0.5（10的开方）  </p>\n<h2 id=\"三种存在老大，老小的关系\"><a href=\"#三种存在老大，老小的关系\" class=\"headerlink\" title=\"三种存在老大，老小的关系\"></a>三种存在老大，老小的关系</h2><p>——————————》》 整数————》浮点数————》复数 大包小 如10+1.0=11.0（整数+浮点数=浮点数）  </p>\n<h4 id=\"四，字符串：\"><a href=\"#四，字符串：\" class=\"headerlink\" title=\"四，字符串：\"></a>四，字符串：</h4><p>字符串由单引号（‘ ’）或双引号(“   “)表示 如‘A’    ， “收到” 字符串是有序序列，从0开始 “收到”的第0个字符是“收”   三引号’ ‘ ‘ 可表示多行字符串，也可以来注释 如’ ‘ ‘  abc sss ‘ ‘ ‘ <strong> 三引号可以同时包含 双单引号</strong> <strong>单可以包双，双可以包单</strong>   字符串序号： 0   1  2  3  4  5 6 口口口口口口口 -7 -6 -5-4-3-2-1   索引：返回单个字符， 字符串【字符序号】  如s[0] 切片：返回字符子串，字符串【开始序号：结束序号】 缺开头序号表示到开头，缺结尾序号表到结尾 跳跃式切片：字符串【开始序号：结尾序号：步长大小】   字符串的特殊字符“ \\” 为了防止冲突表示本意 如 “等等（\\“）” 输出  等等（”） 特定组合表示特定功能 如 \\b(回退） \\n(换行） \\r(回车） [/success]</p>\n","site":{"data":{}},"excerpt":"","more":"<p>[success]</p>\n<h2 id=\"一：注意事项：\"><a href=\"#一：注意事项：\" class=\"headerlink\" title=\"一：注意事项：\"></a>一：注意事项：</h2><h6 id=\"Python严格缩进，严格大小写\"><a href=\"#Python严格缩进，严格大小写\" class=\"headerlink\" title=\"###Python严格缩进，严格大小写##############\"></a><strong>###Python严格缩进，严格大小写##############</strong></h6><h3 id=\"数值类型解释：\"><a href=\"#数值类型解释：\" class=\"headerlink\" title=\"数值类型解释：\"></a>数值类型解释：</h3><h4 id=\"一：整数类型（跟数学一样，可正，可负，没有取值限制）\"><a href=\"#一：整数类型（跟数学一样，可正，可负，没有取值限制）\" class=\"headerlink\" title=\"一：整数类型（跟数学一样，可正，可负，没有取值限制）\"></a>一：整数类型（跟数学一样，可正，可负，没有取值限制）</h4><p>有四种表示方式： 1.十进制：110,520,991 2.二进制：以0b或0B开头：0b110,0B110 3.八进制：以0o或 0O开头：0o110,0O725 4.十六进制:以0x或0X开头：0x1A，0X78 注：第一个都是以小键盘数字0。</p>\n<h4 id=\"二：浮点型（数学中的实数）\"><a href=\"#二：浮点型（数学中的实数）\" class=\"headerlink\" title=\"二：浮点型（数学中的实数）\"></a>二：浮点型（数学中的实数）</h4><p>带有小数点及小数的数字 浮点数间运算尾数存在不确定性 》》》0.2+0.1 0.30000000006 》》》0.2+0.1 0.3 都是一样的，Python就这样   浮点数可以采用科学计数法 2.5e-2就是0.025 2.1E5就是210000.0    </p>\n<h4 id=\"三，复数型（数学中概念一致）\"><a href=\"#三，复数型（数学中概念一致）\" class=\"headerlink\" title=\"三，复数型（数学中概念一致）\"></a>三，复数型（数学中概念一致）</h4><p>形如A +Bx就是复数 A 是实部，B是虚部 有什么用呢？？ Y=52+12X Y.real就可以直接获取实部 Y.imag就可以直接获取虚部     二：数值运算操作 &gt;&gt;&gt;10/3 3.3333333333335</p>\n<blockquote>\n<blockquote>\n<p>10//3 (双斜线表整除）</p>\n</blockquote>\n</blockquote>\n<p>3</p>\n<blockquote>\n<blockquote>\n<p>10%3(%取余运算符）  </p>\n</blockquote>\n</blockquote>\n<p>1 》》》10**2（10的平方） 》》》25**0.5（10的开方）  </p>\n<h2 id=\"三种存在老大，老小的关系\"><a href=\"#三种存在老大，老小的关系\" class=\"headerlink\" title=\"三种存在老大，老小的关系\"></a>三种存在老大，老小的关系</h2><p>——————————》》 整数————》浮点数————》复数 大包小 如10+1.0=11.0（整数+浮点数=浮点数）  </p>\n<h4 id=\"四，字符串：\"><a href=\"#四，字符串：\" class=\"headerlink\" title=\"四，字符串：\"></a>四，字符串：</h4><p>字符串由单引号（‘ ’）或双引号(“   “)表示 如‘A’    ， “收到” 字符串是有序序列，从0开始 “收到”的第0个字符是“收”   三引号’ ‘ ‘ 可表示多行字符串，也可以来注释 如’ ‘ ‘  abc sss ‘ ‘ ‘ <strong> 三引号可以同时包含 双单引号</strong> <strong>单可以包双，双可以包单</strong>   字符串序号： 0   1  2  3  4  5 6 口口口口口口口 -7 -6 -5-4-3-2-1   索引：返回单个字符， 字符串【字符序号】  如s[0] 切片：返回字符子串，字符串【开始序号：结束序号】 缺开头序号表示到开头，缺结尾序号表到结尾 跳跃式切片：字符串【开始序号：结尾序号：步长大小】   字符串的特殊字符“ \\” 为了防止冲突表示本意 如 “等等（\\“）” 输出  等等（”） 特定组合表示特定功能 如 \\b(回退） \\n(换行） \\r(回车） [/success]</p>\n"},{"title":"第二部分:GitKraken破解及教程","toc":false,"date":"2020-03-01T16:20:48.000Z","_content":"\n# 1. 首次打开程序\n第一次打开GitKraken程序时， GitKraken会提示需要登陆，可以用github.com的账号登陆，或者用邮箱创建账号登陆,选择第一个可以直接与github关联.\n![image.png](https://blog.mviai.com/images/FrcP9jLjMr_CgDGrsjsdJ8NlGb1v)\n\n# 2. Authentication（授权）\n我们一般用到比较多的情况是从服务器上clone一个已有的仓库。在clone服务器上的仓库前，首先需要设置/生成本地的加密解密密钥。\n\n打开 GitKraken 的File => Preference => Authentication\n![image.png](https://blog.mviai.com/images/FvjIJjj0Hk_to2a1r7iGY9u32HQE)\n\n\n#  3. 修改用户名\n为了方便项目中代码的管理，需要重新编辑用户名。\n\n点击右上角的图像即可看到所示的下拉菜单，鼠标悬于Profile上，会出现一个Edit按钮。\nFile => Preference =>Profile\n![image.png](https://blog.mviai.com/images/FgRQNecQrAXNKw7E1BWn2_RsjOJW)\n![image.png](https://blog.mviai.com/images/Fj8t_E76fjLstmtCGRMT4YPJDkS_)\n\n# 4. 初始化本地仓库\n如果你需要在自己本地代码的目录下新建一个Git仓库，点击左上角的 File => Init Repo，点击 浏览 按钮选择需要初始化仓库的目录，然后点击 创建储存库 即会出现如下图所示的界面。\n![image.png](https://blog.mviai.com/images/FkUktZPr7tiQnzxoupU1mhV6HjDE)\n- 图中的.gitignore 和 License 都是可选的。.gitignore文件是git在提交时会读取的一个文件，现在可以不用管它的作用是什么（如果项目是一个python工程，我们可以选用预设好的python.gitignore）。当然如果有兴趣对此深入了解的话，建议去看一看progit这本书，这本书详细了介绍了Git。\n![image.png](https://blog.mviai.com/images/Fvhp9AXiQtUPcoeBRPX6hQleo85a)\n\n# 5.克隆服务器上的项目\n首先，返回主界面，点击File => Clone Repo，选择 使用URL克隆，如下图：\n![image.png](https://blog.mviai.com/images/FoQC1UYejtdMgOc81L1Th6DK2FXZ)\n![image.png](https://blog.mviai.com/images/FkWdJIilK-vOsERSv3CjGs43hnZz)\n\n# 6. 打开现有的Git仓库\n点击左上角 File ==> open repo \n![image.png](https://blog.mviai.com/images/FlFcOyn1ibS4sN8cQS4XOqVWafKN)\n\n# 7. Kraken界面\n## 主界面\n![image.png](https://blog.mviai.com/images/ForYMNJhqPEOmBfXUjHXvzEGAv84)\n\n\n## 功能界面\n![image.png](https://blog.mviai.com/images/Fn_PQHqWmEa7BsuVEXikecCeJl7W)\n\t-  最上面的 本地 下拉菜单中显示的是本地的分支。\n\t-  远程 下拉菜单中显示的是远程仓库的列表，点击其中一个远程仓库，就会显示该仓库中拥有的分支数（远程分支）。\n\n**可以通过程序上方的  按钮将本地的分支上传到服务器。（非管理员无法删除服务器上的主分支）**\n\n\t- 标签 下拉菜单中显示的是本地的标签，需要推送到服务器才能分享标签。\n\t- 子模块  表示当前仓库的子模块\n\n## 提交记录区域\n![image.png](https://blog.mviai.com/images/FqStc-VtZh7x9omCdq9ZLedzp6Oz)\n每一行都表示一个提交记录\n\n\n## 文件改动区域\n当文件修改后:\n![image.png](https://blog.mviai.com/images/Fnv7vGLCSuCOXPDpnIXRe7ihHX0o)\n\n未暂存相当于草稿,暂存后就可以提交了\n\n## 顶部操作区域\n![image.png](https://blog.mviai.com/images/FlhZdanFFZofwWUdoTxT_4vVIIqE)\n\n相当于\n1. Undo（回退一个提交记录）；\n2. Redo（回到回退前的那个提交记录）；\n3. Push（将本地的提交记录同步到服务器上）；\n4. Pull（将服务器上的提交记录同步到本地）；\n5. Branch（新建一个分支）；\n\n\n# 8. 提交代码\n修改了某个文件后，在程序右侧会出现已修改文件的列表\n![image.png](https://blog.mviai.com/images/Fq9z9IPUqvRRxr5Kr2lg8qA5PEdd)\n点击文件,就可以查看差异:\n![image.png](https://blog.mviai.com/images/Fg309KGh3ZB5At1Z2qmBbr7hZa4R)\n\n![image.png](https://blog.mviai.com/images/FlCV-IMb-SwJ9HvxSOEo_yQBT1lB)\n\n\n**如果在未暂存区域(草稿):**\n**还可以通过比较,选择性保留及删除**\n点击  暂存 按钮将会暂存这一块修改的内容，保留绿色部分（即保留+2 ~ +4 行的内容，丢弃 -2 ~ -4 行的内容），\n\n 点击 丢弃 将会丢弃掉改动的这一部分，保留红色的部分（保留-2 ~ -4 行的内容，丢弃 +2 ~ +4 行的内容）。\n![image.png](https://blog.mviai.com/images/FtfRJ5sRpAFB78eYBISWuWmy78NC)\n\n## 放弃本次文件的改动\n有些情况下，由于更改代码造成了编译无法通过等错误时，想要放弃这次对文件的修改，将文件还原成上一次提交后的状态，一种简单的恢复文件的方法就是，在未暂存列表中找到这个文件，右键点击，选择丢弃改动就行.(如果要放弃全部更改,点击放弃按钮就行)\n \n## 修改提交记录的描述信息\n![image.png](https://blog.mviai.com/images/FlgOKf1sZsakOMhEZNsIzKb55Yrc)\n![image.png](https://blog.mviai.com/images/Fq8R_ci9YYNkWwUMir0g1AsSYoWW)\n\n## 查看文件的历史修改及其追责\n![image.png](https://blog.mviai.com/images/FjSWsB6MC9hQt_4_S6WFfI53nQdt)\n右键点击,选择历史记录或文件追责\n-\t历史记录(显示每次提交记录与前次提交记录的差异；)\n-\t![image.png](https://blog.mviai.com/images/FkPLaQHa3xI8gDDG2T-0i1FEKITf)\n-\t追责(显示该次提交记录完成的文件内容)\n-\t![image.png](https://blog.mviai.com/images/FqUMFYPXrveBgpnJTPMDLC3jquHP)\n\n\n# 8. 本地分支和标签\n## 在提交记录区中查看分支状态\n![image.png](https://blog.mviai.com/images/FpxYma901gcOm1gb2P3juFhFWMEh)\n\n## 创建本地（Local）分支\n在GitKraken中央区域的提交记录处右键点击,选择中间的 在此处创建分支;\n![image.png](https://blog.mviai.com/images/FhRkHe4QGm3dPa4LraULfcFO6pRY)\n![image.png](https://blog.mviai.com/images/FnB61ZRHeCGormgZrC5nHXZPS07s)\n\n##  切换本地（Local）分支\n左侧有勾的表明该分支是当前所在的分支\n![image.png](https://blog.mviai.com/images/FnB61ZRHeCGormgZrC5nHXZPS07s)\n\n  *直接在本地分支列表中双击  可以切换至该分支*\n\n*参考:https://www.cnblogs.com/brifuture/p/9052512.html*\n","source":"_posts/第二部分-GitKraken破解及教程.md","raw":"---\ntitle: '第二部分:GitKraken破解及教程'\ntags:\n  - GItKraken\ncategories:\n  - 工具\n  - 日常工具\n  - GItKraken\n\ntoc: false\ndate: 2020-03-02 00:20:48\n---\n\n# 1. 首次打开程序\n第一次打开GitKraken程序时， GitKraken会提示需要登陆，可以用github.com的账号登陆，或者用邮箱创建账号登陆,选择第一个可以直接与github关联.\n![image.png](https://blog.mviai.com/images/FrcP9jLjMr_CgDGrsjsdJ8NlGb1v)\n\n# 2. Authentication（授权）\n我们一般用到比较多的情况是从服务器上clone一个已有的仓库。在clone服务器上的仓库前，首先需要设置/生成本地的加密解密密钥。\n\n打开 GitKraken 的File => Preference => Authentication\n![image.png](https://blog.mviai.com/images/FvjIJjj0Hk_to2a1r7iGY9u32HQE)\n\n\n#  3. 修改用户名\n为了方便项目中代码的管理，需要重新编辑用户名。\n\n点击右上角的图像即可看到所示的下拉菜单，鼠标悬于Profile上，会出现一个Edit按钮。\nFile => Preference =>Profile\n![image.png](https://blog.mviai.com/images/FgRQNecQrAXNKw7E1BWn2_RsjOJW)\n![image.png](https://blog.mviai.com/images/Fj8t_E76fjLstmtCGRMT4YPJDkS_)\n\n# 4. 初始化本地仓库\n如果你需要在自己本地代码的目录下新建一个Git仓库，点击左上角的 File => Init Repo，点击 浏览 按钮选择需要初始化仓库的目录，然后点击 创建储存库 即会出现如下图所示的界面。\n![image.png](https://blog.mviai.com/images/FkUktZPr7tiQnzxoupU1mhV6HjDE)\n- 图中的.gitignore 和 License 都是可选的。.gitignore文件是git在提交时会读取的一个文件，现在可以不用管它的作用是什么（如果项目是一个python工程，我们可以选用预设好的python.gitignore）。当然如果有兴趣对此深入了解的话，建议去看一看progit这本书，这本书详细了介绍了Git。\n![image.png](https://blog.mviai.com/images/Fvhp9AXiQtUPcoeBRPX6hQleo85a)\n\n# 5.克隆服务器上的项目\n首先，返回主界面，点击File => Clone Repo，选择 使用URL克隆，如下图：\n![image.png](https://blog.mviai.com/images/FoQC1UYejtdMgOc81L1Th6DK2FXZ)\n![image.png](https://blog.mviai.com/images/FkWdJIilK-vOsERSv3CjGs43hnZz)\n\n# 6. 打开现有的Git仓库\n点击左上角 File ==> open repo \n![image.png](https://blog.mviai.com/images/FlFcOyn1ibS4sN8cQS4XOqVWafKN)\n\n# 7. Kraken界面\n## 主界面\n![image.png](https://blog.mviai.com/images/ForYMNJhqPEOmBfXUjHXvzEGAv84)\n\n\n## 功能界面\n![image.png](https://blog.mviai.com/images/Fn_PQHqWmEa7BsuVEXikecCeJl7W)\n\t-  最上面的 本地 下拉菜单中显示的是本地的分支。\n\t-  远程 下拉菜单中显示的是远程仓库的列表，点击其中一个远程仓库，就会显示该仓库中拥有的分支数（远程分支）。\n\n**可以通过程序上方的  按钮将本地的分支上传到服务器。（非管理员无法删除服务器上的主分支）**\n\n\t- 标签 下拉菜单中显示的是本地的标签，需要推送到服务器才能分享标签。\n\t- 子模块  表示当前仓库的子模块\n\n## 提交记录区域\n![image.png](https://blog.mviai.com/images/FqStc-VtZh7x9omCdq9ZLedzp6Oz)\n每一行都表示一个提交记录\n\n\n## 文件改动区域\n当文件修改后:\n![image.png](https://blog.mviai.com/images/Fnv7vGLCSuCOXPDpnIXRe7ihHX0o)\n\n未暂存相当于草稿,暂存后就可以提交了\n\n## 顶部操作区域\n![image.png](https://blog.mviai.com/images/FlhZdanFFZofwWUdoTxT_4vVIIqE)\n\n相当于\n1. Undo（回退一个提交记录）；\n2. Redo（回到回退前的那个提交记录）；\n3. Push（将本地的提交记录同步到服务器上）；\n4. Pull（将服务器上的提交记录同步到本地）；\n5. Branch（新建一个分支）；\n\n\n# 8. 提交代码\n修改了某个文件后，在程序右侧会出现已修改文件的列表\n![image.png](https://blog.mviai.com/images/Fq9z9IPUqvRRxr5Kr2lg8qA5PEdd)\n点击文件,就可以查看差异:\n![image.png](https://blog.mviai.com/images/Fg309KGh3ZB5At1Z2qmBbr7hZa4R)\n\n![image.png](https://blog.mviai.com/images/FlCV-IMb-SwJ9HvxSOEo_yQBT1lB)\n\n\n**如果在未暂存区域(草稿):**\n**还可以通过比较,选择性保留及删除**\n点击  暂存 按钮将会暂存这一块修改的内容，保留绿色部分（即保留+2 ~ +4 行的内容，丢弃 -2 ~ -4 行的内容），\n\n 点击 丢弃 将会丢弃掉改动的这一部分，保留红色的部分（保留-2 ~ -4 行的内容，丢弃 +2 ~ +4 行的内容）。\n![image.png](https://blog.mviai.com/images/FtfRJ5sRpAFB78eYBISWuWmy78NC)\n\n## 放弃本次文件的改动\n有些情况下，由于更改代码造成了编译无法通过等错误时，想要放弃这次对文件的修改，将文件还原成上一次提交后的状态，一种简单的恢复文件的方法就是，在未暂存列表中找到这个文件，右键点击，选择丢弃改动就行.(如果要放弃全部更改,点击放弃按钮就行)\n \n## 修改提交记录的描述信息\n![image.png](https://blog.mviai.com/images/FlgOKf1sZsakOMhEZNsIzKb55Yrc)\n![image.png](https://blog.mviai.com/images/Fq8R_ci9YYNkWwUMir0g1AsSYoWW)\n\n## 查看文件的历史修改及其追责\n![image.png](https://blog.mviai.com/images/FjSWsB6MC9hQt_4_S6WFfI53nQdt)\n右键点击,选择历史记录或文件追责\n-\t历史记录(显示每次提交记录与前次提交记录的差异；)\n-\t![image.png](https://blog.mviai.com/images/FkPLaQHa3xI8gDDG2T-0i1FEKITf)\n-\t追责(显示该次提交记录完成的文件内容)\n-\t![image.png](https://blog.mviai.com/images/FqUMFYPXrveBgpnJTPMDLC3jquHP)\n\n\n# 8. 本地分支和标签\n## 在提交记录区中查看分支状态\n![image.png](https://blog.mviai.com/images/FpxYma901gcOm1gb2P3juFhFWMEh)\n\n## 创建本地（Local）分支\n在GitKraken中央区域的提交记录处右键点击,选择中间的 在此处创建分支;\n![image.png](https://blog.mviai.com/images/FhRkHe4QGm3dPa4LraULfcFO6pRY)\n![image.png](https://blog.mviai.com/images/FnB61ZRHeCGormgZrC5nHXZPS07s)\n\n##  切换本地（Local）分支\n左侧有勾的表明该分支是当前所在的分支\n![image.png](https://blog.mviai.com/images/FnB61ZRHeCGormgZrC5nHXZPS07s)\n\n  *直接在本地分支列表中双击  可以切换至该分支*\n\n*参考:https://www.cnblogs.com/brifuture/p/9052512.html*\n","slug":"第二部分-GitKraken破解及教程","published":1,"updated":"2021-07-26T09:58:02.569Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m2y003rigta05qustf1","content":"<h1 id=\"1-首次打开程序\"><a href=\"#1-首次打开程序\" class=\"headerlink\" title=\"1. 首次打开程序\"></a>1. 首次打开程序</h1><p>第一次打开GitKraken程序时， GitKraken会提示需要登陆，可以用github.com的账号登陆，或者用邮箱创建账号登陆,选择第一个可以直接与github关联.<br><img src=\"https://blog.mviai.com/images/FrcP9jLjMr_CgDGrsjsdJ8NlGb1v\" alt=\"image.png\"></p>\n<h1 id=\"2-Authentication（授权）\"><a href=\"#2-Authentication（授权）\" class=\"headerlink\" title=\"2. Authentication（授权）\"></a>2. Authentication（授权）</h1><p>我们一般用到比较多的情况是从服务器上clone一个已有的仓库。在clone服务器上的仓库前，首先需要设置/生成本地的加密解密密钥。</p>\n<p>打开 GitKraken 的File =&gt; Preference =&gt; Authentication<br><img src=\"https://blog.mviai.com/images/FvjIJjj0Hk_to2a1r7iGY9u32HQE\" alt=\"image.png\"></p>\n<h1 id=\"3-修改用户名\"><a href=\"#3-修改用户名\" class=\"headerlink\" title=\"3. 修改用户名\"></a>3. 修改用户名</h1><p>为了方便项目中代码的管理，需要重新编辑用户名。</p>\n<p>点击右上角的图像即可看到所示的下拉菜单，鼠标悬于Profile上，会出现一个Edit按钮。<br>File =&gt; Preference =&gt;Profile<br><img src=\"https://blog.mviai.com/images/FgRQNecQrAXNKw7E1BWn2_RsjOJW\" alt=\"image.png\"><br><img src=\"https://blog.mviai.com/images/Fj8t_E76fjLstmtCGRMT4YPJDkS_\" alt=\"image.png\"></p>\n<h1 id=\"4-初始化本地仓库\"><a href=\"#4-初始化本地仓库\" class=\"headerlink\" title=\"4. 初始化本地仓库\"></a>4. 初始化本地仓库</h1><p>如果你需要在自己本地代码的目录下新建一个Git仓库，点击左上角的 File =&gt; Init Repo，点击 浏览 按钮选择需要初始化仓库的目录，然后点击 创建储存库 即会出现如下图所示的界面。<br><img src=\"https://blog.mviai.com/images/FkUktZPr7tiQnzxoupU1mhV6HjDE\" alt=\"image.png\"></p>\n<ul>\n<li>图中的.gitignore 和 License 都是可选的。.gitignore文件是git在提交时会读取的一个文件，现在可以不用管它的作用是什么（如果项目是一个python工程，我们可以选用预设好的python.gitignore）。当然如果有兴趣对此深入了解的话，建议去看一看progit这本书，这本书详细了介绍了Git。<br><img src=\"https://blog.mviai.com/images/Fvhp9AXiQtUPcoeBRPX6hQleo85a\" alt=\"image.png\"></li>\n</ul>\n<h1 id=\"5-克隆服务器上的项目\"><a href=\"#5-克隆服务器上的项目\" class=\"headerlink\" title=\"5.克隆服务器上的项目\"></a>5.克隆服务器上的项目</h1><p>首先，返回主界面，点击File =&gt; Clone Repo，选择 使用URL克隆，如下图：<br><img src=\"https://blog.mviai.com/images/FoQC1UYejtdMgOc81L1Th6DK2FXZ\" alt=\"image.png\"><br><img src=\"https://blog.mviai.com/images/FkWdJIilK-vOsERSv3CjGs43hnZz\" alt=\"image.png\"></p>\n<h1 id=\"6-打开现有的Git仓库\"><a href=\"#6-打开现有的Git仓库\" class=\"headerlink\" title=\"6. 打开现有的Git仓库\"></a>6. 打开现有的Git仓库</h1><p>点击左上角 File ==&gt; open repo<br><img src=\"https://blog.mviai.com/images/FlFcOyn1ibS4sN8cQS4XOqVWafKN\" alt=\"image.png\"></p>\n<h1 id=\"7-Kraken界面\"><a href=\"#7-Kraken界面\" class=\"headerlink\" title=\"7. Kraken界面\"></a>7. Kraken界面</h1><h2 id=\"主界面\"><a href=\"#主界面\" class=\"headerlink\" title=\"主界面\"></a>主界面</h2><p><img src=\"https://blog.mviai.com/images/ForYMNJhqPEOmBfXUjHXvzEGAv84\" alt=\"image.png\"></p>\n<h2 id=\"功能界面\"><a href=\"#功能界面\" class=\"headerlink\" title=\"功能界面\"></a>功能界面</h2><p><img src=\"https://blog.mviai.com/images/Fn_PQHqWmEa7BsuVEXikecCeJl7W\" alt=\"image.png\"></p>\n<pre><code>-  最上面的 本地 下拉菜单中显示的是本地的分支。\n-  远程 下拉菜单中显示的是远程仓库的列表，点击其中一个远程仓库，就会显示该仓库中拥有的分支数（远程分支）。\n</code></pre><p><strong>可以通过程序上方的  按钮将本地的分支上传到服务器。（非管理员无法删除服务器上的主分支）</strong></p>\n<pre><code>- 标签 下拉菜单中显示的是本地的标签，需要推送到服务器才能分享标签。\n- 子模块  表示当前仓库的子模块\n</code></pre><h2 id=\"提交记录区域\"><a href=\"#提交记录区域\" class=\"headerlink\" title=\"提交记录区域\"></a>提交记录区域</h2><p><img src=\"https://blog.mviai.com/images/FqStc-VtZh7x9omCdq9ZLedzp6Oz\" alt=\"image.png\"><br>每一行都表示一个提交记录</p>\n<h2 id=\"文件改动区域\"><a href=\"#文件改动区域\" class=\"headerlink\" title=\"文件改动区域\"></a>文件改动区域</h2><p>当文件修改后:<br><img src=\"https://blog.mviai.com/images/Fnv7vGLCSuCOXPDpnIXRe7ihHX0o\" alt=\"image.png\"></p>\n<p>未暂存相当于草稿,暂存后就可以提交了</p>\n<h2 id=\"顶部操作区域\"><a href=\"#顶部操作区域\" class=\"headerlink\" title=\"顶部操作区域\"></a>顶部操作区域</h2><p><img src=\"https://blog.mviai.com/images/FlhZdanFFZofwWUdoTxT_4vVIIqE\" alt=\"image.png\"></p>\n<p>相当于</p>\n<ol>\n<li>Undo（回退一个提交记录）；</li>\n<li>Redo（回到回退前的那个提交记录）；</li>\n<li>Push（将本地的提交记录同步到服务器上）；</li>\n<li>Pull（将服务器上的提交记录同步到本地）；</li>\n<li>Branch（新建一个分支）；</li>\n</ol>\n<h1 id=\"8-提交代码\"><a href=\"#8-提交代码\" class=\"headerlink\" title=\"8. 提交代码\"></a>8. 提交代码</h1><p>修改了某个文件后，在程序右侧会出现已修改文件的列表<br><img src=\"https://blog.mviai.com/images/Fq9z9IPUqvRRxr5Kr2lg8qA5PEdd\" alt=\"image.png\"><br>点击文件,就可以查看差异:<br><img src=\"https://blog.mviai.com/images/Fg309KGh3ZB5At1Z2qmBbr7hZa4R\" alt=\"image.png\"></p>\n<p><img src=\"https://blog.mviai.com/images/FlCV-IMb-SwJ9HvxSOEo_yQBT1lB\" alt=\"image.png\"></p>\n<p><strong>如果在未暂存区域(草稿):</strong><br><strong>还可以通过比较,选择性保留及删除</strong><br>点击  暂存 按钮将会暂存这一块修改的内容，保留绿色部分（即保留+2 ~ +4 行的内容，丢弃 -2 ~ -4 行的内容），</p>\n<p> 点击 丢弃 将会丢弃掉改动的这一部分，保留红色的部分（保留-2 ~ -4 行的内容，丢弃 +2 ~ +4 行的内容）。<br><img src=\"https://blog.mviai.com/images/FtfRJ5sRpAFB78eYBISWuWmy78NC\" alt=\"image.png\"></p>\n<h2 id=\"放弃本次文件的改动\"><a href=\"#放弃本次文件的改动\" class=\"headerlink\" title=\"放弃本次文件的改动\"></a>放弃本次文件的改动</h2><p>有些情况下，由于更改代码造成了编译无法通过等错误时，想要放弃这次对文件的修改，将文件还原成上一次提交后的状态，一种简单的恢复文件的方法就是，在未暂存列表中找到这个文件，右键点击，选择丢弃改动就行.(如果要放弃全部更改,点击放弃按钮就行)</p>\n<h2 id=\"修改提交记录的描述信息\"><a href=\"#修改提交记录的描述信息\" class=\"headerlink\" title=\"修改提交记录的描述信息\"></a>修改提交记录的描述信息</h2><p><img src=\"https://blog.mviai.com/images/FlgOKf1sZsakOMhEZNsIzKb55Yrc\" alt=\"image.png\"><br><img src=\"https://blog.mviai.com/images/Fq8R_ci9YYNkWwUMir0g1AsSYoWW\" alt=\"image.png\"></p>\n<h2 id=\"查看文件的历史修改及其追责\"><a href=\"#查看文件的历史修改及其追责\" class=\"headerlink\" title=\"查看文件的历史修改及其追责\"></a>查看文件的历史修改及其追责</h2><p><img src=\"https://blog.mviai.com/images/FjSWsB6MC9hQt_4_S6WFfI53nQdt\" alt=\"image.png\"><br>右键点击,选择历史记录或文件追责</p>\n<ul>\n<li>历史记录(显示每次提交记录与前次提交记录的差异；)</li>\n<li><img src=\"https://blog.mviai.com/images/FkPLaQHa3xI8gDDG2T-0i1FEKITf\" alt=\"image.png\"></li>\n<li>追责(显示该次提交记录完成的文件内容)</li>\n<li><img src=\"https://blog.mviai.com/images/FqUMFYPXrveBgpnJTPMDLC3jquHP\" alt=\"image.png\"></li>\n</ul>\n<h1 id=\"8-本地分支和标签\"><a href=\"#8-本地分支和标签\" class=\"headerlink\" title=\"8. 本地分支和标签\"></a>8. 本地分支和标签</h1><h2 id=\"在提交记录区中查看分支状态\"><a href=\"#在提交记录区中查看分支状态\" class=\"headerlink\" title=\"在提交记录区中查看分支状态\"></a>在提交记录区中查看分支状态</h2><p><img src=\"https://blog.mviai.com/images/FpxYma901gcOm1gb2P3juFhFWMEh\" alt=\"image.png\"></p>\n<h2 id=\"创建本地（Local）分支\"><a href=\"#创建本地（Local）分支\" class=\"headerlink\" title=\"创建本地（Local）分支\"></a>创建本地（Local）分支</h2><p>在GitKraken中央区域的提交记录处右键点击,选择中间的 在此处创建分支;<br><img src=\"https://blog.mviai.com/images/FhRkHe4QGm3dPa4LraULfcFO6pRY\" alt=\"image.png\"><br><img src=\"https://blog.mviai.com/images/FnB61ZRHeCGormgZrC5nHXZPS07s\" alt=\"image.png\"></p>\n<h2 id=\"切换本地（Local）分支\"><a href=\"#切换本地（Local）分支\" class=\"headerlink\" title=\"切换本地（Local）分支\"></a>切换本地（Local）分支</h2><p>左侧有勾的表明该分支是当前所在的分支<br><img src=\"https://blog.mviai.com/images/FnB61ZRHeCGormgZrC5nHXZPS07s\" alt=\"image.png\"></p>\n<p>  <em>直接在本地分支列表中双击  可以切换至该分支</em></p>\n<p><em>参考:<a href=\"https://www.cnblogs.com/brifuture/p/9052512.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/brifuture/p/9052512.html</a></em></p>\n","site":{"data":{}},"excerpt":"","more":"<h1 id=\"1-首次打开程序\"><a href=\"#1-首次打开程序\" class=\"headerlink\" title=\"1. 首次打开程序\"></a>1. 首次打开程序</h1><p>第一次打开GitKraken程序时， GitKraken会提示需要登陆，可以用github.com的账号登陆，或者用邮箱创建账号登陆,选择第一个可以直接与github关联.<br><img src=\"https://blog.mviai.com/images/FrcP9jLjMr_CgDGrsjsdJ8NlGb1v\" alt=\"image.png\"></p>\n<h1 id=\"2-Authentication（授权）\"><a href=\"#2-Authentication（授权）\" class=\"headerlink\" title=\"2. Authentication（授权）\"></a>2. Authentication（授权）</h1><p>我们一般用到比较多的情况是从服务器上clone一个已有的仓库。在clone服务器上的仓库前，首先需要设置/生成本地的加密解密密钥。</p>\n<p>打开 GitKraken 的File =&gt; Preference =&gt; Authentication<br><img src=\"https://blog.mviai.com/images/FvjIJjj0Hk_to2a1r7iGY9u32HQE\" alt=\"image.png\"></p>\n<h1 id=\"3-修改用户名\"><a href=\"#3-修改用户名\" class=\"headerlink\" title=\"3. 修改用户名\"></a>3. 修改用户名</h1><p>为了方便项目中代码的管理，需要重新编辑用户名。</p>\n<p>点击右上角的图像即可看到所示的下拉菜单，鼠标悬于Profile上，会出现一个Edit按钮。<br>File =&gt; Preference =&gt;Profile<br><img src=\"https://blog.mviai.com/images/FgRQNecQrAXNKw7E1BWn2_RsjOJW\" alt=\"image.png\"><br><img src=\"https://blog.mviai.com/images/Fj8t_E76fjLstmtCGRMT4YPJDkS_\" alt=\"image.png\"></p>\n<h1 id=\"4-初始化本地仓库\"><a href=\"#4-初始化本地仓库\" class=\"headerlink\" title=\"4. 初始化本地仓库\"></a>4. 初始化本地仓库</h1><p>如果你需要在自己本地代码的目录下新建一个Git仓库，点击左上角的 File =&gt; Init Repo，点击 浏览 按钮选择需要初始化仓库的目录，然后点击 创建储存库 即会出现如下图所示的界面。<br><img src=\"https://blog.mviai.com/images/FkUktZPr7tiQnzxoupU1mhV6HjDE\" alt=\"image.png\"></p>\n<ul>\n<li>图中的.gitignore 和 License 都是可选的。.gitignore文件是git在提交时会读取的一个文件，现在可以不用管它的作用是什么（如果项目是一个python工程，我们可以选用预设好的python.gitignore）。当然如果有兴趣对此深入了解的话，建议去看一看progit这本书，这本书详细了介绍了Git。<br><img src=\"https://blog.mviai.com/images/Fvhp9AXiQtUPcoeBRPX6hQleo85a\" alt=\"image.png\"></li>\n</ul>\n<h1 id=\"5-克隆服务器上的项目\"><a href=\"#5-克隆服务器上的项目\" class=\"headerlink\" title=\"5.克隆服务器上的项目\"></a>5.克隆服务器上的项目</h1><p>首先，返回主界面，点击File =&gt; Clone Repo，选择 使用URL克隆，如下图：<br><img src=\"https://blog.mviai.com/images/FoQC1UYejtdMgOc81L1Th6DK2FXZ\" alt=\"image.png\"><br><img src=\"https://blog.mviai.com/images/FkWdJIilK-vOsERSv3CjGs43hnZz\" alt=\"image.png\"></p>\n<h1 id=\"6-打开现有的Git仓库\"><a href=\"#6-打开现有的Git仓库\" class=\"headerlink\" title=\"6. 打开现有的Git仓库\"></a>6. 打开现有的Git仓库</h1><p>点击左上角 File ==&gt; open repo<br><img src=\"https://blog.mviai.com/images/FlFcOyn1ibS4sN8cQS4XOqVWafKN\" alt=\"image.png\"></p>\n<h1 id=\"7-Kraken界面\"><a href=\"#7-Kraken界面\" class=\"headerlink\" title=\"7. Kraken界面\"></a>7. Kraken界面</h1><h2 id=\"主界面\"><a href=\"#主界面\" class=\"headerlink\" title=\"主界面\"></a>主界面</h2><p><img src=\"https://blog.mviai.com/images/ForYMNJhqPEOmBfXUjHXvzEGAv84\" alt=\"image.png\"></p>\n<h2 id=\"功能界面\"><a href=\"#功能界面\" class=\"headerlink\" title=\"功能界面\"></a>功能界面</h2><p><img src=\"https://blog.mviai.com/images/Fn_PQHqWmEa7BsuVEXikecCeJl7W\" alt=\"image.png\"></p>\n<pre><code>-  最上面的 本地 下拉菜单中显示的是本地的分支。\n-  远程 下拉菜单中显示的是远程仓库的列表，点击其中一个远程仓库，就会显示该仓库中拥有的分支数（远程分支）。\n</code></pre><p><strong>可以通过程序上方的  按钮将本地的分支上传到服务器。（非管理员无法删除服务器上的主分支）</strong></p>\n<pre><code>- 标签 下拉菜单中显示的是本地的标签，需要推送到服务器才能分享标签。\n- 子模块  表示当前仓库的子模块\n</code></pre><h2 id=\"提交记录区域\"><a href=\"#提交记录区域\" class=\"headerlink\" title=\"提交记录区域\"></a>提交记录区域</h2><p><img src=\"https://blog.mviai.com/images/FqStc-VtZh7x9omCdq9ZLedzp6Oz\" alt=\"image.png\"><br>每一行都表示一个提交记录</p>\n<h2 id=\"文件改动区域\"><a href=\"#文件改动区域\" class=\"headerlink\" title=\"文件改动区域\"></a>文件改动区域</h2><p>当文件修改后:<br><img src=\"https://blog.mviai.com/images/Fnv7vGLCSuCOXPDpnIXRe7ihHX0o\" alt=\"image.png\"></p>\n<p>未暂存相当于草稿,暂存后就可以提交了</p>\n<h2 id=\"顶部操作区域\"><a href=\"#顶部操作区域\" class=\"headerlink\" title=\"顶部操作区域\"></a>顶部操作区域</h2><p><img src=\"https://blog.mviai.com/images/FlhZdanFFZofwWUdoTxT_4vVIIqE\" alt=\"image.png\"></p>\n<p>相当于</p>\n<ol>\n<li>Undo（回退一个提交记录）；</li>\n<li>Redo（回到回退前的那个提交记录）；</li>\n<li>Push（将本地的提交记录同步到服务器上）；</li>\n<li>Pull（将服务器上的提交记录同步到本地）；</li>\n<li>Branch（新建一个分支）；</li>\n</ol>\n<h1 id=\"8-提交代码\"><a href=\"#8-提交代码\" class=\"headerlink\" title=\"8. 提交代码\"></a>8. 提交代码</h1><p>修改了某个文件后，在程序右侧会出现已修改文件的列表<br><img src=\"https://blog.mviai.com/images/Fq9z9IPUqvRRxr5Kr2lg8qA5PEdd\" alt=\"image.png\"><br>点击文件,就可以查看差异:<br><img src=\"https://blog.mviai.com/images/Fg309KGh3ZB5At1Z2qmBbr7hZa4R\" alt=\"image.png\"></p>\n<p><img src=\"https://blog.mviai.com/images/FlCV-IMb-SwJ9HvxSOEo_yQBT1lB\" alt=\"image.png\"></p>\n<p><strong>如果在未暂存区域(草稿):</strong><br><strong>还可以通过比较,选择性保留及删除</strong><br>点击  暂存 按钮将会暂存这一块修改的内容，保留绿色部分（即保留+2 ~ +4 行的内容，丢弃 -2 ~ -4 行的内容），</p>\n<p> 点击 丢弃 将会丢弃掉改动的这一部分，保留红色的部分（保留-2 ~ -4 行的内容，丢弃 +2 ~ +4 行的内容）。<br><img src=\"https://blog.mviai.com/images/FtfRJ5sRpAFB78eYBISWuWmy78NC\" alt=\"image.png\"></p>\n<h2 id=\"放弃本次文件的改动\"><a href=\"#放弃本次文件的改动\" class=\"headerlink\" title=\"放弃本次文件的改动\"></a>放弃本次文件的改动</h2><p>有些情况下，由于更改代码造成了编译无法通过等错误时，想要放弃这次对文件的修改，将文件还原成上一次提交后的状态，一种简单的恢复文件的方法就是，在未暂存列表中找到这个文件，右键点击，选择丢弃改动就行.(如果要放弃全部更改,点击放弃按钮就行)</p>\n<h2 id=\"修改提交记录的描述信息\"><a href=\"#修改提交记录的描述信息\" class=\"headerlink\" title=\"修改提交记录的描述信息\"></a>修改提交记录的描述信息</h2><p><img src=\"https://blog.mviai.com/images/FlgOKf1sZsakOMhEZNsIzKb55Yrc\" alt=\"image.png\"><br><img src=\"https://blog.mviai.com/images/Fq8R_ci9YYNkWwUMir0g1AsSYoWW\" alt=\"image.png\"></p>\n<h2 id=\"查看文件的历史修改及其追责\"><a href=\"#查看文件的历史修改及其追责\" class=\"headerlink\" title=\"查看文件的历史修改及其追责\"></a>查看文件的历史修改及其追责</h2><p><img src=\"https://blog.mviai.com/images/FjSWsB6MC9hQt_4_S6WFfI53nQdt\" alt=\"image.png\"><br>右键点击,选择历史记录或文件追责</p>\n<ul>\n<li>历史记录(显示每次提交记录与前次提交记录的差异；)</li>\n<li><img src=\"https://blog.mviai.com/images/FkPLaQHa3xI8gDDG2T-0i1FEKITf\" alt=\"image.png\"></li>\n<li>追责(显示该次提交记录完成的文件内容)</li>\n<li><img src=\"https://blog.mviai.com/images/FqUMFYPXrveBgpnJTPMDLC3jquHP\" alt=\"image.png\"></li>\n</ul>\n<h1 id=\"8-本地分支和标签\"><a href=\"#8-本地分支和标签\" class=\"headerlink\" title=\"8. 本地分支和标签\"></a>8. 本地分支和标签</h1><h2 id=\"在提交记录区中查看分支状态\"><a href=\"#在提交记录区中查看分支状态\" class=\"headerlink\" title=\"在提交记录区中查看分支状态\"></a>在提交记录区中查看分支状态</h2><p><img src=\"https://blog.mviai.com/images/FpxYma901gcOm1gb2P3juFhFWMEh\" alt=\"image.png\"></p>\n<h2 id=\"创建本地（Local）分支\"><a href=\"#创建本地（Local）分支\" class=\"headerlink\" title=\"创建本地（Local）分支\"></a>创建本地（Local）分支</h2><p>在GitKraken中央区域的提交记录处右键点击,选择中间的 在此处创建分支;<br><img src=\"https://blog.mviai.com/images/FhRkHe4QGm3dPa4LraULfcFO6pRY\" alt=\"image.png\"><br><img src=\"https://blog.mviai.com/images/FnB61ZRHeCGormgZrC5nHXZPS07s\" alt=\"image.png\"></p>\n<h2 id=\"切换本地（Local）分支\"><a href=\"#切换本地（Local）分支\" class=\"headerlink\" title=\"切换本地（Local）分支\"></a>切换本地（Local）分支</h2><p>左侧有勾的表明该分支是当前所在的分支<br><img src=\"https://blog.mviai.com/images/FnB61ZRHeCGormgZrC5nHXZPS07s\" alt=\"image.png\"></p>\n<p>  <em>直接在本地分支列表中双击  可以切换至该分支</em></p>\n<p><em>参考:<a href=\"https://www.cnblogs.com/brifuture/p/9052512.html\" target=\"_blank\" rel=\"noopener\">https://www.cnblogs.com/brifuture/p/9052512.html</a></em></p>\n"},{"title":"第六节：控制流程","url":"192.html","id":"192","date":"2018-05-08T06:39:46.000Z","_content":"\n1.break和continue的区别和作用\n----------------------\n\nbreak和continue都是用来控制循环结构的，主要是停止循环。 1.break 有时候我们想在某种条件出现的时候终止循环而不是等到循环条件为false才终止。 这是我们可以使用break来完成。break用于完全结束一个循环，跳出循环体执行循环后面的语句。 2.continue continue和break有点类似，区别在于continue只是终止本次循环，接着还执行后面的循环，break则完全终止循环。 可以理解为continue是跳过当次循环中剩下的语句，执行下一次循环。   ![](https://blog.mviai.com/images/wp-content/uploads/2018/05/if.png)![](https://blog.mviai.com/images/wp-content/uploads/2018/05/2if.png)![](https://blog.mviai.com/images/wp-content/uploads/2018/05/for.png)\n","source":"_posts/第六节：控制流程.md","raw":"---\ntitle: 第六节：控制流程\ntags:\n  - 课后解答\nurl: 192.html\nid: 192\ncategories:\n  - 学习\n  - 教学\ndate: 2018-05-08 14:39:46\n---\n\n1.break和continue的区别和作用\n----------------------\n\nbreak和continue都是用来控制循环结构的，主要是停止循环。 1.break 有时候我们想在某种条件出现的时候终止循环而不是等到循环条件为false才终止。 这是我们可以使用break来完成。break用于完全结束一个循环，跳出循环体执行循环后面的语句。 2.continue continue和break有点类似，区别在于continue只是终止本次循环，接着还执行后面的循环，break则完全终止循环。 可以理解为continue是跳过当次循环中剩下的语句，执行下一次循环。   ![](https://blog.mviai.com/images/wp-content/uploads/2018/05/if.png)![](https://blog.mviai.com/images/wp-content/uploads/2018/05/2if.png)![](https://blog.mviai.com/images/wp-content/uploads/2018/05/for.png)\n","slug":"第六节：控制流程","published":1,"updated":"2021-07-26T09:58:02.570Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m30003vigta5umhb0ms","content":"<h2 id=\"1-break和continue的区别和作用\"><a href=\"#1-break和continue的区别和作用\" class=\"headerlink\" title=\"1.break和continue的区别和作用\"></a>1.break和continue的区别和作用</h2><p>break和continue都是用来控制循环结构的，主要是停止循环。 1.break 有时候我们想在某种条件出现的时候终止循环而不是等到循环条件为false才终止。 这是我们可以使用break来完成。break用于完全结束一个循环，跳出循环体执行循环后面的语句。 2.continue continue和break有点类似，区别在于continue只是终止本次循环，接着还执行后面的循环，break则完全终止循环。 可以理解为continue是跳过当次循环中剩下的语句，执行下一次循环。   <img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/if.png\" alt><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/2if.png\" alt><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/for.png\" alt></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"1-break和continue的区别和作用\"><a href=\"#1-break和continue的区别和作用\" class=\"headerlink\" title=\"1.break和continue的区别和作用\"></a>1.break和continue的区别和作用</h2><p>break和continue都是用来控制循环结构的，主要是停止循环。 1.break 有时候我们想在某种条件出现的时候终止循环而不是等到循环条件为false才终止。 这是我们可以使用break来完成。break用于完全结束一个循环，跳出循环体执行循环后面的语句。 2.continue continue和break有点类似，区别在于continue只是终止本次循环，接着还执行后面的循环，break则完全终止循环。 可以理解为continue是跳过当次循环中剩下的语句，执行下一次循环。   <img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/if.png\" alt><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/2if.png\" alt><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/for.png\" alt></p>\n"},{"title":"第八节：函数作用域和匿名函数","url":"196.html","id":"196","date":"2018-05-08T06:45:20.000Z","_content":"\n\\[info\\]\n\npython 使用 lambda 来创建匿名函数。\n-------------------------\n\n*   lambda只是一个表达式，函数体比def简单很多。\n*   lambda的主体是一个表达式，而不是一个代码块。仅仅能在lambda表达式中封装有限的逻辑进去。\n*   lambda函数拥有自己的命名空间，且不能访问自有参数列表之外或全局命名空间里的参数。\n*   虽然lambda函数看起来只能写一行，却不等同于C或C++的内联函数，后者的目的是调用小函数时不占用栈内存从而增加运行效率。\n\n  形式：    函数名=lambda 参数：表达式                        等价于    def  函数名（参数）： 语句块 return 返回值\n\nlambda作用域说明\n-----------\n\n关于变量在Lambda中的作用域主要可以做出以下几点的总结：\n\n1.  对局部变量可见\n2.  对全局变量可见\n3.  对当前层传入的参数可见\n4.  对上层函数传入的参数可见\n5.  对上层Lambda传入的参数可见\n\n  局部变量和全局变量：详见：[点我](https://blog.mviai.com/images/archives/193)  \n\n闭包：\n---\n\n在函数中可以（嵌套）定义另一个函数时，如果内部的函数引用了外部的函数的变量，则可能产生闭包。闭包可以用来在一个函数与一组“私有”变量之间创建关联关系。在给定函数被多次调用的过程中，这些私有变量能够保持其持久性。 条件： 1)必须有一个内嵌函数(函数里定义的函数）——这对应函数之间的嵌套 2)内嵌函数必须引用一个定义在闭合范围内(外部函数里)的变量——内部函数引用外部变量 3)外部函数必须返回内嵌函数——必须返回那个内部函数   陷阱： **返回函数千万不要引用任何一个循环变量,或者在之后会发生改变的变量.** bug代码如下：\n\n1.  # 希望一次返回3个函数，分别计算1x1,2x2,3x3:  \n2.  def count():  \n3.      fs = \\[\\]  \n4.      for i in range(1, 4):  \n5.          def f():  \n6.               return i*i  \n7.          fs.append(f)  \n8.      return fs  \n\n10.  f1, f2, f3 = count()  \n\n12.  print f1(), f2(), f3()  \n\n改进：\n\n1.  #coding:utf-8  \n2.  \\_\\_author\\_\\_ = 'chad'  \n3.  # 希望一次返回3个函数，分别计算1x1,2x2,3x3:  \n4.  def count():  \n5.      fs = \\[\\]  \n6.      for i in range(1, 4):  \n7.          def f(j):  \n8.              def g():  \n9.                  return j*j  \n10.              return g  \n11.          fs.append(f(i))  \n12.      return fs  \n\n14.  f1, f2, f3 = count()  \n\n16.  print f1(), f2(), f3()  \n\n递归（自己调用自己）：\n-----------\n\n来源于：数学归纳法 直接调用：\n\n`def` `func():`\n\n`print``(``'from func'``)`\n\n`func()`\n\n`func()`\n\n间接调用：\n\n`#间接调用自己`\n\n`def` `foo():`\n\n`print``(``'from foo'``)`\n\n`bar()`\n\n`def` `bar():`\n\n`print``(``'from bar'``)`\n\n`foo()`\n\n`foo()`\n\n典型递归：树结构，阶乘，斐波那契数列，汉诺塔\n\n\\[/info\\]\n","source":"_posts/第八节：函数作用域和匿名函数.md","raw":"---\ntitle: 第八节：函数作用域和匿名函数\ntags:\n  - 课后解答\nurl: 196.html\nid: 196\ncategories:\n  - 学习\n  - 教学\ndate: 2018-05-08 14:45:20\n---\n\n\\[info\\]\n\npython 使用 lambda 来创建匿名函数。\n-------------------------\n\n*   lambda只是一个表达式，函数体比def简单很多。\n*   lambda的主体是一个表达式，而不是一个代码块。仅仅能在lambda表达式中封装有限的逻辑进去。\n*   lambda函数拥有自己的命名空间，且不能访问自有参数列表之外或全局命名空间里的参数。\n*   虽然lambda函数看起来只能写一行，却不等同于C或C++的内联函数，后者的目的是调用小函数时不占用栈内存从而增加运行效率。\n\n  形式：    函数名=lambda 参数：表达式                        等价于    def  函数名（参数）： 语句块 return 返回值\n\nlambda作用域说明\n-----------\n\n关于变量在Lambda中的作用域主要可以做出以下几点的总结：\n\n1.  对局部变量可见\n2.  对全局变量可见\n3.  对当前层传入的参数可见\n4.  对上层函数传入的参数可见\n5.  对上层Lambda传入的参数可见\n\n  局部变量和全局变量：详见：[点我](https://blog.mviai.com/images/archives/193)  \n\n闭包：\n---\n\n在函数中可以（嵌套）定义另一个函数时，如果内部的函数引用了外部的函数的变量，则可能产生闭包。闭包可以用来在一个函数与一组“私有”变量之间创建关联关系。在给定函数被多次调用的过程中，这些私有变量能够保持其持久性。 条件： 1)必须有一个内嵌函数(函数里定义的函数）——这对应函数之间的嵌套 2)内嵌函数必须引用一个定义在闭合范围内(外部函数里)的变量——内部函数引用外部变量 3)外部函数必须返回内嵌函数——必须返回那个内部函数   陷阱： **返回函数千万不要引用任何一个循环变量,或者在之后会发生改变的变量.** bug代码如下：\n\n1.  # 希望一次返回3个函数，分别计算1x1,2x2,3x3:  \n2.  def count():  \n3.      fs = \\[\\]  \n4.      for i in range(1, 4):  \n5.          def f():  \n6.               return i*i  \n7.          fs.append(f)  \n8.      return fs  \n\n10.  f1, f2, f3 = count()  \n\n12.  print f1(), f2(), f3()  \n\n改进：\n\n1.  #coding:utf-8  \n2.  \\_\\_author\\_\\_ = 'chad'  \n3.  # 希望一次返回3个函数，分别计算1x1,2x2,3x3:  \n4.  def count():  \n5.      fs = \\[\\]  \n6.      for i in range(1, 4):  \n7.          def f(j):  \n8.              def g():  \n9.                  return j*j  \n10.              return g  \n11.          fs.append(f(i))  \n12.      return fs  \n\n14.  f1, f2, f3 = count()  \n\n16.  print f1(), f2(), f3()  \n\n递归（自己调用自己）：\n-----------\n\n来源于：数学归纳法 直接调用：\n\n`def` `func():`\n\n`print``(``'from func'``)`\n\n`func()`\n\n`func()`\n\n间接调用：\n\n`#间接调用自己`\n\n`def` `foo():`\n\n`print``(``'from foo'``)`\n\n`bar()`\n\n`def` `bar():`\n\n`print``(``'from bar'``)`\n\n`foo()`\n\n`foo()`\n\n典型递归：树结构，阶乘，斐波那契数列，汉诺塔\n\n\\[/info\\]\n","slug":"第八节：函数作用域和匿名函数","published":1,"updated":"2021-07-26T09:58:02.569Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m31003yigtan83sa9dx","content":"<p>[info]</p>\n<h2 id=\"python-使用-lambda-来创建匿名函数。\"><a href=\"#python-使用-lambda-来创建匿名函数。\" class=\"headerlink\" title=\"python 使用 lambda 来创建匿名函数。\"></a>python 使用 lambda 来创建匿名函数。</h2><ul>\n<li>lambda只是一个表达式，函数体比def简单很多。</li>\n<li>lambda的主体是一个表达式，而不是一个代码块。仅仅能在lambda表达式中封装有限的逻辑进去。</li>\n<li>lambda函数拥有自己的命名空间，且不能访问自有参数列表之外或全局命名空间里的参数。</li>\n<li><p>虽然lambda函数看起来只能写一行，却不等同于C或C++的内联函数，后者的目的是调用小函数时不占用栈内存从而增加运行效率。</p>\n<p>形式：    函数名=lambda 参数：表达式                        等价于    def  函数名（参数）： 语句块 return 返回值</p>\n</li>\n</ul>\n<h2 id=\"lambda作用域说明\"><a href=\"#lambda作用域说明\" class=\"headerlink\" title=\"lambda作用域说明\"></a>lambda作用域说明</h2><p>关于变量在Lambda中的作用域主要可以做出以下几点的总结：</p>\n<ol>\n<li>对局部变量可见</li>\n<li>对全局变量可见</li>\n<li>对当前层传入的参数可见</li>\n<li>对上层函数传入的参数可见</li>\n<li><p>对上层Lambda传入的参数可见</p>\n<p>局部变量和全局变量：详见：<a href=\"https://blog.mviai.com/images/archives/193\" target=\"_blank\" rel=\"noopener\">点我</a>  </p>\n</li>\n</ol>\n<h2 id=\"闭包：\"><a href=\"#闭包：\" class=\"headerlink\" title=\"闭包：\"></a>闭包：</h2><p>在函数中可以（嵌套）定义另一个函数时，如果内部的函数引用了外部的函数的变量，则可能产生闭包。闭包可以用来在一个函数与一组“私有”变量之间创建关联关系。在给定函数被多次调用的过程中，这些私有变量能够保持其持久性。 条件： 1)必须有一个内嵌函数(函数里定义的函数）——这对应函数之间的嵌套 2)内嵌函数必须引用一个定义在闭合范围内(外部函数里)的变量——内部函数引用外部变量 3)外部函数必须返回内嵌函数——必须返回那个内部函数   陷阱： <strong>返回函数千万不要引用任何一个循环变量,或者在之后会发生改变的变量.</strong> bug代码如下：</p>\n<ol>\n<li><h1 id=\"希望一次返回3个函数，分别计算1x1-2x2-3x3\"><a href=\"#希望一次返回3个函数，分别计算1x1-2x2-3x3\" class=\"headerlink\" title=\"希望一次返回3个函数，分别计算1x1,2x2,3x3:\"></a>希望一次返回3个函数，分别计算1x1,2x2,3x3:</h1></li>\n<li>def count():  </li>\n<li>fs = []  </li>\n<li>for i in range(1, 4):  </li>\n<li>def f():  </li>\n<li>return i*i  </li>\n<li>fs.append(f)  </li>\n<li><p>return fs  </p>\n</li>\n<li><p>f1, f2, f3 = count()  </p>\n</li>\n<li><p>print f1(), f2(), f3()  </p>\n</li>\n</ol>\n<p>改进：</p>\n<ol>\n<li>#coding:utf-8  </li>\n<li>__author__ = ‘chad’  </li>\n<li><h1 id=\"希望一次返回3个函数，分别计算1x1-2x2-3x3-1\"><a href=\"#希望一次返回3个函数，分别计算1x1-2x2-3x3-1\" class=\"headerlink\" title=\"希望一次返回3个函数，分别计算1x1,2x2,3x3:\"></a>希望一次返回3个函数，分别计算1x1,2x2,3x3:</h1></li>\n<li>def count():  </li>\n<li>fs = []  </li>\n<li>for i in range(1, 4):  </li>\n<li>def f(j):  </li>\n<li>def g():  </li>\n<li>return j*j  </li>\n<li>return g  </li>\n<li>fs.append(f(i))  </li>\n<li><p>return fs  </p>\n</li>\n<li><p>f1, f2, f3 = count()  </p>\n</li>\n<li><p>print f1(), f2(), f3()  </p>\n</li>\n</ol>\n<h2 id=\"递归（自己调用自己）：\"><a href=\"#递归（自己调用自己）：\" class=\"headerlink\" title=\"递归（自己调用自己）：\"></a>递归（自己调用自己）：</h2><p>来源于：数学归纳法 直接调用：</p>\n<p><code>def</code> <code>func():</code></p>\n<p><code>print`</code>(<code>&#39;from func&#39;</code>)`</p>\n<p><code>func()</code></p>\n<p><code>func()</code></p>\n<p>间接调用：</p>\n<p><code>#间接调用自己</code></p>\n<p><code>def</code> <code>foo():</code></p>\n<p><code>print`</code>(<code>&#39;from foo&#39;</code>)`</p>\n<p><code>bar()</code></p>\n<p><code>def</code> <code>bar():</code></p>\n<p><code>print`</code>(<code>&#39;from bar&#39;</code>)`</p>\n<p><code>foo()</code></p>\n<p><code>foo()</code></p>\n<p>典型递归：树结构，阶乘，斐波那契数列，汉诺塔</p>\n<p>[/info]</p>\n","site":{"data":{}},"excerpt":"","more":"<p>[info]</p>\n<h2 id=\"python-使用-lambda-来创建匿名函数。\"><a href=\"#python-使用-lambda-来创建匿名函数。\" class=\"headerlink\" title=\"python 使用 lambda 来创建匿名函数。\"></a>python 使用 lambda 来创建匿名函数。</h2><ul>\n<li>lambda只是一个表达式，函数体比def简单很多。</li>\n<li>lambda的主体是一个表达式，而不是一个代码块。仅仅能在lambda表达式中封装有限的逻辑进去。</li>\n<li>lambda函数拥有自己的命名空间，且不能访问自有参数列表之外或全局命名空间里的参数。</li>\n<li><p>虽然lambda函数看起来只能写一行，却不等同于C或C++的内联函数，后者的目的是调用小函数时不占用栈内存从而增加运行效率。</p>\n<p>形式：    函数名=lambda 参数：表达式                        等价于    def  函数名（参数）： 语句块 return 返回值</p>\n</li>\n</ul>\n<h2 id=\"lambda作用域说明\"><a href=\"#lambda作用域说明\" class=\"headerlink\" title=\"lambda作用域说明\"></a>lambda作用域说明</h2><p>关于变量在Lambda中的作用域主要可以做出以下几点的总结：</p>\n<ol>\n<li>对局部变量可见</li>\n<li>对全局变量可见</li>\n<li>对当前层传入的参数可见</li>\n<li>对上层函数传入的参数可见</li>\n<li><p>对上层Lambda传入的参数可见</p>\n<p>局部变量和全局变量：详见：<a href=\"https://blog.mviai.com/images/archives/193\" target=\"_blank\" rel=\"noopener\">点我</a>  </p>\n</li>\n</ol>\n<h2 id=\"闭包：\"><a href=\"#闭包：\" class=\"headerlink\" title=\"闭包：\"></a>闭包：</h2><p>在函数中可以（嵌套）定义另一个函数时，如果内部的函数引用了外部的函数的变量，则可能产生闭包。闭包可以用来在一个函数与一组“私有”变量之间创建关联关系。在给定函数被多次调用的过程中，这些私有变量能够保持其持久性。 条件： 1)必须有一个内嵌函数(函数里定义的函数）——这对应函数之间的嵌套 2)内嵌函数必须引用一个定义在闭合范围内(外部函数里)的变量——内部函数引用外部变量 3)外部函数必须返回内嵌函数——必须返回那个内部函数   陷阱： <strong>返回函数千万不要引用任何一个循环变量,或者在之后会发生改变的变量.</strong> bug代码如下：</p>\n<ol>\n<li><h1 id=\"希望一次返回3个函数，分别计算1x1-2x2-3x3\"><a href=\"#希望一次返回3个函数，分别计算1x1-2x2-3x3\" class=\"headerlink\" title=\"希望一次返回3个函数，分别计算1x1,2x2,3x3:\"></a>希望一次返回3个函数，分别计算1x1,2x2,3x3:</h1></li>\n<li>def count():  </li>\n<li>fs = []  </li>\n<li>for i in range(1, 4):  </li>\n<li>def f():  </li>\n<li>return i*i  </li>\n<li>fs.append(f)  </li>\n<li><p>return fs  </p>\n</li>\n<li><p>f1, f2, f3 = count()  </p>\n</li>\n<li><p>print f1(), f2(), f3()  </p>\n</li>\n</ol>\n<p>改进：</p>\n<ol>\n<li>#coding:utf-8  </li>\n<li>__author__ = ‘chad’  </li>\n<li><h1 id=\"希望一次返回3个函数，分别计算1x1-2x2-3x3-1\"><a href=\"#希望一次返回3个函数，分别计算1x1-2x2-3x3-1\" class=\"headerlink\" title=\"希望一次返回3个函数，分别计算1x1,2x2,3x3:\"></a>希望一次返回3个函数，分别计算1x1,2x2,3x3:</h1></li>\n<li>def count():  </li>\n<li>fs = []  </li>\n<li>for i in range(1, 4):  </li>\n<li>def f(j):  </li>\n<li>def g():  </li>\n<li>return j*j  </li>\n<li>return g  </li>\n<li>fs.append(f(i))  </li>\n<li><p>return fs  </p>\n</li>\n<li><p>f1, f2, f3 = count()  </p>\n</li>\n<li><p>print f1(), f2(), f3()  </p>\n</li>\n</ol>\n<h2 id=\"递归（自己调用自己）：\"><a href=\"#递归（自己调用自己）：\" class=\"headerlink\" title=\"递归（自己调用自己）：\"></a>递归（自己调用自己）：</h2><p>来源于：数学归纳法 直接调用：</p>\n<p><code>def</code> <code>func():</code></p>\n<p><code>print`</code>(<code>&#39;from func&#39;</code>)`</p>\n<p><code>func()</code></p>\n<p><code>func()</code></p>\n<p>间接调用：</p>\n<p><code>#间接调用自己</code></p>\n<p><code>def</code> <code>foo():</code></p>\n<p><code>print`</code>(<code>&#39;from foo&#39;</code>)`</p>\n<p><code>bar()</code></p>\n<p><code>def</code> <code>bar():</code></p>\n<p><code>print`</code>(<code>&#39;from bar&#39;</code>)`</p>\n<p><code>foo()</code></p>\n<p><code>foo()</code></p>\n<p>典型递归：树结构，阶乘，斐波那契数列，汉诺塔</p>\n<p>[/info]</p>\n"},{"title":"第五节：散列类型，运算符","url":"191.html","id":"191","date":"2018-05-08T06:38:40.000Z","_content":"\n\\[info\\]\n\n一：集合（无序）\n--------\n\n集合用大括号{}表示，元素间用逗号分割 建立集合类型用{}或set（） 建立空集合类型，必须使用set（）   集合操作： （返回新集合） A|B   并 A-B  差 A&B 交 A^B 补 直接在集合中更新： A|=B A-=B A&=B A^=B 操作方法： 新建：set1 = set() or set1 = {1,2,3}  **value类型：string、tuple、frozenset、数字等不可变类型；** 增：set1.add(5) 增加多个：set.update(\\[5,6,7,8\\]) 删：set1.remove(1) 查：无法通过下标索引 改：不可变类型无法修改元素 与操作：set1 & set2 或操作：set1 | set2 与非操作：set1 ^ set2 减：set1 - set2 判断是否是子集or超集：set1.issubset(set2)  or set1.issubset(set2) 转变成list or tuple: list(set1) or tuple(set1)\n\n二 字典（键（索引）--值（数据））\n------------------\n\n新建：dict = {} or dict = {key:value,.....}  ** key类型：string、tuple、frozenset、数字；value类型；任何类型** 增：dict\\[key\\] = value 批量增（or批量改同key对应的value值）：dict.update(dict2) 删：del(dict\\[key\\]) 查：dict\\[key\\]  or dict.get(key,default= value) 改：dict\\[key\\] = value 判断是否在字典的键中：dict.has_key(key) 列表形式返回字典的键or值：dict.keys() or dict.values() 列表形式返回字典的(key,value)元祖：dict.items()  \n\n三 运算符\n-----\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/05/QQ图片20180509183935.png)![](https://blog.mviai.com/images/wp-content/uploads/2018/05/QQ图片20180509184024.png)![](https://blog.mviai.com/images/wp-content/uploads/2018/05/QQ图片20180509184105.png)   \\[/info\\]\n","source":"_posts/第五节：散列类型，运算符.md","raw":"---\ntitle: 第五节：散列类型，运算符\ntags:\n  - 课后解答\nurl: 191.html\nid: 191\ncategories:\n  - 学习\n  - 教学\ndate: 2018-05-08 14:38:40\n---\n\n\\[info\\]\n\n一：集合（无序）\n--------\n\n集合用大括号{}表示，元素间用逗号分割 建立集合类型用{}或set（） 建立空集合类型，必须使用set（）   集合操作： （返回新集合） A|B   并 A-B  差 A&B 交 A^B 补 直接在集合中更新： A|=B A-=B A&=B A^=B 操作方法： 新建：set1 = set() or set1 = {1,2,3}  **value类型：string、tuple、frozenset、数字等不可变类型；** 增：set1.add(5) 增加多个：set.update(\\[5,6,7,8\\]) 删：set1.remove(1) 查：无法通过下标索引 改：不可变类型无法修改元素 与操作：set1 & set2 或操作：set1 | set2 与非操作：set1 ^ set2 减：set1 - set2 判断是否是子集or超集：set1.issubset(set2)  or set1.issubset(set2) 转变成list or tuple: list(set1) or tuple(set1)\n\n二 字典（键（索引）--值（数据））\n------------------\n\n新建：dict = {} or dict = {key:value,.....}  ** key类型：string、tuple、frozenset、数字；value类型；任何类型** 增：dict\\[key\\] = value 批量增（or批量改同key对应的value值）：dict.update(dict2) 删：del(dict\\[key\\]) 查：dict\\[key\\]  or dict.get(key,default= value) 改：dict\\[key\\] = value 判断是否在字典的键中：dict.has_key(key) 列表形式返回字典的键or值：dict.keys() or dict.values() 列表形式返回字典的(key,value)元祖：dict.items()  \n\n三 运算符\n-----\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/05/QQ图片20180509183935.png)![](https://blog.mviai.com/images/wp-content/uploads/2018/05/QQ图片20180509184024.png)![](https://blog.mviai.com/images/wp-content/uploads/2018/05/QQ图片20180509184105.png)   \\[/info\\]\n","slug":"第五节：散列类型，运算符","published":1,"updated":"2021-07-26T09:58:02.575Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m320041igtarkho11pp","content":"<p>[info]</p>\n<h2 id=\"一：集合（无序）\"><a href=\"#一：集合（无序）\" class=\"headerlink\" title=\"一：集合（无序）\"></a>一：集合（无序）</h2><p>集合用大括号{}表示，元素间用逗号分割 建立集合类型用{}或set（） 建立空集合类型，必须使用set（）   集合操作： （返回新集合） A|B   并 A-B  差 A&amp;B 交 A^B 补 直接在集合中更新： A|=B A-=B A&amp;=B A^=B 操作方法： 新建：set1 = set() or set1 = {1,2,3}  <strong>value类型：string、tuple、frozenset、数字等不可变类型；</strong> 增：set1.add(5) 增加多个：set.update([5,6,7,8]) 删：set1.remove(1) 查：无法通过下标索引 改：不可变类型无法修改元素 与操作：set1 &amp; set2 或操作：set1 | set2 与非操作：set1 ^ set2 减：set1 - set2 判断是否是子集or超集：set1.issubset(set2)  or set1.issubset(set2) 转变成list or tuple: list(set1) or tuple(set1)</p>\n<h2 id=\"二-字典（键（索引）–值（数据））\"><a href=\"#二-字典（键（索引）–值（数据））\" class=\"headerlink\" title=\"二 字典（键（索引）–值（数据））\"></a>二 字典（键（索引）–值（数据））</h2><p>新建：dict = {} or dict = {key:value,…..}  <strong> key类型：string、tuple、frozenset、数字；value类型；任何类型</strong> 增：dict[key] = value 批量增（or批量改同key对应的value值）：dict.update(dict2) 删：del(dict[key]) 查：dict[key]  or dict.get(key,default= value) 改：dict[key] = value 判断是否在字典的键中：dict.has_key(key) 列表形式返回字典的键or值：dict.keys() or dict.values() 列表形式返回字典的(key,value)元祖：dict.items()  </p>\n<h2 id=\"三-运算符\"><a href=\"#三-运算符\" class=\"headerlink\" title=\"三 运算符\"></a>三 运算符</h2><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/QQ图片20180509183935.png\" alt><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/QQ图片20180509184024.png\" alt><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/QQ图片20180509184105.png\" alt>   [/info]</p>\n","site":{"data":{}},"excerpt":"","more":"<p>[info]</p>\n<h2 id=\"一：集合（无序）\"><a href=\"#一：集合（无序）\" class=\"headerlink\" title=\"一：集合（无序）\"></a>一：集合（无序）</h2><p>集合用大括号{}表示，元素间用逗号分割 建立集合类型用{}或set（） 建立空集合类型，必须使用set（）   集合操作： （返回新集合） A|B   并 A-B  差 A&amp;B 交 A^B 补 直接在集合中更新： A|=B A-=B A&amp;=B A^=B 操作方法： 新建：set1 = set() or set1 = {1,2,3}  <strong>value类型：string、tuple、frozenset、数字等不可变类型；</strong> 增：set1.add(5) 增加多个：set.update([5,6,7,8]) 删：set1.remove(1) 查：无法通过下标索引 改：不可变类型无法修改元素 与操作：set1 &amp; set2 或操作：set1 | set2 与非操作：set1 ^ set2 减：set1 - set2 判断是否是子集or超集：set1.issubset(set2)  or set1.issubset(set2) 转变成list or tuple: list(set1) or tuple(set1)</p>\n<h2 id=\"二-字典（键（索引）–值（数据））\"><a href=\"#二-字典（键（索引）–值（数据））\" class=\"headerlink\" title=\"二 字典（键（索引）–值（数据））\"></a>二 字典（键（索引）–值（数据））</h2><p>新建：dict = {} or dict = {key:value,…..}  <strong> key类型：string、tuple、frozenset、数字；value类型；任何类型</strong> 增：dict[key] = value 批量增（or批量改同key对应的value值）：dict.update(dict2) 删：del(dict[key]) 查：dict[key]  or dict.get(key,default= value) 改：dict[key] = value 判断是否在字典的键中：dict.has_key(key) 列表形式返回字典的键or值：dict.keys() or dict.values() 列表形式返回字典的(key,value)元祖：dict.items()  </p>\n<h2 id=\"三-运算符\"><a href=\"#三-运算符\" class=\"headerlink\" title=\"三 运算符\"></a>三 运算符</h2><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/QQ图片20180509183935.png\" alt><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/QQ图片20180509184024.png\" alt><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/QQ图片20180509184105.png\" alt>   [/info]</p>\n"},{"title":"第十三节：异常","url":"245.html","id":"245","date":"2018-05-28T06:36:29.000Z","_content":"\n\\[success\\]  \n\n一：异常及其异常处理：\n-----------\n\n  **什么是异常？**   ------异常：不正常的情况\n\n*   异常即是一个事件，该事件会在程序执行过程中发生，影响了程序的正常执行。一般情况下，在Python无法正常处理程序时就会发生一个异常。\n*   异常是Python对象，表示一个错误。\n*   当Python脚本发生异常时我们需要捕获处理它，否则程序会终止执行。\n\n* * *\n\n**异常出现的原因：** 不正常的情况，在程序中，会有两种体现：\n\n*   代码错误或语法错误；程序都运行不起来！\n*   程序运行过程中，在某些特定条件下，不合适的数据引起程序出现错误导致程序崩溃\n\n> 例如：_要求用户输入一个数字，但是用户误操作输入了字符串，在进行类型转换时就会出现错误导致程序崩溃！_\n\n* * *\n\n**为什么要处理异常？** 当程序在运行过程中，由于用户的误操作或者不合适的数据引发的程序错误，让代码自己处理并保证程序的正常执行。而不至于因为错误导致程序崩溃！        这样提高代码的健壮性！\n\n* * *\n\n**怎么处理异常？** l 捕获处理异常 l 断言处理异常【测试异常信息】 **捕获处理异常语法：** 捕捉异常可以使用 try/except 语句。 try/except语句用来检测try语句块中的错误，从而让except语句捕获异常信息并处理。 如果你不想在异常发生时结束你的程序，只需在try里捕获它。 语法： 以下为简单的_try....except...else_的语法：\n\n![复制代码](https://common.cnblogs.com/images/copycode.gif)\n\n 1 try:\n 2 \n 3 <语句\\>        #运行别的代码\n 4 \n 5 except <名字>：\n 6 \n 7 <语句\\>        #如果在try部份引发了'name'异常\n 8 \n 9 except <名字>，<数据>: 10 \n11 <语句\\>        #如果引发了'name'异常，获得附加的数据\n12 \n13 else: 14 \n15 <语句\\>        #如果没有异常发生\n16 \n17 finally： 18 \n19 <语句\\>                #无论try语句是否发生异常，都要执行的语句\n\n\n\n**处理异常：** **1\\. 基本异常处理** try-except直接处理异常【可以处理任何异常—不能定位具体是什么异常】 try-except \\[异常信息\\] 【可以处理指定的异常】 **2\\. 常见的异常** 所有异常的超类：BaseException 标准异常的超类：Exception(BaseException) 程序执行过程中经常看到的异常： …… **3\\. 处理多个异常** try-except (E1, E2, E3, …,En) as **e** 一个except处理指定的多个异常 try-except E1-except E2-except E3… 每个except处理指定的异常 通常情况下，我们要查看异常信息，就需要打印异常信息—打印**e**变量的值 问题： 1） 系统提供的异常信息，晦涩难懂！ 2） 系统提供的异常信息，毕竟有限！ **4\\. 自定义异常** 通过创建一个新的异常类，程序可以命名它们自己的异常。异常应该是典型的继承自Exception类，通过直接或间接的方式。 以下为与RuntimeError相关的实例,实例中创建了一个类，基类为RuntimeError，用于在异常触发时输出更多的信息。 在try语句块中，用户自定义的异常后执行except块语句，变量 e 是用于创建Networkerror类的实例。\n\n1 class Networkerror(RuntimeError): 2 \n3 def \\_\\_init\\_\\_(self, arg): 4 \n5 self.args = arg\n\n在你定义以上类后，你可以触发该异常，如下所示：\n\n\n'''\n 6 try:\n 7 \n 8 　　raise Networkerror(\"Bad hostname\")\n 9 \n10 except Networkerror,e: 11 \n12　　 print e.args\n'''\n#### 异常的参数\n\n一个异常可以带上参数，可作为输出的异常信息参数。 **5\\. 主动抛出异常** 我们可以使用raise语句自己触发异常 raise语法格式如下：  \n\nraise \\[Exception \\[, args \\[, traceback\\]\\]\\]\n\n语句中Exception是异常的类型（例如，NameError）参数是一个异常参数值。该参数是可选的，如果不提供，异常的参数是\"None\"。 最后一个参数是可选的（在实践中很少使用），如果存在，是跟踪异常对象。\n\n##### 实例\n\n一个异常可以是一个字符串，类或对象。 Python的内核提供的异常，大多数都是实例化的类，这是一个类的实例的参数。 定义一个异常非常简单，如下所示：\n\ndef functionName( level ):\n\nif level < 1: \nraise \"Invalid level!\", level 5         \nThe code below to this would not be executed\nif we raise the exception \n\n  **注意：**为了能够捕获异常，\"except\"语句必须有用相同的异常来抛出类对象或者字符串。 例如我们捕获以上异常，\"except\"语句如下所示：\n\n7     try: 8 Business Logic here... 9     except \"Invalid level!\": 10       Exception handling here... 11    else: 12       Rest of the code here...\n\n在开发的过程中，主动出现一种错误，将错误抛出给程序告诉程序出错了。 **6.异常处理理解** 自定义异常，就是为了专门抛出错误的，抛出错误，就是严重警告这里出现了什么问题 首先-代码执行过程中，出现了异常【系统标准异常】【信息不是很明白】 捕获系统异常，创建一个自定义异常 抛出自定义异常【自定义异常】【信息明确的错误】 自定义异常的目的：转换异常信息，将不明确的异常信息转换成更加精确的异常信息 **转换异常信息：异常的传递~传递更加明确的异常，给后面的代码进行处理！**  \n\n7.Python标准异常\n------------\n\n异常名称\n\n描述\n\nBaseException\n\n所有异常的基类\n\nSystemExit\n\n解释器请求退出\n\nKeyboardInterrupt\n\n用户中断执行(通常是输入^C)\n\nException\n\n常规错误的基类\n\nStopIteration\n\n迭代器没有更多的值\n\nGeneratorExit\n\n生成器(generator)发生异常来通知退出\n\nStandardError\n\n所有的内建标准异常的基类\n\nArithmeticError\n\n所有数值计算错误的基类\n\nFloatingPointError\n\n浮点计算错误\n\nOverflowError\n\n数值运算超出最大限制\n\nZeroDivisionError\n\n除(或取模)零 (所有数据类型)\n\nAssertionError\n\n断言语句失败\n\nAttributeError\n\n对象没有这个属性\n\nEOFError\n\n没有内建输入,到达EOF 标记\n\nEnvironmentError\n\n操作系统错误的基类\n\nIOError\n\n输入/输出操作失败\n\nOSError\n\n操作系统错误\n\nWindowsError\n\n系统调用失败\n\nImportError\n\n导入模块/对象失败\n\nLookupError\n\n无效数据查询的基类\n\nIndexError\n\n序列中没有此索引(index)\n\nKeyError\n\n映射中没有这个键\n\nMemoryError\n\n内存溢出错误(对于Python 解释器不是致命的)\n\nNameError\n\n未声明/初始化对象 (没有属性)\n\nUnboundLocalError\n\n访问未初始化的本地变量\n\nReferenceError\n\n弱引用(Weak reference)试图访问已经垃圾回收了的对象\n\nRuntimeError\n\n一般的运行时错误\n\nNotImplementedError\n\n尚未实现的方法\n\nSyntaxError\n\nPython 语法错误\n\nIndentationError\n\n缩进错误\n\nTabError\n\nTab 和空格混用\n\nSystemError\n\n一般的解释器系统错误\n\nTypeError\n\n对类型无效的操作\n\nValueError\n\n传入无效的参数\n\nUnicodeError\n\nUnicode 相关的错误\n\nUnicodeDecodeError\n\nUnicode 解码时的错误\n\nUnicodeEncodeError\n\nUnicode 编码时错误\n\nUnicodeTranslateError\n\nUnicode 转换时错误\n\nWarning\n\n警告的基类\n\nDeprecationWarning\n\n关于被弃用的特征的警告\n\nFutureWarning\n\n关于构造将来语义会有改变的警告\n\nOverflowWarning\n\n旧的关于自动提升为长整型(long)的警告\n\nPendingDeprecationWarning\n\n关于特性将会被废弃的警告\n\nRuntimeWarning\n\n可疑的运行时行为(runtime behavior)的警告\n\nSyntaxWarning\n\n可疑的语法的警告\n\nUserWarning\n\n用户代码生成的警告\n\n二：python断言\n----------\n\n使用assert断言是学习**[python](http://www.iplaypy.com/ \"python下载\")**一个非常好的习惯，python **assert 断言**句语格式及用法很简单。在没完善一个程序之前，我们不知道程序在哪里会出错，与其让它在运行最崩溃，不如在出现错误条件时就崩溃，这时候就需要assert断言的帮助。本文主要是讲assert断言的基础知识。\n\npython assert断言的作用\n------------------\n\npython assert断言是声明其布尔值必须为真的判定，如果发生异常就说明表达示为假。可以理解assert断言语句为raise-if-not，用来测试表示式，其返回值为假，就会触发[异常](http://www.iplaypy.com/jichu/exception.html)。\n\nassert断言语句的语法格式\n---------------\n\nassert python 怎么用？ expression assert 表达式 下面做一些assert用法的语句供参考：\nassert 1==1 \nassert 2+2==2*2 \nassert len(\\['my boy',12\\])<10\nassert range(4)==\\[0,1,2,3\\]\n\n如何为assert断言语句添加异常参数\n-------------------\n\nassert的异常参数，其实就是在断言表达式后添加[字符串](http://www.iplaypy.com/jichu/str.html)信息，用来解释断言并更好的知道是哪里出了问题。格式如下： assert expression \\[, arguments\\] \nassert 表达式 \\[, 参数\\]\n","source":"_posts/第十三节：异常.md","raw":"---\ntitle: 第十三节：异常\ntags:\n  - 课后解答\nurl: 245.html\nid: 245\ncategories:\n  - 学习\n  - 教学\n\ndate: 2018-05-28 14:36:29\n---\n\n\\[success\\]  \n\n一：异常及其异常处理：\n-----------\n\n  **什么是异常？**   ------异常：不正常的情况\n\n*   异常即是一个事件，该事件会在程序执行过程中发生，影响了程序的正常执行。一般情况下，在Python无法正常处理程序时就会发生一个异常。\n*   异常是Python对象，表示一个错误。\n*   当Python脚本发生异常时我们需要捕获处理它，否则程序会终止执行。\n\n* * *\n\n**异常出现的原因：** 不正常的情况，在程序中，会有两种体现：\n\n*   代码错误或语法错误；程序都运行不起来！\n*   程序运行过程中，在某些特定条件下，不合适的数据引起程序出现错误导致程序崩溃\n\n> 例如：_要求用户输入一个数字，但是用户误操作输入了字符串，在进行类型转换时就会出现错误导致程序崩溃！_\n\n* * *\n\n**为什么要处理异常？** 当程序在运行过程中，由于用户的误操作或者不合适的数据引发的程序错误，让代码自己处理并保证程序的正常执行。而不至于因为错误导致程序崩溃！        这样提高代码的健壮性！\n\n* * *\n\n**怎么处理异常？** l 捕获处理异常 l 断言处理异常【测试异常信息】 **捕获处理异常语法：** 捕捉异常可以使用 try/except 语句。 try/except语句用来检测try语句块中的错误，从而让except语句捕获异常信息并处理。 如果你不想在异常发生时结束你的程序，只需在try里捕获它。 语法： 以下为简单的_try....except...else_的语法：\n\n![复制代码](https://common.cnblogs.com/images/copycode.gif)\n\n 1 try:\n 2 \n 3 <语句\\>        #运行别的代码\n 4 \n 5 except <名字>：\n 6 \n 7 <语句\\>        #如果在try部份引发了'name'异常\n 8 \n 9 except <名字>，<数据>: 10 \n11 <语句\\>        #如果引发了'name'异常，获得附加的数据\n12 \n13 else: 14 \n15 <语句\\>        #如果没有异常发生\n16 \n17 finally： 18 \n19 <语句\\>                #无论try语句是否发生异常，都要执行的语句\n\n\n\n**处理异常：** **1\\. 基本异常处理** try-except直接处理异常【可以处理任何异常—不能定位具体是什么异常】 try-except \\[异常信息\\] 【可以处理指定的异常】 **2\\. 常见的异常** 所有异常的超类：BaseException 标准异常的超类：Exception(BaseException) 程序执行过程中经常看到的异常： …… **3\\. 处理多个异常** try-except (E1, E2, E3, …,En) as **e** 一个except处理指定的多个异常 try-except E1-except E2-except E3… 每个except处理指定的异常 通常情况下，我们要查看异常信息，就需要打印异常信息—打印**e**变量的值 问题： 1） 系统提供的异常信息，晦涩难懂！ 2） 系统提供的异常信息，毕竟有限！ **4\\. 自定义异常** 通过创建一个新的异常类，程序可以命名它们自己的异常。异常应该是典型的继承自Exception类，通过直接或间接的方式。 以下为与RuntimeError相关的实例,实例中创建了一个类，基类为RuntimeError，用于在异常触发时输出更多的信息。 在try语句块中，用户自定义的异常后执行except块语句，变量 e 是用于创建Networkerror类的实例。\n\n1 class Networkerror(RuntimeError): 2 \n3 def \\_\\_init\\_\\_(self, arg): 4 \n5 self.args = arg\n\n在你定义以上类后，你可以触发该异常，如下所示：\n\n\n'''\n 6 try:\n 7 \n 8 　　raise Networkerror(\"Bad hostname\")\n 9 \n10 except Networkerror,e: 11 \n12　　 print e.args\n'''\n#### 异常的参数\n\n一个异常可以带上参数，可作为输出的异常信息参数。 **5\\. 主动抛出异常** 我们可以使用raise语句自己触发异常 raise语法格式如下：  \n\nraise \\[Exception \\[, args \\[, traceback\\]\\]\\]\n\n语句中Exception是异常的类型（例如，NameError）参数是一个异常参数值。该参数是可选的，如果不提供，异常的参数是\"None\"。 最后一个参数是可选的（在实践中很少使用），如果存在，是跟踪异常对象。\n\n##### 实例\n\n一个异常可以是一个字符串，类或对象。 Python的内核提供的异常，大多数都是实例化的类，这是一个类的实例的参数。 定义一个异常非常简单，如下所示：\n\ndef functionName( level ):\n\nif level < 1: \nraise \"Invalid level!\", level 5         \nThe code below to this would not be executed\nif we raise the exception \n\n  **注意：**为了能够捕获异常，\"except\"语句必须有用相同的异常来抛出类对象或者字符串。 例如我们捕获以上异常，\"except\"语句如下所示：\n\n7     try: 8 Business Logic here... 9     except \"Invalid level!\": 10       Exception handling here... 11    else: 12       Rest of the code here...\n\n在开发的过程中，主动出现一种错误，将错误抛出给程序告诉程序出错了。 **6.异常处理理解** 自定义异常，就是为了专门抛出错误的，抛出错误，就是严重警告这里出现了什么问题 首先-代码执行过程中，出现了异常【系统标准异常】【信息不是很明白】 捕获系统异常，创建一个自定义异常 抛出自定义异常【自定义异常】【信息明确的错误】 自定义异常的目的：转换异常信息，将不明确的异常信息转换成更加精确的异常信息 **转换异常信息：异常的传递~传递更加明确的异常，给后面的代码进行处理！**  \n\n7.Python标准异常\n------------\n\n异常名称\n\n描述\n\nBaseException\n\n所有异常的基类\n\nSystemExit\n\n解释器请求退出\n\nKeyboardInterrupt\n\n用户中断执行(通常是输入^C)\n\nException\n\n常规错误的基类\n\nStopIteration\n\n迭代器没有更多的值\n\nGeneratorExit\n\n生成器(generator)发生异常来通知退出\n\nStandardError\n\n所有的内建标准异常的基类\n\nArithmeticError\n\n所有数值计算错误的基类\n\nFloatingPointError\n\n浮点计算错误\n\nOverflowError\n\n数值运算超出最大限制\n\nZeroDivisionError\n\n除(或取模)零 (所有数据类型)\n\nAssertionError\n\n断言语句失败\n\nAttributeError\n\n对象没有这个属性\n\nEOFError\n\n没有内建输入,到达EOF 标记\n\nEnvironmentError\n\n操作系统错误的基类\n\nIOError\n\n输入/输出操作失败\n\nOSError\n\n操作系统错误\n\nWindowsError\n\n系统调用失败\n\nImportError\n\n导入模块/对象失败\n\nLookupError\n\n无效数据查询的基类\n\nIndexError\n\n序列中没有此索引(index)\n\nKeyError\n\n映射中没有这个键\n\nMemoryError\n\n内存溢出错误(对于Python 解释器不是致命的)\n\nNameError\n\n未声明/初始化对象 (没有属性)\n\nUnboundLocalError\n\n访问未初始化的本地变量\n\nReferenceError\n\n弱引用(Weak reference)试图访问已经垃圾回收了的对象\n\nRuntimeError\n\n一般的运行时错误\n\nNotImplementedError\n\n尚未实现的方法\n\nSyntaxError\n\nPython 语法错误\n\nIndentationError\n\n缩进错误\n\nTabError\n\nTab 和空格混用\n\nSystemError\n\n一般的解释器系统错误\n\nTypeError\n\n对类型无效的操作\n\nValueError\n\n传入无效的参数\n\nUnicodeError\n\nUnicode 相关的错误\n\nUnicodeDecodeError\n\nUnicode 解码时的错误\n\nUnicodeEncodeError\n\nUnicode 编码时错误\n\nUnicodeTranslateError\n\nUnicode 转换时错误\n\nWarning\n\n警告的基类\n\nDeprecationWarning\n\n关于被弃用的特征的警告\n\nFutureWarning\n\n关于构造将来语义会有改变的警告\n\nOverflowWarning\n\n旧的关于自动提升为长整型(long)的警告\n\nPendingDeprecationWarning\n\n关于特性将会被废弃的警告\n\nRuntimeWarning\n\n可疑的运行时行为(runtime behavior)的警告\n\nSyntaxWarning\n\n可疑的语法的警告\n\nUserWarning\n\n用户代码生成的警告\n\n二：python断言\n----------\n\n使用assert断言是学习**[python](http://www.iplaypy.com/ \"python下载\")**一个非常好的习惯，python **assert 断言**句语格式及用法很简单。在没完善一个程序之前，我们不知道程序在哪里会出错，与其让它在运行最崩溃，不如在出现错误条件时就崩溃，这时候就需要assert断言的帮助。本文主要是讲assert断言的基础知识。\n\npython assert断言的作用\n------------------\n\npython assert断言是声明其布尔值必须为真的判定，如果发生异常就说明表达示为假。可以理解assert断言语句为raise-if-not，用来测试表示式，其返回值为假，就会触发[异常](http://www.iplaypy.com/jichu/exception.html)。\n\nassert断言语句的语法格式\n---------------\n\nassert python 怎么用？ expression assert 表达式 下面做一些assert用法的语句供参考：\nassert 1==1 \nassert 2+2==2*2 \nassert len(\\['my boy',12\\])<10\nassert range(4)==\\[0,1,2,3\\]\n\n如何为assert断言语句添加异常参数\n-------------------\n\nassert的异常参数，其实就是在断言表达式后添加[字符串](http://www.iplaypy.com/jichu/str.html)信息，用来解释断言并更好的知道是哪里出了问题。格式如下： assert expression \\[, arguments\\] \nassert 表达式 \\[, 参数\\]\n","slug":"第十三节：异常","published":1,"updated":"2021-07-26T09:58:02.572Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m330045igtaeusxazq0","content":"<p>[success]  </p>\n<h2 id=\"一：异常及其异常处理：\"><a href=\"#一：异常及其异常处理：\" class=\"headerlink\" title=\"一：异常及其异常处理：\"></a>一：异常及其异常处理：</h2><p>  <strong>什么是异常？</strong>   ——异常：不正常的情况</p>\n<ul>\n<li>异常即是一个事件，该事件会在程序执行过程中发生，影响了程序的正常执行。一般情况下，在Python无法正常处理程序时就会发生一个异常。</li>\n<li>异常是Python对象，表示一个错误。</li>\n<li>当Python脚本发生异常时我们需要捕获处理它，否则程序会终止执行。</li>\n</ul>\n<hr>\n<p><strong>异常出现的原因：</strong> 不正常的情况，在程序中，会有两种体现：</p>\n<ul>\n<li>代码错误或语法错误；程序都运行不起来！</li>\n<li>程序运行过程中，在某些特定条件下，不合适的数据引起程序出现错误导致程序崩溃</li>\n</ul>\n<blockquote>\n<p>例如：<em>要求用户输入一个数字，但是用户误操作输入了字符串，在进行类型转换时就会出现错误导致程序崩溃！</em></p>\n</blockquote>\n<hr>\n<p><strong>为什么要处理异常？</strong> 当程序在运行过程中，由于用户的误操作或者不合适的数据引发的程序错误，让代码自己处理并保证程序的正常执行。而不至于因为错误导致程序崩溃！        这样提高代码的健壮性！</p>\n<hr>\n<p><strong>怎么处理异常？</strong> l 捕获处理异常 l 断言处理异常【测试异常信息】 <strong>捕获处理异常语法：</strong> 捕捉异常可以使用 try/except 语句。 try/except语句用来检测try语句块中的错误，从而让except语句捕获异常信息并处理。 如果你不想在异常发生时结束你的程序，只需在try里捕获它。 语法： 以下为简单的<em>try….except…else</em>的语法：</p>\n<p><img src=\"https://common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></p>\n<p> 1 try:<br> 2<br> 3 &lt;语句>        #运行别的代码<br> 4<br> 5 except &lt;名字&gt;：<br> 6<br> 7 &lt;语句>        #如果在try部份引发了’name’异常<br> 8<br> 9 except &lt;名字&gt;，&lt;数据&gt;: 10<br>11 &lt;语句>        #如果引发了’name’异常，获得附加的数据<br>12<br>13 else: 14<br>15 &lt;语句>        #如果没有异常发生<br>16<br>17 finally： 18<br>19 &lt;语句>                #无论try语句是否发生异常，都要执行的语句</p>\n<p><strong>处理异常：</strong> <strong>1. 基本异常处理</strong> try-except直接处理异常【可以处理任何异常—不能定位具体是什么异常】 try-except [异常信息] 【可以处理指定的异常】 <strong>2. 常见的异常</strong> 所有异常的超类：BaseException 标准异常的超类：Exception(BaseException) 程序执行过程中经常看到的异常： …… <strong>3. 处理多个异常</strong> try-except (E1, E2, E3, …,En) as <strong>e</strong> 一个except处理指定的多个异常 try-except E1-except E2-except E3… 每个except处理指定的异常 通常情况下，我们要查看异常信息，就需要打印异常信息—打印<strong>e</strong>变量的值 问题： 1） 系统提供的异常信息，晦涩难懂！ 2） 系统提供的异常信息，毕竟有限！ <strong>4. 自定义异常</strong> 通过创建一个新的异常类，程序可以命名它们自己的异常。异常应该是典型的继承自Exception类，通过直接或间接的方式。 以下为与RuntimeError相关的实例,实例中创建了一个类，基类为RuntimeError，用于在异常触发时输出更多的信息。 在try语句块中，用户自定义的异常后执行except块语句，变量 e 是用于创建Networkerror类的实例。</p>\n<p>1 class Networkerror(RuntimeError): 2<br>3 def __init__(self, arg): 4<br>5 self.args = arg</p>\n<p>在你定义以上类后，你可以触发该异常，如下所示：</p>\n<p>‘’’<br> 6 try:<br> 7<br> 8 　　raise Networkerror(“Bad hostname”)<br> 9<br>10 except Networkerror,e: 11<br>12　　 print e.args<br>‘’’</p>\n<h4 id=\"异常的参数\"><a href=\"#异常的参数\" class=\"headerlink\" title=\"异常的参数\"></a>异常的参数</h4><p>一个异常可以带上参数，可作为输出的异常信息参数。 <strong>5. 主动抛出异常</strong> 我们可以使用raise语句自己触发异常 raise语法格式如下：  </p>\n<p>raise [Exception [, args [, traceback]]]</p>\n<p>语句中Exception是异常的类型（例如，NameError）参数是一个异常参数值。该参数是可选的，如果不提供，异常的参数是”None”。 最后一个参数是可选的（在实践中很少使用），如果存在，是跟踪异常对象。</p>\n<h5 id=\"实例\"><a href=\"#实例\" class=\"headerlink\" title=\"实例\"></a>实例</h5><p>一个异常可以是一个字符串，类或对象。 Python的内核提供的异常，大多数都是实例化的类，这是一个类的实例的参数。 定义一个异常非常简单，如下所示：</p>\n<p>def functionName( level ):</p>\n<p>if level &lt; 1:<br>raise “Invalid level!”, level 5<br>The code below to this would not be executed<br>if we raise the exception </p>\n<p>  <strong>注意：</strong>为了能够捕获异常，”except”语句必须有用相同的异常来抛出类对象或者字符串。 例如我们捕获以上异常，”except”语句如下所示：</p>\n<p>7     try: 8 Business Logic here… 9     except “Invalid level!”: 10       Exception handling here… 11    else: 12       Rest of the code here…</p>\n<p>在开发的过程中，主动出现一种错误，将错误抛出给程序告诉程序出错了。 <strong>6.异常处理理解</strong> 自定义异常，就是为了专门抛出错误的，抛出错误，就是严重警告这里出现了什么问题 首先-代码执行过程中，出现了异常【系统标准异常】【信息不是很明白】 捕获系统异常，创建一个自定义异常 抛出自定义异常【自定义异常】【信息明确的错误】 自定义异常的目的：转换异常信息，将不明确的异常信息转换成更加精确的异常信息 <strong>转换异常信息：异常的传递~传递更加明确的异常，给后面的代码进行处理！</strong>  </p>\n<h2 id=\"7-Python标准异常\"><a href=\"#7-Python标准异常\" class=\"headerlink\" title=\"7.Python标准异常\"></a>7.Python标准异常</h2><p>异常名称</p>\n<p>描述</p>\n<p>BaseException</p>\n<p>所有异常的基类</p>\n<p>SystemExit</p>\n<p>解释器请求退出</p>\n<p>KeyboardInterrupt</p>\n<p>用户中断执行(通常是输入^C)</p>\n<p>Exception</p>\n<p>常规错误的基类</p>\n<p>StopIteration</p>\n<p>迭代器没有更多的值</p>\n<p>GeneratorExit</p>\n<p>生成器(generator)发生异常来通知退出</p>\n<p>StandardError</p>\n<p>所有的内建标准异常的基类</p>\n<p>ArithmeticError</p>\n<p>所有数值计算错误的基类</p>\n<p>FloatingPointError</p>\n<p>浮点计算错误</p>\n<p>OverflowError</p>\n<p>数值运算超出最大限制</p>\n<p>ZeroDivisionError</p>\n<p>除(或取模)零 (所有数据类型)</p>\n<p>AssertionError</p>\n<p>断言语句失败</p>\n<p>AttributeError</p>\n<p>对象没有这个属性</p>\n<p>EOFError</p>\n<p>没有内建输入,到达EOF 标记</p>\n<p>EnvironmentError</p>\n<p>操作系统错误的基类</p>\n<p>IOError</p>\n<p>输入/输出操作失败</p>\n<p>OSError</p>\n<p>操作系统错误</p>\n<p>WindowsError</p>\n<p>系统调用失败</p>\n<p>ImportError</p>\n<p>导入模块/对象失败</p>\n<p>LookupError</p>\n<p>无效数据查询的基类</p>\n<p>IndexError</p>\n<p>序列中没有此索引(index)</p>\n<p>KeyError</p>\n<p>映射中没有这个键</p>\n<p>MemoryError</p>\n<p>内存溢出错误(对于Python 解释器不是致命的)</p>\n<p>NameError</p>\n<p>未声明/初始化对象 (没有属性)</p>\n<p>UnboundLocalError</p>\n<p>访问未初始化的本地变量</p>\n<p>ReferenceError</p>\n<p>弱引用(Weak reference)试图访问已经垃圾回收了的对象</p>\n<p>RuntimeError</p>\n<p>一般的运行时错误</p>\n<p>NotImplementedError</p>\n<p>尚未实现的方法</p>\n<p>SyntaxError</p>\n<p>Python 语法错误</p>\n<p>IndentationError</p>\n<p>缩进错误</p>\n<p>TabError</p>\n<p>Tab 和空格混用</p>\n<p>SystemError</p>\n<p>一般的解释器系统错误</p>\n<p>TypeError</p>\n<p>对类型无效的操作</p>\n<p>ValueError</p>\n<p>传入无效的参数</p>\n<p>UnicodeError</p>\n<p>Unicode 相关的错误</p>\n<p>UnicodeDecodeError</p>\n<p>Unicode 解码时的错误</p>\n<p>UnicodeEncodeError</p>\n<p>Unicode 编码时错误</p>\n<p>UnicodeTranslateError</p>\n<p>Unicode 转换时错误</p>\n<p>Warning</p>\n<p>警告的基类</p>\n<p>DeprecationWarning</p>\n<p>关于被弃用的特征的警告</p>\n<p>FutureWarning</p>\n<p>关于构造将来语义会有改变的警告</p>\n<p>OverflowWarning</p>\n<p>旧的关于自动提升为长整型(long)的警告</p>\n<p>PendingDeprecationWarning</p>\n<p>关于特性将会被废弃的警告</p>\n<p>RuntimeWarning</p>\n<p>可疑的运行时行为(runtime behavior)的警告</p>\n<p>SyntaxWarning</p>\n<p>可疑的语法的警告</p>\n<p>UserWarning</p>\n<p>用户代码生成的警告</p>\n<h2 id=\"二：python断言\"><a href=\"#二：python断言\" class=\"headerlink\" title=\"二：python断言\"></a>二：python断言</h2><p>使用assert断言是学习<strong><a href=\"http://www.iplaypy.com/\" title=\"python下载\" target=\"_blank\" rel=\"noopener\">python</a></strong>一个非常好的习惯，python <strong>assert 断言</strong>句语格式及用法很简单。在没完善一个程序之前，我们不知道程序在哪里会出错，与其让它在运行最崩溃，不如在出现错误条件时就崩溃，这时候就需要assert断言的帮助。本文主要是讲assert断言的基础知识。</p>\n<h2 id=\"python-assert断言的作用\"><a href=\"#python-assert断言的作用\" class=\"headerlink\" title=\"python assert断言的作用\"></a>python assert断言的作用</h2><p>python assert断言是声明其布尔值必须为真的判定，如果发生异常就说明表达示为假。可以理解assert断言语句为raise-if-not，用来测试表示式，其返回值为假，就会触发<a href=\"http://www.iplaypy.com/jichu/exception.html\" target=\"_blank\" rel=\"noopener\">异常</a>。</p>\n<h2 id=\"assert断言语句的语法格式\"><a href=\"#assert断言语句的语法格式\" class=\"headerlink\" title=\"assert断言语句的语法格式\"></a>assert断言语句的语法格式</h2><p>assert python 怎么用？ expression assert 表达式 下面做一些assert用法的语句供参考：<br>assert 1==1<br>assert 2+2==2*2<br>assert len([‘my boy’,12])&lt;10<br>assert range(4)==[0,1,2,3]</p>\n<h2 id=\"如何为assert断言语句添加异常参数\"><a href=\"#如何为assert断言语句添加异常参数\" class=\"headerlink\" title=\"如何为assert断言语句添加异常参数\"></a>如何为assert断言语句添加异常参数</h2><p>assert的异常参数，其实就是在断言表达式后添加<a href=\"http://www.iplaypy.com/jichu/str.html\" target=\"_blank\" rel=\"noopener\">字符串</a>信息，用来解释断言并更好的知道是哪里出了问题。格式如下： assert expression [, arguments]<br>assert 表达式 [, 参数]</p>\n","site":{"data":{}},"excerpt":"","more":"<p>[success]  </p>\n<h2 id=\"一：异常及其异常处理：\"><a href=\"#一：异常及其异常处理：\" class=\"headerlink\" title=\"一：异常及其异常处理：\"></a>一：异常及其异常处理：</h2><p>  <strong>什么是异常？</strong>   ——异常：不正常的情况</p>\n<ul>\n<li>异常即是一个事件，该事件会在程序执行过程中发生，影响了程序的正常执行。一般情况下，在Python无法正常处理程序时就会发生一个异常。</li>\n<li>异常是Python对象，表示一个错误。</li>\n<li>当Python脚本发生异常时我们需要捕获处理它，否则程序会终止执行。</li>\n</ul>\n<hr>\n<p><strong>异常出现的原因：</strong> 不正常的情况，在程序中，会有两种体现：</p>\n<ul>\n<li>代码错误或语法错误；程序都运行不起来！</li>\n<li>程序运行过程中，在某些特定条件下，不合适的数据引起程序出现错误导致程序崩溃</li>\n</ul>\n<blockquote>\n<p>例如：<em>要求用户输入一个数字，但是用户误操作输入了字符串，在进行类型转换时就会出现错误导致程序崩溃！</em></p>\n</blockquote>\n<hr>\n<p><strong>为什么要处理异常？</strong> 当程序在运行过程中，由于用户的误操作或者不合适的数据引发的程序错误，让代码自己处理并保证程序的正常执行。而不至于因为错误导致程序崩溃！        这样提高代码的健壮性！</p>\n<hr>\n<p><strong>怎么处理异常？</strong> l 捕获处理异常 l 断言处理异常【测试异常信息】 <strong>捕获处理异常语法：</strong> 捕捉异常可以使用 try/except 语句。 try/except语句用来检测try语句块中的错误，从而让except语句捕获异常信息并处理。 如果你不想在异常发生时结束你的程序，只需在try里捕获它。 语法： 以下为简单的<em>try….except…else</em>的语法：</p>\n<p><img src=\"https://common.cnblogs.com/images/copycode.gif\" alt=\"复制代码\"></p>\n<p> 1 try:<br> 2<br> 3 &lt;语句>        #运行别的代码<br> 4<br> 5 except &lt;名字&gt;：<br> 6<br> 7 &lt;语句>        #如果在try部份引发了’name’异常<br> 8<br> 9 except &lt;名字&gt;，&lt;数据&gt;: 10<br>11 &lt;语句>        #如果引发了’name’异常，获得附加的数据<br>12<br>13 else: 14<br>15 &lt;语句>        #如果没有异常发生<br>16<br>17 finally： 18<br>19 &lt;语句>                #无论try语句是否发生异常，都要执行的语句</p>\n<p><strong>处理异常：</strong> <strong>1. 基本异常处理</strong> try-except直接处理异常【可以处理任何异常—不能定位具体是什么异常】 try-except [异常信息] 【可以处理指定的异常】 <strong>2. 常见的异常</strong> 所有异常的超类：BaseException 标准异常的超类：Exception(BaseException) 程序执行过程中经常看到的异常： …… <strong>3. 处理多个异常</strong> try-except (E1, E2, E3, …,En) as <strong>e</strong> 一个except处理指定的多个异常 try-except E1-except E2-except E3… 每个except处理指定的异常 通常情况下，我们要查看异常信息，就需要打印异常信息—打印<strong>e</strong>变量的值 问题： 1） 系统提供的异常信息，晦涩难懂！ 2） 系统提供的异常信息，毕竟有限！ <strong>4. 自定义异常</strong> 通过创建一个新的异常类，程序可以命名它们自己的异常。异常应该是典型的继承自Exception类，通过直接或间接的方式。 以下为与RuntimeError相关的实例,实例中创建了一个类，基类为RuntimeError，用于在异常触发时输出更多的信息。 在try语句块中，用户自定义的异常后执行except块语句，变量 e 是用于创建Networkerror类的实例。</p>\n<p>1 class Networkerror(RuntimeError): 2<br>3 def __init__(self, arg): 4<br>5 self.args = arg</p>\n<p>在你定义以上类后，你可以触发该异常，如下所示：</p>\n<p>‘’’<br> 6 try:<br> 7<br> 8 　　raise Networkerror(“Bad hostname”)<br> 9<br>10 except Networkerror,e: 11<br>12　　 print e.args<br>‘’’</p>\n<h4 id=\"异常的参数\"><a href=\"#异常的参数\" class=\"headerlink\" title=\"异常的参数\"></a>异常的参数</h4><p>一个异常可以带上参数，可作为输出的异常信息参数。 <strong>5. 主动抛出异常</strong> 我们可以使用raise语句自己触发异常 raise语法格式如下：  </p>\n<p>raise [Exception [, args [, traceback]]]</p>\n<p>语句中Exception是异常的类型（例如，NameError）参数是一个异常参数值。该参数是可选的，如果不提供，异常的参数是”None”。 最后一个参数是可选的（在实践中很少使用），如果存在，是跟踪异常对象。</p>\n<h5 id=\"实例\"><a href=\"#实例\" class=\"headerlink\" title=\"实例\"></a>实例</h5><p>一个异常可以是一个字符串，类或对象。 Python的内核提供的异常，大多数都是实例化的类，这是一个类的实例的参数。 定义一个异常非常简单，如下所示：</p>\n<p>def functionName( level ):</p>\n<p>if level &lt; 1:<br>raise “Invalid level!”, level 5<br>The code below to this would not be executed<br>if we raise the exception </p>\n<p>  <strong>注意：</strong>为了能够捕获异常，”except”语句必须有用相同的异常来抛出类对象或者字符串。 例如我们捕获以上异常，”except”语句如下所示：</p>\n<p>7     try: 8 Business Logic here… 9     except “Invalid level!”: 10       Exception handling here… 11    else: 12       Rest of the code here…</p>\n<p>在开发的过程中，主动出现一种错误，将错误抛出给程序告诉程序出错了。 <strong>6.异常处理理解</strong> 自定义异常，就是为了专门抛出错误的，抛出错误，就是严重警告这里出现了什么问题 首先-代码执行过程中，出现了异常【系统标准异常】【信息不是很明白】 捕获系统异常，创建一个自定义异常 抛出自定义异常【自定义异常】【信息明确的错误】 自定义异常的目的：转换异常信息，将不明确的异常信息转换成更加精确的异常信息 <strong>转换异常信息：异常的传递~传递更加明确的异常，给后面的代码进行处理！</strong>  </p>\n<h2 id=\"7-Python标准异常\"><a href=\"#7-Python标准异常\" class=\"headerlink\" title=\"7.Python标准异常\"></a>7.Python标准异常</h2><p>异常名称</p>\n<p>描述</p>\n<p>BaseException</p>\n<p>所有异常的基类</p>\n<p>SystemExit</p>\n<p>解释器请求退出</p>\n<p>KeyboardInterrupt</p>\n<p>用户中断执行(通常是输入^C)</p>\n<p>Exception</p>\n<p>常规错误的基类</p>\n<p>StopIteration</p>\n<p>迭代器没有更多的值</p>\n<p>GeneratorExit</p>\n<p>生成器(generator)发生异常来通知退出</p>\n<p>StandardError</p>\n<p>所有的内建标准异常的基类</p>\n<p>ArithmeticError</p>\n<p>所有数值计算错误的基类</p>\n<p>FloatingPointError</p>\n<p>浮点计算错误</p>\n<p>OverflowError</p>\n<p>数值运算超出最大限制</p>\n<p>ZeroDivisionError</p>\n<p>除(或取模)零 (所有数据类型)</p>\n<p>AssertionError</p>\n<p>断言语句失败</p>\n<p>AttributeError</p>\n<p>对象没有这个属性</p>\n<p>EOFError</p>\n<p>没有内建输入,到达EOF 标记</p>\n<p>EnvironmentError</p>\n<p>操作系统错误的基类</p>\n<p>IOError</p>\n<p>输入/输出操作失败</p>\n<p>OSError</p>\n<p>操作系统错误</p>\n<p>WindowsError</p>\n<p>系统调用失败</p>\n<p>ImportError</p>\n<p>导入模块/对象失败</p>\n<p>LookupError</p>\n<p>无效数据查询的基类</p>\n<p>IndexError</p>\n<p>序列中没有此索引(index)</p>\n<p>KeyError</p>\n<p>映射中没有这个键</p>\n<p>MemoryError</p>\n<p>内存溢出错误(对于Python 解释器不是致命的)</p>\n<p>NameError</p>\n<p>未声明/初始化对象 (没有属性)</p>\n<p>UnboundLocalError</p>\n<p>访问未初始化的本地变量</p>\n<p>ReferenceError</p>\n<p>弱引用(Weak reference)试图访问已经垃圾回收了的对象</p>\n<p>RuntimeError</p>\n<p>一般的运行时错误</p>\n<p>NotImplementedError</p>\n<p>尚未实现的方法</p>\n<p>SyntaxError</p>\n<p>Python 语法错误</p>\n<p>IndentationError</p>\n<p>缩进错误</p>\n<p>TabError</p>\n<p>Tab 和空格混用</p>\n<p>SystemError</p>\n<p>一般的解释器系统错误</p>\n<p>TypeError</p>\n<p>对类型无效的操作</p>\n<p>ValueError</p>\n<p>传入无效的参数</p>\n<p>UnicodeError</p>\n<p>Unicode 相关的错误</p>\n<p>UnicodeDecodeError</p>\n<p>Unicode 解码时的错误</p>\n<p>UnicodeEncodeError</p>\n<p>Unicode 编码时错误</p>\n<p>UnicodeTranslateError</p>\n<p>Unicode 转换时错误</p>\n<p>Warning</p>\n<p>警告的基类</p>\n<p>DeprecationWarning</p>\n<p>关于被弃用的特征的警告</p>\n<p>FutureWarning</p>\n<p>关于构造将来语义会有改变的警告</p>\n<p>OverflowWarning</p>\n<p>旧的关于自动提升为长整型(long)的警告</p>\n<p>PendingDeprecationWarning</p>\n<p>关于特性将会被废弃的警告</p>\n<p>RuntimeWarning</p>\n<p>可疑的运行时行为(runtime behavior)的警告</p>\n<p>SyntaxWarning</p>\n<p>可疑的语法的警告</p>\n<p>UserWarning</p>\n<p>用户代码生成的警告</p>\n<h2 id=\"二：python断言\"><a href=\"#二：python断言\" class=\"headerlink\" title=\"二：python断言\"></a>二：python断言</h2><p>使用assert断言是学习<strong><a href=\"http://www.iplaypy.com/\" title=\"python下载\" target=\"_blank\" rel=\"noopener\">python</a></strong>一个非常好的习惯，python <strong>assert 断言</strong>句语格式及用法很简单。在没完善一个程序之前，我们不知道程序在哪里会出错，与其让它在运行最崩溃，不如在出现错误条件时就崩溃，这时候就需要assert断言的帮助。本文主要是讲assert断言的基础知识。</p>\n<h2 id=\"python-assert断言的作用\"><a href=\"#python-assert断言的作用\" class=\"headerlink\" title=\"python assert断言的作用\"></a>python assert断言的作用</h2><p>python assert断言是声明其布尔值必须为真的判定，如果发生异常就说明表达示为假。可以理解assert断言语句为raise-if-not，用来测试表示式，其返回值为假，就会触发<a href=\"http://www.iplaypy.com/jichu/exception.html\" target=\"_blank\" rel=\"noopener\">异常</a>。</p>\n<h2 id=\"assert断言语句的语法格式\"><a href=\"#assert断言语句的语法格式\" class=\"headerlink\" title=\"assert断言语句的语法格式\"></a>assert断言语句的语法格式</h2><p>assert python 怎么用？ expression assert 表达式 下面做一些assert用法的语句供参考：<br>assert 1==1<br>assert 2+2==2*2<br>assert len([‘my boy’,12])&lt;10<br>assert range(4)==[0,1,2,3]</p>\n<h2 id=\"如何为assert断言语句添加异常参数\"><a href=\"#如何为assert断言语句添加异常参数\" class=\"headerlink\" title=\"如何为assert断言语句添加异常参数\"></a>如何为assert断言语句添加异常参数</h2><p>assert的异常参数，其实就是在断言表达式后添加<a href=\"http://www.iplaypy.com/jichu/str.html\" target=\"_blank\" rel=\"noopener\">字符串</a>信息，用来解释断言并更好的知道是哪里出了问题。格式如下： assert expression [, arguments]<br>assert 表达式 [, 参数]</p>\n"},{"title":"第十二节：文件IO，私有属性和方法","url":"244.html","id":"244","date":"2018-05-23T12:08:42.000Z","_content":"\n\n\n一；文件io\n------\n\n### 基本操作：\n\n文件的存储方式\n-------\n\n*   计算机中，文件是以二进制的方式保存的\n*   文本文件就是可以使用文本编辑器查看，二进制文件无法使用文本编辑器查看，是提供给其他软件使用的，例如图片，音视频等\n\n操作文件的套路\n-------\n\n1、打开文件open\n\n*   open函数负责打开文件， 并返回文件对象\n*   打开文件的方式有很多种，常用的如下：\n    *   r 只读，默认模式，如果文件不存在，抛出异常\n    *   w 只写，如果文件存在，则覆盖，不存在，则创建\n    *   a 追加，如果文件存在，指针会放在文件的结尾，不存在，创建新文件并写入\n    *   rb 以二进制读取内容\n    *   wb 以二进制写入内容 开发中更多的时候会以只读，只写的方式来操作文件 2、读写文件read，write\n*   read方法一次性读入并返回文件的所有内容，执行后，文件指针会移动到文件的末尾\n*   readline方法可以一次读取一行内容\n*   方法执行后，会把文件指针移动到下一行，准备再次读取，读取大文件时，使用此方法在while循环中，依次读取，节约内存 3、关闭文件close\n*   close，如果忘记关闭文件，会造成系统资源消耗，且会影响到后续对文件的访问\n\n**文件指针**\n\n*   文件指针标记从哪个位置开始读取数据\n*   第一次打开文件时，通常文件指针会指向文件的开始位置，当执行read后，文件指针移动到末尾\n*   在同一个python文件中，如果执行了read，那么再次使用此方法时，时无法获得内容的，可以使用seek方法改变指针位置\n\n文件/目录的常用管理操作\n------------\n\n在python中，使用代码实现文件目录操作，需要导入os模块 **文件操作** os.rename(源文件名，目标文件名) os.remove（文件名） **目录操作** os.listdir 目录列表，类似ls os.mkdir 创建目录，和linux一致 os.rmdir 删除目录 os.chdir 修改工作目录 os.getcwd 获取当前工作目录current work directory os.path.isdir（文件路径） 判断是否是目录 os.path.isfile 判断是否是文件\n\n### python 文件操作seek() 和 telll()  \n\nfile.seek()方法格式： seek(offset,whence=0)   移动文件读取指针到制定位置 offset:开始的偏移量，也就是代表需要移动偏移的字节数。 whence： 给offset参数一个定义，表示要从哪个位置开始偏移；0代表从文件开头算起，1代表开始从当前位置开始算起，2代表从文件末尾开始算起。当有换行时，会被换行截断。 seek（）无返回值，故值为None   tell() : 文科文件的当前位置，即tell是获取文件指针位置。 readline(n):读入若干行，n代表读入的最长字节数。 readlines() :读入所有行的内容 read读入所有行的内容\n\n### 上下文管理器\n\n普通版： def A1(): f=open(\"out.txt\",\"w\") f.write(\"123\") f.close() 威胁：如果调用异常，资源卡住，无法释放     升级版： def A1(): f=open(\"out.txt\",\"w\") try： f.write(\"123\") except IOError： print（“error”） finally： f.close() 优雅版： def A1（）： with open（“out.txt”，“w”） as f： f.write（“123”）\n\n### 优雅的With as语句\n\nPython提供了With语句语法，来构建对资源创建与释放的语法糖。给Database添加两个魔法方法：\n\n'''python\n\nclass  Database(object):\n\n\ndef \\_\\_enter\\_\\_(self):\n\nself.connect()\n\nreturn  self\n\ndef \\_\\_exit\\_\\_(self,  exc_type,  exc_val,  exc_tb):\n\nself.close()\n'''\n然后修改handle_query函数如下：\n\n\n\ndef handle_query():\n\nwith Database()  as  db:\n\nprint  'handle ---',  db.query()\n'''\n在Database类实例的时候，使用with语句。一切正常work。比起装饰器的版本，虽然多写了一些字符，但是代码可读性变强了\n\nio模块\n----\n\nStringIO顾名思义就是在内存中读写str。 要把str写入StringIO，我们需要先创建一个StringIO，然后，像文件一样写入即可：\n\n    from io import StringIO\n    f = StringIO()\n    print(f.write('hello py1 '))  # 10\n    print(f.write('hello py2 '))  # 10\n    print(f.write('hello py3 '))  # 10\n    print(f.getvalue()) # hello py1 hello py2 hello py3\n\n要读取StringIO，可以用一个str初始化StringIO，然后，像读文件一样读取：\n\n    from io import StringIO\n    f = StringIO('Hello!\\nHi!\\nGoodbye!')\n    print(f.read())\n\nStringIO操作的只能是str，如果要操作二进制数据，就需要使用BytesIO\n\n    from io import BytesIO\n    f = BytesIO() \n    print(f.write('中文'.encode('utf-8')))\n    # 请注意，写入的不是str，而是经过UTF-8编码的bytes\n    \n    print(f.getvalue()) # b'\\xe4\\xb8\\xad\\xe6\\x96\\x87'\n\n* * *\n\nBytesIO\n=======\n\n和StringIO类似，也可以用一个bytes初始化BytesIO，然后，像读文件一样读取：\n\n    from io import StringIO\n    f = BytesIO(b'\\xe4\\xb8\\xad\\xe6\\x96\\x87')\n    f.read()\n    b'\\xe4\\xb8\\xad\\xe6\\x96\\x87'\n\n* * *\n\nStringIO和BytesIO是在内存中操作str和bytes的方法，使得和读写文件具有一致的接口。  \n\nos模块\n----\n\n`os.getcwd() 获取当前工作目录，即当前python脚本工作的目录路径`\n\n`os.chdir(``\"dirname\"``)  改变当前脚本工作目录；相当于shell下cd`\n\n`os.curdir  返回当前目录: (``'.'``)`\n\n`os.pardir  获取当前目录的父目录字符串名：(``'..'``)`\n\n`os.makedirs(``'dirname1/dirname2'``)    可生成多层递归目录`\n\n`os.removedirs(``'dirname1'``)    若目录为空，则删除，并递归到上一级目录，如若也为空，则删除，依此类推`\n\n`os.mkdir(``'dirname'``)    生成单级目录；相当于shell中mkdir dirname`\n\n`os.rmdir(``'dirname'``)    删除单级空目录，若目录不为空则无法删除，报错；相当于shell中rmdir dirname`\n\n`os.listdir(``'dirname'``)    列出指定目录下的所有文件和子目录，包括隐藏文件，并以列表方式打印`\n\n`os.remove()  删除一个文件`\n\n`os.rename(``\"oldname\"``,``\"newname\"``)  重命名文件``/``目录`\n\n`os.stat(``'path/filename'``)  获取文件``/``目录信息`\n\n`os.sep    输出操作系统特定的路径分隔符，win下为``\"\\\\\",Linux下为\"``/``\"`\n\n`os.linesep    输出当前平台使用的行终止符，win下为``\"\\t\\n\"``,Linux下为``\"\\n\"`\n\n`os.pathsep    输出用于分割文件路径的字符串`\n\n`os.name    输出字符串指示当前使用平台。win``-``>``'nt'``; Linux``-``>``'posix'`\n\n`os.system(``\"bash command\"``)  运行shell命令，直接显示`\n\n`os.environ  获取系统环境变量`\n\n`os.path.abspath(path)  返回path规范化的绝对路径`\n\n`os.path.split(path)  将path分割成目录和文件名二元组返回`\n\n`os.path.dirname(path)  返回path的目录。其实就是os.path.split(path)的第一个元素`\n\n`os.path.basename(path)  返回path最后的文件名。如何path以／或\\结尾，那么就会返回空值。即os.path.split(path)的第二个元素`\n\n`os.path.exists(path)  如果path存在，返回``True``；如果path不存在，返回``False`\n\n`os.path.isabs(path)  如果path是绝对路径，返回``True`\n\n`os.path.isfile(path)  如果path是一个存在的文件，返回``True``。否则返回``False`\n\n`os.path.isdir(path)  如果path是一个存在的目录，则返回``True``。否则返回``False`\n\n`os.path.join(path1[, path2[, ...]])  将多个路径组合后返回，第一个绝对路径之前的参数将被忽略`\n\n`os.path.getatime(path)  返回path所指向的文件或者目录的最后存取时间`\n\n`os.path.getmtime(path)  返回path所指向的文件或者目录的最后修改时间`\n\n4.sys模块\n\n`sys.argv           命令行参数``List``，第一个元素是程序本身路径`\n\n`sys.exit(n)        退出程序，正常退出时exit(``0``)`\n\n`sys.version        获取Python解释程序的版本信息`\n\n`sys.maxint         最大的``Int``值`\n\n`sys.path           返回模块的搜索路径，初始化时使用PYTHONPATH环境变量的值`\n\n`sys.platform       返回操作系统平台名称`\n\n`sys.stdout.write(``'please:'``)`\n\n`val ``=``sys.stdin.readline()[:``-``1``]`\n\nshutil模块：https://docs.python.org/3/library/shutil.html?highlight=shutil#module-shutil\n\n私有属性和方法\n-------\n\n如果有一个对象，当需要对其进行修改属性时，有2种方法： （1）对象名.属性名=数据---->直接修改 （2）对象名.方法名()----->间接修改 为了更好的保障属性安全，不能随意修改，一般处理方式为： （1）将属性定义为私有属性 （2）添加一个可以调用的方法，供调用，也就是间接调用属性 私有方法是不能直接调用的\n","source":"_posts/第十二节：文件IO，私有属性和方法.md","raw":"---\ntitle: 第十二节：文件IO，私有属性和方法\ntags:\n  - 课后解答\nurl: 244.html\nid: 244\ncategories:\n - 学习\n - 教学\ndate: 2018-05-23 20:08:42\n---\n\n\n\n一；文件io\n------\n\n### 基本操作：\n\n文件的存储方式\n-------\n\n*   计算机中，文件是以二进制的方式保存的\n*   文本文件就是可以使用文本编辑器查看，二进制文件无法使用文本编辑器查看，是提供给其他软件使用的，例如图片，音视频等\n\n操作文件的套路\n-------\n\n1、打开文件open\n\n*   open函数负责打开文件， 并返回文件对象\n*   打开文件的方式有很多种，常用的如下：\n    *   r 只读，默认模式，如果文件不存在，抛出异常\n    *   w 只写，如果文件存在，则覆盖，不存在，则创建\n    *   a 追加，如果文件存在，指针会放在文件的结尾，不存在，创建新文件并写入\n    *   rb 以二进制读取内容\n    *   wb 以二进制写入内容 开发中更多的时候会以只读，只写的方式来操作文件 2、读写文件read，write\n*   read方法一次性读入并返回文件的所有内容，执行后，文件指针会移动到文件的末尾\n*   readline方法可以一次读取一行内容\n*   方法执行后，会把文件指针移动到下一行，准备再次读取，读取大文件时，使用此方法在while循环中，依次读取，节约内存 3、关闭文件close\n*   close，如果忘记关闭文件，会造成系统资源消耗，且会影响到后续对文件的访问\n\n**文件指针**\n\n*   文件指针标记从哪个位置开始读取数据\n*   第一次打开文件时，通常文件指针会指向文件的开始位置，当执行read后，文件指针移动到末尾\n*   在同一个python文件中，如果执行了read，那么再次使用此方法时，时无法获得内容的，可以使用seek方法改变指针位置\n\n文件/目录的常用管理操作\n------------\n\n在python中，使用代码实现文件目录操作，需要导入os模块 **文件操作** os.rename(源文件名，目标文件名) os.remove（文件名） **目录操作** os.listdir 目录列表，类似ls os.mkdir 创建目录，和linux一致 os.rmdir 删除目录 os.chdir 修改工作目录 os.getcwd 获取当前工作目录current work directory os.path.isdir（文件路径） 判断是否是目录 os.path.isfile 判断是否是文件\n\n### python 文件操作seek() 和 telll()  \n\nfile.seek()方法格式： seek(offset,whence=0)   移动文件读取指针到制定位置 offset:开始的偏移量，也就是代表需要移动偏移的字节数。 whence： 给offset参数一个定义，表示要从哪个位置开始偏移；0代表从文件开头算起，1代表开始从当前位置开始算起，2代表从文件末尾开始算起。当有换行时，会被换行截断。 seek（）无返回值，故值为None   tell() : 文科文件的当前位置，即tell是获取文件指针位置。 readline(n):读入若干行，n代表读入的最长字节数。 readlines() :读入所有行的内容 read读入所有行的内容\n\n### 上下文管理器\n\n普通版： def A1(): f=open(\"out.txt\",\"w\") f.write(\"123\") f.close() 威胁：如果调用异常，资源卡住，无法释放     升级版： def A1(): f=open(\"out.txt\",\"w\") try： f.write(\"123\") except IOError： print（“error”） finally： f.close() 优雅版： def A1（）： with open（“out.txt”，“w”） as f： f.write（“123”）\n\n### 优雅的With as语句\n\nPython提供了With语句语法，来构建对资源创建与释放的语法糖。给Database添加两个魔法方法：\n\n'''python\n\nclass  Database(object):\n\n\ndef \\_\\_enter\\_\\_(self):\n\nself.connect()\n\nreturn  self\n\ndef \\_\\_exit\\_\\_(self,  exc_type,  exc_val,  exc_tb):\n\nself.close()\n'''\n然后修改handle_query函数如下：\n\n\n\ndef handle_query():\n\nwith Database()  as  db:\n\nprint  'handle ---',  db.query()\n'''\n在Database类实例的时候，使用with语句。一切正常work。比起装饰器的版本，虽然多写了一些字符，但是代码可读性变强了\n\nio模块\n----\n\nStringIO顾名思义就是在内存中读写str。 要把str写入StringIO，我们需要先创建一个StringIO，然后，像文件一样写入即可：\n\n    from io import StringIO\n    f = StringIO()\n    print(f.write('hello py1 '))  # 10\n    print(f.write('hello py2 '))  # 10\n    print(f.write('hello py3 '))  # 10\n    print(f.getvalue()) # hello py1 hello py2 hello py3\n\n要读取StringIO，可以用一个str初始化StringIO，然后，像读文件一样读取：\n\n    from io import StringIO\n    f = StringIO('Hello!\\nHi!\\nGoodbye!')\n    print(f.read())\n\nStringIO操作的只能是str，如果要操作二进制数据，就需要使用BytesIO\n\n    from io import BytesIO\n    f = BytesIO() \n    print(f.write('中文'.encode('utf-8')))\n    # 请注意，写入的不是str，而是经过UTF-8编码的bytes\n    \n    print(f.getvalue()) # b'\\xe4\\xb8\\xad\\xe6\\x96\\x87'\n\n* * *\n\nBytesIO\n=======\n\n和StringIO类似，也可以用一个bytes初始化BytesIO，然后，像读文件一样读取：\n\n    from io import StringIO\n    f = BytesIO(b'\\xe4\\xb8\\xad\\xe6\\x96\\x87')\n    f.read()\n    b'\\xe4\\xb8\\xad\\xe6\\x96\\x87'\n\n* * *\n\nStringIO和BytesIO是在内存中操作str和bytes的方法，使得和读写文件具有一致的接口。  \n\nos模块\n----\n\n`os.getcwd() 获取当前工作目录，即当前python脚本工作的目录路径`\n\n`os.chdir(``\"dirname\"``)  改变当前脚本工作目录；相当于shell下cd`\n\n`os.curdir  返回当前目录: (``'.'``)`\n\n`os.pardir  获取当前目录的父目录字符串名：(``'..'``)`\n\n`os.makedirs(``'dirname1/dirname2'``)    可生成多层递归目录`\n\n`os.removedirs(``'dirname1'``)    若目录为空，则删除，并递归到上一级目录，如若也为空，则删除，依此类推`\n\n`os.mkdir(``'dirname'``)    生成单级目录；相当于shell中mkdir dirname`\n\n`os.rmdir(``'dirname'``)    删除单级空目录，若目录不为空则无法删除，报错；相当于shell中rmdir dirname`\n\n`os.listdir(``'dirname'``)    列出指定目录下的所有文件和子目录，包括隐藏文件，并以列表方式打印`\n\n`os.remove()  删除一个文件`\n\n`os.rename(``\"oldname\"``,``\"newname\"``)  重命名文件``/``目录`\n\n`os.stat(``'path/filename'``)  获取文件``/``目录信息`\n\n`os.sep    输出操作系统特定的路径分隔符，win下为``\"\\\\\",Linux下为\"``/``\"`\n\n`os.linesep    输出当前平台使用的行终止符，win下为``\"\\t\\n\"``,Linux下为``\"\\n\"`\n\n`os.pathsep    输出用于分割文件路径的字符串`\n\n`os.name    输出字符串指示当前使用平台。win``-``>``'nt'``; Linux``-``>``'posix'`\n\n`os.system(``\"bash command\"``)  运行shell命令，直接显示`\n\n`os.environ  获取系统环境变量`\n\n`os.path.abspath(path)  返回path规范化的绝对路径`\n\n`os.path.split(path)  将path分割成目录和文件名二元组返回`\n\n`os.path.dirname(path)  返回path的目录。其实就是os.path.split(path)的第一个元素`\n\n`os.path.basename(path)  返回path最后的文件名。如何path以／或\\结尾，那么就会返回空值。即os.path.split(path)的第二个元素`\n\n`os.path.exists(path)  如果path存在，返回``True``；如果path不存在，返回``False`\n\n`os.path.isabs(path)  如果path是绝对路径，返回``True`\n\n`os.path.isfile(path)  如果path是一个存在的文件，返回``True``。否则返回``False`\n\n`os.path.isdir(path)  如果path是一个存在的目录，则返回``True``。否则返回``False`\n\n`os.path.join(path1[, path2[, ...]])  将多个路径组合后返回，第一个绝对路径之前的参数将被忽略`\n\n`os.path.getatime(path)  返回path所指向的文件或者目录的最后存取时间`\n\n`os.path.getmtime(path)  返回path所指向的文件或者目录的最后修改时间`\n\n4.sys模块\n\n`sys.argv           命令行参数``List``，第一个元素是程序本身路径`\n\n`sys.exit(n)        退出程序，正常退出时exit(``0``)`\n\n`sys.version        获取Python解释程序的版本信息`\n\n`sys.maxint         最大的``Int``值`\n\n`sys.path           返回模块的搜索路径，初始化时使用PYTHONPATH环境变量的值`\n\n`sys.platform       返回操作系统平台名称`\n\n`sys.stdout.write(``'please:'``)`\n\n`val ``=``sys.stdin.readline()[:``-``1``]`\n\nshutil模块：https://docs.python.org/3/library/shutil.html?highlight=shutil#module-shutil\n\n私有属性和方法\n-------\n\n如果有一个对象，当需要对其进行修改属性时，有2种方法： （1）对象名.属性名=数据---->直接修改 （2）对象名.方法名()----->间接修改 为了更好的保障属性安全，不能随意修改，一般处理方式为： （1）将属性定义为私有属性 （2）添加一个可以调用的方法，供调用，也就是间接调用属性 私有方法是不能直接调用的\n","slug":"第十二节：文件IO，私有属性和方法","published":1,"updated":"2021-07-26T09:58:02.571Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m350048igtaf306c3w4","content":"<h2 id=\"一；文件io\"><a href=\"#一；文件io\" class=\"headerlink\" title=\"一；文件io\"></a>一；文件io</h2><h3 id=\"基本操作：\"><a href=\"#基本操作：\" class=\"headerlink\" title=\"基本操作：\"></a>基本操作：</h3><h2 id=\"文件的存储方式\"><a href=\"#文件的存储方式\" class=\"headerlink\" title=\"文件的存储方式\"></a>文件的存储方式</h2><ul>\n<li>计算机中，文件是以二进制的方式保存的</li>\n<li>文本文件就是可以使用文本编辑器查看，二进制文件无法使用文本编辑器查看，是提供给其他软件使用的，例如图片，音视频等</li>\n</ul>\n<h2 id=\"操作文件的套路\"><a href=\"#操作文件的套路\" class=\"headerlink\" title=\"操作文件的套路\"></a>操作文件的套路</h2><p>1、打开文件open</p>\n<ul>\n<li>open函数负责打开文件， 并返回文件对象</li>\n<li>打开文件的方式有很多种，常用的如下：<ul>\n<li>r 只读，默认模式，如果文件不存在，抛出异常</li>\n<li>w 只写，如果文件存在，则覆盖，不存在，则创建</li>\n<li>a 追加，如果文件存在，指针会放在文件的结尾，不存在，创建新文件并写入</li>\n<li>rb 以二进制读取内容</li>\n<li>wb 以二进制写入内容 开发中更多的时候会以只读，只写的方式来操作文件 2、读写文件read，write</li>\n</ul>\n</li>\n<li>read方法一次性读入并返回文件的所有内容，执行后，文件指针会移动到文件的末尾</li>\n<li>readline方法可以一次读取一行内容</li>\n<li>方法执行后，会把文件指针移动到下一行，准备再次读取，读取大文件时，使用此方法在while循环中，依次读取，节约内存 3、关闭文件close</li>\n<li>close，如果忘记关闭文件，会造成系统资源消耗，且会影响到后续对文件的访问</li>\n</ul>\n<p><strong>文件指针</strong></p>\n<ul>\n<li>文件指针标记从哪个位置开始读取数据</li>\n<li>第一次打开文件时，通常文件指针会指向文件的开始位置，当执行read后，文件指针移动到末尾</li>\n<li>在同一个python文件中，如果执行了read，那么再次使用此方法时，时无法获得内容的，可以使用seek方法改变指针位置</li>\n</ul>\n<h2 id=\"文件-目录的常用管理操作\"><a href=\"#文件-目录的常用管理操作\" class=\"headerlink\" title=\"文件/目录的常用管理操作\"></a>文件/目录的常用管理操作</h2><p>在python中，使用代码实现文件目录操作，需要导入os模块 <strong>文件操作</strong> os.rename(源文件名，目标文件名) os.remove（文件名） <strong>目录操作</strong> os.listdir 目录列表，类似ls os.mkdir 创建目录，和linux一致 os.rmdir 删除目录 os.chdir 修改工作目录 os.getcwd 获取当前工作目录current work directory os.path.isdir（文件路径） 判断是否是目录 os.path.isfile 判断是否是文件</p>\n<h3 id=\"python-文件操作seek-和-telll\"><a href=\"#python-文件操作seek-和-telll\" class=\"headerlink\" title=\"python 文件操作seek() 和 telll()\"></a>python 文件操作seek() 和 telll()</h3><p>file.seek()方法格式： seek(offset,whence=0)   移动文件读取指针到制定位置 offset:开始的偏移量，也就是代表需要移动偏移的字节数。 whence： 给offset参数一个定义，表示要从哪个位置开始偏移；0代表从文件开头算起，1代表开始从当前位置开始算起，2代表从文件末尾开始算起。当有换行时，会被换行截断。 seek（）无返回值，故值为None   tell() : 文科文件的当前位置，即tell是获取文件指针位置。 readline(n):读入若干行，n代表读入的最长字节数。 readlines() :读入所有行的内容 read读入所有行的内容</p>\n<h3 id=\"上下文管理器\"><a href=\"#上下文管理器\" class=\"headerlink\" title=\"上下文管理器\"></a>上下文管理器</h3><p>普通版： def A1(): f=open(“out.txt”,”w”) f.write(“123”) f.close() 威胁：如果调用异常，资源卡住，无法释放     升级版： def A1(): f=open(“out.txt”,”w”) try： f.write(“123”) except IOError： print（“error”） finally： f.close() 优雅版： def A1（）： with open（“out.txt”，“w”） as f： f.write（“123”）</p>\n<h3 id=\"优雅的With-as语句\"><a href=\"#优雅的With-as语句\" class=\"headerlink\" title=\"优雅的With as语句\"></a>优雅的With as语句</h3><p>Python提供了With语句语法，来构建对资源创建与释放的语法糖。给Database添加两个魔法方法：</p>\n<p>‘’’python</p>\n<p>class  Database(object):</p>\n<p>def __enter__(self):</p>\n<p>self.connect()</p>\n<p>return  self</p>\n<p>def __exit__(self,  exc_type,  exc_val,  exc_tb):</p>\n<p>self.close()<br>‘’’<br>然后修改handle_query函数如下：</p>\n<p>def handle_query():</p>\n<p>with Database()  as  db:</p>\n<p>print  ‘handle —‘,  db.query()<br>‘’’<br>在Database类实例的时候，使用with语句。一切正常work。比起装饰器的版本，虽然多写了一些字符，但是代码可读性变强了</p>\n<h2 id=\"io模块\"><a href=\"#io模块\" class=\"headerlink\" title=\"io模块\"></a>io模块</h2><p>StringIO顾名思义就是在内存中读写str。 要把str写入StringIO，我们需要先创建一个StringIO，然后，像文件一样写入即可：</p>\n<pre><code>from io import StringIO\nf = StringIO()\nprint(f.write(&apos;hello py1 &apos;))  # 10\nprint(f.write(&apos;hello py2 &apos;))  # 10\nprint(f.write(&apos;hello py3 &apos;))  # 10\nprint(f.getvalue()) # hello py1 hello py2 hello py3\n</code></pre><p>要读取StringIO，可以用一个str初始化StringIO，然后，像读文件一样读取：</p>\n<pre><code>from io import StringIO\nf = StringIO(&apos;Hello!\\nHi!\\nGoodbye!&apos;)\nprint(f.read())\n</code></pre><p>StringIO操作的只能是str，如果要操作二进制数据，就需要使用BytesIO</p>\n<pre><code>from io import BytesIO\nf = BytesIO() \nprint(f.write(&apos;中文&apos;.encode(&apos;utf-8&apos;)))\n# 请注意，写入的不是str，而是经过UTF-8编码的bytes\n\nprint(f.getvalue()) # b&apos;\\xe4\\xb8\\xad\\xe6\\x96\\x87&apos;\n</code></pre><hr>\n<h1 id=\"BytesIO\"><a href=\"#BytesIO\" class=\"headerlink\" title=\"BytesIO\"></a>BytesIO</h1><p>和StringIO类似，也可以用一个bytes初始化BytesIO，然后，像读文件一样读取：</p>\n<pre><code>from io import StringIO\nf = BytesIO(b&apos;\\xe4\\xb8\\xad\\xe6\\x96\\x87&apos;)\nf.read()\nb&apos;\\xe4\\xb8\\xad\\xe6\\x96\\x87&apos;\n</code></pre><hr>\n<p>StringIO和BytesIO是在内存中操作str和bytes的方法，使得和读写文件具有一致的接口。  </p>\n<h2 id=\"os模块\"><a href=\"#os模块\" class=\"headerlink\" title=\"os模块\"></a>os模块</h2><p><code>os.getcwd() 获取当前工作目录，即当前python脚本工作的目录路径</code></p>\n<p><code>os.chdir(`</code>“dirname”<code></code>)  改变当前脚本工作目录；相当于shell下cd`</p>\n<p><code>os.curdir  返回当前目录: (`</code>‘.’<code></code>)`</p>\n<p><code>os.pardir  获取当前目录的父目录字符串名：(`</code>‘..’<code></code>)`</p>\n<p><code>os.makedirs(`</code>‘dirname1/dirname2’<code></code>)    可生成多层递归目录`</p>\n<p><code>os.removedirs(`</code>‘dirname1’<code></code>)    若目录为空，则删除，并递归到上一级目录，如若也为空，则删除，依此类推`</p>\n<p><code>os.mkdir(`</code>‘dirname’<code></code>)    生成单级目录；相当于shell中mkdir dirname`</p>\n<p><code>os.rmdir(`</code>‘dirname’<code></code>)    删除单级空目录，若目录不为空则无法删除，报错；相当于shell中rmdir dirname`</p>\n<p><code>os.listdir(`</code>‘dirname’<code></code>)    列出指定目录下的所有文件和子目录，包括隐藏文件，并以列表方式打印`</p>\n<p><code>os.remove()  删除一个文件</code></p>\n<p><code>os.rename(`</code>“oldname”<code>,</code>“newname”<code>)  重命名文件</code>/<code></code>目录`</p>\n<p><code>os.stat(`</code>‘path/filename’<code>)  获取文件</code>/<code></code>目录信息`</p>\n<p><code>os.sep    输出操作系统特定的路径分隔符，win下为`</code>“\\“,Linux下为”<code>/</code>“`</p>\n<p><code>os.linesep    输出当前平台使用的行终止符，win下为`</code>“\\t\\n”<code>,Linux下为</code>“\\n”`</p>\n<p><code>os.pathsep    输出用于分割文件路径的字符串</code></p>\n<p><code>os.name    输出字符串指示当前使用平台。win`</code>-<code>&gt;</code>‘nt’<code>; Linux</code>-<code>&gt;</code>‘posix’`</p>\n<p><code>os.system(`</code>“bash command”<code></code>)  运行shell命令，直接显示`</p>\n<p><code>os.environ  获取系统环境变量</code></p>\n<p><code>os.path.abspath(path)  返回path规范化的绝对路径</code></p>\n<p><code>os.path.split(path)  将path分割成目录和文件名二元组返回</code></p>\n<p><code>os.path.dirname(path)  返回path的目录。其实就是os.path.split(path)的第一个元素</code></p>\n<p><code>os.path.basename(path)  返回path最后的文件名。如何path以／或\\结尾，那么就会返回空值。即os.path.split(path)的第二个元素</code></p>\n<p><code>os.path.exists(path)  如果path存在，返回`</code>True<code>；如果path不存在，返回</code>False`</p>\n<p><code>os.path.isabs(path)  如果path是绝对路径，返回`</code>True`</p>\n<p><code>os.path.isfile(path)  如果path是一个存在的文件，返回`</code>True<code>。否则返回</code>False`</p>\n<p><code>os.path.isdir(path)  如果path是一个存在的目录，则返回`</code>True<code>。否则返回</code>False`</p>\n<p><code>os.path.join(path1[, path2[, ...]])  将多个路径组合后返回，第一个绝对路径之前的参数将被忽略</code></p>\n<p><code>os.path.getatime(path)  返回path所指向的文件或者目录的最后存取时间</code></p>\n<p><code>os.path.getmtime(path)  返回path所指向的文件或者目录的最后修改时间</code></p>\n<p>4.sys模块</p>\n<p><code>sys.argv           命令行参数`</code>List<code></code>，第一个元素是程序本身路径`</p>\n<p><code>sys.exit(n)        退出程序，正常退出时exit(`</code>0<code></code>)`</p>\n<p><code>sys.version        获取Python解释程序的版本信息</code></p>\n<p><code>sys.maxint         最大的`</code>Int<code></code>值`</p>\n<p><code>sys.path           返回模块的搜索路径，初始化时使用PYTHONPATH环境变量的值</code></p>\n<p><code>sys.platform       返回操作系统平台名称</code></p>\n<p><code>sys.stdout.write(`</code>‘please:’<code></code>)`</p>\n<p><code>val `</code>=<code>sys.stdin.readline()[:</code>-<code>1</code>]`</p>\n<p>shutil模块：<a href=\"https://docs.python.org/3/library/shutil.html?highlight=shutil#module-shutil\" target=\"_blank\" rel=\"noopener\">https://docs.python.org/3/library/shutil.html?highlight=shutil#module-shutil</a></p>\n<h2 id=\"私有属性和方法\"><a href=\"#私有属性和方法\" class=\"headerlink\" title=\"私有属性和方法\"></a>私有属性和方法</h2><p>如果有一个对象，当需要对其进行修改属性时，有2种方法： （1）对象名.属性名=数据—-&gt;直接修改 （2）对象名.方法名()—–&gt;间接修改 为了更好的保障属性安全，不能随意修改，一般处理方式为： （1）将属性定义为私有属性 （2）添加一个可以调用的方法，供调用，也就是间接调用属性 私有方法是不能直接调用的</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"一；文件io\"><a href=\"#一；文件io\" class=\"headerlink\" title=\"一；文件io\"></a>一；文件io</h2><h3 id=\"基本操作：\"><a href=\"#基本操作：\" class=\"headerlink\" title=\"基本操作：\"></a>基本操作：</h3><h2 id=\"文件的存储方式\"><a href=\"#文件的存储方式\" class=\"headerlink\" title=\"文件的存储方式\"></a>文件的存储方式</h2><ul>\n<li>计算机中，文件是以二进制的方式保存的</li>\n<li>文本文件就是可以使用文本编辑器查看，二进制文件无法使用文本编辑器查看，是提供给其他软件使用的，例如图片，音视频等</li>\n</ul>\n<h2 id=\"操作文件的套路\"><a href=\"#操作文件的套路\" class=\"headerlink\" title=\"操作文件的套路\"></a>操作文件的套路</h2><p>1、打开文件open</p>\n<ul>\n<li>open函数负责打开文件， 并返回文件对象</li>\n<li>打开文件的方式有很多种，常用的如下：<ul>\n<li>r 只读，默认模式，如果文件不存在，抛出异常</li>\n<li>w 只写，如果文件存在，则覆盖，不存在，则创建</li>\n<li>a 追加，如果文件存在，指针会放在文件的结尾，不存在，创建新文件并写入</li>\n<li>rb 以二进制读取内容</li>\n<li>wb 以二进制写入内容 开发中更多的时候会以只读，只写的方式来操作文件 2、读写文件read，write</li>\n</ul>\n</li>\n<li>read方法一次性读入并返回文件的所有内容，执行后，文件指针会移动到文件的末尾</li>\n<li>readline方法可以一次读取一行内容</li>\n<li>方法执行后，会把文件指针移动到下一行，准备再次读取，读取大文件时，使用此方法在while循环中，依次读取，节约内存 3、关闭文件close</li>\n<li>close，如果忘记关闭文件，会造成系统资源消耗，且会影响到后续对文件的访问</li>\n</ul>\n<p><strong>文件指针</strong></p>\n<ul>\n<li>文件指针标记从哪个位置开始读取数据</li>\n<li>第一次打开文件时，通常文件指针会指向文件的开始位置，当执行read后，文件指针移动到末尾</li>\n<li>在同一个python文件中，如果执行了read，那么再次使用此方法时，时无法获得内容的，可以使用seek方法改变指针位置</li>\n</ul>\n<h2 id=\"文件-目录的常用管理操作\"><a href=\"#文件-目录的常用管理操作\" class=\"headerlink\" title=\"文件/目录的常用管理操作\"></a>文件/目录的常用管理操作</h2><p>在python中，使用代码实现文件目录操作，需要导入os模块 <strong>文件操作</strong> os.rename(源文件名，目标文件名) os.remove（文件名） <strong>目录操作</strong> os.listdir 目录列表，类似ls os.mkdir 创建目录，和linux一致 os.rmdir 删除目录 os.chdir 修改工作目录 os.getcwd 获取当前工作目录current work directory os.path.isdir（文件路径） 判断是否是目录 os.path.isfile 判断是否是文件</p>\n<h3 id=\"python-文件操作seek-和-telll\"><a href=\"#python-文件操作seek-和-telll\" class=\"headerlink\" title=\"python 文件操作seek() 和 telll()\"></a>python 文件操作seek() 和 telll()</h3><p>file.seek()方法格式： seek(offset,whence=0)   移动文件读取指针到制定位置 offset:开始的偏移量，也就是代表需要移动偏移的字节数。 whence： 给offset参数一个定义，表示要从哪个位置开始偏移；0代表从文件开头算起，1代表开始从当前位置开始算起，2代表从文件末尾开始算起。当有换行时，会被换行截断。 seek（）无返回值，故值为None   tell() : 文科文件的当前位置，即tell是获取文件指针位置。 readline(n):读入若干行，n代表读入的最长字节数。 readlines() :读入所有行的内容 read读入所有行的内容</p>\n<h3 id=\"上下文管理器\"><a href=\"#上下文管理器\" class=\"headerlink\" title=\"上下文管理器\"></a>上下文管理器</h3><p>普通版： def A1(): f=open(“out.txt”,”w”) f.write(“123”) f.close() 威胁：如果调用异常，资源卡住，无法释放     升级版： def A1(): f=open(“out.txt”,”w”) try： f.write(“123”) except IOError： print（“error”） finally： f.close() 优雅版： def A1（）： with open（“out.txt”，“w”） as f： f.write（“123”）</p>\n<h3 id=\"优雅的With-as语句\"><a href=\"#优雅的With-as语句\" class=\"headerlink\" title=\"优雅的With as语句\"></a>优雅的With as语句</h3><p>Python提供了With语句语法，来构建对资源创建与释放的语法糖。给Database添加两个魔法方法：</p>\n<p>‘’’python</p>\n<p>class  Database(object):</p>\n<p>def __enter__(self):</p>\n<p>self.connect()</p>\n<p>return  self</p>\n<p>def __exit__(self,  exc_type,  exc_val,  exc_tb):</p>\n<p>self.close()<br>‘’’<br>然后修改handle_query函数如下：</p>\n<p>def handle_query():</p>\n<p>with Database()  as  db:</p>\n<p>print  ‘handle —‘,  db.query()<br>‘’’<br>在Database类实例的时候，使用with语句。一切正常work。比起装饰器的版本，虽然多写了一些字符，但是代码可读性变强了</p>\n<h2 id=\"io模块\"><a href=\"#io模块\" class=\"headerlink\" title=\"io模块\"></a>io模块</h2><p>StringIO顾名思义就是在内存中读写str。 要把str写入StringIO，我们需要先创建一个StringIO，然后，像文件一样写入即可：</p>\n<pre><code>from io import StringIO\nf = StringIO()\nprint(f.write(&apos;hello py1 &apos;))  # 10\nprint(f.write(&apos;hello py2 &apos;))  # 10\nprint(f.write(&apos;hello py3 &apos;))  # 10\nprint(f.getvalue()) # hello py1 hello py2 hello py3\n</code></pre><p>要读取StringIO，可以用一个str初始化StringIO，然后，像读文件一样读取：</p>\n<pre><code>from io import StringIO\nf = StringIO(&apos;Hello!\\nHi!\\nGoodbye!&apos;)\nprint(f.read())\n</code></pre><p>StringIO操作的只能是str，如果要操作二进制数据，就需要使用BytesIO</p>\n<pre><code>from io import BytesIO\nf = BytesIO() \nprint(f.write(&apos;中文&apos;.encode(&apos;utf-8&apos;)))\n# 请注意，写入的不是str，而是经过UTF-8编码的bytes\n\nprint(f.getvalue()) # b&apos;\\xe4\\xb8\\xad\\xe6\\x96\\x87&apos;\n</code></pre><hr>\n<h1 id=\"BytesIO\"><a href=\"#BytesIO\" class=\"headerlink\" title=\"BytesIO\"></a>BytesIO</h1><p>和StringIO类似，也可以用一个bytes初始化BytesIO，然后，像读文件一样读取：</p>\n<pre><code>from io import StringIO\nf = BytesIO(b&apos;\\xe4\\xb8\\xad\\xe6\\x96\\x87&apos;)\nf.read()\nb&apos;\\xe4\\xb8\\xad\\xe6\\x96\\x87&apos;\n</code></pre><hr>\n<p>StringIO和BytesIO是在内存中操作str和bytes的方法，使得和读写文件具有一致的接口。  </p>\n<h2 id=\"os模块\"><a href=\"#os模块\" class=\"headerlink\" title=\"os模块\"></a>os模块</h2><p><code>os.getcwd() 获取当前工作目录，即当前python脚本工作的目录路径</code></p>\n<p><code>os.chdir(`</code>“dirname”<code></code>)  改变当前脚本工作目录；相当于shell下cd`</p>\n<p><code>os.curdir  返回当前目录: (`</code>‘.’<code></code>)`</p>\n<p><code>os.pardir  获取当前目录的父目录字符串名：(`</code>‘..’<code></code>)`</p>\n<p><code>os.makedirs(`</code>‘dirname1/dirname2’<code></code>)    可生成多层递归目录`</p>\n<p><code>os.removedirs(`</code>‘dirname1’<code></code>)    若目录为空，则删除，并递归到上一级目录，如若也为空，则删除，依此类推`</p>\n<p><code>os.mkdir(`</code>‘dirname’<code></code>)    生成单级目录；相当于shell中mkdir dirname`</p>\n<p><code>os.rmdir(`</code>‘dirname’<code></code>)    删除单级空目录，若目录不为空则无法删除，报错；相当于shell中rmdir dirname`</p>\n<p><code>os.listdir(`</code>‘dirname’<code></code>)    列出指定目录下的所有文件和子目录，包括隐藏文件，并以列表方式打印`</p>\n<p><code>os.remove()  删除一个文件</code></p>\n<p><code>os.rename(`</code>“oldname”<code>,</code>“newname”<code>)  重命名文件</code>/<code></code>目录`</p>\n<p><code>os.stat(`</code>‘path/filename’<code>)  获取文件</code>/<code></code>目录信息`</p>\n<p><code>os.sep    输出操作系统特定的路径分隔符，win下为`</code>“\\“,Linux下为”<code>/</code>“`</p>\n<p><code>os.linesep    输出当前平台使用的行终止符，win下为`</code>“\\t\\n”<code>,Linux下为</code>“\\n”`</p>\n<p><code>os.pathsep    输出用于分割文件路径的字符串</code></p>\n<p><code>os.name    输出字符串指示当前使用平台。win`</code>-<code>&gt;</code>‘nt’<code>; Linux</code>-<code>&gt;</code>‘posix’`</p>\n<p><code>os.system(`</code>“bash command”<code></code>)  运行shell命令，直接显示`</p>\n<p><code>os.environ  获取系统环境变量</code></p>\n<p><code>os.path.abspath(path)  返回path规范化的绝对路径</code></p>\n<p><code>os.path.split(path)  将path分割成目录和文件名二元组返回</code></p>\n<p><code>os.path.dirname(path)  返回path的目录。其实就是os.path.split(path)的第一个元素</code></p>\n<p><code>os.path.basename(path)  返回path最后的文件名。如何path以／或\\结尾，那么就会返回空值。即os.path.split(path)的第二个元素</code></p>\n<p><code>os.path.exists(path)  如果path存在，返回`</code>True<code>；如果path不存在，返回</code>False`</p>\n<p><code>os.path.isabs(path)  如果path是绝对路径，返回`</code>True`</p>\n<p><code>os.path.isfile(path)  如果path是一个存在的文件，返回`</code>True<code>。否则返回</code>False`</p>\n<p><code>os.path.isdir(path)  如果path是一个存在的目录，则返回`</code>True<code>。否则返回</code>False`</p>\n<p><code>os.path.join(path1[, path2[, ...]])  将多个路径组合后返回，第一个绝对路径之前的参数将被忽略</code></p>\n<p><code>os.path.getatime(path)  返回path所指向的文件或者目录的最后存取时间</code></p>\n<p><code>os.path.getmtime(path)  返回path所指向的文件或者目录的最后修改时间</code></p>\n<p>4.sys模块</p>\n<p><code>sys.argv           命令行参数`</code>List<code></code>，第一个元素是程序本身路径`</p>\n<p><code>sys.exit(n)        退出程序，正常退出时exit(`</code>0<code></code>)`</p>\n<p><code>sys.version        获取Python解释程序的版本信息</code></p>\n<p><code>sys.maxint         最大的`</code>Int<code></code>值`</p>\n<p><code>sys.path           返回模块的搜索路径，初始化时使用PYTHONPATH环境变量的值</code></p>\n<p><code>sys.platform       返回操作系统平台名称</code></p>\n<p><code>sys.stdout.write(`</code>‘please:’<code></code>)`</p>\n<p><code>val `</code>=<code>sys.stdin.readline()[:</code>-<code>1</code>]`</p>\n<p>shutil模块：<a href=\"https://docs.python.org/3/library/shutil.html?highlight=shutil#module-shutil\" target=\"_blank\" rel=\"noopener\">https://docs.python.org/3/library/shutil.html?highlight=shutil#module-shutil</a></p>\n<h2 id=\"私有属性和方法\"><a href=\"#私有属性和方法\" class=\"headerlink\" title=\"私有属性和方法\"></a>私有属性和方法</h2><p>如果有一个对象，当需要对其进行修改属性时，有2种方法： （1）对象名.属性名=数据—-&gt;直接修改 （2）对象名.方法名()—–&gt;间接修改 为了更好的保障属性安全，不能随意修改，一般处理方式为： （1）将属性定义为私有属性 （2）添加一个可以调用的方法，供调用，也就是间接调用属性 私有方法是不能直接调用的</p>\n"},{"title":"第十五节：正则表达式","url":"250.html","id":"250","date":"2018-05-30T07:23:13.000Z","_content":"\n\n\n### 1.1正则表达式的大致匹配过程是：\n\n1.依次拿出表达式和文本中的字符比较， 2.如果每一个字符都能匹配，则匹配成功；一旦有匹配不成功的字符则匹配失败。 3.如果表达式中有量词或边界，这个过程会稍微有一些不同。\n\n### 1.2. 数量词的贪婪模式与非贪婪模式\n\n正则表达式通常用于在文本中查找匹配的字符串。 贪婪模式，总是尝试匹配尽可能多的字符； 非贪婪模式则相反，总是尝试匹配尽可能少的字符。 Python里数量词默认是贪婪的。 例如：正则表达式\"ab*\"如果用于查找\"abbbc\"，将找到\"abbb\"。 而如果使用非贪婪的数量词\"ab*?\"，将找到\"a\"。    \n\n正则表达式\n\n代表的匹配字符\n\n\\[0-9\\]\n\n0123456789任意之一\n\n\\[a-z\\]\n\n小写字母任意之一\n\n\\[A-Z\\]\n\n大写字母任意之一\n\n\\\\d\n\n等同于\\[0-9\\]\n\n\\\\D\n\n等同于\\[^0-9\\]匹配非数字\n\n\\\\w\n\n等同于\\[a-z0-9A-Z_\\]匹配大小写字母、数字和下划线\n\n\\\\W\n\n等同于\\[^a-z0-9A-Z_\\]等同于上一条取非\n\n下面列举一些正则表达式里的元字符及其作用\n\n元字符\n\n说明\n\n.\n\n代表任意字符\n\n|\n\n逻辑或操作符\n\n\\[ \\]\n\n匹配内部的任一字符或子表达式\n\n\\[^\\]\n\n对字符集和取非\n\n-\n\n定义一个区间\n\n\\\n\n对下一字符取非（通常是普通变特殊，特殊变普通）\n\n*\n\n匹配前面的字符或者子表达式0次或多次\n\n*?\n\n惰性匹配上一个\n\n+\n\n匹配前一个字符或子表达式一次或多次\n\n+?\n\n惰性匹配上一个\n\n?\n\n匹配前一个字符或子表达式0次或1次重复\n\n{n}\n\n匹配前一个字符或子表达式\n\n{m,n}\n\n匹配前一个字符或子表达式至少m次至多n次\n\n{n,}\n\n匹配前一个字符或者子表达式至少n次\n\n{n,}?\n\n前一个的惰性匹配\n\n^\n\n匹配字符串的开头\n\n\\\\A\n\n匹配字符串开头\n\n$\n\n匹配字符串结束\n\n\\[\\\\b\\]\n\n退格字符\n\n\\\\c\n\n匹配一个控制字符\n\n\\\\d\n\n匹配任意数字\n\n\\\\D\n\n匹配数字以外的字符\n\n\\\\t\n\n匹配制表符\n\n\\\\w\n\n匹配任意数字字母下划线\n\n\\\\W\n\n不匹配数字字母下划线\n\n### 1.3. 反斜杠的问题\n\n与大多数编程语言相同，正则表达式里使用\"\\\\\"作为转义字符，这就可能造成反斜杠困扰。 假如你需要匹配文本中的字符\"\\\\\"，那么使用编程语言表示的正则表达式里将需要4个反斜杠\"\\\\\\\\\\\\\"：  Python里的原生字符串很好地解决了这个问题，这个例子中的正则表达式可以使用r\"\\\\\\\"表示。 同样，匹配一个数字的\"\\\\\\d\"可以写成r\"\\\\d\"。 有了原生字符串，妈妈再也不用担心我的反斜杠问题\n\n2.1.  **re**\n------------\n\n**compile**(pattern\\[,flags\\] ) 根据包含正则表达式的字符串创建模式对象。 match()决定 RE 是否在字符串刚开始的位置匹配 search()扫描字符串，找到这个 RE 匹配的位置 findall()找到 RE 匹配的所有子串，并把它们作为一个列表返回 finditer()找到 RE 匹配的所有子串，并把它们作为一个迭代器返回 split()将字符串在 RE 匹配的地方分片并生成一个列表， sub()找到 RE 匹配的所有子串，并将其用一个不同的字符串替换 subn()与 sub() 相同，但返回新的字符串和替换次数\n\n    res = re.match(pattern, string, flags=0)\n    #字符串的开头是否能匹配正则表达式。返回_sre.SRE_Match对象，如果\n    #不能匹配返回None。\n    # 如果匹配的话，res.string可以获得原始的字符串，并不是匹配的字符串 \n\n    re.sub(pattern, repl, string, count=0, flags=0)\n    \n    #找到 RE 匹配的所有子串，并将其用repl替换。可选参数 \n    #count 是模式匹配後替换的最大次数；count 必须是非负整数。缺省值\n    #是 0 表示替换所有的匹配。如果无匹配，字符串将会无改变地返回。如\n    #果有匹配,则返回替换后的字符串\n    # pattern='he$' 尾部匹配\n    # pattern='^he' 头部匹配，等价于match\n\n    re.findall(pattern,string)\n    # 从 string中找到所有 匹配 pattern的子串，作为列表返回\n    #如果没有匹配的话，返回空数组，可用来当做if的判断条件\n    #空数组为False\n    # pattern='he$' 尾部匹配\n    # pattern='^he' 头部匹配，等价于match\n\n    re.search(pattern, string)\n    #顾名思义，查找，如果找到返回一个match对象，找不到，返回None。\n    # pattern='he$' 尾部匹配\n    # pattern='^he' 头部匹配，等价于match\n    \n    \n\n","source":"_posts/第十五节：正则表达式.md","raw":"---\ntitle: 第十五节：正则表达式\ntags:\n  - 课后解答\nurl: 250.html\nid: 250\ncategories:\n  - 学习\n  - 教学\ndate: 2018-05-30 15:23:13\n---\n\n\n\n### 1.1正则表达式的大致匹配过程是：\n\n1.依次拿出表达式和文本中的字符比较， 2.如果每一个字符都能匹配，则匹配成功；一旦有匹配不成功的字符则匹配失败。 3.如果表达式中有量词或边界，这个过程会稍微有一些不同。\n\n### 1.2. 数量词的贪婪模式与非贪婪模式\n\n正则表达式通常用于在文本中查找匹配的字符串。 贪婪模式，总是尝试匹配尽可能多的字符； 非贪婪模式则相反，总是尝试匹配尽可能少的字符。 Python里数量词默认是贪婪的。 例如：正则表达式\"ab*\"如果用于查找\"abbbc\"，将找到\"abbb\"。 而如果使用非贪婪的数量词\"ab*?\"，将找到\"a\"。    \n\n正则表达式\n\n代表的匹配字符\n\n\\[0-9\\]\n\n0123456789任意之一\n\n\\[a-z\\]\n\n小写字母任意之一\n\n\\[A-Z\\]\n\n大写字母任意之一\n\n\\\\d\n\n等同于\\[0-9\\]\n\n\\\\D\n\n等同于\\[^0-9\\]匹配非数字\n\n\\\\w\n\n等同于\\[a-z0-9A-Z_\\]匹配大小写字母、数字和下划线\n\n\\\\W\n\n等同于\\[^a-z0-9A-Z_\\]等同于上一条取非\n\n下面列举一些正则表达式里的元字符及其作用\n\n元字符\n\n说明\n\n.\n\n代表任意字符\n\n|\n\n逻辑或操作符\n\n\\[ \\]\n\n匹配内部的任一字符或子表达式\n\n\\[^\\]\n\n对字符集和取非\n\n-\n\n定义一个区间\n\n\\\n\n对下一字符取非（通常是普通变特殊，特殊变普通）\n\n*\n\n匹配前面的字符或者子表达式0次或多次\n\n*?\n\n惰性匹配上一个\n\n+\n\n匹配前一个字符或子表达式一次或多次\n\n+?\n\n惰性匹配上一个\n\n?\n\n匹配前一个字符或子表达式0次或1次重复\n\n{n}\n\n匹配前一个字符或子表达式\n\n{m,n}\n\n匹配前一个字符或子表达式至少m次至多n次\n\n{n,}\n\n匹配前一个字符或者子表达式至少n次\n\n{n,}?\n\n前一个的惰性匹配\n\n^\n\n匹配字符串的开头\n\n\\\\A\n\n匹配字符串开头\n\n$\n\n匹配字符串结束\n\n\\[\\\\b\\]\n\n退格字符\n\n\\\\c\n\n匹配一个控制字符\n\n\\\\d\n\n匹配任意数字\n\n\\\\D\n\n匹配数字以外的字符\n\n\\\\t\n\n匹配制表符\n\n\\\\w\n\n匹配任意数字字母下划线\n\n\\\\W\n\n不匹配数字字母下划线\n\n### 1.3. 反斜杠的问题\n\n与大多数编程语言相同，正则表达式里使用\"\\\\\"作为转义字符，这就可能造成反斜杠困扰。 假如你需要匹配文本中的字符\"\\\\\"，那么使用编程语言表示的正则表达式里将需要4个反斜杠\"\\\\\\\\\\\\\"：  Python里的原生字符串很好地解决了这个问题，这个例子中的正则表达式可以使用r\"\\\\\\\"表示。 同样，匹配一个数字的\"\\\\\\d\"可以写成r\"\\\\d\"。 有了原生字符串，妈妈再也不用担心我的反斜杠问题\n\n2.1.  **re**\n------------\n\n**compile**(pattern\\[,flags\\] ) 根据包含正则表达式的字符串创建模式对象。 match()决定 RE 是否在字符串刚开始的位置匹配 search()扫描字符串，找到这个 RE 匹配的位置 findall()找到 RE 匹配的所有子串，并把它们作为一个列表返回 finditer()找到 RE 匹配的所有子串，并把它们作为一个迭代器返回 split()将字符串在 RE 匹配的地方分片并生成一个列表， sub()找到 RE 匹配的所有子串，并将其用一个不同的字符串替换 subn()与 sub() 相同，但返回新的字符串和替换次数\n\n    res = re.match(pattern, string, flags=0)\n    #字符串的开头是否能匹配正则表达式。返回_sre.SRE_Match对象，如果\n    #不能匹配返回None。\n    # 如果匹配的话，res.string可以获得原始的字符串，并不是匹配的字符串 \n\n    re.sub(pattern, repl, string, count=0, flags=0)\n    \n    #找到 RE 匹配的所有子串，并将其用repl替换。可选参数 \n    #count 是模式匹配後替换的最大次数；count 必须是非负整数。缺省值\n    #是 0 表示替换所有的匹配。如果无匹配，字符串将会无改变地返回。如\n    #果有匹配,则返回替换后的字符串\n    # pattern='he$' 尾部匹配\n    # pattern='^he' 头部匹配，等价于match\n\n    re.findall(pattern,string)\n    # 从 string中找到所有 匹配 pattern的子串，作为列表返回\n    #如果没有匹配的话，返回空数组，可用来当做if的判断条件\n    #空数组为False\n    # pattern='he$' 尾部匹配\n    # pattern='^he' 头部匹配，等价于match\n\n    re.search(pattern, string)\n    #顾名思义，查找，如果找到返回一个match对象，找不到，返回None。\n    # pattern='he$' 尾部匹配\n    # pattern='^he' 头部匹配，等价于match\n    \n    \n\n","slug":"第十五节：正则表达式","published":1,"updated":"2021-07-26T09:58:02.574Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m36004bigta4lbhnnkt","content":"<h3 id=\"1-1正则表达式的大致匹配过程是：\"><a href=\"#1-1正则表达式的大致匹配过程是：\" class=\"headerlink\" title=\"1.1正则表达式的大致匹配过程是：\"></a>1.1正则表达式的大致匹配过程是：</h3><p>1.依次拿出表达式和文本中的字符比较， 2.如果每一个字符都能匹配，则匹配成功；一旦有匹配不成功的字符则匹配失败。 3.如果表达式中有量词或边界，这个过程会稍微有一些不同。</p>\n<h3 id=\"1-2-数量词的贪婪模式与非贪婪模式\"><a href=\"#1-2-数量词的贪婪模式与非贪婪模式\" class=\"headerlink\" title=\"1.2. 数量词的贪婪模式与非贪婪模式\"></a>1.2. 数量词的贪婪模式与非贪婪模式</h3><p>正则表达式通常用于在文本中查找匹配的字符串。 贪婪模式，总是尝试匹配尽可能多的字符； 非贪婪模式则相反，总是尝试匹配尽可能少的字符。 Python里数量词默认是贪婪的。 例如：正则表达式”ab<em>“如果用于查找”abbbc”，将找到”abbb”。 而如果使用非贪婪的数量词”ab</em>?”，将找到”a”。    </p>\n<p>正则表达式</p>\n<p>代表的匹配字符</p>\n<p>[0-9]</p>\n<p>0123456789任意之一</p>\n<p>[a-z]</p>\n<p>小写字母任意之一</p>\n<p>[A-Z]</p>\n<p>大写字母任意之一</p>\n<p>\\d</p>\n<p>等同于[0-9]</p>\n<p>\\D</p>\n<p>等同于[^0-9]匹配非数字</p>\n<p>\\w</p>\n<p>等同于[a-z0-9A-Z_]匹配大小写字母、数字和下划线</p>\n<p>\\W</p>\n<p>等同于[^a-z0-9A-Z_]等同于上一条取非</p>\n<p>下面列举一些正则表达式里的元字符及其作用</p>\n<p>元字符</p>\n<p>说明</p>\n<p>.</p>\n<p>代表任意字符</p>\n<p>|</p>\n<p>逻辑或操作符</p>\n<p>[ ]</p>\n<p>匹配内部的任一字符或子表达式</p>\n<p>[^]</p>\n<p>对字符集和取非</p>\n<p>-</p>\n<p>定义一个区间</p>\n<p>\\</p>\n<p>对下一字符取非（通常是普通变特殊，特殊变普通）</p>\n<p>*</p>\n<p>匹配前面的字符或者子表达式0次或多次</p>\n<p>*?</p>\n<p>惰性匹配上一个</p>\n<p>+</p>\n<p>匹配前一个字符或子表达式一次或多次</p>\n<p>+?</p>\n<p>惰性匹配上一个</p>\n<p>?</p>\n<p>匹配前一个字符或子表达式0次或1次重复</p>\n<p>{n}</p>\n<p>匹配前一个字符或子表达式</p>\n<p>{m,n}</p>\n<p>匹配前一个字符或子表达式至少m次至多n次</p>\n<p>{n,}</p>\n<p>匹配前一个字符或者子表达式至少n次</p>\n<p>{n,}?</p>\n<p>前一个的惰性匹配</p>\n<p>^</p>\n<p>匹配字符串的开头</p>\n<p>\\A</p>\n<p>匹配字符串开头</p>\n<p>$</p>\n<p>匹配字符串结束</p>\n<p>[\\b]</p>\n<p>退格字符</p>\n<p>\\c</p>\n<p>匹配一个控制字符</p>\n<p>\\d</p>\n<p>匹配任意数字</p>\n<p>\\D</p>\n<p>匹配数字以外的字符</p>\n<p>\\t</p>\n<p>匹配制表符</p>\n<p>\\w</p>\n<p>匹配任意数字字母下划线</p>\n<p>\\W</p>\n<p>不匹配数字字母下划线</p>\n<h3 id=\"1-3-反斜杠的问题\"><a href=\"#1-3-反斜杠的问题\" class=\"headerlink\" title=\"1.3. 反斜杠的问题\"></a>1.3. 反斜杠的问题</h3><p>与大多数编程语言相同，正则表达式里使用”\\“作为转义字符，这就可能造成反斜杠困扰。 假如你需要匹配文本中的字符”\\“，那么使用编程语言表示的正则表达式里将需要4个反斜杠”\\\\\\“：  Python里的原生字符串很好地解决了这个问题，这个例子中的正则表达式可以使用r”\\\\”表示。 同样，匹配一个数字的”\\\\d”可以写成r”\\d”。 有了原生字符串，妈妈再也不用担心我的反斜杠问题</p>\n<h2 id=\"2-1-re\"><a href=\"#2-1-re\" class=\"headerlink\" title=\"2.1.  re\"></a>2.1.  <strong>re</strong></h2><p><strong>compile</strong>(pattern[,flags] ) 根据包含正则表达式的字符串创建模式对象。 match()决定 RE 是否在字符串刚开始的位置匹配 search()扫描字符串，找到这个 RE 匹配的位置 findall()找到 RE 匹配的所有子串，并把它们作为一个列表返回 finditer()找到 RE 匹配的所有子串，并把它们作为一个迭代器返回 split()将字符串在 RE 匹配的地方分片并生成一个列表， sub()找到 RE 匹配的所有子串，并将其用一个不同的字符串替换 subn()与 sub() 相同，但返回新的字符串和替换次数</p>\n<pre><code>res = re.match(pattern, string, flags=0)\n#字符串的开头是否能匹配正则表达式。返回_sre.SRE_Match对象，如果\n#不能匹配返回None。\n# 如果匹配的话，res.string可以获得原始的字符串，并不是匹配的字符串 \n\nre.sub(pattern, repl, string, count=0, flags=0)\n\n#找到 RE 匹配的所有子串，并将其用repl替换。可选参数 \n#count 是模式匹配後替换的最大次数；count 必须是非负整数。缺省值\n#是 0 表示替换所有的匹配。如果无匹配，字符串将会无改变地返回。如\n#果有匹配,则返回替换后的字符串\n# pattern=&apos;he$&apos; 尾部匹配\n# pattern=&apos;^he&apos; 头部匹配，等价于match\n\nre.findall(pattern,string)\n# 从 string中找到所有 匹配 pattern的子串，作为列表返回\n#如果没有匹配的话，返回空数组，可用来当做if的判断条件\n#空数组为False\n# pattern=&apos;he$&apos; 尾部匹配\n# pattern=&apos;^he&apos; 头部匹配，等价于match\n\nre.search(pattern, string)\n#顾名思义，查找，如果找到返回一个match对象，找不到，返回None。\n# pattern=&apos;he$&apos; 尾部匹配\n# pattern=&apos;^he&apos; 头部匹配，等价于match\n</code></pre>","site":{"data":{}},"excerpt":"","more":"<h3 id=\"1-1正则表达式的大致匹配过程是：\"><a href=\"#1-1正则表达式的大致匹配过程是：\" class=\"headerlink\" title=\"1.1正则表达式的大致匹配过程是：\"></a>1.1正则表达式的大致匹配过程是：</h3><p>1.依次拿出表达式和文本中的字符比较， 2.如果每一个字符都能匹配，则匹配成功；一旦有匹配不成功的字符则匹配失败。 3.如果表达式中有量词或边界，这个过程会稍微有一些不同。</p>\n<h3 id=\"1-2-数量词的贪婪模式与非贪婪模式\"><a href=\"#1-2-数量词的贪婪模式与非贪婪模式\" class=\"headerlink\" title=\"1.2. 数量词的贪婪模式与非贪婪模式\"></a>1.2. 数量词的贪婪模式与非贪婪模式</h3><p>正则表达式通常用于在文本中查找匹配的字符串。 贪婪模式，总是尝试匹配尽可能多的字符； 非贪婪模式则相反，总是尝试匹配尽可能少的字符。 Python里数量词默认是贪婪的。 例如：正则表达式”ab<em>“如果用于查找”abbbc”，将找到”abbb”。 而如果使用非贪婪的数量词”ab</em>?”，将找到”a”。    </p>\n<p>正则表达式</p>\n<p>代表的匹配字符</p>\n<p>[0-9]</p>\n<p>0123456789任意之一</p>\n<p>[a-z]</p>\n<p>小写字母任意之一</p>\n<p>[A-Z]</p>\n<p>大写字母任意之一</p>\n<p>\\d</p>\n<p>等同于[0-9]</p>\n<p>\\D</p>\n<p>等同于[^0-9]匹配非数字</p>\n<p>\\w</p>\n<p>等同于[a-z0-9A-Z_]匹配大小写字母、数字和下划线</p>\n<p>\\W</p>\n<p>等同于[^a-z0-9A-Z_]等同于上一条取非</p>\n<p>下面列举一些正则表达式里的元字符及其作用</p>\n<p>元字符</p>\n<p>说明</p>\n<p>.</p>\n<p>代表任意字符</p>\n<p>|</p>\n<p>逻辑或操作符</p>\n<p>[ ]</p>\n<p>匹配内部的任一字符或子表达式</p>\n<p>[^]</p>\n<p>对字符集和取非</p>\n<p>-</p>\n<p>定义一个区间</p>\n<p>\\</p>\n<p>对下一字符取非（通常是普通变特殊，特殊变普通）</p>\n<p>*</p>\n<p>匹配前面的字符或者子表达式0次或多次</p>\n<p>*?</p>\n<p>惰性匹配上一个</p>\n<p>+</p>\n<p>匹配前一个字符或子表达式一次或多次</p>\n<p>+?</p>\n<p>惰性匹配上一个</p>\n<p>?</p>\n<p>匹配前一个字符或子表达式0次或1次重复</p>\n<p>{n}</p>\n<p>匹配前一个字符或子表达式</p>\n<p>{m,n}</p>\n<p>匹配前一个字符或子表达式至少m次至多n次</p>\n<p>{n,}</p>\n<p>匹配前一个字符或者子表达式至少n次</p>\n<p>{n,}?</p>\n<p>前一个的惰性匹配</p>\n<p>^</p>\n<p>匹配字符串的开头</p>\n<p>\\A</p>\n<p>匹配字符串开头</p>\n<p>$</p>\n<p>匹配字符串结束</p>\n<p>[\\b]</p>\n<p>退格字符</p>\n<p>\\c</p>\n<p>匹配一个控制字符</p>\n<p>\\d</p>\n<p>匹配任意数字</p>\n<p>\\D</p>\n<p>匹配数字以外的字符</p>\n<p>\\t</p>\n<p>匹配制表符</p>\n<p>\\w</p>\n<p>匹配任意数字字母下划线</p>\n<p>\\W</p>\n<p>不匹配数字字母下划线</p>\n<h3 id=\"1-3-反斜杠的问题\"><a href=\"#1-3-反斜杠的问题\" class=\"headerlink\" title=\"1.3. 反斜杠的问题\"></a>1.3. 反斜杠的问题</h3><p>与大多数编程语言相同，正则表达式里使用”\\“作为转义字符，这就可能造成反斜杠困扰。 假如你需要匹配文本中的字符”\\“，那么使用编程语言表示的正则表达式里将需要4个反斜杠”\\\\\\“：  Python里的原生字符串很好地解决了这个问题，这个例子中的正则表达式可以使用r”\\\\”表示。 同样，匹配一个数字的”\\\\d”可以写成r”\\d”。 有了原生字符串，妈妈再也不用担心我的反斜杠问题</p>\n<h2 id=\"2-1-re\"><a href=\"#2-1-re\" class=\"headerlink\" title=\"2.1.  re\"></a>2.1.  <strong>re</strong></h2><p><strong>compile</strong>(pattern[,flags] ) 根据包含正则表达式的字符串创建模式对象。 match()决定 RE 是否在字符串刚开始的位置匹配 search()扫描字符串，找到这个 RE 匹配的位置 findall()找到 RE 匹配的所有子串，并把它们作为一个列表返回 finditer()找到 RE 匹配的所有子串，并把它们作为一个迭代器返回 split()将字符串在 RE 匹配的地方分片并生成一个列表， sub()找到 RE 匹配的所有子串，并将其用一个不同的字符串替换 subn()与 sub() 相同，但返回新的字符串和替换次数</p>\n<pre><code>res = re.match(pattern, string, flags=0)\n#字符串的开头是否能匹配正则表达式。返回_sre.SRE_Match对象，如果\n#不能匹配返回None。\n# 如果匹配的话，res.string可以获得原始的字符串，并不是匹配的字符串 \n\nre.sub(pattern, repl, string, count=0, flags=0)\n\n#找到 RE 匹配的所有子串，并将其用repl替换。可选参数 \n#count 是模式匹配後替换的最大次数；count 必须是非负整数。缺省值\n#是 0 表示替换所有的匹配。如果无匹配，字符串将会无改变地返回。如\n#果有匹配,则返回替换后的字符串\n# pattern=&apos;he$&apos; 尾部匹配\n# pattern=&apos;^he&apos; 头部匹配，等价于match\n\nre.findall(pattern,string)\n# 从 string中找到所有 匹配 pattern的子串，作为列表返回\n#如果没有匹配的话，返回空数组，可用来当做if的判断条件\n#空数组为False\n# pattern=&apos;he$&apos; 尾部匹配\n# pattern=&apos;^he&apos; 头部匹配，等价于match\n\nre.search(pattern, string)\n#顾名思义，查找，如果找到返回一个match对象，找不到，返回None。\n# pattern=&apos;he$&apos; 尾部匹配\n# pattern=&apos;^he&apos; 头部匹配，等价于match\n</code></pre>"},{"title":"第十一节：描述符，装饰器，定制属性访问，__new__方法","url":"241.html","id":"241","date":"2018-05-21T10:57:23.000Z","_content":"\n\\[warning\\]\n\n\\_\\_new\\_\\_方法：\n--------------\n\n**\\_\\_new\\_\\_ 方法是什么？** \\_\\_new\\_\\_方法接受的参数虽然也是和\\_\\_init\\_\\_一样，但\\_\\_init\\_\\_是在类实例创建之后调用，而 \\_\\_new\\_\\_方法正是创建这个类实例的方法。 **\\_\\_new\\_\\_ 的作用** 依照Python官方文档的说法，\\_\\_new\\_\\_方法主要是当你继承一些不可变的class时(比如int, str, tuple)， 提供给你一个自定义这些类的实例化过程的途径。还有就是实现自定义的metaclass。  \n\n定制属性访问:\n-------\n\n`object.``__getattr__`（_self_，_name_）[](https://docs.python.org/3/reference/datamodel.html#object.__getattr__ \"这个定义的永久性\")\n\n当默认的属性访问失败，并调用[`AttributeError`](https://docs.python.org/3/library/exceptions.html#AttributeError \"AttributeError的\")（或者[`__getattribute__()`](https://docs.python.org/3/reference/datamodel.html#object.__getattribute__ \"对象.__ getattribute__\")引发[`AttributeError`](https://docs.python.org/3/library/exceptions.html#AttributeError \"AttributeError的\")，因为_名字_是不是一个实例的属性或分类的属性`self`;或[`__get__()`](https://docs.python.org/3/reference/datamodel.html#object.__get__ \"对象.__ get__\")的_名称_属性提升[`AttributeError`](https://docs.python.org/3/library/exceptions.html#AttributeError \"AttributeError的\")）。此方法应该返回（计算）的属性值或引发[`AttributeError`](https://docs.python.org/3/library/exceptions.html#AttributeError \"AttributeError的\")异常。 请注意，如果通过正常机制找到属性，[`__getattr__()`](https://docs.python.org/3/reference/datamodel.html#object.__getattr__ \"对象.__ getattr__\")则不会调用该属性。（这是[`__getattr__()`](https://docs.python.org/3/reference/datamodel.html#object.__getattr__ \"对象.__ getattr__\")和之间的故意不对称[`__setattr__()`](https://docs.python.org/3/reference/datamodel.html#object.__setattr__ \"对象.__ setattr__\")）。这是出于效率原因而完成的，否则[`__getattr__()`](https://docs.python.org/3/reference/datamodel.html#object.__getattr__ \"对象.__ getattr__\")将无法访问实例的其他属性。请注意，至少在实例变量中，您可以通过在实例属性字典中不插入任何值（而是将它们插入另一个对象中）来伪造完全控制。请参阅[`__getattribute__()`](https://docs.python.org/3/reference/datamodel.html#object.__getattribute__ \"对象.__ getattribute__\")下面的方法，以实际获得对属性访问的完全控制。\n\n`object.``__getattribute__`（_self_，_name_）[](https://docs.python.org/3/reference/datamodel.html#object.__getattribute__ \"这个定义的永久性\")\n\n无条件地调用以实现类的实例的属性访问。如果这个类还定义了[`__getattr__()`](https://docs.python.org/3/reference/datamodel.html#object.__getattr__ \"对象.__ getattr__\")，那么除非[`__getattribute__()`](https://docs.python.org/3/reference/datamodel.html#object.__getattribute__ \"对象.__ getattribute__\")明确地调用它或引发一个，否则后者将不会被调用[`AttributeError`](https://docs.python.org/3/library/exceptions.html#AttributeError \"AttributeError的\")。此方法应返回（计算）的属性值或引发[`AttributeError`](https://docs.python.org/3/library/exceptions.html#AttributeError \"AttributeError的\")异常。为了避免此方法中的无限递归，它的实现应始终调用具有相同名称的基类方法来访问它所需的任何属性，例如。`object.__getattribute__(self,name)`\n\n注意\n\n当通过语言语法或内置函数隐式调用查找特殊方法时，此方法仍可能被忽略。请参阅[特殊方法查找](https://docs.python.org/3/reference/datamodel.html#special-lookup)。\n\n`object.``__setattr__`（_self_，_name_，_value_）[](https://docs.python.org/3/reference/datamodel.html#object.__setattr__ \"这个定义的永久性\")\n\n在试图进行属性分配时调用。这被称为而不是正常机制（即将值存储在实例字典中）。_name_是属性名称，_value_是要分配给它的值。 如果[`__setattr__()`](https://docs.python.org/3/reference/datamodel.html#object.__setattr__ \"对象.__ setattr__\")想分配给实例属性，它应该调用具有相同名称的基类方法，例如。`object.__setattr__(self,name,value)`\n\n`object.``__delattr__`（_self_，_name_）[](https://docs.python.org/3/reference/datamodel.html#object.__delattr__ \"这个定义的永久性\")\n\n像[`__setattr__()`](https://docs.python.org/3/reference/datamodel.html#object.__setattr__ \"对象.__ setattr__\")但删除属性而不是赋值。这应该只在对对象有意义时才能实现。`delobj.name`\n\n`object.``__dir__`（_self_）[](https://docs.python.org/3/reference/datamodel.html#object.__dir__ \"这个定义的永久性\")\n\n[`dir()`](https://docs.python.org/3/library/functions.html#dir \"DIR\")在对象上调用时调用。必须返回一个序列。[`dir()`](https://docs.python.org/3/library/functions.html#dir \"DIR\")将返回的序列转换为列表并对其进行排序。\n\n   \n\n描述符：\n----\n\n一句话概括：描述符就是可重用的属性\n-----------------\n\n在这里我要告诉你：从根本上讲，描述符就是可以重复使用的属性。也就是说，描述符可以让你编写这样的代码：\n\n1\n\n2\n\n3\n\n4\n\nf  =  Foo()\n\nb  =  f.bar\n\nf.bar  =  c\n\ndel  f.bar\n\n而在解释器执行上述代码时，当发现你试图访问属性（b = f.bar）、对属性赋值（f.bar = c）或者删除一个实例变量的属性（del f.bar）时，就会去调用自定义的方法。    \n\n装饰器:\n----\n\n01 什么是装饰器？\n----------\n\n装饰器可以让一个Python函数拥有原本没有的功能，也就是你可以通过装饰器，让一个平淡无奇的函数变的强大，变的漂亮。 举几个现实中的例子 1、你一个男的程序员，穿上女装，戴上假发，你就有了女人的外表（穿女装、戴假发的过程就是新的特效，你拥有了女人的外表，你原来的小jj还在，没有消失） 2、你新买的毛坯房，装修，买家具后变好看了（装修、家具就是新的特效） 3、孙悟空被放进炼丹炉装饰了一下，出来后，学会了火眼金睛，以前的本领都还在\n\n02 为什么Python要引入装饰器？\n-------------------\n\n因为引入装饰器会便于开发，便于代码复用，可以把烂泥扶上墙， 装饰器可以让你一秒变女人且可以保住小JJ，当你某天后悔想重新变回男人，只要脱掉女装和假发即可（如果你变女人的时候，给小JJ做了手术（直接修改函数体的内容），想再变回男人可就痛苦了哦）\n\n03 装饰器有利于解决哪些问题？\n----------------\n\n例子1： 扩展功能 比如你写了一段代码，当你执行 **孙悟空()** 就打印出它目前的技能\n\n    # python3支持用中文做函数名，\n    # 这里为了方便你理解，就用中文，实际情况为了兼容性，你可别用中文哦\n    \n    def 孙悟空():\n      print('吃桃子')\n    孙悟空()\n    # 输出:\n    # 吃桃子\n    \n\n现在你希望 **孙悟空**这个函数 打印出 **’有火眼金睛了’**，该怎么做呢？ 是的，你可以直接在函数里加一段 **print('有火眼金睛了')** 但是这样会破坏原来的代码，如果你的代码量很多很多的话，修改起来则是灾难， 不过别担心，你还可以用装饰器来装饰他，让他在原本基础上，扩展出新的功能 代码如下\n\n    def 炼丹炉(func): # func就是‘孙悟空’这个函数\n      def 变身(*args, **kwargs): #*args, **kwargs就是‘孙悟空’的参数列表，这里的‘孙悟空’函数没有传参数，我们写上也不影响，建议都写上  \n          print('有火眼金睛了') # 加特效，增加新功能，比如孙悟空的进了炼丹炉后，有了火眼金睛技能  \n          return func(*args, **kwargs) #保留原来的功能，原来孙悟空的技能，如吃桃子\n      return 变身 # 炼丹成功，更强大的，有了火眼金睛技能的孙悟空出世\n    \n    @炼丹炉\n    def 孙悟空():\n      print('吃桃子')\n    \n    孙悟空()\n    # 输出:\n    # 有火眼金睛了\n    # 吃桃子\n    \n\n例子2：扩展权限认证 比如你的代码，默认打开就播放动画片，代码如下\n\n    def play():\n      print('开始播放动画片 《喜洋洋和灰太狼》')\n    \n    play()\n    # 输出\n    # 开始播放动画片 《喜洋洋和灰太狼》\n    \n\n但是突然某天，你突然希望只允许1岁到10才可以看这个动画片，不希望程序员大叔看这个动画片怎么办？ 是的，你可以修改这个代码，加上年龄限制，但如果我们用装饰器的话，就更简单了，就可以不用破坏原来的代码，而且方便扩展到其他函数上\n\n    userAge = 40\n    \n    def canYou(func):\n      def decorator(*args, **kwargs):\n          if userAge > 1 and userAge < 10:\n              return func(*args, **kwargs)\n          print('你的年龄不符合要求，不能看')\n      return decorator\n    \n    @canYou\n    def play():\n      print('开始播放动画片 《喜洋洋和灰太狼》')\n    \n    play()\n    # 输出\n    # 你的年龄不符合要求，不能看\n    # 你可以修改上面的 userAge 为9 试试\n    \n\n你看，是不是很简单，实际情况中，很多时候，你需要对一段代码加上权限认证，加上各种功能；但是又不想，或者不方便破坏原有代码，则可以用装饰器去扩展它\n\n04 装饰器背后的实现原理是什么？\n-----------------\n\n原理 代码逆推后如下\n\n    def 炼丹炉(func): \n      def 变身(*args, **kwargs):  \n          print('有火眼金睛了') \n          return func(*args, **kwargs) \n      return 变身 \n    \n    def 孙悟空():  \n      print('吃桃子')\n    新_孙悟空 = 炼丹炉(孙悟空) #放入原料，原来的弱小的孙悟空，生成炼丹方案给 新_孙悟空 ，这里也可以把炼丹方案给 原来的‘孙悟空’，为了方便理解，给了新的孙悟空 \n    \n    新_孙悟空() # 执行炼丹程序，新的孙悟空出世\n    \n\n然后这段代码，写起来有点麻烦，Python官方出了一个快捷代码，也就是语法糖，用了语法糖就变成了下面这样\n\n    def 炼丹炉(func): \n      def 变身(*args, **kwargs):  \n          print('有火眼金睛了') \n          return func(*args, **kwargs) \n      return 变身 \n    \n    @炼丹炉  # 把下面的 ‘孙悟空’ 塞进炼丹炉，并把新的孙悟空复制给下面的函数\n    def 孙悟空():  \n      print('吃桃子')\n    \n    孙悟空() # 执行炼丹程序，新的孙悟空出世\n    \n\n可以一次性在一个函数上用多个装饰器吗？ 当然可以，下面我们给孙悟空，弄个金箍棒，让他学会72变，学会飞\n\n    def 炼丹炉(func):\n      def 变身(*args, **kwargs):\n          print('有火眼金睛了')\n          return func(*args, **kwargs)\n      return 变身\n    \n    def 龙宫走一趟(func):\n      def 你好(*args, **kwargs):\n          print('有金箍棒了')\n          return func(*args, **kwargs)\n      return 你好\n    \n    def 拜师学艺(func):\n      def 师傅(*args, **kwargs):\n          print('学会飞、72变了')\n          return func(*args, **kwargs)\n      return 师傅\n    \n    @拜师学艺\n    @龙宫走一趟\n    @炼丹炉  \n    def 孙悟空():\n      print('吃桃子')\n    \n    孙悟空()\n    # 输出\n    # 学会飞、72变了\n    # 有金箍棒了\n    # 有火眼金睛了\n    # 吃桃子\n    \n\n上面代码的等效于 **拜师学艺(龙宫走一趟(炼丹炉(孙悟空)))** 代码的执行顺序是 **先从内到外** **先执行 炼丹炉，然后是龙宫走一趟，最后是拜师学艺，\\[/warning\\]**\n\n链接：https://www.zhihu.com/question/26930016/answer/360300235\n","source":"_posts/第十一节：描述符，装饰器，定制属性访问，__new__方法.md","raw":"---\ntitle: 第十一节：描述符，装饰器，定制属性访问，__new__方法\ntags:\n  - 课后解答\nurl: 241.html\nid: 241\ncategories:\n  - 学习\n  - 教学\ndate: 2018-05-21 18:57:23\n---\n\n\\[warning\\]\n\n\\_\\_new\\_\\_方法：\n--------------\n\n**\\_\\_new\\_\\_ 方法是什么？** \\_\\_new\\_\\_方法接受的参数虽然也是和\\_\\_init\\_\\_一样，但\\_\\_init\\_\\_是在类实例创建之后调用，而 \\_\\_new\\_\\_方法正是创建这个类实例的方法。 **\\_\\_new\\_\\_ 的作用** 依照Python官方文档的说法，\\_\\_new\\_\\_方法主要是当你继承一些不可变的class时(比如int, str, tuple)， 提供给你一个自定义这些类的实例化过程的途径。还有就是实现自定义的metaclass。  \n\n定制属性访问:\n-------\n\n`object.``__getattr__`（_self_，_name_）[](https://docs.python.org/3/reference/datamodel.html#object.__getattr__ \"这个定义的永久性\")\n\n当默认的属性访问失败，并调用[`AttributeError`](https://docs.python.org/3/library/exceptions.html#AttributeError \"AttributeError的\")（或者[`__getattribute__()`](https://docs.python.org/3/reference/datamodel.html#object.__getattribute__ \"对象.__ getattribute__\")引发[`AttributeError`](https://docs.python.org/3/library/exceptions.html#AttributeError \"AttributeError的\")，因为_名字_是不是一个实例的属性或分类的属性`self`;或[`__get__()`](https://docs.python.org/3/reference/datamodel.html#object.__get__ \"对象.__ get__\")的_名称_属性提升[`AttributeError`](https://docs.python.org/3/library/exceptions.html#AttributeError \"AttributeError的\")）。此方法应该返回（计算）的属性值或引发[`AttributeError`](https://docs.python.org/3/library/exceptions.html#AttributeError \"AttributeError的\")异常。 请注意，如果通过正常机制找到属性，[`__getattr__()`](https://docs.python.org/3/reference/datamodel.html#object.__getattr__ \"对象.__ getattr__\")则不会调用该属性。（这是[`__getattr__()`](https://docs.python.org/3/reference/datamodel.html#object.__getattr__ \"对象.__ getattr__\")和之间的故意不对称[`__setattr__()`](https://docs.python.org/3/reference/datamodel.html#object.__setattr__ \"对象.__ setattr__\")）。这是出于效率原因而完成的，否则[`__getattr__()`](https://docs.python.org/3/reference/datamodel.html#object.__getattr__ \"对象.__ getattr__\")将无法访问实例的其他属性。请注意，至少在实例变量中，您可以通过在实例属性字典中不插入任何值（而是将它们插入另一个对象中）来伪造完全控制。请参阅[`__getattribute__()`](https://docs.python.org/3/reference/datamodel.html#object.__getattribute__ \"对象.__ getattribute__\")下面的方法，以实际获得对属性访问的完全控制。\n\n`object.``__getattribute__`（_self_，_name_）[](https://docs.python.org/3/reference/datamodel.html#object.__getattribute__ \"这个定义的永久性\")\n\n无条件地调用以实现类的实例的属性访问。如果这个类还定义了[`__getattr__()`](https://docs.python.org/3/reference/datamodel.html#object.__getattr__ \"对象.__ getattr__\")，那么除非[`__getattribute__()`](https://docs.python.org/3/reference/datamodel.html#object.__getattribute__ \"对象.__ getattribute__\")明确地调用它或引发一个，否则后者将不会被调用[`AttributeError`](https://docs.python.org/3/library/exceptions.html#AttributeError \"AttributeError的\")。此方法应返回（计算）的属性值或引发[`AttributeError`](https://docs.python.org/3/library/exceptions.html#AttributeError \"AttributeError的\")异常。为了避免此方法中的无限递归，它的实现应始终调用具有相同名称的基类方法来访问它所需的任何属性，例如。`object.__getattribute__(self,name)`\n\n注意\n\n当通过语言语法或内置函数隐式调用查找特殊方法时，此方法仍可能被忽略。请参阅[特殊方法查找](https://docs.python.org/3/reference/datamodel.html#special-lookup)。\n\n`object.``__setattr__`（_self_，_name_，_value_）[](https://docs.python.org/3/reference/datamodel.html#object.__setattr__ \"这个定义的永久性\")\n\n在试图进行属性分配时调用。这被称为而不是正常机制（即将值存储在实例字典中）。_name_是属性名称，_value_是要分配给它的值。 如果[`__setattr__()`](https://docs.python.org/3/reference/datamodel.html#object.__setattr__ \"对象.__ setattr__\")想分配给实例属性，它应该调用具有相同名称的基类方法，例如。`object.__setattr__(self,name,value)`\n\n`object.``__delattr__`（_self_，_name_）[](https://docs.python.org/3/reference/datamodel.html#object.__delattr__ \"这个定义的永久性\")\n\n像[`__setattr__()`](https://docs.python.org/3/reference/datamodel.html#object.__setattr__ \"对象.__ setattr__\")但删除属性而不是赋值。这应该只在对对象有意义时才能实现。`delobj.name`\n\n`object.``__dir__`（_self_）[](https://docs.python.org/3/reference/datamodel.html#object.__dir__ \"这个定义的永久性\")\n\n[`dir()`](https://docs.python.org/3/library/functions.html#dir \"DIR\")在对象上调用时调用。必须返回一个序列。[`dir()`](https://docs.python.org/3/library/functions.html#dir \"DIR\")将返回的序列转换为列表并对其进行排序。\n\n   \n\n描述符：\n----\n\n一句话概括：描述符就是可重用的属性\n-----------------\n\n在这里我要告诉你：从根本上讲，描述符就是可以重复使用的属性。也就是说，描述符可以让你编写这样的代码：\n\n1\n\n2\n\n3\n\n4\n\nf  =  Foo()\n\nb  =  f.bar\n\nf.bar  =  c\n\ndel  f.bar\n\n而在解释器执行上述代码时，当发现你试图访问属性（b = f.bar）、对属性赋值（f.bar = c）或者删除一个实例变量的属性（del f.bar）时，就会去调用自定义的方法。    \n\n装饰器:\n----\n\n01 什么是装饰器？\n----------\n\n装饰器可以让一个Python函数拥有原本没有的功能，也就是你可以通过装饰器，让一个平淡无奇的函数变的强大，变的漂亮。 举几个现实中的例子 1、你一个男的程序员，穿上女装，戴上假发，你就有了女人的外表（穿女装、戴假发的过程就是新的特效，你拥有了女人的外表，你原来的小jj还在，没有消失） 2、你新买的毛坯房，装修，买家具后变好看了（装修、家具就是新的特效） 3、孙悟空被放进炼丹炉装饰了一下，出来后，学会了火眼金睛，以前的本领都还在\n\n02 为什么Python要引入装饰器？\n-------------------\n\n因为引入装饰器会便于开发，便于代码复用，可以把烂泥扶上墙， 装饰器可以让你一秒变女人且可以保住小JJ，当你某天后悔想重新变回男人，只要脱掉女装和假发即可（如果你变女人的时候，给小JJ做了手术（直接修改函数体的内容），想再变回男人可就痛苦了哦）\n\n03 装饰器有利于解决哪些问题？\n----------------\n\n例子1： 扩展功能 比如你写了一段代码，当你执行 **孙悟空()** 就打印出它目前的技能\n\n    # python3支持用中文做函数名，\n    # 这里为了方便你理解，就用中文，实际情况为了兼容性，你可别用中文哦\n    \n    def 孙悟空():\n      print('吃桃子')\n    孙悟空()\n    # 输出:\n    # 吃桃子\n    \n\n现在你希望 **孙悟空**这个函数 打印出 **’有火眼金睛了’**，该怎么做呢？ 是的，你可以直接在函数里加一段 **print('有火眼金睛了')** 但是这样会破坏原来的代码，如果你的代码量很多很多的话，修改起来则是灾难， 不过别担心，你还可以用装饰器来装饰他，让他在原本基础上，扩展出新的功能 代码如下\n\n    def 炼丹炉(func): # func就是‘孙悟空’这个函数\n      def 变身(*args, **kwargs): #*args, **kwargs就是‘孙悟空’的参数列表，这里的‘孙悟空’函数没有传参数，我们写上也不影响，建议都写上  \n          print('有火眼金睛了') # 加特效，增加新功能，比如孙悟空的进了炼丹炉后，有了火眼金睛技能  \n          return func(*args, **kwargs) #保留原来的功能，原来孙悟空的技能，如吃桃子\n      return 变身 # 炼丹成功，更强大的，有了火眼金睛技能的孙悟空出世\n    \n    @炼丹炉\n    def 孙悟空():\n      print('吃桃子')\n    \n    孙悟空()\n    # 输出:\n    # 有火眼金睛了\n    # 吃桃子\n    \n\n例子2：扩展权限认证 比如你的代码，默认打开就播放动画片，代码如下\n\n    def play():\n      print('开始播放动画片 《喜洋洋和灰太狼》')\n    \n    play()\n    # 输出\n    # 开始播放动画片 《喜洋洋和灰太狼》\n    \n\n但是突然某天，你突然希望只允许1岁到10才可以看这个动画片，不希望程序员大叔看这个动画片怎么办？ 是的，你可以修改这个代码，加上年龄限制，但如果我们用装饰器的话，就更简单了，就可以不用破坏原来的代码，而且方便扩展到其他函数上\n\n    userAge = 40\n    \n    def canYou(func):\n      def decorator(*args, **kwargs):\n          if userAge > 1 and userAge < 10:\n              return func(*args, **kwargs)\n          print('你的年龄不符合要求，不能看')\n      return decorator\n    \n    @canYou\n    def play():\n      print('开始播放动画片 《喜洋洋和灰太狼》')\n    \n    play()\n    # 输出\n    # 你的年龄不符合要求，不能看\n    # 你可以修改上面的 userAge 为9 试试\n    \n\n你看，是不是很简单，实际情况中，很多时候，你需要对一段代码加上权限认证，加上各种功能；但是又不想，或者不方便破坏原有代码，则可以用装饰器去扩展它\n\n04 装饰器背后的实现原理是什么？\n-----------------\n\n原理 代码逆推后如下\n\n    def 炼丹炉(func): \n      def 变身(*args, **kwargs):  \n          print('有火眼金睛了') \n          return func(*args, **kwargs) \n      return 变身 \n    \n    def 孙悟空():  \n      print('吃桃子')\n    新_孙悟空 = 炼丹炉(孙悟空) #放入原料，原来的弱小的孙悟空，生成炼丹方案给 新_孙悟空 ，这里也可以把炼丹方案给 原来的‘孙悟空’，为了方便理解，给了新的孙悟空 \n    \n    新_孙悟空() # 执行炼丹程序，新的孙悟空出世\n    \n\n然后这段代码，写起来有点麻烦，Python官方出了一个快捷代码，也就是语法糖，用了语法糖就变成了下面这样\n\n    def 炼丹炉(func): \n      def 变身(*args, **kwargs):  \n          print('有火眼金睛了') \n          return func(*args, **kwargs) \n      return 变身 \n    \n    @炼丹炉  # 把下面的 ‘孙悟空’ 塞进炼丹炉，并把新的孙悟空复制给下面的函数\n    def 孙悟空():  \n      print('吃桃子')\n    \n    孙悟空() # 执行炼丹程序，新的孙悟空出世\n    \n\n可以一次性在一个函数上用多个装饰器吗？ 当然可以，下面我们给孙悟空，弄个金箍棒，让他学会72变，学会飞\n\n    def 炼丹炉(func):\n      def 变身(*args, **kwargs):\n          print('有火眼金睛了')\n          return func(*args, **kwargs)\n      return 变身\n    \n    def 龙宫走一趟(func):\n      def 你好(*args, **kwargs):\n          print('有金箍棒了')\n          return func(*args, **kwargs)\n      return 你好\n    \n    def 拜师学艺(func):\n      def 师傅(*args, **kwargs):\n          print('学会飞、72变了')\n          return func(*args, **kwargs)\n      return 师傅\n    \n    @拜师学艺\n    @龙宫走一趟\n    @炼丹炉  \n    def 孙悟空():\n      print('吃桃子')\n    \n    孙悟空()\n    # 输出\n    # 学会飞、72变了\n    # 有金箍棒了\n    # 有火眼金睛了\n    # 吃桃子\n    \n\n上面代码的等效于 **拜师学艺(龙宫走一趟(炼丹炉(孙悟空)))** 代码的执行顺序是 **先从内到外** **先执行 炼丹炉，然后是龙宫走一趟，最后是拜师学艺，\\[/warning\\]**\n\n链接：https://www.zhihu.com/question/26930016/answer/360300235\n","slug":"第十一节：描述符，装饰器，定制属性访问，__new__方法","published":1,"updated":"2021-07-26T09:58:02.574Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m38004figta9x7jgotb","content":"<p>[warning]</p>\n<h2 id=\"new-方法：\"><a href=\"#new-方法：\" class=\"headerlink\" title=\"__new__方法：\"></a>__new__方法：</h2><p><strong>__new__ 方法是什么？</strong> __new__方法接受的参数虽然也是和__init__一样，但__init__是在类实例创建之后调用，而 __new__方法正是创建这个类实例的方法。 <strong>__new__ 的作用</strong> 依照Python官方文档的说法，__new__方法主要是当你继承一些不可变的class时(比如int, str, tuple)， 提供给你一个自定义这些类的实例化过程的途径。还有就是实现自定义的metaclass。  </p>\n<h2 id=\"定制属性访问\"><a href=\"#定制属性访问\" class=\"headerlink\" title=\"定制属性访问:\"></a>定制属性访问:</h2><p><code>object.`</code><strong>getattr</strong>`（<em>self</em>，<em>name</em>）<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__getattr__\" title=\"这个定义的永久性\" target=\"_blank\" rel=\"noopener\"></a></p>\n<p>当默认的属性访问失败，并调用<a href=\"https://docs.python.org/3/library/exceptions.html#AttributeError\" title=\"AttributeError的\" target=\"_blank\" rel=\"noopener\"><code>AttributeError</code></a>（或者<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__getattribute__\" title=\"对象.__ getattribute__\" target=\"_blank\" rel=\"noopener\"><code>__getattribute__()</code></a>引发<a href=\"https://docs.python.org/3/library/exceptions.html#AttributeError\" title=\"AttributeError的\" target=\"_blank\" rel=\"noopener\"><code>AttributeError</code></a>，因为_名字<em>是不是一个实例的属性或分类的属性<code>self</code>;或<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__get__\" title=\"对象.__ get__\" target=\"_blank\" rel=\"noopener\"><code>__get__()</code></a>的</em>名称_属性提升<a href=\"https://docs.python.org/3/library/exceptions.html#AttributeError\" title=\"AttributeError的\" target=\"_blank\" rel=\"noopener\"><code>AttributeError</code></a>）。此方法应该返回（计算）的属性值或引发<a href=\"https://docs.python.org/3/library/exceptions.html#AttributeError\" title=\"AttributeError的\" target=\"_blank\" rel=\"noopener\"><code>AttributeError</code></a>异常。 请注意，如果通过正常机制找到属性，<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__getattr__\" title=\"对象.__ getattr__\" target=\"_blank\" rel=\"noopener\"><code>__getattr__()</code></a>则不会调用该属性。（这是<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__getattr__\" title=\"对象.__ getattr__\" target=\"_blank\" rel=\"noopener\"><code>__getattr__()</code></a>和之间的故意不对称<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__setattr__\" title=\"对象.__ setattr__\" target=\"_blank\" rel=\"noopener\"><code>__setattr__()</code></a>）。这是出于效率原因而完成的，否则<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__getattr__\" title=\"对象.__ getattr__\" target=\"_blank\" rel=\"noopener\"><code>__getattr__()</code></a>将无法访问实例的其他属性。请注意，至少在实例变量中，您可以通过在实例属性字典中不插入任何值（而是将它们插入另一个对象中）来伪造完全控制。请参阅<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__getattribute__\" title=\"对象.__ getattribute__\" target=\"_blank\" rel=\"noopener\"><code>__getattribute__()</code></a>下面的方法，以实际获得对属性访问的完全控制。</p>\n<p><code>object.`</code><strong>getattribute</strong>`（<em>self</em>，<em>name</em>）<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__getattribute__\" title=\"这个定义的永久性\" target=\"_blank\" rel=\"noopener\"></a></p>\n<p>无条件地调用以实现类的实例的属性访问。如果这个类还定义了<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__getattr__\" title=\"对象.__ getattr__\" target=\"_blank\" rel=\"noopener\"><code>__getattr__()</code></a>，那么除非<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__getattribute__\" title=\"对象.__ getattribute__\" target=\"_blank\" rel=\"noopener\"><code>__getattribute__()</code></a>明确地调用它或引发一个，否则后者将不会被调用<a href=\"https://docs.python.org/3/library/exceptions.html#AttributeError\" title=\"AttributeError的\" target=\"_blank\" rel=\"noopener\"><code>AttributeError</code></a>。此方法应返回（计算）的属性值或引发<a href=\"https://docs.python.org/3/library/exceptions.html#AttributeError\" title=\"AttributeError的\" target=\"_blank\" rel=\"noopener\"><code>AttributeError</code></a>异常。为了避免此方法中的无限递归，它的实现应始终调用具有相同名称的基类方法来访问它所需的任何属性，例如。<code>object.__getattribute__(self,name)</code></p>\n<p>注意</p>\n<p>当通过语言语法或内置函数隐式调用查找特殊方法时，此方法仍可能被忽略。请参阅<a href=\"https://docs.python.org/3/reference/datamodel.html#special-lookup\" target=\"_blank\" rel=\"noopener\">特殊方法查找</a>。</p>\n<p><code>object.`</code><strong>setattr</strong>`（<em>self</em>，<em>name</em>，<em>value</em>）<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__setattr__\" title=\"这个定义的永久性\" target=\"_blank\" rel=\"noopener\"></a></p>\n<p>在试图进行属性分配时调用。这被称为而不是正常机制（即将值存储在实例字典中）。<em>name</em>是属性名称，<em>value</em>是要分配给它的值。 如果<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__setattr__\" title=\"对象.__ setattr__\" target=\"_blank\" rel=\"noopener\"><code>__setattr__()</code></a>想分配给实例属性，它应该调用具有相同名称的基类方法，例如。<code>object.__setattr__(self,name,value)</code></p>\n<p><code>object.`</code><strong>delattr</strong>`（<em>self</em>，<em>name</em>）<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__delattr__\" title=\"这个定义的永久性\" target=\"_blank\" rel=\"noopener\"></a></p>\n<p>像<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__setattr__\" title=\"对象.__ setattr__\" target=\"_blank\" rel=\"noopener\"><code>__setattr__()</code></a>但删除属性而不是赋值。这应该只在对对象有意义时才能实现。<code>delobj.name</code></p>\n<p><code>object.`</code><strong>dir</strong>`（<em>self</em>）<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__dir__\" title=\"这个定义的永久性\" target=\"_blank\" rel=\"noopener\"></a></p>\n<p><a href=\"https://docs.python.org/3/library/functions.html#dir\" title=\"DIR\" target=\"_blank\" rel=\"noopener\"><code>dir()</code></a>在对象上调用时调用。必须返回一个序列。<a href=\"https://docs.python.org/3/library/functions.html#dir\" title=\"DIR\" target=\"_blank\" rel=\"noopener\"><code>dir()</code></a>将返回的序列转换为列表并对其进行排序。</p>\n<h2 id=\"描述符：\"><a href=\"#描述符：\" class=\"headerlink\" title=\"描述符：\"></a>描述符：</h2><h2 id=\"一句话概括：描述符就是可重用的属性\"><a href=\"#一句话概括：描述符就是可重用的属性\" class=\"headerlink\" title=\"一句话概括：描述符就是可重用的属性\"></a>一句话概括：描述符就是可重用的属性</h2><p>在这里我要告诉你：从根本上讲，描述符就是可以重复使用的属性。也就是说，描述符可以让你编写这样的代码：</p>\n<p>1</p>\n<p>2</p>\n<p>3</p>\n<p>4</p>\n<p>f  =  Foo()</p>\n<p>b  =  f.bar</p>\n<p>f.bar  =  c</p>\n<p>del  f.bar</p>\n<p>而在解释器执行上述代码时，当发现你试图访问属性（b = f.bar）、对属性赋值（f.bar = c）或者删除一个实例变量的属性（del f.bar）时，就会去调用自定义的方法。    </p>\n<h2 id=\"装饰器\"><a href=\"#装饰器\" class=\"headerlink\" title=\"装饰器:\"></a>装饰器:</h2><h2 id=\"01-什么是装饰器？\"><a href=\"#01-什么是装饰器？\" class=\"headerlink\" title=\"01 什么是装饰器？\"></a>01 什么是装饰器？</h2><p>装饰器可以让一个Python函数拥有原本没有的功能，也就是你可以通过装饰器，让一个平淡无奇的函数变的强大，变的漂亮。 举几个现实中的例子 1、你一个男的程序员，穿上女装，戴上假发，你就有了女人的外表（穿女装、戴假发的过程就是新的特效，你拥有了女人的外表，你原来的小jj还在，没有消失） 2、你新买的毛坯房，装修，买家具后变好看了（装修、家具就是新的特效） 3、孙悟空被放进炼丹炉装饰了一下，出来后，学会了火眼金睛，以前的本领都还在</p>\n<h2 id=\"02-为什么Python要引入装饰器？\"><a href=\"#02-为什么Python要引入装饰器？\" class=\"headerlink\" title=\"02 为什么Python要引入装饰器？\"></a>02 为什么Python要引入装饰器？</h2><p>因为引入装饰器会便于开发，便于代码复用，可以把烂泥扶上墙， 装饰器可以让你一秒变女人且可以保住小JJ，当你某天后悔想重新变回男人，只要脱掉女装和假发即可（如果你变女人的时候，给小JJ做了手术（直接修改函数体的内容），想再变回男人可就痛苦了哦）</p>\n<h2 id=\"03-装饰器有利于解决哪些问题？\"><a href=\"#03-装饰器有利于解决哪些问题？\" class=\"headerlink\" title=\"03 装饰器有利于解决哪些问题？\"></a>03 装饰器有利于解决哪些问题？</h2><p>例子1： 扩展功能 比如你写了一段代码，当你执行 <strong>孙悟空()</strong> 就打印出它目前的技能</p>\n<pre><code># python3支持用中文做函数名，\n# 这里为了方便你理解，就用中文，实际情况为了兼容性，你可别用中文哦\n\ndef 孙悟空():\n  print(&apos;吃桃子&apos;)\n孙悟空()\n# 输出:\n# 吃桃子\n</code></pre><p>现在你希望 <strong>孙悟空</strong>这个函数 打印出 <strong>’有火眼金睛了’</strong>，该怎么做呢？ 是的，你可以直接在函数里加一段 <strong>print(‘有火眼金睛了’)</strong> 但是这样会破坏原来的代码，如果你的代码量很多很多的话，修改起来则是灾难， 不过别担心，你还可以用装饰器来装饰他，让他在原本基础上，扩展出新的功能 代码如下</p>\n<pre><code>def 炼丹炉(func): # func就是‘孙悟空’这个函数\n  def 变身(*args, **kwargs): #*args, **kwargs就是‘孙悟空’的参数列表，这里的‘孙悟空’函数没有传参数，我们写上也不影响，建议都写上  \n      print(&apos;有火眼金睛了&apos;) # 加特效，增加新功能，比如孙悟空的进了炼丹炉后，有了火眼金睛技能  \n      return func(*args, **kwargs) #保留原来的功能，原来孙悟空的技能，如吃桃子\n  return 变身 # 炼丹成功，更强大的，有了火眼金睛技能的孙悟空出世\n\n@炼丹炉\ndef 孙悟空():\n  print(&apos;吃桃子&apos;)\n\n孙悟空()\n# 输出:\n# 有火眼金睛了\n# 吃桃子\n</code></pre><p>例子2：扩展权限认证 比如你的代码，默认打开就播放动画片，代码如下</p>\n<pre><code>def play():\n  print(&apos;开始播放动画片 《喜洋洋和灰太狼》&apos;)\n\nplay()\n# 输出\n# 开始播放动画片 《喜洋洋和灰太狼》\n</code></pre><p>但是突然某天，你突然希望只允许1岁到10才可以看这个动画片，不希望程序员大叔看这个动画片怎么办？ 是的，你可以修改这个代码，加上年龄限制，但如果我们用装饰器的话，就更简单了，就可以不用破坏原来的代码，而且方便扩展到其他函数上</p>\n<pre><code>userAge = 40\n\ndef canYou(func):\n  def decorator(*args, **kwargs):\n      if userAge &gt; 1 and userAge &lt; 10:\n          return func(*args, **kwargs)\n      print(&apos;你的年龄不符合要求，不能看&apos;)\n  return decorator\n\n@canYou\ndef play():\n  print(&apos;开始播放动画片 《喜洋洋和灰太狼》&apos;)\n\nplay()\n# 输出\n# 你的年龄不符合要求，不能看\n# 你可以修改上面的 userAge 为9 试试\n</code></pre><p>你看，是不是很简单，实际情况中，很多时候，你需要对一段代码加上权限认证，加上各种功能；但是又不想，或者不方便破坏原有代码，则可以用装饰器去扩展它</p>\n<h2 id=\"04-装饰器背后的实现原理是什么？\"><a href=\"#04-装饰器背后的实现原理是什么？\" class=\"headerlink\" title=\"04 装饰器背后的实现原理是什么？\"></a>04 装饰器背后的实现原理是什么？</h2><p>原理 代码逆推后如下</p>\n<pre><code>def 炼丹炉(func): \n  def 变身(*args, **kwargs):  \n      print(&apos;有火眼金睛了&apos;) \n      return func(*args, **kwargs) \n  return 变身 \n\ndef 孙悟空():  \n  print(&apos;吃桃子&apos;)\n新_孙悟空 = 炼丹炉(孙悟空) #放入原料，原来的弱小的孙悟空，生成炼丹方案给 新_孙悟空 ，这里也可以把炼丹方案给 原来的‘孙悟空’，为了方便理解，给了新的孙悟空 \n\n新_孙悟空() # 执行炼丹程序，新的孙悟空出世\n</code></pre><p>然后这段代码，写起来有点麻烦，Python官方出了一个快捷代码，也就是语法糖，用了语法糖就变成了下面这样</p>\n<pre><code>def 炼丹炉(func): \n  def 变身(*args, **kwargs):  \n      print(&apos;有火眼金睛了&apos;) \n      return func(*args, **kwargs) \n  return 变身 \n\n@炼丹炉  # 把下面的 ‘孙悟空’ 塞进炼丹炉，并把新的孙悟空复制给下面的函数\ndef 孙悟空():  \n  print(&apos;吃桃子&apos;)\n\n孙悟空() # 执行炼丹程序，新的孙悟空出世\n</code></pre><p>可以一次性在一个函数上用多个装饰器吗？ 当然可以，下面我们给孙悟空，弄个金箍棒，让他学会72变，学会飞</p>\n<pre><code>def 炼丹炉(func):\n  def 变身(*args, **kwargs):\n      print(&apos;有火眼金睛了&apos;)\n      return func(*args, **kwargs)\n  return 变身\n\ndef 龙宫走一趟(func):\n  def 你好(*args, **kwargs):\n      print(&apos;有金箍棒了&apos;)\n      return func(*args, **kwargs)\n  return 你好\n\ndef 拜师学艺(func):\n  def 师傅(*args, **kwargs):\n      print(&apos;学会飞、72变了&apos;)\n      return func(*args, **kwargs)\n  return 师傅\n\n@拜师学艺\n@龙宫走一趟\n@炼丹炉  \ndef 孙悟空():\n  print(&apos;吃桃子&apos;)\n\n孙悟空()\n# 输出\n# 学会飞、72变了\n# 有金箍棒了\n# 有火眼金睛了\n# 吃桃子\n</code></pre><p>上面代码的等效于 <strong>拜师学艺(龙宫走一趟(炼丹炉(孙悟空)))</strong> 代码的执行顺序是 <strong>先从内到外</strong> <strong>先执行 炼丹炉，然后是龙宫走一趟，最后是拜师学艺，[/warning]</strong></p>\n<p>链接：<a href=\"https://www.zhihu.com/question/26930016/answer/360300235\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/26930016/answer/360300235</a></p>\n","site":{"data":{}},"excerpt":"","more":"<p>[warning]</p>\n<h2 id=\"new-方法：\"><a href=\"#new-方法：\" class=\"headerlink\" title=\"__new__方法：\"></a>__new__方法：</h2><p><strong>__new__ 方法是什么？</strong> __new__方法接受的参数虽然也是和__init__一样，但__init__是在类实例创建之后调用，而 __new__方法正是创建这个类实例的方法。 <strong>__new__ 的作用</strong> 依照Python官方文档的说法，__new__方法主要是当你继承一些不可变的class时(比如int, str, tuple)， 提供给你一个自定义这些类的实例化过程的途径。还有就是实现自定义的metaclass。  </p>\n<h2 id=\"定制属性访问\"><a href=\"#定制属性访问\" class=\"headerlink\" title=\"定制属性访问:\"></a>定制属性访问:</h2><p><code>object.`</code><strong>getattr</strong>`（<em>self</em>，<em>name</em>）<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__getattr__\" title=\"这个定义的永久性\" target=\"_blank\" rel=\"noopener\"></a></p>\n<p>当默认的属性访问失败，并调用<a href=\"https://docs.python.org/3/library/exceptions.html#AttributeError\" title=\"AttributeError的\" target=\"_blank\" rel=\"noopener\"><code>AttributeError</code></a>（或者<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__getattribute__\" title=\"对象.__ getattribute__\" target=\"_blank\" rel=\"noopener\"><code>__getattribute__()</code></a>引发<a href=\"https://docs.python.org/3/library/exceptions.html#AttributeError\" title=\"AttributeError的\" target=\"_blank\" rel=\"noopener\"><code>AttributeError</code></a>，因为_名字<em>是不是一个实例的属性或分类的属性<code>self</code>;或<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__get__\" title=\"对象.__ get__\" target=\"_blank\" rel=\"noopener\"><code>__get__()</code></a>的</em>名称_属性提升<a href=\"https://docs.python.org/3/library/exceptions.html#AttributeError\" title=\"AttributeError的\" target=\"_blank\" rel=\"noopener\"><code>AttributeError</code></a>）。此方法应该返回（计算）的属性值或引发<a href=\"https://docs.python.org/3/library/exceptions.html#AttributeError\" title=\"AttributeError的\" target=\"_blank\" rel=\"noopener\"><code>AttributeError</code></a>异常。 请注意，如果通过正常机制找到属性，<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__getattr__\" title=\"对象.__ getattr__\" target=\"_blank\" rel=\"noopener\"><code>__getattr__()</code></a>则不会调用该属性。（这是<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__getattr__\" title=\"对象.__ getattr__\" target=\"_blank\" rel=\"noopener\"><code>__getattr__()</code></a>和之间的故意不对称<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__setattr__\" title=\"对象.__ setattr__\" target=\"_blank\" rel=\"noopener\"><code>__setattr__()</code></a>）。这是出于效率原因而完成的，否则<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__getattr__\" title=\"对象.__ getattr__\" target=\"_blank\" rel=\"noopener\"><code>__getattr__()</code></a>将无法访问实例的其他属性。请注意，至少在实例变量中，您可以通过在实例属性字典中不插入任何值（而是将它们插入另一个对象中）来伪造完全控制。请参阅<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__getattribute__\" title=\"对象.__ getattribute__\" target=\"_blank\" rel=\"noopener\"><code>__getattribute__()</code></a>下面的方法，以实际获得对属性访问的完全控制。</p>\n<p><code>object.`</code><strong>getattribute</strong>`（<em>self</em>，<em>name</em>）<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__getattribute__\" title=\"这个定义的永久性\" target=\"_blank\" rel=\"noopener\"></a></p>\n<p>无条件地调用以实现类的实例的属性访问。如果这个类还定义了<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__getattr__\" title=\"对象.__ getattr__\" target=\"_blank\" rel=\"noopener\"><code>__getattr__()</code></a>，那么除非<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__getattribute__\" title=\"对象.__ getattribute__\" target=\"_blank\" rel=\"noopener\"><code>__getattribute__()</code></a>明确地调用它或引发一个，否则后者将不会被调用<a href=\"https://docs.python.org/3/library/exceptions.html#AttributeError\" title=\"AttributeError的\" target=\"_blank\" rel=\"noopener\"><code>AttributeError</code></a>。此方法应返回（计算）的属性值或引发<a href=\"https://docs.python.org/3/library/exceptions.html#AttributeError\" title=\"AttributeError的\" target=\"_blank\" rel=\"noopener\"><code>AttributeError</code></a>异常。为了避免此方法中的无限递归，它的实现应始终调用具有相同名称的基类方法来访问它所需的任何属性，例如。<code>object.__getattribute__(self,name)</code></p>\n<p>注意</p>\n<p>当通过语言语法或内置函数隐式调用查找特殊方法时，此方法仍可能被忽略。请参阅<a href=\"https://docs.python.org/3/reference/datamodel.html#special-lookup\" target=\"_blank\" rel=\"noopener\">特殊方法查找</a>。</p>\n<p><code>object.`</code><strong>setattr</strong>`（<em>self</em>，<em>name</em>，<em>value</em>）<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__setattr__\" title=\"这个定义的永久性\" target=\"_blank\" rel=\"noopener\"></a></p>\n<p>在试图进行属性分配时调用。这被称为而不是正常机制（即将值存储在实例字典中）。<em>name</em>是属性名称，<em>value</em>是要分配给它的值。 如果<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__setattr__\" title=\"对象.__ setattr__\" target=\"_blank\" rel=\"noopener\"><code>__setattr__()</code></a>想分配给实例属性，它应该调用具有相同名称的基类方法，例如。<code>object.__setattr__(self,name,value)</code></p>\n<p><code>object.`</code><strong>delattr</strong>`（<em>self</em>，<em>name</em>）<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__delattr__\" title=\"这个定义的永久性\" target=\"_blank\" rel=\"noopener\"></a></p>\n<p>像<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__setattr__\" title=\"对象.__ setattr__\" target=\"_blank\" rel=\"noopener\"><code>__setattr__()</code></a>但删除属性而不是赋值。这应该只在对对象有意义时才能实现。<code>delobj.name</code></p>\n<p><code>object.`</code><strong>dir</strong>`（<em>self</em>）<a href=\"https://docs.python.org/3/reference/datamodel.html#object.__dir__\" title=\"这个定义的永久性\" target=\"_blank\" rel=\"noopener\"></a></p>\n<p><a href=\"https://docs.python.org/3/library/functions.html#dir\" title=\"DIR\" target=\"_blank\" rel=\"noopener\"><code>dir()</code></a>在对象上调用时调用。必须返回一个序列。<a href=\"https://docs.python.org/3/library/functions.html#dir\" title=\"DIR\" target=\"_blank\" rel=\"noopener\"><code>dir()</code></a>将返回的序列转换为列表并对其进行排序。</p>\n<h2 id=\"描述符：\"><a href=\"#描述符：\" class=\"headerlink\" title=\"描述符：\"></a>描述符：</h2><h2 id=\"一句话概括：描述符就是可重用的属性\"><a href=\"#一句话概括：描述符就是可重用的属性\" class=\"headerlink\" title=\"一句话概括：描述符就是可重用的属性\"></a>一句话概括：描述符就是可重用的属性</h2><p>在这里我要告诉你：从根本上讲，描述符就是可以重复使用的属性。也就是说，描述符可以让你编写这样的代码：</p>\n<p>1</p>\n<p>2</p>\n<p>3</p>\n<p>4</p>\n<p>f  =  Foo()</p>\n<p>b  =  f.bar</p>\n<p>f.bar  =  c</p>\n<p>del  f.bar</p>\n<p>而在解释器执行上述代码时，当发现你试图访问属性（b = f.bar）、对属性赋值（f.bar = c）或者删除一个实例变量的属性（del f.bar）时，就会去调用自定义的方法。    </p>\n<h2 id=\"装饰器\"><a href=\"#装饰器\" class=\"headerlink\" title=\"装饰器:\"></a>装饰器:</h2><h2 id=\"01-什么是装饰器？\"><a href=\"#01-什么是装饰器？\" class=\"headerlink\" title=\"01 什么是装饰器？\"></a>01 什么是装饰器？</h2><p>装饰器可以让一个Python函数拥有原本没有的功能，也就是你可以通过装饰器，让一个平淡无奇的函数变的强大，变的漂亮。 举几个现实中的例子 1、你一个男的程序员，穿上女装，戴上假发，你就有了女人的外表（穿女装、戴假发的过程就是新的特效，你拥有了女人的外表，你原来的小jj还在，没有消失） 2、你新买的毛坯房，装修，买家具后变好看了（装修、家具就是新的特效） 3、孙悟空被放进炼丹炉装饰了一下，出来后，学会了火眼金睛，以前的本领都还在</p>\n<h2 id=\"02-为什么Python要引入装饰器？\"><a href=\"#02-为什么Python要引入装饰器？\" class=\"headerlink\" title=\"02 为什么Python要引入装饰器？\"></a>02 为什么Python要引入装饰器？</h2><p>因为引入装饰器会便于开发，便于代码复用，可以把烂泥扶上墙， 装饰器可以让你一秒变女人且可以保住小JJ，当你某天后悔想重新变回男人，只要脱掉女装和假发即可（如果你变女人的时候，给小JJ做了手术（直接修改函数体的内容），想再变回男人可就痛苦了哦）</p>\n<h2 id=\"03-装饰器有利于解决哪些问题？\"><a href=\"#03-装饰器有利于解决哪些问题？\" class=\"headerlink\" title=\"03 装饰器有利于解决哪些问题？\"></a>03 装饰器有利于解决哪些问题？</h2><p>例子1： 扩展功能 比如你写了一段代码，当你执行 <strong>孙悟空()</strong> 就打印出它目前的技能</p>\n<pre><code># python3支持用中文做函数名，\n# 这里为了方便你理解，就用中文，实际情况为了兼容性，你可别用中文哦\n\ndef 孙悟空():\n  print(&apos;吃桃子&apos;)\n孙悟空()\n# 输出:\n# 吃桃子\n</code></pre><p>现在你希望 <strong>孙悟空</strong>这个函数 打印出 <strong>’有火眼金睛了’</strong>，该怎么做呢？ 是的，你可以直接在函数里加一段 <strong>print(‘有火眼金睛了’)</strong> 但是这样会破坏原来的代码，如果你的代码量很多很多的话，修改起来则是灾难， 不过别担心，你还可以用装饰器来装饰他，让他在原本基础上，扩展出新的功能 代码如下</p>\n<pre><code>def 炼丹炉(func): # func就是‘孙悟空’这个函数\n  def 变身(*args, **kwargs): #*args, **kwargs就是‘孙悟空’的参数列表，这里的‘孙悟空’函数没有传参数，我们写上也不影响，建议都写上  \n      print(&apos;有火眼金睛了&apos;) # 加特效，增加新功能，比如孙悟空的进了炼丹炉后，有了火眼金睛技能  \n      return func(*args, **kwargs) #保留原来的功能，原来孙悟空的技能，如吃桃子\n  return 变身 # 炼丹成功，更强大的，有了火眼金睛技能的孙悟空出世\n\n@炼丹炉\ndef 孙悟空():\n  print(&apos;吃桃子&apos;)\n\n孙悟空()\n# 输出:\n# 有火眼金睛了\n# 吃桃子\n</code></pre><p>例子2：扩展权限认证 比如你的代码，默认打开就播放动画片，代码如下</p>\n<pre><code>def play():\n  print(&apos;开始播放动画片 《喜洋洋和灰太狼》&apos;)\n\nplay()\n# 输出\n# 开始播放动画片 《喜洋洋和灰太狼》\n</code></pre><p>但是突然某天，你突然希望只允许1岁到10才可以看这个动画片，不希望程序员大叔看这个动画片怎么办？ 是的，你可以修改这个代码，加上年龄限制，但如果我们用装饰器的话，就更简单了，就可以不用破坏原来的代码，而且方便扩展到其他函数上</p>\n<pre><code>userAge = 40\n\ndef canYou(func):\n  def decorator(*args, **kwargs):\n      if userAge &gt; 1 and userAge &lt; 10:\n          return func(*args, **kwargs)\n      print(&apos;你的年龄不符合要求，不能看&apos;)\n  return decorator\n\n@canYou\ndef play():\n  print(&apos;开始播放动画片 《喜洋洋和灰太狼》&apos;)\n\nplay()\n# 输出\n# 你的年龄不符合要求，不能看\n# 你可以修改上面的 userAge 为9 试试\n</code></pre><p>你看，是不是很简单，实际情况中，很多时候，你需要对一段代码加上权限认证，加上各种功能；但是又不想，或者不方便破坏原有代码，则可以用装饰器去扩展它</p>\n<h2 id=\"04-装饰器背后的实现原理是什么？\"><a href=\"#04-装饰器背后的实现原理是什么？\" class=\"headerlink\" title=\"04 装饰器背后的实现原理是什么？\"></a>04 装饰器背后的实现原理是什么？</h2><p>原理 代码逆推后如下</p>\n<pre><code>def 炼丹炉(func): \n  def 变身(*args, **kwargs):  \n      print(&apos;有火眼金睛了&apos;) \n      return func(*args, **kwargs) \n  return 变身 \n\ndef 孙悟空():  \n  print(&apos;吃桃子&apos;)\n新_孙悟空 = 炼丹炉(孙悟空) #放入原料，原来的弱小的孙悟空，生成炼丹方案给 新_孙悟空 ，这里也可以把炼丹方案给 原来的‘孙悟空’，为了方便理解，给了新的孙悟空 \n\n新_孙悟空() # 执行炼丹程序，新的孙悟空出世\n</code></pre><p>然后这段代码，写起来有点麻烦，Python官方出了一个快捷代码，也就是语法糖，用了语法糖就变成了下面这样</p>\n<pre><code>def 炼丹炉(func): \n  def 变身(*args, **kwargs):  \n      print(&apos;有火眼金睛了&apos;) \n      return func(*args, **kwargs) \n  return 变身 \n\n@炼丹炉  # 把下面的 ‘孙悟空’ 塞进炼丹炉，并把新的孙悟空复制给下面的函数\ndef 孙悟空():  \n  print(&apos;吃桃子&apos;)\n\n孙悟空() # 执行炼丹程序，新的孙悟空出世\n</code></pre><p>可以一次性在一个函数上用多个装饰器吗？ 当然可以，下面我们给孙悟空，弄个金箍棒，让他学会72变，学会飞</p>\n<pre><code>def 炼丹炉(func):\n  def 变身(*args, **kwargs):\n      print(&apos;有火眼金睛了&apos;)\n      return func(*args, **kwargs)\n  return 变身\n\ndef 龙宫走一趟(func):\n  def 你好(*args, **kwargs):\n      print(&apos;有金箍棒了&apos;)\n      return func(*args, **kwargs)\n  return 你好\n\ndef 拜师学艺(func):\n  def 师傅(*args, **kwargs):\n      print(&apos;学会飞、72变了&apos;)\n      return func(*args, **kwargs)\n  return 师傅\n\n@拜师学艺\n@龙宫走一趟\n@炼丹炉  \ndef 孙悟空():\n  print(&apos;吃桃子&apos;)\n\n孙悟空()\n# 输出\n# 学会飞、72变了\n# 有金箍棒了\n# 有火眼金睛了\n# 吃桃子\n</code></pre><p>上面代码的等效于 <strong>拜师学艺(龙宫走一趟(炼丹炉(孙悟空)))</strong> 代码的执行顺序是 <strong>先从内到外</strong> <strong>先执行 炼丹炉，然后是龙宫走一趟，最后是拜师学艺，[/warning]</strong></p>\n<p>链接：<a href=\"https://www.zhihu.com/question/26930016/answer/360300235\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/26930016/answer/360300235</a></p>\n"},{"title":"第十节:多继承与魔法方法","url":"233.html","id":"233","date":"2018-05-18T11:19:38.000Z","_content":"\n\n一：多继承：\n------\n\nclass A(): def \\_\\_init\\_\\_(self): print(\"A\") class B(A): def \\_\\_init\\_\\_(self): super().\\_\\_init\\_\\_() print(\"B\") class C(A): def \\_\\_init\\_\\_(self): super().\\_\\_init\\_\\_() print(\"C\") class D(B, C): def \\_\\_init\\_\\_(self): super().\\_\\_init\\_\\_() print(\"D\") D()   ![](https://blog.mviai.com/images/wp-content/uploads/2018/05/OMR.png) python 支持多继承，但对与经典类和新式类来说，多继承查找的顺序是不一样的。 经典类的搜索方式是按照“**从左至右，深度优先**”的方式去查找属性。 新式类的搜索方式是采用“**广度优先**”的方式去查找属性。    \n\n二：魔法方法：\n-------\n\n**1、何为魔法方法：** 　　Python中，一定要区分开函数和方法的含义； 1.函数：类外部定义的，跟类没有直接关系的；形式： def func(*argv): 　　2.方法：class内部定义的函数（对象的方法也可以认为是属性）；分为两种： 　　　　① python自动产生的（魔法方法）：一般形式为 \\_\\_func\\_\\_()，python会在对应的时机自动调用该函数； 　　　　② 人为自定义的方法：一般和普通函数没有区别，只是定义在了class中而已 　　3.方法与函数的区别： 　　　　方法可认为是函数的特殊情况； 　　　　① 方法定义在class内部 　　　　② 方法的第一个参数应为 cls(类方法) 或者 self(实例方法)     **2、魔法方法汇总：** ![](https://blog.mviai.com/images/wp-content/uploads/2018/05/1.png)![](https://blog.mviai.com/images/wp-content/uploads/2018/05/2.png)![](https://blog.mviai.com/images/wp-content/uploads/2018/05/3.png)![](https://blog.mviai.com/images/wp-content/uploads/2018/05/4.png) ①.以上所有的魔法方法，君采用\\_\\_xx\\_\\_形式（__为双 \"_\"，双下划线） ②.以上魔法方法为Python解释器自动调用，当然也可以手动调用 ③.魔法方法Python解释器自动给出默认的，因此除非需要改变其内部功能，其它时刻刻使用默认魔法方法 ④.魔法方法是针对class而言的，脱离了”类“谈magic_method是没有意义的 ⑤.*argv为可变的参数列表，类似C语言的va(variable argument),注意与指针的区别，python中暂时忘掉指针，因为python的内存机制都是解释器自动完成的\n\n\n","source":"_posts/第十节：多继承与魔法方法.md","raw":"---\ntitle: '第十节:多继承与魔法方法'\ntags:\n  - 课后解答\nurl: 233.html\nid: 233\ncategories:\n  - 学习\n  - 教学\ndate: 2018-05-18 19:19:38\n---\n\n\n一：多继承：\n------\n\nclass A(): def \\_\\_init\\_\\_(self): print(\"A\") class B(A): def \\_\\_init\\_\\_(self): super().\\_\\_init\\_\\_() print(\"B\") class C(A): def \\_\\_init\\_\\_(self): super().\\_\\_init\\_\\_() print(\"C\") class D(B, C): def \\_\\_init\\_\\_(self): super().\\_\\_init\\_\\_() print(\"D\") D()   ![](https://blog.mviai.com/images/wp-content/uploads/2018/05/OMR.png) python 支持多继承，但对与经典类和新式类来说，多继承查找的顺序是不一样的。 经典类的搜索方式是按照“**从左至右，深度优先**”的方式去查找属性。 新式类的搜索方式是采用“**广度优先**”的方式去查找属性。    \n\n二：魔法方法：\n-------\n\n**1、何为魔法方法：** 　　Python中，一定要区分开函数和方法的含义； 1.函数：类外部定义的，跟类没有直接关系的；形式： def func(*argv): 　　2.方法：class内部定义的函数（对象的方法也可以认为是属性）；分为两种： 　　　　① python自动产生的（魔法方法）：一般形式为 \\_\\_func\\_\\_()，python会在对应的时机自动调用该函数； 　　　　② 人为自定义的方法：一般和普通函数没有区别，只是定义在了class中而已 　　3.方法与函数的区别： 　　　　方法可认为是函数的特殊情况； 　　　　① 方法定义在class内部 　　　　② 方法的第一个参数应为 cls(类方法) 或者 self(实例方法)     **2、魔法方法汇总：** ![](https://blog.mviai.com/images/wp-content/uploads/2018/05/1.png)![](https://blog.mviai.com/images/wp-content/uploads/2018/05/2.png)![](https://blog.mviai.com/images/wp-content/uploads/2018/05/3.png)![](https://blog.mviai.com/images/wp-content/uploads/2018/05/4.png) ①.以上所有的魔法方法，君采用\\_\\_xx\\_\\_形式（__为双 \"_\"，双下划线） ②.以上魔法方法为Python解释器自动调用，当然也可以手动调用 ③.魔法方法Python解释器自动给出默认的，因此除非需要改变其内部功能，其它时刻刻使用默认魔法方法 ④.魔法方法是针对class而言的，脱离了”类“谈magic_method是没有意义的 ⑤.*argv为可变的参数列表，类似C语言的va(variable argument),注意与指针的区别，python中暂时忘掉指针，因为python的内存机制都是解释器自动完成的\n\n\n","slug":"第十节：多继承与魔法方法","published":1,"updated":"2021-07-26T09:58:02.571Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m39004iigtabyd2xu7u","content":"<h2 id=\"一：多继承：\"><a href=\"#一：多继承：\" class=\"headerlink\" title=\"一：多继承：\"></a>一：多继承：</h2><p>class A(): def __init__(self): print(“A”) class B(A): def __init__(self): super().__init__() print(“B”) class C(A): def __init__(self): super().__init__() print(“C”) class D(B, C): def __init__(self): super().__init__() print(“D”) D()   <img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/OMR.png\" alt> python 支持多继承，但对与经典类和新式类来说，多继承查找的顺序是不一样的。 经典类的搜索方式是按照“<strong>从左至右，深度优先</strong>”的方式去查找属性。 新式类的搜索方式是采用“<strong>广度优先</strong>”的方式去查找属性。    </p>\n<h2 id=\"二：魔法方法：\"><a href=\"#二：魔法方法：\" class=\"headerlink\" title=\"二：魔法方法：\"></a>二：魔法方法：</h2><p><strong>1、何为魔法方法：</strong> 　　Python中，一定要区分开函数和方法的含义； 1.函数：类外部定义的，跟类没有直接关系的；形式： def func(<em>argv): 　　2.方法：class内部定义的函数（对象的方法也可以认为是属性）；分为两种： 　　　　① python自动产生的（魔法方法）：一般形式为 __func__()，python会在对应的时机自动调用该函数； 　　　　② 人为自定义的方法：一般和普通函数没有区别，只是定义在了class中而已 　　3.方法与函数的区别： 　　　　方法可认为是函数的特殊情况； 　　　　① 方法定义在class内部 　　　　② 方法的第一个参数应为 cls(类方法) 或者 self(实例方法)     <strong>2、魔法方法汇总：</strong> <img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/1.png\" alt><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/2.png\" alt><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/3.png\" alt><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/4.png\" alt> ①.以上所有的魔法方法，君采用__xx__形式（__为双 “_”，双下划线） ②.以上魔法方法为Python解释器自动调用，当然也可以手动调用 ③.魔法方法Python解释器自动给出默认的，因此除非需要改变其内部功能，其它时刻刻使用默认魔法方法 ④.魔法方法是针对class而言的，脱离了”类“谈magic_method是没有意义的 ⑤.</em>argv为可变的参数列表，类似C语言的va(variable argument),注意与指针的区别，python中暂时忘掉指针，因为python的内存机制都是解释器自动完成的</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"一：多继承：\"><a href=\"#一：多继承：\" class=\"headerlink\" title=\"一：多继承：\"></a>一：多继承：</h2><p>class A(): def __init__(self): print(“A”) class B(A): def __init__(self): super().__init__() print(“B”) class C(A): def __init__(self): super().__init__() print(“C”) class D(B, C): def __init__(self): super().__init__() print(“D”) D()   <img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/OMR.png\" alt> python 支持多继承，但对与经典类和新式类来说，多继承查找的顺序是不一样的。 经典类的搜索方式是按照“<strong>从左至右，深度优先</strong>”的方式去查找属性。 新式类的搜索方式是采用“<strong>广度优先</strong>”的方式去查找属性。    </p>\n<h2 id=\"二：魔法方法：\"><a href=\"#二：魔法方法：\" class=\"headerlink\" title=\"二：魔法方法：\"></a>二：魔法方法：</h2><p><strong>1、何为魔法方法：</strong> 　　Python中，一定要区分开函数和方法的含义； 1.函数：类外部定义的，跟类没有直接关系的；形式： def func(<em>argv): 　　2.方法：class内部定义的函数（对象的方法也可以认为是属性）；分为两种： 　　　　① python自动产生的（魔法方法）：一般形式为 __func__()，python会在对应的时机自动调用该函数； 　　　　② 人为自定义的方法：一般和普通函数没有区别，只是定义在了class中而已 　　3.方法与函数的区别： 　　　　方法可认为是函数的特殊情况； 　　　　① 方法定义在class内部 　　　　② 方法的第一个参数应为 cls(类方法) 或者 self(实例方法)     <strong>2、魔法方法汇总：</strong> <img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/1.png\" alt><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/2.png\" alt><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/3.png\" alt><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/4.png\" alt> ①.以上所有的魔法方法，君采用__xx__形式（__为双 “_”，双下划线） ②.以上魔法方法为Python解释器自动调用，当然也可以手动调用 ③.魔法方法Python解释器自动给出默认的，因此除非需要改变其内部功能，其它时刻刻使用默认魔法方法 ④.魔法方法是针对class而言的，脱离了”类“谈magic_method是没有意义的 ⑤.</em>argv为可变的参数列表，类似C语言的va(variable argument),注意与指针的区别，python中暂时忘掉指针，因为python的内存机制都是解释器自动完成的</p>\n"},{"title":"第十四节：推导表达式，迭代器，生成器，模块，包","url":"246.html","id":"246","date":"2018-05-28T07:57:39.000Z","_content":"\n\\[danger\\]\n\n一：推导表达式：\n========\n\n一、列表推导式和生成器表达式\n--------------\n\n1 #列表推导式\n2 l = \\[i for i in range(10)\\] 3 print(l) 4 l1 = \\['选项%s'%i for i in range(10)\\] 5 print(l1)\n\n1.把列表解析的\\[\\]换成()得到的就是生成器表达式 2.列表解析与生成器表达式都是一种便利的编程方式，只不过生成器表达式更节省内存 3.Python不但使用迭代器协议，让for循环变得更加通用。大部分内置函数，也是使用迭代器协议访问对象的。例如， sum函数是Python的内置函数，该函数使用迭代器协议访问对象，而生成器实现了迭代器协议，所以，我们可以直接这样计算一系列值的和：\n\n1 sum(x ** 2 for x in range(4))\n\n二、列表推导式\n-------\n\n下面是一个以列表推导式为例的推导式详细格式，同样适用于其他推导式。\n\n1 variable = \\[out\\_exp\\_res for out_exp in input_list if out_exp == 2\\] 2 out\\_exp\\_res:　　列表生成元素表达式，可以是有返回值的函数。 3   for out_exp in input\\_list：　　迭代input\\_list将out\\_exp传入out\\_exp_res表达式中。 4   if out_exp == 2：　　根据条件过滤哪些值可以。 5 \n6 #变量（加工后的变量） for 变量 in 可迭代数据类型 条件判断\n\n### 例一：30以内所有能被3整除的数\n\n1 multiples = \\[i for i in range(30) if i % 3 is 0\\] 2 print(multiples) 3 # Output: \\[0, 3, 6, 9, 12, 15, 18, 21, 24, 27\\]\n\n### 例二：30以内所有能被3整除的数的平方\n\n1 def squared(x): 2     return x*x 3 multiples = \\[squared(i) for i in range(30) if i % 3 is 0\\] 4 print(multiples)\n\n### 例三:找到嵌套列表中名字含有两个‘e’的所有名字\n\n1 names = \\[\\['Tom', 'Billy', 'Jefferson', 'Andrew', 'Wesley', 'Steven', 'Joe'\\], 2          \\['Alice', 'Jill', 'Ana', 'Wendy', 'Jennifer', 'Sherry', 'Eva'\\]\\] 3 \n4 print(\\[name for lst in names for name in lst if name.count('e') >= 2\\])  # 注意遍历顺序，这是实现的关键 \n\n**列表推导****+****条件判断：** l2 = \\[iforiinrange(1, 11) ifi % 2 == 0\\]\n\n**列表推导****+****三目运算：** l3 = \\[i if i % 2 == 0 else 0 for i in range(1, 11)\\]\n\n三、字典推导式\n-------\n\n### 例一：将一个字典的key和value对调\n\n1 mcase = {'a': 10, 'b': 34} 2 #mcase的值 : key\n3 mcase_frequency = {mcase\\[k\\]: k for k in mcase} 4 print(mcase_frequency)\n\n### 例二：合并大小写对应的value值，将k统一成小写\n\n1 mcase = {'a': 10, 'b': 34, 'A': 7, 'Z': 3} 2 #key.lower() : mcase.get(小写的当前key,0) + mcase.get(大写的当前key,0)\n3 #如果没有找到的话，get返回0.和0相加还是原来数\n4 mcase_frequency = {k.lower(): mcase.get(k.lower(), 0) + mcase.get(k.upper(), 0) for k in mcase.keys()} 5 print(mcase_frequency)\n\n四、集合推导式\n-------\n\n### 例：计算列表中每个值的平方，自带去重功能\n\n     \n\n二：迭代器和生成器：\n----------\n\n迭代器\n---\n\n迭代是Python最强大的功能之一，是访问集合元素的一种方式。 迭代器是一个可以记住遍历的位置的对象。 迭代器对象从集合的第一个元素开始访问，直到所有的元素被访问完结束。迭代器只能往前不会后退。 迭代器有两个基本的方法： \\_iter\\_\\_方法：返回迭代器自身。可以通过python内建函数iter()调用。 \\_\\_next\\_\\_方法：当next方法被调用的时候，迭代器会返回它的下一个值，如果next方法被调用，但迭代器没有只可以返回，就会引发一个StopIteration异常。该方法可以通过 python 内建函数next()调用。  字符串，列表或元组对象都可用于创建迭代器：\n\n生成器\n---\n\n简单的说，生成是包含yield关键字的函数。本质上来说，关键字yield是一个语法糖，内部实现支持了迭代器协议，同时yield内部是一个状态机，维护着挂起和继续的状态。 跟普通函数不同的是，生成器是一个返回迭代器的函数，只能用于迭代操作，更简单点理解生成器就是一个迭代器。 在调用生成器运行的过程中，每次遇到 yield 时函数会暂停并保存当前所有的运行信息，返回 yield 的值, 并在下一次执行 next() 方法时从当前位置继续运行。 调用一个生成器函数，返回的是一个迭代器对象。\n\n三，模块：\n-----\n\nPython 模块(Module)，是一个 Python 文件，以 .py 结尾，包含了 Python 对象定义和Python语句。 模块让你能够有逻辑地组织你的 Python 代码段。 把相关的代码分配到一个模块里能让你的代码更好用，更易懂。 模块能定义函数，类和变量，模块里也能包含可执行的代码。  \n\n### import 语句\n\n### 模块的引入\n\n模块定义好后，我们可以使用 import 语句来引入模块，语法如下：\n\n### from…import 语句\n\nPython 的 from 语句让你从模块中导入一个指定的部分到当前命名空间中。语法如下：\n\n### from…import* 语句\n\n把一个模块的所有内容全都导入到当前的命名空间也是可行的，只需使用如下声明：\n\n### 搜索路径\n\n当你导入一个模块，Python 解析器对模块位置的搜索顺序是：\n\n*   1、当前目录\n*   2、如果不在当前目录，Python 则搜索在 shell 变量 PYTHONPATH 下的每个目录。\n*   3、如果都找不到，Python会察看默认路径。UNIX下，默认路径一般为/usr/local/lib/python/。\n\n模块搜索路径存储在 system 模块的 sys.path 变量中。变量里包含当前目录，PYTHONPATH和由安装过程决定的默认目录\n\n四，包及包的管理\n========\n\n**包概念：** 把很多模块放到一个文件夹里面，就可以形成一个包 **包管理：** 当把很多模块放在文件中时，为了方便引用包中的模块，引入了包管理 在包管理中，加入此模块，则包名可以直接通过属性访问的方式，访问此模块内的对象，此模块不加上可能不会报错，但是规范是要加上，文件内容可以为空 **相对路径导入****:** 在包管理中，可以通过 . (一个点) 和 .. (两个点)分别来导入同层和上一层的模块\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/05/图片1.png)\n\n**引入作用:** **在包中，如果包中模块要导入同一包中的其他模块，就必须使用此方法导入** 使用方法： from .module(..module) import obj (as new_name) **引入之后的影响:** 当一个模块中出现此导入方式，则该模块不能被直接运行，只能被导入  \n\n我的理解是 from . import XXX默认的就是在当前程序所在文件夹里\\_\\_init\\_\\_.py程序中导入XXX，如果当前程序所在文件夹里没有\\_\\_init\\_\\_.py文件的话，就不能这样写，而应该写成from .A import XXX，A是指当前文件夹下你想导入的函数(或者其他的)的python程序名，如果你想导入的函数不在当前文件夹，那么就有可能用到 from .. import XXX(即上一个文件夹中的\\_\\_init\\_\\_.py)，或者from ..A import XXX(即上一个文件夹中的文件A\n\nhttps://www.zhihu.com/question/28688151/answer/66982373\n\n\\[/danger\\]\n","source":"_posts/第十四节：推导表达式，迭代器，生成器，模块，包.md","raw":"---\ntitle: 第十四节：推导表达式，迭代器，生成器，模块，包\ntags:\n  - 课后解答\nurl: 246.html\nid: 246\ncategories:\n  - 学习\n  - 教学\ndate: 2018-05-28 15:57:39\n---\n\n\\[danger\\]\n\n一：推导表达式：\n========\n\n一、列表推导式和生成器表达式\n--------------\n\n1 #列表推导式\n2 l = \\[i for i in range(10)\\] 3 print(l) 4 l1 = \\['选项%s'%i for i in range(10)\\] 5 print(l1)\n\n1.把列表解析的\\[\\]换成()得到的就是生成器表达式 2.列表解析与生成器表达式都是一种便利的编程方式，只不过生成器表达式更节省内存 3.Python不但使用迭代器协议，让for循环变得更加通用。大部分内置函数，也是使用迭代器协议访问对象的。例如， sum函数是Python的内置函数，该函数使用迭代器协议访问对象，而生成器实现了迭代器协议，所以，我们可以直接这样计算一系列值的和：\n\n1 sum(x ** 2 for x in range(4))\n\n二、列表推导式\n-------\n\n下面是一个以列表推导式为例的推导式详细格式，同样适用于其他推导式。\n\n1 variable = \\[out\\_exp\\_res for out_exp in input_list if out_exp == 2\\] 2 out\\_exp\\_res:　　列表生成元素表达式，可以是有返回值的函数。 3   for out_exp in input\\_list：　　迭代input\\_list将out\\_exp传入out\\_exp_res表达式中。 4   if out_exp == 2：　　根据条件过滤哪些值可以。 5 \n6 #变量（加工后的变量） for 变量 in 可迭代数据类型 条件判断\n\n### 例一：30以内所有能被3整除的数\n\n1 multiples = \\[i for i in range(30) if i % 3 is 0\\] 2 print(multiples) 3 # Output: \\[0, 3, 6, 9, 12, 15, 18, 21, 24, 27\\]\n\n### 例二：30以内所有能被3整除的数的平方\n\n1 def squared(x): 2     return x*x 3 multiples = \\[squared(i) for i in range(30) if i % 3 is 0\\] 4 print(multiples)\n\n### 例三:找到嵌套列表中名字含有两个‘e’的所有名字\n\n1 names = \\[\\['Tom', 'Billy', 'Jefferson', 'Andrew', 'Wesley', 'Steven', 'Joe'\\], 2          \\['Alice', 'Jill', 'Ana', 'Wendy', 'Jennifer', 'Sherry', 'Eva'\\]\\] 3 \n4 print(\\[name for lst in names for name in lst if name.count('e') >= 2\\])  # 注意遍历顺序，这是实现的关键 \n\n**列表推导****+****条件判断：** l2 = \\[iforiinrange(1, 11) ifi % 2 == 0\\]\n\n**列表推导****+****三目运算：** l3 = \\[i if i % 2 == 0 else 0 for i in range(1, 11)\\]\n\n三、字典推导式\n-------\n\n### 例一：将一个字典的key和value对调\n\n1 mcase = {'a': 10, 'b': 34} 2 #mcase的值 : key\n3 mcase_frequency = {mcase\\[k\\]: k for k in mcase} 4 print(mcase_frequency)\n\n### 例二：合并大小写对应的value值，将k统一成小写\n\n1 mcase = {'a': 10, 'b': 34, 'A': 7, 'Z': 3} 2 #key.lower() : mcase.get(小写的当前key,0) + mcase.get(大写的当前key,0)\n3 #如果没有找到的话，get返回0.和0相加还是原来数\n4 mcase_frequency = {k.lower(): mcase.get(k.lower(), 0) + mcase.get(k.upper(), 0) for k in mcase.keys()} 5 print(mcase_frequency)\n\n四、集合推导式\n-------\n\n### 例：计算列表中每个值的平方，自带去重功能\n\n     \n\n二：迭代器和生成器：\n----------\n\n迭代器\n---\n\n迭代是Python最强大的功能之一，是访问集合元素的一种方式。 迭代器是一个可以记住遍历的位置的对象。 迭代器对象从集合的第一个元素开始访问，直到所有的元素被访问完结束。迭代器只能往前不会后退。 迭代器有两个基本的方法： \\_iter\\_\\_方法：返回迭代器自身。可以通过python内建函数iter()调用。 \\_\\_next\\_\\_方法：当next方法被调用的时候，迭代器会返回它的下一个值，如果next方法被调用，但迭代器没有只可以返回，就会引发一个StopIteration异常。该方法可以通过 python 内建函数next()调用。  字符串，列表或元组对象都可用于创建迭代器：\n\n生成器\n---\n\n简单的说，生成是包含yield关键字的函数。本质上来说，关键字yield是一个语法糖，内部实现支持了迭代器协议，同时yield内部是一个状态机，维护着挂起和继续的状态。 跟普通函数不同的是，生成器是一个返回迭代器的函数，只能用于迭代操作，更简单点理解生成器就是一个迭代器。 在调用生成器运行的过程中，每次遇到 yield 时函数会暂停并保存当前所有的运行信息，返回 yield 的值, 并在下一次执行 next() 方法时从当前位置继续运行。 调用一个生成器函数，返回的是一个迭代器对象。\n\n三，模块：\n-----\n\nPython 模块(Module)，是一个 Python 文件，以 .py 结尾，包含了 Python 对象定义和Python语句。 模块让你能够有逻辑地组织你的 Python 代码段。 把相关的代码分配到一个模块里能让你的代码更好用，更易懂。 模块能定义函数，类和变量，模块里也能包含可执行的代码。  \n\n### import 语句\n\n### 模块的引入\n\n模块定义好后，我们可以使用 import 语句来引入模块，语法如下：\n\n### from…import 语句\n\nPython 的 from 语句让你从模块中导入一个指定的部分到当前命名空间中。语法如下：\n\n### from…import* 语句\n\n把一个模块的所有内容全都导入到当前的命名空间也是可行的，只需使用如下声明：\n\n### 搜索路径\n\n当你导入一个模块，Python 解析器对模块位置的搜索顺序是：\n\n*   1、当前目录\n*   2、如果不在当前目录，Python 则搜索在 shell 变量 PYTHONPATH 下的每个目录。\n*   3、如果都找不到，Python会察看默认路径。UNIX下，默认路径一般为/usr/local/lib/python/。\n\n模块搜索路径存储在 system 模块的 sys.path 变量中。变量里包含当前目录，PYTHONPATH和由安装过程决定的默认目录\n\n四，包及包的管理\n========\n\n**包概念：** 把很多模块放到一个文件夹里面，就可以形成一个包 **包管理：** 当把很多模块放在文件中时，为了方便引用包中的模块，引入了包管理 在包管理中，加入此模块，则包名可以直接通过属性访问的方式，访问此模块内的对象，此模块不加上可能不会报错，但是规范是要加上，文件内容可以为空 **相对路径导入****:** 在包管理中，可以通过 . (一个点) 和 .. (两个点)分别来导入同层和上一层的模块\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/05/图片1.png)\n\n**引入作用:** **在包中，如果包中模块要导入同一包中的其他模块，就必须使用此方法导入** 使用方法： from .module(..module) import obj (as new_name) **引入之后的影响:** 当一个模块中出现此导入方式，则该模块不能被直接运行，只能被导入  \n\n我的理解是 from . import XXX默认的就是在当前程序所在文件夹里\\_\\_init\\_\\_.py程序中导入XXX，如果当前程序所在文件夹里没有\\_\\_init\\_\\_.py文件的话，就不能这样写，而应该写成from .A import XXX，A是指当前文件夹下你想导入的函数(或者其他的)的python程序名，如果你想导入的函数不在当前文件夹，那么就有可能用到 from .. import XXX(即上一个文件夹中的\\_\\_init\\_\\_.py)，或者from ..A import XXX(即上一个文件夹中的文件A\n\nhttps://www.zhihu.com/question/28688151/answer/66982373\n\n\\[/danger\\]\n","slug":"第十四节：推导表达式，迭代器，生成器，模块，包","published":1,"updated":"2021-07-26T09:58:02.573Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m3a004ligta57gv0gt5","content":"<p>[danger]</p>\n<h1 id=\"一：推导表达式：\"><a href=\"#一：推导表达式：\" class=\"headerlink\" title=\"一：推导表达式：\"></a>一：推导表达式：</h1><h2 id=\"一、列表推导式和生成器表达式\"><a href=\"#一、列表推导式和生成器表达式\" class=\"headerlink\" title=\"一、列表推导式和生成器表达式\"></a>一、列表推导式和生成器表达式</h2><p>1 #列表推导式<br>2 l = [i for i in range(10)] 3 print(l) 4 l1 = [‘选项%s’%i for i in range(10)] 5 print(l1)</p>\n<p>1.把列表解析的[]换成()得到的就是生成器表达式 2.列表解析与生成器表达式都是一种便利的编程方式，只不过生成器表达式更节省内存 3.Python不但使用迭代器协议，让for循环变得更加通用。大部分内置函数，也是使用迭代器协议访问对象的。例如， sum函数是Python的内置函数，该函数使用迭代器协议访问对象，而生成器实现了迭代器协议，所以，我们可以直接这样计算一系列值的和：</p>\n<p>1 sum(x ** 2 for x in range(4))</p>\n<h2 id=\"二、列表推导式\"><a href=\"#二、列表推导式\" class=\"headerlink\" title=\"二、列表推导式\"></a>二、列表推导式</h2><p>下面是一个以列表推导式为例的推导式详细格式，同样适用于其他推导式。</p>\n<p>1 variable = [out_exp_res for out_exp in input_list if out_exp == 2] 2 out_exp_res:　　列表生成元素表达式，可以是有返回值的函数。 3   for out_exp in input_list：　　迭代input_list将out_exp传入out_exp_res表达式中。 4   if out_exp == 2：　　根据条件过滤哪些值可以。 5<br>6 #变量（加工后的变量） for 变量 in 可迭代数据类型 条件判断</p>\n<h3 id=\"例一：30以内所有能被3整除的数\"><a href=\"#例一：30以内所有能被3整除的数\" class=\"headerlink\" title=\"例一：30以内所有能被3整除的数\"></a>例一：30以内所有能被3整除的数</h3><p>1 multiples = [i for i in range(30) if i % 3 is 0] 2 print(multiples) 3 # Output: [0, 3, 6, 9, 12, 15, 18, 21, 24, 27]</p>\n<h3 id=\"例二：30以内所有能被3整除的数的平方\"><a href=\"#例二：30以内所有能被3整除的数的平方\" class=\"headerlink\" title=\"例二：30以内所有能被3整除的数的平方\"></a>例二：30以内所有能被3整除的数的平方</h3><p>1 def squared(x): 2     return x*x 3 multiples = [squared(i) for i in range(30) if i % 3 is 0] 4 print(multiples)</p>\n<h3 id=\"例三-找到嵌套列表中名字含有两个‘e’的所有名字\"><a href=\"#例三-找到嵌套列表中名字含有两个‘e’的所有名字\" class=\"headerlink\" title=\"例三:找到嵌套列表中名字含有两个‘e’的所有名字\"></a>例三:找到嵌套列表中名字含有两个‘e’的所有名字</h3><p>1 names = [[‘Tom’, ‘Billy’, ‘Jefferson’, ‘Andrew’, ‘Wesley’, ‘Steven’, ‘Joe’], 2          [‘Alice’, ‘Jill’, ‘Ana’, ‘Wendy’, ‘Jennifer’, ‘Sherry’, ‘Eva’]] 3<br>4 print([name for lst in names for name in lst if name.count(‘e’) &gt;= 2])  # 注意遍历顺序，这是实现的关键 </p>\n<p><strong>列表推导**</strong>+<strong>**条件判断：</strong> l2 = [iforiinrange(1, 11) ifi % 2 == 0]</p>\n<p><strong>列表推导**</strong>+<strong>**三目运算：</strong> l3 = [i if i % 2 == 0 else 0 for i in range(1, 11)]</p>\n<h2 id=\"三、字典推导式\"><a href=\"#三、字典推导式\" class=\"headerlink\" title=\"三、字典推导式\"></a>三、字典推导式</h2><h3 id=\"例一：将一个字典的key和value对调\"><a href=\"#例一：将一个字典的key和value对调\" class=\"headerlink\" title=\"例一：将一个字典的key和value对调\"></a>例一：将一个字典的key和value对调</h3><p>1 mcase = {‘a’: 10, ‘b’: 34} 2 #mcase的值 : key<br>3 mcase_frequency = {mcase[k]: k for k in mcase} 4 print(mcase_frequency)</p>\n<h3 id=\"例二：合并大小写对应的value值，将k统一成小写\"><a href=\"#例二：合并大小写对应的value值，将k统一成小写\" class=\"headerlink\" title=\"例二：合并大小写对应的value值，将k统一成小写\"></a>例二：合并大小写对应的value值，将k统一成小写</h3><p>1 mcase = {‘a’: 10, ‘b’: 34, ‘A’: 7, ‘Z’: 3} 2 #key.lower() : mcase.get(小写的当前key,0) + mcase.get(大写的当前key,0)<br>3 #如果没有找到的话，get返回0.和0相加还是原来数<br>4 mcase_frequency = {k.lower(): mcase.get(k.lower(), 0) + mcase.get(k.upper(), 0) for k in mcase.keys()} 5 print(mcase_frequency)</p>\n<h2 id=\"四、集合推导式\"><a href=\"#四、集合推导式\" class=\"headerlink\" title=\"四、集合推导式\"></a>四、集合推导式</h2><h3 id=\"例：计算列表中每个值的平方，自带去重功能\"><a href=\"#例：计算列表中每个值的平方，自带去重功能\" class=\"headerlink\" title=\"例：计算列表中每个值的平方，自带去重功能\"></a>例：计算列表中每个值的平方，自带去重功能</h3><h2 id=\"二：迭代器和生成器：\"><a href=\"#二：迭代器和生成器：\" class=\"headerlink\" title=\"二：迭代器和生成器：\"></a>二：迭代器和生成器：</h2><h2 id=\"迭代器\"><a href=\"#迭代器\" class=\"headerlink\" title=\"迭代器\"></a>迭代器</h2><p>迭代是Python最强大的功能之一，是访问集合元素的一种方式。 迭代器是一个可以记住遍历的位置的对象。 迭代器对象从集合的第一个元素开始访问，直到所有的元素被访问完结束。迭代器只能往前不会后退。 迭代器有两个基本的方法： _iter__方法：返回迭代器自身。可以通过python内建函数iter()调用。 __next__方法：当next方法被调用的时候，迭代器会返回它的下一个值，如果next方法被调用，但迭代器没有只可以返回，就会引发一个StopIteration异常。该方法可以通过 python 内建函数next()调用。  字符串，列表或元组对象都可用于创建迭代器：</p>\n<h2 id=\"生成器\"><a href=\"#生成器\" class=\"headerlink\" title=\"生成器\"></a>生成器</h2><p>简单的说，生成是包含yield关键字的函数。本质上来说，关键字yield是一个语法糖，内部实现支持了迭代器协议，同时yield内部是一个状态机，维护着挂起和继续的状态。 跟普通函数不同的是，生成器是一个返回迭代器的函数，只能用于迭代操作，更简单点理解生成器就是一个迭代器。 在调用生成器运行的过程中，每次遇到 yield 时函数会暂停并保存当前所有的运行信息，返回 yield 的值, 并在下一次执行 next() 方法时从当前位置继续运行。 调用一个生成器函数，返回的是一个迭代器对象。</p>\n<h2 id=\"三，模块：\"><a href=\"#三，模块：\" class=\"headerlink\" title=\"三，模块：\"></a>三，模块：</h2><p>Python 模块(Module)，是一个 Python 文件，以 .py 结尾，包含了 Python 对象定义和Python语句。 模块让你能够有逻辑地组织你的 Python 代码段。 把相关的代码分配到一个模块里能让你的代码更好用，更易懂。 模块能定义函数，类和变量，模块里也能包含可执行的代码。  </p>\n<h3 id=\"import-语句\"><a href=\"#import-语句\" class=\"headerlink\" title=\"import 语句\"></a>import 语句</h3><h3 id=\"模块的引入\"><a href=\"#模块的引入\" class=\"headerlink\" title=\"模块的引入\"></a>模块的引入</h3><p>模块定义好后，我们可以使用 import 语句来引入模块，语法如下：</p>\n<h3 id=\"from…import-语句\"><a href=\"#from…import-语句\" class=\"headerlink\" title=\"from…import 语句\"></a>from…import 语句</h3><p>Python 的 from 语句让你从模块中导入一个指定的部分到当前命名空间中。语法如下：</p>\n<h3 id=\"from…import-语句-1\"><a href=\"#from…import-语句-1\" class=\"headerlink\" title=\"from…import* 语句\"></a>from…import* 语句</h3><p>把一个模块的所有内容全都导入到当前的命名空间也是可行的，只需使用如下声明：</p>\n<h3 id=\"搜索路径\"><a href=\"#搜索路径\" class=\"headerlink\" title=\"搜索路径\"></a>搜索路径</h3><p>当你导入一个模块，Python 解析器对模块位置的搜索顺序是：</p>\n<ul>\n<li>1、当前目录</li>\n<li>2、如果不在当前目录，Python 则搜索在 shell 变量 PYTHONPATH 下的每个目录。</li>\n<li>3、如果都找不到，Python会察看默认路径。UNIX下，默认路径一般为/usr/local/lib/python/。</li>\n</ul>\n<p>模块搜索路径存储在 system 模块的 sys.path 变量中。变量里包含当前目录，PYTHONPATH和由安装过程决定的默认目录</p>\n<h1 id=\"四，包及包的管理\"><a href=\"#四，包及包的管理\" class=\"headerlink\" title=\"四，包及包的管理\"></a>四，包及包的管理</h1><p><strong>包概念：</strong> 把很多模块放到一个文件夹里面，就可以形成一个包 <strong>包管理：</strong> 当把很多模块放在文件中时，为了方便引用包中的模块，引入了包管理 在包管理中，加入此模块，则包名可以直接通过属性访问的方式，访问此模块内的对象，此模块不加上可能不会报错，但是规范是要加上，文件内容可以为空 <strong>相对路径导入**</strong>:** 在包管理中，可以通过 . (一个点) 和 .. (两个点)分别来导入同层和上一层的模块</p>\n<p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/图片1.png\" alt></p>\n<p><strong>引入作用:</strong> <strong>在包中，如果包中模块要导入同一包中的其他模块，就必须使用此方法导入</strong> 使用方法： from .module(..module) import obj (as new_name) <strong>引入之后的影响:</strong> 当一个模块中出现此导入方式，则该模块不能被直接运行，只能被导入  </p>\n<p>我的理解是 from . import XXX默认的就是在当前程序所在文件夹里__init__.py程序中导入XXX，如果当前程序所在文件夹里没有__init__.py文件的话，就不能这样写，而应该写成from .A import XXX，A是指当前文件夹下你想导入的函数(或者其他的)的python程序名，如果你想导入的函数不在当前文件夹，那么就有可能用到 from .. import XXX(即上一个文件夹中的__init__.py)，或者from ..A import XXX(即上一个文件夹中的文件A</p>\n<p><a href=\"https://www.zhihu.com/question/28688151/answer/66982373\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/28688151/answer/66982373</a></p>\n<p>[/danger]</p>\n","site":{"data":{}},"excerpt":"","more":"<p>[danger]</p>\n<h1 id=\"一：推导表达式：\"><a href=\"#一：推导表达式：\" class=\"headerlink\" title=\"一：推导表达式：\"></a>一：推导表达式：</h1><h2 id=\"一、列表推导式和生成器表达式\"><a href=\"#一、列表推导式和生成器表达式\" class=\"headerlink\" title=\"一、列表推导式和生成器表达式\"></a>一、列表推导式和生成器表达式</h2><p>1 #列表推导式<br>2 l = [i for i in range(10)] 3 print(l) 4 l1 = [‘选项%s’%i for i in range(10)] 5 print(l1)</p>\n<p>1.把列表解析的[]换成()得到的就是生成器表达式 2.列表解析与生成器表达式都是一种便利的编程方式，只不过生成器表达式更节省内存 3.Python不但使用迭代器协议，让for循环变得更加通用。大部分内置函数，也是使用迭代器协议访问对象的。例如， sum函数是Python的内置函数，该函数使用迭代器协议访问对象，而生成器实现了迭代器协议，所以，我们可以直接这样计算一系列值的和：</p>\n<p>1 sum(x ** 2 for x in range(4))</p>\n<h2 id=\"二、列表推导式\"><a href=\"#二、列表推导式\" class=\"headerlink\" title=\"二、列表推导式\"></a>二、列表推导式</h2><p>下面是一个以列表推导式为例的推导式详细格式，同样适用于其他推导式。</p>\n<p>1 variable = [out_exp_res for out_exp in input_list if out_exp == 2] 2 out_exp_res:　　列表生成元素表达式，可以是有返回值的函数。 3   for out_exp in input_list：　　迭代input_list将out_exp传入out_exp_res表达式中。 4   if out_exp == 2：　　根据条件过滤哪些值可以。 5<br>6 #变量（加工后的变量） for 变量 in 可迭代数据类型 条件判断</p>\n<h3 id=\"例一：30以内所有能被3整除的数\"><a href=\"#例一：30以内所有能被3整除的数\" class=\"headerlink\" title=\"例一：30以内所有能被3整除的数\"></a>例一：30以内所有能被3整除的数</h3><p>1 multiples = [i for i in range(30) if i % 3 is 0] 2 print(multiples) 3 # Output: [0, 3, 6, 9, 12, 15, 18, 21, 24, 27]</p>\n<h3 id=\"例二：30以内所有能被3整除的数的平方\"><a href=\"#例二：30以内所有能被3整除的数的平方\" class=\"headerlink\" title=\"例二：30以内所有能被3整除的数的平方\"></a>例二：30以内所有能被3整除的数的平方</h3><p>1 def squared(x): 2     return x*x 3 multiples = [squared(i) for i in range(30) if i % 3 is 0] 4 print(multiples)</p>\n<h3 id=\"例三-找到嵌套列表中名字含有两个‘e’的所有名字\"><a href=\"#例三-找到嵌套列表中名字含有两个‘e’的所有名字\" class=\"headerlink\" title=\"例三:找到嵌套列表中名字含有两个‘e’的所有名字\"></a>例三:找到嵌套列表中名字含有两个‘e’的所有名字</h3><p>1 names = [[‘Tom’, ‘Billy’, ‘Jefferson’, ‘Andrew’, ‘Wesley’, ‘Steven’, ‘Joe’], 2          [‘Alice’, ‘Jill’, ‘Ana’, ‘Wendy’, ‘Jennifer’, ‘Sherry’, ‘Eva’]] 3<br>4 print([name for lst in names for name in lst if name.count(‘e’) &gt;= 2])  # 注意遍历顺序，这是实现的关键 </p>\n<p><strong>列表推导**</strong>+<strong>**条件判断：</strong> l2 = [iforiinrange(1, 11) ifi % 2 == 0]</p>\n<p><strong>列表推导**</strong>+<strong>**三目运算：</strong> l3 = [i if i % 2 == 0 else 0 for i in range(1, 11)]</p>\n<h2 id=\"三、字典推导式\"><a href=\"#三、字典推导式\" class=\"headerlink\" title=\"三、字典推导式\"></a>三、字典推导式</h2><h3 id=\"例一：将一个字典的key和value对调\"><a href=\"#例一：将一个字典的key和value对调\" class=\"headerlink\" title=\"例一：将一个字典的key和value对调\"></a>例一：将一个字典的key和value对调</h3><p>1 mcase = {‘a’: 10, ‘b’: 34} 2 #mcase的值 : key<br>3 mcase_frequency = {mcase[k]: k for k in mcase} 4 print(mcase_frequency)</p>\n<h3 id=\"例二：合并大小写对应的value值，将k统一成小写\"><a href=\"#例二：合并大小写对应的value值，将k统一成小写\" class=\"headerlink\" title=\"例二：合并大小写对应的value值，将k统一成小写\"></a>例二：合并大小写对应的value值，将k统一成小写</h3><p>1 mcase = {‘a’: 10, ‘b’: 34, ‘A’: 7, ‘Z’: 3} 2 #key.lower() : mcase.get(小写的当前key,0) + mcase.get(大写的当前key,0)<br>3 #如果没有找到的话，get返回0.和0相加还是原来数<br>4 mcase_frequency = {k.lower(): mcase.get(k.lower(), 0) + mcase.get(k.upper(), 0) for k in mcase.keys()} 5 print(mcase_frequency)</p>\n<h2 id=\"四、集合推导式\"><a href=\"#四、集合推导式\" class=\"headerlink\" title=\"四、集合推导式\"></a>四、集合推导式</h2><h3 id=\"例：计算列表中每个值的平方，自带去重功能\"><a href=\"#例：计算列表中每个值的平方，自带去重功能\" class=\"headerlink\" title=\"例：计算列表中每个值的平方，自带去重功能\"></a>例：计算列表中每个值的平方，自带去重功能</h3><h2 id=\"二：迭代器和生成器：\"><a href=\"#二：迭代器和生成器：\" class=\"headerlink\" title=\"二：迭代器和生成器：\"></a>二：迭代器和生成器：</h2><h2 id=\"迭代器\"><a href=\"#迭代器\" class=\"headerlink\" title=\"迭代器\"></a>迭代器</h2><p>迭代是Python最强大的功能之一，是访问集合元素的一种方式。 迭代器是一个可以记住遍历的位置的对象。 迭代器对象从集合的第一个元素开始访问，直到所有的元素被访问完结束。迭代器只能往前不会后退。 迭代器有两个基本的方法： _iter__方法：返回迭代器自身。可以通过python内建函数iter()调用。 __next__方法：当next方法被调用的时候，迭代器会返回它的下一个值，如果next方法被调用，但迭代器没有只可以返回，就会引发一个StopIteration异常。该方法可以通过 python 内建函数next()调用。  字符串，列表或元组对象都可用于创建迭代器：</p>\n<h2 id=\"生成器\"><a href=\"#生成器\" class=\"headerlink\" title=\"生成器\"></a>生成器</h2><p>简单的说，生成是包含yield关键字的函数。本质上来说，关键字yield是一个语法糖，内部实现支持了迭代器协议，同时yield内部是一个状态机，维护着挂起和继续的状态。 跟普通函数不同的是，生成器是一个返回迭代器的函数，只能用于迭代操作，更简单点理解生成器就是一个迭代器。 在调用生成器运行的过程中，每次遇到 yield 时函数会暂停并保存当前所有的运行信息，返回 yield 的值, 并在下一次执行 next() 方法时从当前位置继续运行。 调用一个生成器函数，返回的是一个迭代器对象。</p>\n<h2 id=\"三，模块：\"><a href=\"#三，模块：\" class=\"headerlink\" title=\"三，模块：\"></a>三，模块：</h2><p>Python 模块(Module)，是一个 Python 文件，以 .py 结尾，包含了 Python 对象定义和Python语句。 模块让你能够有逻辑地组织你的 Python 代码段。 把相关的代码分配到一个模块里能让你的代码更好用，更易懂。 模块能定义函数，类和变量，模块里也能包含可执行的代码。  </p>\n<h3 id=\"import-语句\"><a href=\"#import-语句\" class=\"headerlink\" title=\"import 语句\"></a>import 语句</h3><h3 id=\"模块的引入\"><a href=\"#模块的引入\" class=\"headerlink\" title=\"模块的引入\"></a>模块的引入</h3><p>模块定义好后，我们可以使用 import 语句来引入模块，语法如下：</p>\n<h3 id=\"from…import-语句\"><a href=\"#from…import-语句\" class=\"headerlink\" title=\"from…import 语句\"></a>from…import 语句</h3><p>Python 的 from 语句让你从模块中导入一个指定的部分到当前命名空间中。语法如下：</p>\n<h3 id=\"from…import-语句-1\"><a href=\"#from…import-语句-1\" class=\"headerlink\" title=\"from…import* 语句\"></a>from…import* 语句</h3><p>把一个模块的所有内容全都导入到当前的命名空间也是可行的，只需使用如下声明：</p>\n<h3 id=\"搜索路径\"><a href=\"#搜索路径\" class=\"headerlink\" title=\"搜索路径\"></a>搜索路径</h3><p>当你导入一个模块，Python 解析器对模块位置的搜索顺序是：</p>\n<ul>\n<li>1、当前目录</li>\n<li>2、如果不在当前目录，Python 则搜索在 shell 变量 PYTHONPATH 下的每个目录。</li>\n<li>3、如果都找不到，Python会察看默认路径。UNIX下，默认路径一般为/usr/local/lib/python/。</li>\n</ul>\n<p>模块搜索路径存储在 system 模块的 sys.path 变量中。变量里包含当前目录，PYTHONPATH和由安装过程决定的默认目录</p>\n<h1 id=\"四，包及包的管理\"><a href=\"#四，包及包的管理\" class=\"headerlink\" title=\"四，包及包的管理\"></a>四，包及包的管理</h1><p><strong>包概念：</strong> 把很多模块放到一个文件夹里面，就可以形成一个包 <strong>包管理：</strong> 当把很多模块放在文件中时，为了方便引用包中的模块，引入了包管理 在包管理中，加入此模块，则包名可以直接通过属性访问的方式，访问此模块内的对象，此模块不加上可能不会报错，但是规范是要加上，文件内容可以为空 <strong>相对路径导入**</strong>:** 在包管理中，可以通过 . (一个点) 和 .. (两个点)分别来导入同层和上一层的模块</p>\n<p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/05/图片1.png\" alt></p>\n<p><strong>引入作用:</strong> <strong>在包中，如果包中模块要导入同一包中的其他模块，就必须使用此方法导入</strong> 使用方法： from .module(..module) import obj (as new_name) <strong>引入之后的影响:</strong> 当一个模块中出现此导入方式，则该模块不能被直接运行，只能被导入  </p>\n<p>我的理解是 from . import XXX默认的就是在当前程序所在文件夹里__init__.py程序中导入XXX，如果当前程序所在文件夹里没有__init__.py文件的话，就不能这样写，而应该写成from .A import XXX，A是指当前文件夹下你想导入的函数(或者其他的)的python程序名，如果你想导入的函数不在当前文件夹，那么就有可能用到 from .. import XXX(即上一个文件夹中的__init__.py)，或者from ..A import XXX(即上一个文件夹中的文件A</p>\n<p><a href=\"https://www.zhihu.com/question/28688151/answer/66982373\" target=\"_blank\" rel=\"noopener\">https://www.zhihu.com/question/28688151/answer/66982373</a></p>\n<p>[/danger]</p>\n"},{"title":"第四节：格式化输出，字符串","date":"2018-05-08T06:38:40.000Z","_content":"\n## 一:格式化输出\n**1、整数的输出\n%o —— oct 八进制\n%d —— dec 十进制\n%x —— hex 十六进制**\n```python\n1  print(\"%o\" % 20)\n2 24\n3  print(\"%d\" % 20)\n4 20\n5  print(\"%x\" % 20)\n6 14\n```\n2、浮点数输出\n（1）格式化输出\n**1. %f ——保留小数点后面六位有效数字\n2. %.3f，保留3位小数位\n3. %e ——保留小数点后面六位有效数字，指数形式输出\n4. %.3e，保留3位小数位，使用科学计数法\n5. %g ——在保证六位有效数字的前提下，使用小数方式，否则使用科学计数法\n6. %.3g，保留3位有效数字，使用小数或科学计数法`**\n```python\n1  print(\"%f\" % 1.11) # 默认保留6位小数\n2 1.110000\n3  print(\"%.1f\" % 1.11) # 取1位小数\n4 1.1\n5  print(\"%e\" % 1.11) # 默认6位小数，用科学计数法\n6 1.110000e+00\n7  print(\"%.3e\" % 1.11) # 取3位小数，用科学计数法\n8 1.110e+00\n9  print(\"%g\" % 1111.1111) # 默认6位有效数字\n10 1111.11\n11  print(\"%.7g\" % 1111.1111) # 取7位有效数字\n12 1111.111\n13  print(\"%.2g\" % 1111.1111) # 取2位有效数字，自动转换为科学计数法\n14 1.1e+03\n```\n（2）内置round()\n**\nround(number[, ndigits])\n参数：\nnumber - 这是一个数字表达式。\nndigits - 表示从小数点到最后四舍五入的位数。默认值为0。\n返回值\n该方法返回x的小数点舍入为n位数后的值。\n\nround()函数只有一个参数，不指定位数的时候，返回一个整数，而且是最靠近的整数，类似于四舍五入，当指定取舍的小数点位数的时候，一般情况也是使用四舍五入的规则，但是碰到.5的情况时，如果要取舍的位数前的小数是奇数，则直接舍弃，如果是偶数则向上取舍。\n\n注：“.5”这个是一个“坑”，且python2和python3出来的接口有时候是不一样的，尽量避免使用round()函数吧**\n```python\n1  round(1.1125) # 四舍五入，不指定位数，取整\n2 1\n3  round(1.1135,3) # 取3位小数，由于3为奇数，则向下“舍”\n4 1.113\n5  round(1.1125,3) # 取3位小数，由于2为偶数，则向上“入”\n6 1.113\n7  round(1.5) # 无法理解，查阅一些资料是说python会对数据进行截断，没有深究\n8 2\n9  round(2.5) # 无法理解\n10 2\n11  round(1.675,2) # 无法理解\n12 1.68\n13  round(2.675,2) # 无法理解\n14 2.67\n15 \n```\n3、字符串输出\n%s\n%10s——右对齐，占位符10位\n%-10s——左对齐，占位符10位\n%.2s——截取2位字符串\n%10.2s——10位占位符，截取两位字符串\n```python\n1  print(\"%s\" % \"hello world\") # 字符串输出\n2 hello world\n3  print(\"%20s\" % \"hello world\") # 右对齐，取20位，不够则补位\n4 hello world\n5  print(\"%-20s\" % \"hello world\") # 左对齐，取20位，不够则补位\n6 hello world\n7  print(\"%.2s\" % \"hello world\") # 取2位\n8 he\n9  print(\"%10.2s\" % \"hello world\") # 右对齐，取2位\n10 he\n11  print(\"%-10.2s\" % \"hello world\") # 左对齐，取2位\n12 he\n```\n4、 其他\n\n字符串格式代码如下\n\n（2）常用转义字符如下\n\n二、format用法\n\n相对基本格式化输出采用‘%’的方法，format()功能更强大，该函数把字符串当成一个模板，通过传入的参数进行格式化，并且使用大括号‘{}’作为特殊字符代替‘%’\n\n使用方法由两种：b.format(a)和format(a,b)。\n\n1、基本用法\n\n（1）不带编号，即“{}”\n\n（2）带数字编号，可调换顺序，即“{1}”、“{2}”\n\n（3）带关键字，即“{a}”、“{tom}”\n```python\n1  print(\"{} {}\".format(\"hello\",\"world\")) # 不带字段\n2 hello world\n3  print(\"{0} {1}\".format(\"hello\",\"world\")) # 带数字编号\n4 hello world\n5  print(\"{0} {1} {0}\".format(\"hello\",\"world\")) # 打乱顺序\n6 hello world hello\n7  print(\"{1} {1} {0}\".format(\"hello\",\"world\"))\n8 world world hello\n9  print(\"{a} {tom} {a}\".format(tom=\"hello\",a=\"world\")) # 带关键字\n10 world hello world\n```\n2、进阶用法\n\n（1）（默认）左对齐、 右对齐、^ 中间对齐、= （只用于数字）在小数点后进行补齐\n\n（2）取位数“{:4s}”、\"{:.2f}\"等\n```python\n1  print(\"{} and {}\".format(\"hello\",\"world\")) # 默认左对齐\n2 hello and world\n3  print(\"{:10s} and {:10s}\".format(\"hello\",\"world\")) # 取10位左对齐，取10位右对齐\n4 hello and world\n5  print(\"{:^10s} and {:^10s}\".format(\"hello\",\"world\")) # 取10位中间对齐\n6 hello and world\n7  print(\"{} is {:.2f}\".format(1.123,1.123)) # 取2位小数\n8 1.123 is 1.12\n9  print(\"{0} is {0:10.2f}\".format(1.123)) # 取2位小数，右对齐，取10位\n10 1.123 is 1.12\n```\n3、多个格式化\n**\n\"b\" - 二进制。将数字以2为基数进行输出。\n\"c\" - 字符。在打印之前将整数转换成对应的Unicode字符串。\n\"d\" - 十进制整数。将数字以10为基数进行输出。\n\"o\" - 八进制。将数字以8为基数进行输出。\n\"x\" - 十六进制。将数字以16为基数进行输出，9以上的位数用小写字母。\n\"e\" - 幂符号。用科学计数法打印数字。用\"e\"表示幂。\n\"g\" - 一般格式。将数值以fixed-point格式输出。当数值特别大的时候，用幂形式打印。\n\"n\" - 数字。当值为整数时和\"d\"相同，值为浮点数时和\"g\"相同。不同的是它会根据区域设置插入数字分隔符。\n\"%\" - 百分数。将数值乘以100然后以fixed-point(\"f\")格式打印，值后面会有一个百分号。**\n```python\n1  print(\"{0:b}\".format(3))\n2 11\n3  print(\"{:c}\".format(58))\n4 :\n5  print(\"{:d}\".format(20))\n6 20\n7  print(\"{:o}\".format(20))\n8 24\n9  print(\"{:x}\".format(20))\n10 14\n11  print(\"{:e}\".format(20))\n12 2.000000e+01\n13  print(\"{:g}\".format(20.1))\n14 20.1\n15  print(\"{:f}\".format(20))\n16 20.000000\n17  print(\"{:n}\".format(20))\n18 20\n19  print(\"{:%}\".format(20))\n20 2000.000000%\n21 \n```\n转载地址；http://www.cnblogs.com/fat39/p/7245035.html\n\n","source":"_posts/第四节：格式化输出，字符串.md","raw":"---\ntitle: 第四节：格式化输出，字符串\ntags:\n  - 课后解答\ncategories:\n  - 学习\n  - 教学\ndate: 2018-05-08 14:38:40\n---\n\n## 一:格式化输出\n**1、整数的输出\n%o —— oct 八进制\n%d —— dec 十进制\n%x —— hex 十六进制**\n```python\n1  print(\"%o\" % 20)\n2 24\n3  print(\"%d\" % 20)\n4 20\n5  print(\"%x\" % 20)\n6 14\n```\n2、浮点数输出\n（1）格式化输出\n**1. %f ——保留小数点后面六位有效数字\n2. %.3f，保留3位小数位\n3. %e ——保留小数点后面六位有效数字，指数形式输出\n4. %.3e，保留3位小数位，使用科学计数法\n5. %g ——在保证六位有效数字的前提下，使用小数方式，否则使用科学计数法\n6. %.3g，保留3位有效数字，使用小数或科学计数法`**\n```python\n1  print(\"%f\" % 1.11) # 默认保留6位小数\n2 1.110000\n3  print(\"%.1f\" % 1.11) # 取1位小数\n4 1.1\n5  print(\"%e\" % 1.11) # 默认6位小数，用科学计数法\n6 1.110000e+00\n7  print(\"%.3e\" % 1.11) # 取3位小数，用科学计数法\n8 1.110e+00\n9  print(\"%g\" % 1111.1111) # 默认6位有效数字\n10 1111.11\n11  print(\"%.7g\" % 1111.1111) # 取7位有效数字\n12 1111.111\n13  print(\"%.2g\" % 1111.1111) # 取2位有效数字，自动转换为科学计数法\n14 1.1e+03\n```\n（2）内置round()\n**\nround(number[, ndigits])\n参数：\nnumber - 这是一个数字表达式。\nndigits - 表示从小数点到最后四舍五入的位数。默认值为0。\n返回值\n该方法返回x的小数点舍入为n位数后的值。\n\nround()函数只有一个参数，不指定位数的时候，返回一个整数，而且是最靠近的整数，类似于四舍五入，当指定取舍的小数点位数的时候，一般情况也是使用四舍五入的规则，但是碰到.5的情况时，如果要取舍的位数前的小数是奇数，则直接舍弃，如果是偶数则向上取舍。\n\n注：“.5”这个是一个“坑”，且python2和python3出来的接口有时候是不一样的，尽量避免使用round()函数吧**\n```python\n1  round(1.1125) # 四舍五入，不指定位数，取整\n2 1\n3  round(1.1135,3) # 取3位小数，由于3为奇数，则向下“舍”\n4 1.113\n5  round(1.1125,3) # 取3位小数，由于2为偶数，则向上“入”\n6 1.113\n7  round(1.5) # 无法理解，查阅一些资料是说python会对数据进行截断，没有深究\n8 2\n9  round(2.5) # 无法理解\n10 2\n11  round(1.675,2) # 无法理解\n12 1.68\n13  round(2.675,2) # 无法理解\n14 2.67\n15 \n```\n3、字符串输出\n%s\n%10s——右对齐，占位符10位\n%-10s——左对齐，占位符10位\n%.2s——截取2位字符串\n%10.2s——10位占位符，截取两位字符串\n```python\n1  print(\"%s\" % \"hello world\") # 字符串输出\n2 hello world\n3  print(\"%20s\" % \"hello world\") # 右对齐，取20位，不够则补位\n4 hello world\n5  print(\"%-20s\" % \"hello world\") # 左对齐，取20位，不够则补位\n6 hello world\n7  print(\"%.2s\" % \"hello world\") # 取2位\n8 he\n9  print(\"%10.2s\" % \"hello world\") # 右对齐，取2位\n10 he\n11  print(\"%-10.2s\" % \"hello world\") # 左对齐，取2位\n12 he\n```\n4、 其他\n\n字符串格式代码如下\n\n（2）常用转义字符如下\n\n二、format用法\n\n相对基本格式化输出采用‘%’的方法，format()功能更强大，该函数把字符串当成一个模板，通过传入的参数进行格式化，并且使用大括号‘{}’作为特殊字符代替‘%’\n\n使用方法由两种：b.format(a)和format(a,b)。\n\n1、基本用法\n\n（1）不带编号，即“{}”\n\n（2）带数字编号，可调换顺序，即“{1}”、“{2}”\n\n（3）带关键字，即“{a}”、“{tom}”\n```python\n1  print(\"{} {}\".format(\"hello\",\"world\")) # 不带字段\n2 hello world\n3  print(\"{0} {1}\".format(\"hello\",\"world\")) # 带数字编号\n4 hello world\n5  print(\"{0} {1} {0}\".format(\"hello\",\"world\")) # 打乱顺序\n6 hello world hello\n7  print(\"{1} {1} {0}\".format(\"hello\",\"world\"))\n8 world world hello\n9  print(\"{a} {tom} {a}\".format(tom=\"hello\",a=\"world\")) # 带关键字\n10 world hello world\n```\n2、进阶用法\n\n（1）（默认）左对齐、 右对齐、^ 中间对齐、= （只用于数字）在小数点后进行补齐\n\n（2）取位数“{:4s}”、\"{:.2f}\"等\n```python\n1  print(\"{} and {}\".format(\"hello\",\"world\")) # 默认左对齐\n2 hello and world\n3  print(\"{:10s} and {:10s}\".format(\"hello\",\"world\")) # 取10位左对齐，取10位右对齐\n4 hello and world\n5  print(\"{:^10s} and {:^10s}\".format(\"hello\",\"world\")) # 取10位中间对齐\n6 hello and world\n7  print(\"{} is {:.2f}\".format(1.123,1.123)) # 取2位小数\n8 1.123 is 1.12\n9  print(\"{0} is {0:10.2f}\".format(1.123)) # 取2位小数，右对齐，取10位\n10 1.123 is 1.12\n```\n3、多个格式化\n**\n\"b\" - 二进制。将数字以2为基数进行输出。\n\"c\" - 字符。在打印之前将整数转换成对应的Unicode字符串。\n\"d\" - 十进制整数。将数字以10为基数进行输出。\n\"o\" - 八进制。将数字以8为基数进行输出。\n\"x\" - 十六进制。将数字以16为基数进行输出，9以上的位数用小写字母。\n\"e\" - 幂符号。用科学计数法打印数字。用\"e\"表示幂。\n\"g\" - 一般格式。将数值以fixed-point格式输出。当数值特别大的时候，用幂形式打印。\n\"n\" - 数字。当值为整数时和\"d\"相同，值为浮点数时和\"g\"相同。不同的是它会根据区域设置插入数字分隔符。\n\"%\" - 百分数。将数值乘以100然后以fixed-point(\"f\")格式打印，值后面会有一个百分号。**\n```python\n1  print(\"{0:b}\".format(3))\n2 11\n3  print(\"{:c}\".format(58))\n4 :\n5  print(\"{:d}\".format(20))\n6 20\n7  print(\"{:o}\".format(20))\n8 24\n9  print(\"{:x}\".format(20))\n10 14\n11  print(\"{:e}\".format(20))\n12 2.000000e+01\n13  print(\"{:g}\".format(20.1))\n14 20.1\n15  print(\"{:f}\".format(20))\n16 20.000000\n17  print(\"{:n}\".format(20))\n18 20\n19  print(\"{:%}\".format(20))\n20 2000.000000%\n21 \n```\n转载地址；http://www.cnblogs.com/fat39/p/7245035.html\n\n","slug":"第四节：格式化输出，字符串","published":1,"updated":"2021-07-26T09:58:02.574Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m3b004nigtaizijwihb","content":"<h2 id=\"一-格式化输出\"><a href=\"#一-格式化输出\" class=\"headerlink\" title=\"一:格式化输出\"></a>一:格式化输出</h2><p><strong>1、整数的输出<br>%o —— oct 八进制<br>%d —— dec 十进制<br>%x —— hex 十六进制</strong><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">1</span>  print(<span class=\"string\">\"%o\"</span> % <span class=\"number\">20</span>)</span><br><span class=\"line\"><span class=\"number\">2</span> <span class=\"number\">24</span></span><br><span class=\"line\"><span class=\"number\">3</span>  print(<span class=\"string\">\"%d\"</span> % <span class=\"number\">20</span>)</span><br><span class=\"line\"><span class=\"number\">4</span> <span class=\"number\">20</span></span><br><span class=\"line\"><span class=\"number\">5</span>  print(<span class=\"string\">\"%x\"</span> % <span class=\"number\">20</span>)</span><br><span class=\"line\"><span class=\"number\">6</span> <span class=\"number\">14</span></span><br></pre></td></tr></table></figure></p>\n<p>2、浮点数输出<br>（1）格式化输出<br>**1. %f ——保留小数点后面六位有效数字</p>\n<ol start=\"2\">\n<li>%.3f，保留3位小数位</li>\n<li>%e ——保留小数点后面六位有效数字，指数形式输出</li>\n<li>%.3e，保留3位小数位，使用科学计数法</li>\n<li>%g ——在保证六位有效数字的前提下，使用小数方式，否则使用科学计数法</li>\n<li>%.3g，保留3位有效数字，使用小数或科学计数法`**<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">1</span>  print(<span class=\"string\">\"%f\"</span> % <span class=\"number\">1.11</span>) <span class=\"comment\"># 默认保留6位小数</span></span><br><span class=\"line\"><span class=\"number\">2</span> <span class=\"number\">1.110000</span></span><br><span class=\"line\"><span class=\"number\">3</span>  print(<span class=\"string\">\"%.1f\"</span> % <span class=\"number\">1.11</span>) <span class=\"comment\"># 取1位小数</span></span><br><span class=\"line\"><span class=\"number\">4</span> <span class=\"number\">1.1</span></span><br><span class=\"line\"><span class=\"number\">5</span>  print(<span class=\"string\">\"%e\"</span> % <span class=\"number\">1.11</span>) <span class=\"comment\"># 默认6位小数，用科学计数法</span></span><br><span class=\"line\"><span class=\"number\">6</span> <span class=\"number\">1.110000e+00</span></span><br><span class=\"line\"><span class=\"number\">7</span>  print(<span class=\"string\">\"%.3e\"</span> % <span class=\"number\">1.11</span>) <span class=\"comment\"># 取3位小数，用科学计数法</span></span><br><span class=\"line\"><span class=\"number\">8</span> <span class=\"number\">1.110e+00</span></span><br><span class=\"line\"><span class=\"number\">9</span>  print(<span class=\"string\">\"%g\"</span> % <span class=\"number\">1111.1111</span>) <span class=\"comment\"># 默认6位有效数字</span></span><br><span class=\"line\"><span class=\"number\">10</span> <span class=\"number\">1111.11</span></span><br><span class=\"line\"><span class=\"number\">11</span>  print(<span class=\"string\">\"%.7g\"</span> % <span class=\"number\">1111.1111</span>) <span class=\"comment\"># 取7位有效数字</span></span><br><span class=\"line\"><span class=\"number\">12</span> <span class=\"number\">1111.111</span></span><br><span class=\"line\"><span class=\"number\">13</span>  print(<span class=\"string\">\"%.2g\"</span> % <span class=\"number\">1111.1111</span>) <span class=\"comment\"># 取2位有效数字，自动转换为科学计数法</span></span><br><span class=\"line\"><span class=\"number\">14</span> <span class=\"number\">1.1e+03</span></span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>（2）内置round()<br>**<br>round(number[, ndigits])<br>参数：<br>number - 这是一个数字表达式。<br>ndigits - 表示从小数点到最后四舍五入的位数。默认值为0。<br>返回值<br>该方法返回x的小数点舍入为n位数后的值。</p>\n<p>round()函数只有一个参数，不指定位数的时候，返回一个整数，而且是最靠近的整数，类似于四舍五入，当指定取舍的小数点位数的时候，一般情况也是使用四舍五入的规则，但是碰到.5的情况时，如果要取舍的位数前的小数是奇数，则直接舍弃，如果是偶数则向上取舍。</p>\n<p>注：“.5”这个是一个“坑”，且python2和python3出来的接口有时候是不一样的，尽量避免使用round()函数吧**<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">1</span>  round(<span class=\"number\">1.1125</span>) <span class=\"comment\"># 四舍五入，不指定位数，取整</span></span><br><span class=\"line\"><span class=\"number\">2</span> <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"number\">3</span>  round(<span class=\"number\">1.1135</span>,<span class=\"number\">3</span>) <span class=\"comment\"># 取3位小数，由于3为奇数，则向下“舍”</span></span><br><span class=\"line\"><span class=\"number\">4</span> <span class=\"number\">1.113</span></span><br><span class=\"line\"><span class=\"number\">5</span>  round(<span class=\"number\">1.1125</span>,<span class=\"number\">3</span>) <span class=\"comment\"># 取3位小数，由于2为偶数，则向上“入”</span></span><br><span class=\"line\"><span class=\"number\">6</span> <span class=\"number\">1.113</span></span><br><span class=\"line\"><span class=\"number\">7</span>  round(<span class=\"number\">1.5</span>) <span class=\"comment\"># 无法理解，查阅一些资料是说python会对数据进行截断，没有深究</span></span><br><span class=\"line\"><span class=\"number\">8</span> <span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"number\">9</span>  round(<span class=\"number\">2.5</span>) <span class=\"comment\"># 无法理解</span></span><br><span class=\"line\"><span class=\"number\">10</span> <span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"number\">11</span>  round(<span class=\"number\">1.675</span>,<span class=\"number\">2</span>) <span class=\"comment\"># 无法理解</span></span><br><span class=\"line\"><span class=\"number\">12</span> <span class=\"number\">1.68</span></span><br><span class=\"line\"><span class=\"number\">13</span>  round(<span class=\"number\">2.675</span>,<span class=\"number\">2</span>) <span class=\"comment\"># 无法理解</span></span><br><span class=\"line\"><span class=\"number\">14</span> <span class=\"number\">2.67</span></span><br><span class=\"line\"><span class=\"number\">15</span></span><br></pre></td></tr></table></figure></p>\n<p>3、字符串输出<br>%s<br>%10s——右对齐，占位符10位<br>%-10s——左对齐，占位符10位<br>%.2s——截取2位字符串<br>%10.2s——10位占位符，截取两位字符串<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">1</span>  print(<span class=\"string\">\"%s\"</span> % <span class=\"string\">\"hello world\"</span>) <span class=\"comment\"># 字符串输出</span></span><br><span class=\"line\"><span class=\"number\">2</span> hello world</span><br><span class=\"line\"><span class=\"number\">3</span>  print(<span class=\"string\">\"%20s\"</span> % <span class=\"string\">\"hello world\"</span>) <span class=\"comment\"># 右对齐，取20位，不够则补位</span></span><br><span class=\"line\"><span class=\"number\">4</span> hello world</span><br><span class=\"line\"><span class=\"number\">5</span>  print(<span class=\"string\">\"%-20s\"</span> % <span class=\"string\">\"hello world\"</span>) <span class=\"comment\"># 左对齐，取20位，不够则补位</span></span><br><span class=\"line\"><span class=\"number\">6</span> hello world</span><br><span class=\"line\"><span class=\"number\">7</span>  print(<span class=\"string\">\"%.2s\"</span> % <span class=\"string\">\"hello world\"</span>) <span class=\"comment\"># 取2位</span></span><br><span class=\"line\"><span class=\"number\">8</span> he</span><br><span class=\"line\"><span class=\"number\">9</span>  print(<span class=\"string\">\"%10.2s\"</span> % <span class=\"string\">\"hello world\"</span>) <span class=\"comment\"># 右对齐，取2位</span></span><br><span class=\"line\"><span class=\"number\">10</span> he</span><br><span class=\"line\"><span class=\"number\">11</span>  print(<span class=\"string\">\"%-10.2s\"</span> % <span class=\"string\">\"hello world\"</span>) <span class=\"comment\"># 左对齐，取2位</span></span><br><span class=\"line\"><span class=\"number\">12</span> he</span><br></pre></td></tr></table></figure></p>\n<p>4、 其他</p>\n<p>字符串格式代码如下</p>\n<p>（2）常用转义字符如下</p>\n<p>二、format用法</p>\n<p>相对基本格式化输出采用‘%’的方法，format()功能更强大，该函数把字符串当成一个模板，通过传入的参数进行格式化，并且使用大括号‘{}’作为特殊字符代替‘%’</p>\n<p>使用方法由两种：b.format(a)和format(a,b)。</p>\n<p>1、基本用法</p>\n<p>（1）不带编号，即“{}”</p>\n<p>（2）带数字编号，可调换顺序，即“{1}”、“{2}”</p>\n<p>（3）带关键字，即“{a}”、“{tom}”<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">1</span>  print(<span class=\"string\">\"&#123;&#125; &#123;&#125;\"</span>.format(<span class=\"string\">\"hello\"</span>,<span class=\"string\">\"world\"</span>)) <span class=\"comment\"># 不带字段</span></span><br><span class=\"line\"><span class=\"number\">2</span> hello world</span><br><span class=\"line\"><span class=\"number\">3</span>  print(<span class=\"string\">\"&#123;0&#125; &#123;1&#125;\"</span>.format(<span class=\"string\">\"hello\"</span>,<span class=\"string\">\"world\"</span>)) <span class=\"comment\"># 带数字编号</span></span><br><span class=\"line\"><span class=\"number\">4</span> hello world</span><br><span class=\"line\"><span class=\"number\">5</span>  print(<span class=\"string\">\"&#123;0&#125; &#123;1&#125; &#123;0&#125;\"</span>.format(<span class=\"string\">\"hello\"</span>,<span class=\"string\">\"world\"</span>)) <span class=\"comment\"># 打乱顺序</span></span><br><span class=\"line\"><span class=\"number\">6</span> hello world hello</span><br><span class=\"line\"><span class=\"number\">7</span>  print(<span class=\"string\">\"&#123;1&#125; &#123;1&#125; &#123;0&#125;\"</span>.format(<span class=\"string\">\"hello\"</span>,<span class=\"string\">\"world\"</span>))</span><br><span class=\"line\"><span class=\"number\">8</span> world world hello</span><br><span class=\"line\"><span class=\"number\">9</span>  print(<span class=\"string\">\"&#123;a&#125; &#123;tom&#125; &#123;a&#125;\"</span>.format(tom=<span class=\"string\">\"hello\"</span>,a=<span class=\"string\">\"world\"</span>)) <span class=\"comment\"># 带关键字</span></span><br><span class=\"line\"><span class=\"number\">10</span> world hello world</span><br></pre></td></tr></table></figure></p>\n<p>2、进阶用法</p>\n<p>（1）（默认）左对齐、 右对齐、^ 中间对齐、= （只用于数字）在小数点后进行补齐</p>\n<p>（2）取位数“{:4s}”、”{:.2f}”等<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">1</span>  print(<span class=\"string\">\"&#123;&#125; and &#123;&#125;\"</span>.format(<span class=\"string\">\"hello\"</span>,<span class=\"string\">\"world\"</span>)) <span class=\"comment\"># 默认左对齐</span></span><br><span class=\"line\"><span class=\"number\">2</span> hello <span class=\"keyword\">and</span> world</span><br><span class=\"line\"><span class=\"number\">3</span>  print(<span class=\"string\">\"&#123;:10s&#125; and &#123;:10s&#125;\"</span>.format(<span class=\"string\">\"hello\"</span>,<span class=\"string\">\"world\"</span>)) <span class=\"comment\"># 取10位左对齐，取10位右对齐</span></span><br><span class=\"line\"><span class=\"number\">4</span> hello <span class=\"keyword\">and</span> world</span><br><span class=\"line\"><span class=\"number\">5</span>  print(<span class=\"string\">\"&#123;:^10s&#125; and &#123;:^10s&#125;\"</span>.format(<span class=\"string\">\"hello\"</span>,<span class=\"string\">\"world\"</span>)) <span class=\"comment\"># 取10位中间对齐</span></span><br><span class=\"line\"><span class=\"number\">6</span> hello <span class=\"keyword\">and</span> world</span><br><span class=\"line\"><span class=\"number\">7</span>  print(<span class=\"string\">\"&#123;&#125; is &#123;:.2f&#125;\"</span>.format(<span class=\"number\">1.123</span>,<span class=\"number\">1.123</span>)) <span class=\"comment\"># 取2位小数</span></span><br><span class=\"line\"><span class=\"number\">8</span> <span class=\"number\">1.123</span> <span class=\"keyword\">is</span> <span class=\"number\">1.12</span></span><br><span class=\"line\"><span class=\"number\">9</span>  print(<span class=\"string\">\"&#123;0&#125; is &#123;0:10.2f&#125;\"</span>.format(<span class=\"number\">1.123</span>)) <span class=\"comment\"># 取2位小数，右对齐，取10位</span></span><br><span class=\"line\"><span class=\"number\">10</span> <span class=\"number\">1.123</span> <span class=\"keyword\">is</span> <span class=\"number\">1.12</span></span><br></pre></td></tr></table></figure></p>\n<p>3、多个格式化<br><strong><br>“b” - 二进制。将数字以2为基数进行输出。<br>“c” - 字符。在打印之前将整数转换成对应的Unicode字符串。<br>“d” - 十进制整数。将数字以10为基数进行输出。<br>“o” - 八进制。将数字以8为基数进行输出。<br>“x” - 十六进制。将数字以16为基数进行输出，9以上的位数用小写字母。<br>“e” - 幂符号。用科学计数法打印数字。用”e”表示幂。<br>“g” - 一般格式。将数值以fixed-point格式输出。当数值特别大的时候，用幂形式打印。<br>“n” - 数字。当值为整数时和”d”相同，值为浮点数时和”g”相同。不同的是它会根据区域设置插入数字分隔符。<br>“%” - 百分数。将数值乘以100然后以fixed-point(“f”)格式打印，值后面会有一个百分号。</strong><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">1</span>  print(<span class=\"string\">\"&#123;0:b&#125;\"</span>.format(<span class=\"number\">3</span>))</span><br><span class=\"line\"><span class=\"number\">2</span> <span class=\"number\">11</span></span><br><span class=\"line\"><span class=\"number\">3</span>  print(<span class=\"string\">\"&#123;:c&#125;\"</span>.format(<span class=\"number\">58</span>))</span><br><span class=\"line\"><span class=\"number\">4</span> :</span><br><span class=\"line\"><span class=\"number\">5</span>  print(<span class=\"string\">\"&#123;:d&#125;\"</span>.format(<span class=\"number\">20</span>))</span><br><span class=\"line\"><span class=\"number\">6</span> <span class=\"number\">20</span></span><br><span class=\"line\"><span class=\"number\">7</span>  print(<span class=\"string\">\"&#123;:o&#125;\"</span>.format(<span class=\"number\">20</span>))</span><br><span class=\"line\"><span class=\"number\">8</span> <span class=\"number\">24</span></span><br><span class=\"line\"><span class=\"number\">9</span>  print(<span class=\"string\">\"&#123;:x&#125;\"</span>.format(<span class=\"number\">20</span>))</span><br><span class=\"line\"><span class=\"number\">10</span> <span class=\"number\">14</span></span><br><span class=\"line\"><span class=\"number\">11</span>  print(<span class=\"string\">\"&#123;:e&#125;\"</span>.format(<span class=\"number\">20</span>))</span><br><span class=\"line\"><span class=\"number\">12</span> <span class=\"number\">2.000000e+01</span></span><br><span class=\"line\"><span class=\"number\">13</span>  print(<span class=\"string\">\"&#123;:g&#125;\"</span>.format(<span class=\"number\">20.1</span>))</span><br><span class=\"line\"><span class=\"number\">14</span> <span class=\"number\">20.1</span></span><br><span class=\"line\"><span class=\"number\">15</span>  print(<span class=\"string\">\"&#123;:f&#125;\"</span>.format(<span class=\"number\">20</span>))</span><br><span class=\"line\"><span class=\"number\">16</span> <span class=\"number\">20.000000</span></span><br><span class=\"line\"><span class=\"number\">17</span>  print(<span class=\"string\">\"&#123;:n&#125;\"</span>.format(<span class=\"number\">20</span>))</span><br><span class=\"line\"><span class=\"number\">18</span> <span class=\"number\">20</span></span><br><span class=\"line\"><span class=\"number\">19</span>  print(<span class=\"string\">\"&#123;:%&#125;\"</span>.format(<span class=\"number\">20</span>))</span><br><span class=\"line\"><span class=\"number\">20</span> <span class=\"number\">2000.000000</span>%</span><br><span class=\"line\"><span class=\"number\">21</span></span><br></pre></td></tr></table></figure></p>\n<p>转载地址；<a href=\"http://www.cnblogs.com/fat39/p/7245035.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/fat39/p/7245035.html</a></p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"一-格式化输出\"><a href=\"#一-格式化输出\" class=\"headerlink\" title=\"一:格式化输出\"></a>一:格式化输出</h2><p><strong>1、整数的输出<br>%o —— oct 八进制<br>%d —— dec 十进制<br>%x —— hex 十六进制</strong><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">1</span>  print(<span class=\"string\">\"%o\"</span> % <span class=\"number\">20</span>)</span><br><span class=\"line\"><span class=\"number\">2</span> <span class=\"number\">24</span></span><br><span class=\"line\"><span class=\"number\">3</span>  print(<span class=\"string\">\"%d\"</span> % <span class=\"number\">20</span>)</span><br><span class=\"line\"><span class=\"number\">4</span> <span class=\"number\">20</span></span><br><span class=\"line\"><span class=\"number\">5</span>  print(<span class=\"string\">\"%x\"</span> % <span class=\"number\">20</span>)</span><br><span class=\"line\"><span class=\"number\">6</span> <span class=\"number\">14</span></span><br></pre></td></tr></table></figure></p>\n<p>2、浮点数输出<br>（1）格式化输出<br>**1. %f ——保留小数点后面六位有效数字</p>\n<ol start=\"2\">\n<li>%.3f，保留3位小数位</li>\n<li>%e ——保留小数点后面六位有效数字，指数形式输出</li>\n<li>%.3e，保留3位小数位，使用科学计数法</li>\n<li>%g ——在保证六位有效数字的前提下，使用小数方式，否则使用科学计数法</li>\n<li>%.3g，保留3位有效数字，使用小数或科学计数法`**<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">1</span>  print(<span class=\"string\">\"%f\"</span> % <span class=\"number\">1.11</span>) <span class=\"comment\"># 默认保留6位小数</span></span><br><span class=\"line\"><span class=\"number\">2</span> <span class=\"number\">1.110000</span></span><br><span class=\"line\"><span class=\"number\">3</span>  print(<span class=\"string\">\"%.1f\"</span> % <span class=\"number\">1.11</span>) <span class=\"comment\"># 取1位小数</span></span><br><span class=\"line\"><span class=\"number\">4</span> <span class=\"number\">1.1</span></span><br><span class=\"line\"><span class=\"number\">5</span>  print(<span class=\"string\">\"%e\"</span> % <span class=\"number\">1.11</span>) <span class=\"comment\"># 默认6位小数，用科学计数法</span></span><br><span class=\"line\"><span class=\"number\">6</span> <span class=\"number\">1.110000e+00</span></span><br><span class=\"line\"><span class=\"number\">7</span>  print(<span class=\"string\">\"%.3e\"</span> % <span class=\"number\">1.11</span>) <span class=\"comment\"># 取3位小数，用科学计数法</span></span><br><span class=\"line\"><span class=\"number\">8</span> <span class=\"number\">1.110e+00</span></span><br><span class=\"line\"><span class=\"number\">9</span>  print(<span class=\"string\">\"%g\"</span> % <span class=\"number\">1111.1111</span>) <span class=\"comment\"># 默认6位有效数字</span></span><br><span class=\"line\"><span class=\"number\">10</span> <span class=\"number\">1111.11</span></span><br><span class=\"line\"><span class=\"number\">11</span>  print(<span class=\"string\">\"%.7g\"</span> % <span class=\"number\">1111.1111</span>) <span class=\"comment\"># 取7位有效数字</span></span><br><span class=\"line\"><span class=\"number\">12</span> <span class=\"number\">1111.111</span></span><br><span class=\"line\"><span class=\"number\">13</span>  print(<span class=\"string\">\"%.2g\"</span> % <span class=\"number\">1111.1111</span>) <span class=\"comment\"># 取2位有效数字，自动转换为科学计数法</span></span><br><span class=\"line\"><span class=\"number\">14</span> <span class=\"number\">1.1e+03</span></span><br></pre></td></tr></table></figure>\n</li>\n</ol>\n<p>（2）内置round()<br>**<br>round(number[, ndigits])<br>参数：<br>number - 这是一个数字表达式。<br>ndigits - 表示从小数点到最后四舍五入的位数。默认值为0。<br>返回值<br>该方法返回x的小数点舍入为n位数后的值。</p>\n<p>round()函数只有一个参数，不指定位数的时候，返回一个整数，而且是最靠近的整数，类似于四舍五入，当指定取舍的小数点位数的时候，一般情况也是使用四舍五入的规则，但是碰到.5的情况时，如果要取舍的位数前的小数是奇数，则直接舍弃，如果是偶数则向上取舍。</p>\n<p>注：“.5”这个是一个“坑”，且python2和python3出来的接口有时候是不一样的，尽量避免使用round()函数吧**<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">1</span>  round(<span class=\"number\">1.1125</span>) <span class=\"comment\"># 四舍五入，不指定位数，取整</span></span><br><span class=\"line\"><span class=\"number\">2</span> <span class=\"number\">1</span></span><br><span class=\"line\"><span class=\"number\">3</span>  round(<span class=\"number\">1.1135</span>,<span class=\"number\">3</span>) <span class=\"comment\"># 取3位小数，由于3为奇数，则向下“舍”</span></span><br><span class=\"line\"><span class=\"number\">4</span> <span class=\"number\">1.113</span></span><br><span class=\"line\"><span class=\"number\">5</span>  round(<span class=\"number\">1.1125</span>,<span class=\"number\">3</span>) <span class=\"comment\"># 取3位小数，由于2为偶数，则向上“入”</span></span><br><span class=\"line\"><span class=\"number\">6</span> <span class=\"number\">1.113</span></span><br><span class=\"line\"><span class=\"number\">7</span>  round(<span class=\"number\">1.5</span>) <span class=\"comment\"># 无法理解，查阅一些资料是说python会对数据进行截断，没有深究</span></span><br><span class=\"line\"><span class=\"number\">8</span> <span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"number\">9</span>  round(<span class=\"number\">2.5</span>) <span class=\"comment\"># 无法理解</span></span><br><span class=\"line\"><span class=\"number\">10</span> <span class=\"number\">2</span></span><br><span class=\"line\"><span class=\"number\">11</span>  round(<span class=\"number\">1.675</span>,<span class=\"number\">2</span>) <span class=\"comment\"># 无法理解</span></span><br><span class=\"line\"><span class=\"number\">12</span> <span class=\"number\">1.68</span></span><br><span class=\"line\"><span class=\"number\">13</span>  round(<span class=\"number\">2.675</span>,<span class=\"number\">2</span>) <span class=\"comment\"># 无法理解</span></span><br><span class=\"line\"><span class=\"number\">14</span> <span class=\"number\">2.67</span></span><br><span class=\"line\"><span class=\"number\">15</span></span><br></pre></td></tr></table></figure></p>\n<p>3、字符串输出<br>%s<br>%10s——右对齐，占位符10位<br>%-10s——左对齐，占位符10位<br>%.2s——截取2位字符串<br>%10.2s——10位占位符，截取两位字符串<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">1</span>  print(<span class=\"string\">\"%s\"</span> % <span class=\"string\">\"hello world\"</span>) <span class=\"comment\"># 字符串输出</span></span><br><span class=\"line\"><span class=\"number\">2</span> hello world</span><br><span class=\"line\"><span class=\"number\">3</span>  print(<span class=\"string\">\"%20s\"</span> % <span class=\"string\">\"hello world\"</span>) <span class=\"comment\"># 右对齐，取20位，不够则补位</span></span><br><span class=\"line\"><span class=\"number\">4</span> hello world</span><br><span class=\"line\"><span class=\"number\">5</span>  print(<span class=\"string\">\"%-20s\"</span> % <span class=\"string\">\"hello world\"</span>) <span class=\"comment\"># 左对齐，取20位，不够则补位</span></span><br><span class=\"line\"><span class=\"number\">6</span> hello world</span><br><span class=\"line\"><span class=\"number\">7</span>  print(<span class=\"string\">\"%.2s\"</span> % <span class=\"string\">\"hello world\"</span>) <span class=\"comment\"># 取2位</span></span><br><span class=\"line\"><span class=\"number\">8</span> he</span><br><span class=\"line\"><span class=\"number\">9</span>  print(<span class=\"string\">\"%10.2s\"</span> % <span class=\"string\">\"hello world\"</span>) <span class=\"comment\"># 右对齐，取2位</span></span><br><span class=\"line\"><span class=\"number\">10</span> he</span><br><span class=\"line\"><span class=\"number\">11</span>  print(<span class=\"string\">\"%-10.2s\"</span> % <span class=\"string\">\"hello world\"</span>) <span class=\"comment\"># 左对齐，取2位</span></span><br><span class=\"line\"><span class=\"number\">12</span> he</span><br></pre></td></tr></table></figure></p>\n<p>4、 其他</p>\n<p>字符串格式代码如下</p>\n<p>（2）常用转义字符如下</p>\n<p>二、format用法</p>\n<p>相对基本格式化输出采用‘%’的方法，format()功能更强大，该函数把字符串当成一个模板，通过传入的参数进行格式化，并且使用大括号‘{}’作为特殊字符代替‘%’</p>\n<p>使用方法由两种：b.format(a)和format(a,b)。</p>\n<p>1、基本用法</p>\n<p>（1）不带编号，即“{}”</p>\n<p>（2）带数字编号，可调换顺序，即“{1}”、“{2}”</p>\n<p>（3）带关键字，即“{a}”、“{tom}”<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">1</span>  print(<span class=\"string\">\"&#123;&#125; &#123;&#125;\"</span>.format(<span class=\"string\">\"hello\"</span>,<span class=\"string\">\"world\"</span>)) <span class=\"comment\"># 不带字段</span></span><br><span class=\"line\"><span class=\"number\">2</span> hello world</span><br><span class=\"line\"><span class=\"number\">3</span>  print(<span class=\"string\">\"&#123;0&#125; &#123;1&#125;\"</span>.format(<span class=\"string\">\"hello\"</span>,<span class=\"string\">\"world\"</span>)) <span class=\"comment\"># 带数字编号</span></span><br><span class=\"line\"><span class=\"number\">4</span> hello world</span><br><span class=\"line\"><span class=\"number\">5</span>  print(<span class=\"string\">\"&#123;0&#125; &#123;1&#125; &#123;0&#125;\"</span>.format(<span class=\"string\">\"hello\"</span>,<span class=\"string\">\"world\"</span>)) <span class=\"comment\"># 打乱顺序</span></span><br><span class=\"line\"><span class=\"number\">6</span> hello world hello</span><br><span class=\"line\"><span class=\"number\">7</span>  print(<span class=\"string\">\"&#123;1&#125; &#123;1&#125; &#123;0&#125;\"</span>.format(<span class=\"string\">\"hello\"</span>,<span class=\"string\">\"world\"</span>))</span><br><span class=\"line\"><span class=\"number\">8</span> world world hello</span><br><span class=\"line\"><span class=\"number\">9</span>  print(<span class=\"string\">\"&#123;a&#125; &#123;tom&#125; &#123;a&#125;\"</span>.format(tom=<span class=\"string\">\"hello\"</span>,a=<span class=\"string\">\"world\"</span>)) <span class=\"comment\"># 带关键字</span></span><br><span class=\"line\"><span class=\"number\">10</span> world hello world</span><br></pre></td></tr></table></figure></p>\n<p>2、进阶用法</p>\n<p>（1）（默认）左对齐、 右对齐、^ 中间对齐、= （只用于数字）在小数点后进行补齐</p>\n<p>（2）取位数“{:4s}”、”{:.2f}”等<br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">1</span>  print(<span class=\"string\">\"&#123;&#125; and &#123;&#125;\"</span>.format(<span class=\"string\">\"hello\"</span>,<span class=\"string\">\"world\"</span>)) <span class=\"comment\"># 默认左对齐</span></span><br><span class=\"line\"><span class=\"number\">2</span> hello <span class=\"keyword\">and</span> world</span><br><span class=\"line\"><span class=\"number\">3</span>  print(<span class=\"string\">\"&#123;:10s&#125; and &#123;:10s&#125;\"</span>.format(<span class=\"string\">\"hello\"</span>,<span class=\"string\">\"world\"</span>)) <span class=\"comment\"># 取10位左对齐，取10位右对齐</span></span><br><span class=\"line\"><span class=\"number\">4</span> hello <span class=\"keyword\">and</span> world</span><br><span class=\"line\"><span class=\"number\">5</span>  print(<span class=\"string\">\"&#123;:^10s&#125; and &#123;:^10s&#125;\"</span>.format(<span class=\"string\">\"hello\"</span>,<span class=\"string\">\"world\"</span>)) <span class=\"comment\"># 取10位中间对齐</span></span><br><span class=\"line\"><span class=\"number\">6</span> hello <span class=\"keyword\">and</span> world</span><br><span class=\"line\"><span class=\"number\">7</span>  print(<span class=\"string\">\"&#123;&#125; is &#123;:.2f&#125;\"</span>.format(<span class=\"number\">1.123</span>,<span class=\"number\">1.123</span>)) <span class=\"comment\"># 取2位小数</span></span><br><span class=\"line\"><span class=\"number\">8</span> <span class=\"number\">1.123</span> <span class=\"keyword\">is</span> <span class=\"number\">1.12</span></span><br><span class=\"line\"><span class=\"number\">9</span>  print(<span class=\"string\">\"&#123;0&#125; is &#123;0:10.2f&#125;\"</span>.format(<span class=\"number\">1.123</span>)) <span class=\"comment\"># 取2位小数，右对齐，取10位</span></span><br><span class=\"line\"><span class=\"number\">10</span> <span class=\"number\">1.123</span> <span class=\"keyword\">is</span> <span class=\"number\">1.12</span></span><br></pre></td></tr></table></figure></p>\n<p>3、多个格式化<br><strong><br>“b” - 二进制。将数字以2为基数进行输出。<br>“c” - 字符。在打印之前将整数转换成对应的Unicode字符串。<br>“d” - 十进制整数。将数字以10为基数进行输出。<br>“o” - 八进制。将数字以8为基数进行输出。<br>“x” - 十六进制。将数字以16为基数进行输出，9以上的位数用小写字母。<br>“e” - 幂符号。用科学计数法打印数字。用”e”表示幂。<br>“g” - 一般格式。将数值以fixed-point格式输出。当数值特别大的时候，用幂形式打印。<br>“n” - 数字。当值为整数时和”d”相同，值为浮点数时和”g”相同。不同的是它会根据区域设置插入数字分隔符。<br>“%” - 百分数。将数值乘以100然后以fixed-point(“f”)格式打印，值后面会有一个百分号。</strong><br><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"number\">1</span>  print(<span class=\"string\">\"&#123;0:b&#125;\"</span>.format(<span class=\"number\">3</span>))</span><br><span class=\"line\"><span class=\"number\">2</span> <span class=\"number\">11</span></span><br><span class=\"line\"><span class=\"number\">3</span>  print(<span class=\"string\">\"&#123;:c&#125;\"</span>.format(<span class=\"number\">58</span>))</span><br><span class=\"line\"><span class=\"number\">4</span> :</span><br><span class=\"line\"><span class=\"number\">5</span>  print(<span class=\"string\">\"&#123;:d&#125;\"</span>.format(<span class=\"number\">20</span>))</span><br><span class=\"line\"><span class=\"number\">6</span> <span class=\"number\">20</span></span><br><span class=\"line\"><span class=\"number\">7</span>  print(<span class=\"string\">\"&#123;:o&#125;\"</span>.format(<span class=\"number\">20</span>))</span><br><span class=\"line\"><span class=\"number\">8</span> <span class=\"number\">24</span></span><br><span class=\"line\"><span class=\"number\">9</span>  print(<span class=\"string\">\"&#123;:x&#125;\"</span>.format(<span class=\"number\">20</span>))</span><br><span class=\"line\"><span class=\"number\">10</span> <span class=\"number\">14</span></span><br><span class=\"line\"><span class=\"number\">11</span>  print(<span class=\"string\">\"&#123;:e&#125;\"</span>.format(<span class=\"number\">20</span>))</span><br><span class=\"line\"><span class=\"number\">12</span> <span class=\"number\">2.000000e+01</span></span><br><span class=\"line\"><span class=\"number\">13</span>  print(<span class=\"string\">\"&#123;:g&#125;\"</span>.format(<span class=\"number\">20.1</span>))</span><br><span class=\"line\"><span class=\"number\">14</span> <span class=\"number\">20.1</span></span><br><span class=\"line\"><span class=\"number\">15</span>  print(<span class=\"string\">\"&#123;:f&#125;\"</span>.format(<span class=\"number\">20</span>))</span><br><span class=\"line\"><span class=\"number\">16</span> <span class=\"number\">20.000000</span></span><br><span class=\"line\"><span class=\"number\">17</span>  print(<span class=\"string\">\"&#123;:n&#125;\"</span>.format(<span class=\"number\">20</span>))</span><br><span class=\"line\"><span class=\"number\">18</span> <span class=\"number\">20</span></span><br><span class=\"line\"><span class=\"number\">19</span>  print(<span class=\"string\">\"&#123;:%&#125;\"</span>.format(<span class=\"number\">20</span>))</span><br><span class=\"line\"><span class=\"number\">20</span> <span class=\"number\">2000.000000</span>%</span><br><span class=\"line\"><span class=\"number\">21</span></span><br></pre></td></tr></table></figure></p>\n<p>转载地址；<a href=\"http://www.cnblogs.com/fat39/p/7245035.html\" target=\"_blank\" rel=\"noopener\">http://www.cnblogs.com/fat39/p/7245035.html</a></p>\n"},{"title":"解决向github提交代码不用输入帐号密码","date":"2019-05-04T09:49:34.000Z","_content":"方案一：\n\n在你的用户目录下新建一个文本文件.git-credentials\n```\nWindows：C:/Users/username\n\nMac OS X： /Users/username\n\nLinux： /home/username\n#注意：鼠标右键新建文件重复命名是成功不了的，需要借助Sublime等IDE工具来创建文件。\n```\n.git-credentials在文件中输入以下内容：\n```\nhttps:{username}:{password}@github.com\n\n#{username}和{password}是你的github的账号和密码\n```\n修改git配置\n执行命令：\n```\ngit config --global credential.helper store\n```\n上述命令会在.gitconfig文件(.gitconfig与.git-credentials在同目录下)末尾添加如下配置:\n```\n[user]\n    name = alice\n    email = alice@aol.com\n[credential]\n    helper = store\n```\n\n经过上述三步配置之后, 你push代码到github时, 便无需再输入用户名密码了\n\n方案二：\n\n在命令行输入命令:\n```\ngit config --global credential.helper store\n```\n这一步会在用户目录下的.gitconfig文件最后添加：\n```\n[credential]\n    helper = store\n    \n```\npush 代码\n *   push你的代码 (git push), 这时会让你输入用户名和密码, 这一步输入的用户名密码会被记住, 下次再push代码时就不用输入用户名密码!这一步会在用户目录下生成文件.git-credential记录用户名密码的信息。\n\n总结：\n* 方案一与方案二都是创建.git-credential文件并写入用户信息，一个是手动创建，一个命令创建。\n","source":"_posts/解决向github提交代码不用输入帐号密码.md","raw":"---\ntitle: 解决向github提交代码不用输入帐号密码\ndate: 2019-05-04 17:49:34\ntags:\n    - github\ncategories:\n    - 工具\n    - 日常工具\n    - github\n---\n方案一：\n\n在你的用户目录下新建一个文本文件.git-credentials\n```\nWindows：C:/Users/username\n\nMac OS X： /Users/username\n\nLinux： /home/username\n#注意：鼠标右键新建文件重复命名是成功不了的，需要借助Sublime等IDE工具来创建文件。\n```\n.git-credentials在文件中输入以下内容：\n```\nhttps:{username}:{password}@github.com\n\n#{username}和{password}是你的github的账号和密码\n```\n修改git配置\n执行命令：\n```\ngit config --global credential.helper store\n```\n上述命令会在.gitconfig文件(.gitconfig与.git-credentials在同目录下)末尾添加如下配置:\n```\n[user]\n    name = alice\n    email = alice@aol.com\n[credential]\n    helper = store\n```\n\n经过上述三步配置之后, 你push代码到github时, 便无需再输入用户名密码了\n\n方案二：\n\n在命令行输入命令:\n```\ngit config --global credential.helper store\n```\n这一步会在用户目录下的.gitconfig文件最后添加：\n```\n[credential]\n    helper = store\n    \n```\npush 代码\n *   push你的代码 (git push), 这时会让你输入用户名和密码, 这一步输入的用户名密码会被记住, 下次再push代码时就不用输入用户名密码!这一步会在用户目录下生成文件.git-credential记录用户名密码的信息。\n\n总结：\n* 方案一与方案二都是创建.git-credential文件并写入用户信息，一个是手动创建，一个命令创建。\n","slug":"解决向github提交代码不用输入帐号密码","published":1,"updated":"2021-07-26T09:58:02.581Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m3c004qigtay36bc7hm","content":"<p>方案一：</p>\n<p>在你的用户目录下新建一个文本文件.git-credentials<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Windows：C:/Users/username</span><br><span class=\"line\"></span><br><span class=\"line\">Mac OS X： /Users/username</span><br><span class=\"line\"></span><br><span class=\"line\">Linux： /home/username</span><br><span class=\"line\">#注意：鼠标右键新建文件重复命名是成功不了的，需要借助Sublime等IDE工具来创建文件。</span><br></pre></td></tr></table></figure></p>\n<p>.git-credentials在文件中输入以下内容：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">https:&#123;username&#125;:&#123;password&#125;@github.com</span><br><span class=\"line\"></span><br><span class=\"line\">#&#123;username&#125;和&#123;password&#125;是你的github的账号和密码</span><br></pre></td></tr></table></figure></p>\n<p>修改git配置<br>执行命令：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git config --global credential.helper store</span><br></pre></td></tr></table></figure></p>\n<p>上述命令会在.gitconfig文件(.gitconfig与.git-credentials在同目录下)末尾添加如下配置:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[user]</span><br><span class=\"line\">    name = alice</span><br><span class=\"line\">    email = alice@aol.com</span><br><span class=\"line\">[credential]</span><br><span class=\"line\">    helper = store</span><br></pre></td></tr></table></figure></p>\n<p>经过上述三步配置之后, 你push代码到github时, 便无需再输入用户名密码了</p>\n<p>方案二：</p>\n<p>在命令行输入命令:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git config --global credential.helper store</span><br></pre></td></tr></table></figure></p>\n<p>这一步会在用户目录下的.gitconfig文件最后添加：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[credential]</span><br><span class=\"line\">    helper = store</span><br></pre></td></tr></table></figure></p>\n<p>push 代码</p>\n<ul>\n<li>push你的代码 (git push), 这时会让你输入用户名和密码, 这一步输入的用户名密码会被记住, 下次再push代码时就不用输入用户名密码!这一步会在用户目录下生成文件.git-credential记录用户名密码的信息。</li>\n</ul>\n<p>总结：</p>\n<ul>\n<li>方案一与方案二都是创建.git-credential文件并写入用户信息，一个是手动创建，一个命令创建。</li>\n</ul>\n","site":{"data":{}},"excerpt":"","more":"<p>方案一：</p>\n<p>在你的用户目录下新建一个文本文件.git-credentials<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Windows：C:/Users/username</span><br><span class=\"line\"></span><br><span class=\"line\">Mac OS X： /Users/username</span><br><span class=\"line\"></span><br><span class=\"line\">Linux： /home/username</span><br><span class=\"line\">#注意：鼠标右键新建文件重复命名是成功不了的，需要借助Sublime等IDE工具来创建文件。</span><br></pre></td></tr></table></figure></p>\n<p>.git-credentials在文件中输入以下内容：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">https:&#123;username&#125;:&#123;password&#125;@github.com</span><br><span class=\"line\"></span><br><span class=\"line\">#&#123;username&#125;和&#123;password&#125;是你的github的账号和密码</span><br></pre></td></tr></table></figure></p>\n<p>修改git配置<br>执行命令：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git config --global credential.helper store</span><br></pre></td></tr></table></figure></p>\n<p>上述命令会在.gitconfig文件(.gitconfig与.git-credentials在同目录下)末尾添加如下配置:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[user]</span><br><span class=\"line\">    name = alice</span><br><span class=\"line\">    email = alice@aol.com</span><br><span class=\"line\">[credential]</span><br><span class=\"line\">    helper = store</span><br></pre></td></tr></table></figure></p>\n<p>经过上述三步配置之后, 你push代码到github时, 便无需再输入用户名密码了</p>\n<p>方案二：</p>\n<p>在命令行输入命令:<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">git config --global credential.helper store</span><br></pre></td></tr></table></figure></p>\n<p>这一步会在用户目录下的.gitconfig文件最后添加：<br><figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">[credential]</span><br><span class=\"line\">    helper = store</span><br></pre></td></tr></table></figure></p>\n<p>push 代码</p>\n<ul>\n<li>push你的代码 (git push), 这时会让你输入用户名和密码, 这一步输入的用户名密码会被记住, 下次再push代码时就不用输入用户名密码!这一步会在用户目录下生成文件.git-credential记录用户名密码的信息。</li>\n</ul>\n<p>总结：</p>\n<ul>\n<li>方案一与方案二都是创建.git-credential文件并写入用户信息，一个是手动创建，一个命令创建。</li>\n</ul>\n"},{"title":"解决wordpress下载插件 安装失败 无法创建目录问题","url":"87.html","id":"87","date":"2018-04-05T13:03:58.000Z","_content":"\n\\[warning\\]\n\n本文只针对liunx\n----------\n\nmac可以简单直接更改文件权限，windows 直接获取管理员权限 用户名组名为 www-data(大家可能不太一样）而此时wordpress用户组为root，这样就不能创建目录了，具体原因大家可以查阅linux相关知识。 我们在default目录下 输入ls -l wordpress (wordpress目录具体地址)  就可以看到用户组了，下面是未修改的用户和用户组，都是root ![](https://blog.mviai.com/images/wp-content/uploads/2018/04/20170128222146285-300x200.png) 如果不知道自己用户组是www-data还是www ，网上教程都是www，于是自己直接在外面创建文件，然后赋予权限 ，最后ls -l 展示下 发现如图 ![](https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-07-14-01-41屏幕截图-300x86.png) 自己全是www-data 说明自己是www-data用户组   然后修改wordpress目录下整体权限（我是直接把wordprss解压到www下的） ![](https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-07-14-02-34屏幕截图-300x183.png) 然后大功告成 \\[/warning\\]\n","source":"_posts/解决wordpress下载插件 安装失败 无法创建目录问题.md","raw":"---\ntitle: 解决wordpress下载插件 安装失败 无法创建目录问题\ntags:\n  - wordpress\nurl: 87.html\nid: 87\ncategories:\n  - 网站\n  - wordpress\ndate: 2018-04-05 21:03:58\n---\n\n\\[warning\\]\n\n本文只针对liunx\n----------\n\nmac可以简单直接更改文件权限，windows 直接获取管理员权限 用户名组名为 www-data(大家可能不太一样）而此时wordpress用户组为root，这样就不能创建目录了，具体原因大家可以查阅linux相关知识。 我们在default目录下 输入ls -l wordpress (wordpress目录具体地址)  就可以看到用户组了，下面是未修改的用户和用户组，都是root ![](https://blog.mviai.com/images/wp-content/uploads/2018/04/20170128222146285-300x200.png) 如果不知道自己用户组是www-data还是www ，网上教程都是www，于是自己直接在外面创建文件，然后赋予权限 ，最后ls -l 展示下 发现如图 ![](https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-07-14-01-41屏幕截图-300x86.png) 自己全是www-data 说明自己是www-data用户组   然后修改wordpress目录下整体权限（我是直接把wordprss解压到www下的） ![](https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-07-14-02-34屏幕截图-300x183.png) 然后大功告成 \\[/warning\\]\n","slug":"解决wordpress下载插件 安装失败 无法创建目录问题","published":1,"updated":"2021-07-26T09:47:32.236Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m3d004rigtaxpczvvrj","content":"<p>[warning]</p>\n<h2 id=\"本文只针对liunx\"><a href=\"#本文只针对liunx\" class=\"headerlink\" title=\"本文只针对liunx\"></a>本文只针对liunx</h2><p>mac可以简单直接更改文件权限，windows 直接获取管理员权限 用户名组名为 www-data(大家可能不太一样）而此时wordpress用户组为root，这样就不能创建目录了，具体原因大家可以查阅linux相关知识。 我们在default目录下 输入ls -l wordpress (wordpress目录具体地址)  就可以看到用户组了，下面是未修改的用户和用户组，都是root <img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/20170128222146285-300x200.png\" alt> 如果不知道自己用户组是www-data还是www ，网上教程都是www，于是自己直接在外面创建文件，然后赋予权限 ，最后ls -l 展示下 发现如图 <img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-07-14-01-41屏幕截图-300x86.png\" alt> 自己全是www-data 说明自己是www-data用户组   然后修改wordpress目录下整体权限（我是直接把wordprss解压到www下的） <img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-07-14-02-34屏幕截图-300x183.png\" alt> 然后大功告成 [/warning]</p>\n","site":{"data":{}},"excerpt":"","more":"<p>[warning]</p>\n<h2 id=\"本文只针对liunx\"><a href=\"#本文只针对liunx\" class=\"headerlink\" title=\"本文只针对liunx\"></a>本文只针对liunx</h2><p>mac可以简单直接更改文件权限，windows 直接获取管理员权限 用户名组名为 www-data(大家可能不太一样）而此时wordpress用户组为root，这样就不能创建目录了，具体原因大家可以查阅linux相关知识。 我们在default目录下 输入ls -l wordpress (wordpress目录具体地址)  就可以看到用户组了，下面是未修改的用户和用户组，都是root <img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/20170128222146285-300x200.png\" alt> 如果不知道自己用户组是www-data还是www ，网上教程都是www，于是自己直接在外面创建文件，然后赋予权限 ，最后ls -l 展示下 发现如图 <img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-07-14-01-41屏幕截图-300x86.png\" alt> 自己全是www-data 说明自己是www-data用户组   然后修改wordpress目录下整体权限（我是直接把wordprss解压到www下的） <img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-07-14-02-34屏幕截图-300x183.png\" alt> 然后大功告成 [/warning]</p>\n"},{"title":"计算机网络体系结构","url":"155.html","id":"155","date":"2018-04-09T14:06:12.000Z","_content":"\n1.计算机发展\n-------\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-10_013920.png)\n\n2.计算机网络组成\n---------\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-10_014053-300x138.png)\n\n3.网络功能\n------\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-10_014108.png)\n\n4.网络性能指标\n--------\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-10_014128.png)\n\n5.网络分类\n------\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-10_014104.png)\n\n6.网络接口，协议，服务\n------------\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-10_014121.png)\n\n疑难解答：\n-----\n\n### 1.协议与服务有什么区别与联系？\n\n协议是控制两个对等实体进行通信的规则集合，在协议控制下，两个对等实体间使得本层能向下，向上一层提供服务 区别：协议的实现保证了能够向上一层提供服务。本层服务用户只能看见服务而**无法看见下面协议** 协议是**水平**的，服务是**垂直**的\n\n### 2.计算机网络与分布式系统别区\n\n二者区别主要是软件不同  \n\n### **3.速率提高体现在单位时间发送到链路上的比特数增多，并不是跑的快了**！\n\n### 4.理解传输时延，发送时延，传播时延\n\n**传输时延就是发送时延。** 传播时延是指电磁波在信道传播一定距离花费的时间 传播时延=信道长度/电磁波在信道上的传播速率 [**如何下载使用思维导图（点我）**](https://blog.mviai.com/images/archives/172) 思维导图下载：链接：https://pan.yangxin.com/s/1TJXj8CgDO-JUbpgcTY6AWg  \\[reply\\]密码：rdxd\\[/reply\\] 待续。。。。。。。\n","source":"_posts/计算机网络体系结构.md","raw":"---\ntitle: 计算机网络体系结构\ntags:\n  - 计算机网络\nurl: 155.html\nid: 155\ncategories:\n  - 学习\n  - 计算机网络\n  - 网络体系\ndate: 2018-04-09 22:06:12\n\n---\n\n1.计算机发展\n-------\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-10_013920.png)\n\n2.计算机网络组成\n---------\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-10_014053-300x138.png)\n\n3.网络功能\n------\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-10_014108.png)\n\n4.网络性能指标\n--------\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-10_014128.png)\n\n5.网络分类\n------\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-10_014104.png)\n\n6.网络接口，协议，服务\n------------\n\n![](https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-10_014121.png)\n\n疑难解答：\n-----\n\n### 1.协议与服务有什么区别与联系？\n\n协议是控制两个对等实体进行通信的规则集合，在协议控制下，两个对等实体间使得本层能向下，向上一层提供服务 区别：协议的实现保证了能够向上一层提供服务。本层服务用户只能看见服务而**无法看见下面协议** 协议是**水平**的，服务是**垂直**的\n\n### 2.计算机网络与分布式系统别区\n\n二者区别主要是软件不同  \n\n### **3.速率提高体现在单位时间发送到链路上的比特数增多，并不是跑的快了**！\n\n### 4.理解传输时延，发送时延，传播时延\n\n**传输时延就是发送时延。** 传播时延是指电磁波在信道传播一定距离花费的时间 传播时延=信道长度/电磁波在信道上的传播速率 [**如何下载使用思维导图（点我）**](https://blog.mviai.com/images/archives/172) 思维导图下载：链接：https://pan.yangxin.com/s/1TJXj8CgDO-JUbpgcTY6AWg  \\[reply\\]密码：rdxd\\[/reply\\] 待续。。。。。。。\n","slug":"计算机网络体系结构","published":1,"updated":"2021-07-26T09:58:02.580Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m3e004vigtav82h0lqb","content":"<h2 id=\"1-计算机发展\"><a href=\"#1-计算机发展\" class=\"headerlink\" title=\"1.计算机发展\"></a>1.计算机发展</h2><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-10_013920.png\" alt></p>\n<h2 id=\"2-计算机网络组成\"><a href=\"#2-计算机网络组成\" class=\"headerlink\" title=\"2.计算机网络组成\"></a>2.计算机网络组成</h2><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-10_014053-300x138.png\" alt></p>\n<h2 id=\"3-网络功能\"><a href=\"#3-网络功能\" class=\"headerlink\" title=\"3.网络功能\"></a>3.网络功能</h2><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-10_014108.png\" alt></p>\n<h2 id=\"4-网络性能指标\"><a href=\"#4-网络性能指标\" class=\"headerlink\" title=\"4.网络性能指标\"></a>4.网络性能指标</h2><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-10_014128.png\" alt></p>\n<h2 id=\"5-网络分类\"><a href=\"#5-网络分类\" class=\"headerlink\" title=\"5.网络分类\"></a>5.网络分类</h2><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-10_014104.png\" alt></p>\n<h2 id=\"6-网络接口，协议，服务\"><a href=\"#6-网络接口，协议，服务\" class=\"headerlink\" title=\"6.网络接口，协议，服务\"></a>6.网络接口，协议，服务</h2><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-10_014121.png\" alt></p>\n<h2 id=\"疑难解答：\"><a href=\"#疑难解答：\" class=\"headerlink\" title=\"疑难解答：\"></a>疑难解答：</h2><h3 id=\"1-协议与服务有什么区别与联系？\"><a href=\"#1-协议与服务有什么区别与联系？\" class=\"headerlink\" title=\"1.协议与服务有什么区别与联系？\"></a>1.协议与服务有什么区别与联系？</h3><p>协议是控制两个对等实体进行通信的规则集合，在协议控制下，两个对等实体间使得本层能向下，向上一层提供服务 区别：协议的实现保证了能够向上一层提供服务。本层服务用户只能看见服务而<strong>无法看见下面协议</strong> 协议是<strong>水平</strong>的，服务是<strong>垂直</strong>的</p>\n<h3 id=\"2-计算机网络与分布式系统别区\"><a href=\"#2-计算机网络与分布式系统别区\" class=\"headerlink\" title=\"2.计算机网络与分布式系统别区\"></a>2.计算机网络与分布式系统别区</h3><p>二者区别主要是软件不同  </p>\n<h3 id=\"3-速率提高体现在单位时间发送到链路上的比特数增多，并不是跑的快了！\"><a href=\"#3-速率提高体现在单位时间发送到链路上的比特数增多，并不是跑的快了！\" class=\"headerlink\" title=\"3.速率提高体现在单位时间发送到链路上的比特数增多，并不是跑的快了！\"></a><strong>3.速率提高体现在单位时间发送到链路上的比特数增多，并不是跑的快了</strong>！</h3><h3 id=\"4-理解传输时延，发送时延，传播时延\"><a href=\"#4-理解传输时延，发送时延，传播时延\" class=\"headerlink\" title=\"4.理解传输时延，发送时延，传播时延\"></a>4.理解传输时延，发送时延，传播时延</h3><p><strong>传输时延就是发送时延。</strong> 传播时延是指电磁波在信道传播一定距离花费的时间 传播时延=信道长度/电磁波在信道上的传播速率 <a href=\"https://blog.mviai.com/images/archives/172\" target=\"_blank\" rel=\"noopener\"><strong>如何下载使用思维导图（点我）</strong></a> 思维导图下载：链接：<a href=\"https://pan.yangxin.com/s/1TJXj8CgDO-JUbpgcTY6AWg\" target=\"_blank\" rel=\"noopener\">https://pan.yangxin.com/s/1TJXj8CgDO-JUbpgcTY6AWg</a>  [reply]密码：rdxd[/reply] 待续。。。。。。。</p>\n","site":{"data":{}},"excerpt":"","more":"<h2 id=\"1-计算机发展\"><a href=\"#1-计算机发展\" class=\"headerlink\" title=\"1.计算机发展\"></a>1.计算机发展</h2><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-10_013920.png\" alt></p>\n<h2 id=\"2-计算机网络组成\"><a href=\"#2-计算机网络组成\" class=\"headerlink\" title=\"2.计算机网络组成\"></a>2.计算机网络组成</h2><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-10_014053-300x138.png\" alt></p>\n<h2 id=\"3-网络功能\"><a href=\"#3-网络功能\" class=\"headerlink\" title=\"3.网络功能\"></a>3.网络功能</h2><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-10_014108.png\" alt></p>\n<h2 id=\"4-网络性能指标\"><a href=\"#4-网络性能指标\" class=\"headerlink\" title=\"4.网络性能指标\"></a>4.网络性能指标</h2><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-10_014128.png\" alt></p>\n<h2 id=\"5-网络分类\"><a href=\"#5-网络分类\" class=\"headerlink\" title=\"5.网络分类\"></a>5.网络分类</h2><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-10_014104.png\" alt></p>\n<h2 id=\"6-网络接口，协议，服务\"><a href=\"#6-网络接口，协议，服务\" class=\"headerlink\" title=\"6.网络接口，协议，服务\"></a>6.网络接口，协议，服务</h2><p><img src=\"https://blog.mviai.com/images/wp-content/uploads/2018/04/2018-04-10_014121.png\" alt></p>\n<h2 id=\"疑难解答：\"><a href=\"#疑难解答：\" class=\"headerlink\" title=\"疑难解答：\"></a>疑难解答：</h2><h3 id=\"1-协议与服务有什么区别与联系？\"><a href=\"#1-协议与服务有什么区别与联系？\" class=\"headerlink\" title=\"1.协议与服务有什么区别与联系？\"></a>1.协议与服务有什么区别与联系？</h3><p>协议是控制两个对等实体进行通信的规则集合，在协议控制下，两个对等实体间使得本层能向下，向上一层提供服务 区别：协议的实现保证了能够向上一层提供服务。本层服务用户只能看见服务而<strong>无法看见下面协议</strong> 协议是<strong>水平</strong>的，服务是<strong>垂直</strong>的</p>\n<h3 id=\"2-计算机网络与分布式系统别区\"><a href=\"#2-计算机网络与分布式系统别区\" class=\"headerlink\" title=\"2.计算机网络与分布式系统别区\"></a>2.计算机网络与分布式系统别区</h3><p>二者区别主要是软件不同  </p>\n<h3 id=\"3-速率提高体现在单位时间发送到链路上的比特数增多，并不是跑的快了！\"><a href=\"#3-速率提高体现在单位时间发送到链路上的比特数增多，并不是跑的快了！\" class=\"headerlink\" title=\"3.速率提高体现在单位时间发送到链路上的比特数增多，并不是跑的快了！\"></a><strong>3.速率提高体现在单位时间发送到链路上的比特数增多，并不是跑的快了</strong>！</h3><h3 id=\"4-理解传输时延，发送时延，传播时延\"><a href=\"#4-理解传输时延，发送时延，传播时延\" class=\"headerlink\" title=\"4.理解传输时延，发送时延，传播时延\"></a>4.理解传输时延，发送时延，传播时延</h3><p><strong>传输时延就是发送时延。</strong> 传播时延是指电磁波在信道传播一定距离花费的时间 传播时延=信道长度/电磁波在信道上的传播速率 <a href=\"https://blog.mviai.com/images/archives/172\" target=\"_blank\" rel=\"noopener\"><strong>如何下载使用思维导图（点我）</strong></a> 思维导图下载：链接：<a href=\"https://pan.yangxin.com/s/1TJXj8CgDO-JUbpgcTY6AWg\" target=\"_blank\" rel=\"noopener\">https://pan.yangxin.com/s/1TJXj8CgDO-JUbpgcTY6AWg</a>  [reply]密码：rdxd[/reply] 待续。。。。。。。</p>\n"},{"title":"阈值分割","toc":false,"date":"2020-03-08T17:26:44.000Z","_content":"\n# 什么是图像阈值\n![image.png](https://blog.mviai.com/images/Fn5xqMS4X6jN0--YE7zgY47l2LfF)\n灰度值   0-->255  黑-->白 暗-->亮\n\n# 工作原理\n所有阈值算法都将源图像（src）和阈值（thresh）作为输入，并通过将源像素（x，y）的像素值与阈值进行比较来生成输出图像（dst）。如果src（x，y）> thresh，则为dst（x，y）分配一个值。否则，将为dst（x，y）分配一些其他值。\n\n# 二值化(type = THRESH_BINARY )\n最简单的阈值形式称为二值化。除了源图像（src）和阈值（thresh）之外，它还使用另一个称为最大值（maxValue）的输入参数。在每个像素位置（x，y），它将像素值src（x，y）与thresh进行比较。如果src（x，y）大于thresh，则将目标图像像素dst（x，y）的值设置为maxValue，否则将其设置为零。\n- 二值化（thresh = 0和maxValue = 255）\n- ![image.png](https://blog.mviai.com/images/Fg1I9CWbDTr4TuzBnAj_dZBzrYWi)\n- 二值化（thresh= 127，maxValue= 255）\n- ![image.png](https://blog.mviai.com/images/Fv1pTQtw9FsxHhO9F4v5Ac31Be1w)\n- 将maxValue设置为128的二值化\n- ![image.png](https://blog.mviai.com/images/FiByv3uqNQ-nmg26XScffnMk7p1M)\n- \n\n# 反向二值化（类型= THRESH_BINARY_INV）\n反向二值化与二值化恰好相反。如果相应的源像素大于阈值，则将目标像素设置为零；如果源像素小于阈值，则将目标像素设置为maxValue。\n![image.png](https://blog.mviai.com/images/FkGSgV0-6uydZVQlUclO3ZyrSckp)\n反向二值化（thresh = 127，maxValue = 0）\n\n\n# 截断阈值（类型= THRESH_TRUNC）\n在这种类型的阈值处理中，如果源像素值大于阈值，则将目标像素设置为阈值（  thresh） 。否则，将其设置为源像素值。maxValue被忽略。\n - 高于阈值（127）的所有值均被设置为127，并且小于或等于127的所有值均保持不变。maxValue被忽略。\n - ![image.png](https://blog.mviai.com/images/FoU2pwY1kupkcwNVxz5AFHkw4rWz)\n\n\n# 零阈值（类型= THRESH_TOZERO）\n在这种阈值化中，如果源像素值大于阈值，则将目标像素值设置为对应的源像素值。否则将其设置为零。maxValue被忽略。\n- 零阈值（阈值= 127）\n- ![image.png](https://blog.mviai.com/images/FppxkaM7HQq1li844yKJ7nWQgW8d)\n\n# 反转零阈值（类型= THRESH_TOZERO_INV）\n在这种阈值处理中，如果源像素值大于阈值，则将目标像素值设置为零。否则，将其设置为源像素值。maxValue被忽略。\n将阈值反转为零,低于阈值的数字保留其灰度值，高于阈值的数字为0（边界除外）。边界上的伪影是由于以下事实：边界上的像素值从0过渡到几个像素上的数字值。因此，某些边界像素低于阈值。\n\n![image.png](https://blog.mviai.com/images/FoGfZgexKOvcf4uIuP-7J_hqniG3)\n\n\n```python\n\n# 导入 opencv\nimport cv2 \n\n# 读取图片\nsrc = cv2.imread(\"threshold.png\", cv2.IMREAD_GRAYSCALE); \n\n# 二值化\nth, dst = cv2.threshold(src, 0, 255, cv2.THRESH_BINARY); \ncv2.imwrite(\"opencv-threshold-example.jpg\", dst); \n\n# maxValue设置为128的阈值\nth, dst = cv2.threshold(src, 0, 128, cv2.THRESH_BINARY); \ncv2.imwrite(\"opencv-thresh-binary-maxval.jpg\", dst); \n\n# 设置为127的阈值\nth, dst = cv2.threshold(src,127,255, cv2.THRESH_BINARY); \ncv2.imwrite(\"opencv-thresh-binary.jpg\", dst); \n\n#反二值化\nth, dst = cv2.threshold(src,127,255, cv2.THRESH_BINARY_INV); \ncv2.imwrite(\"opencv-thresh-binary-inv.jpg\", dst); \n\n# 截断阈值\nth, dst = cv2.threshold(src,127,255, cv2.THRESH_TRUNC); \ncv2.imwrite(\"opencv-thresh-trunc.jpg\", dst); \n\n# 零阈值\nth, dst = cv2.threshold(src,127,255, cv2.THRESH_TOZERO); \ncv2.imwrite(\"opencv-thresh-tozero.jpg\", dst); \n\n# 反转零阈值\nth, dst = cv2.threshold(src,127,255, cv2.THRESH_TOZERO_INV); \ncv2.imwrite(\"opencv-thresh-to-zero-inv.jpg\", dst); \n\n```\n\n```C++\n\n\n// 导入相关包\n#include \"opencv2/opencv.hpp\"\n\nusing namespace cv;\nusing namespace std;\n\nint main( int argc, char** argv )\n{\n\n\t// 读取图片\n\tMat src = imread(\"threshold.png\", IMREAD_GRAYSCALE); \n\tMat dst; \n\t\n\t// 二值化\n\tthreshold(src,dst,0, 255, THRESH_BINARY); \n\timwrite(\"../opencv-threshold-example.jpg\", dst);\n\n\t// maxValue设置为128的阈值\n\tthreshold(src, dst, 0, 128, THRESH_BINARY); \n\timwrite(\"../opencv-thresh-binary-maxval.jpg\", dst);\n\t\n\t// 设置为127的阈值\n\tthreshold(src,dst,127,255, THRESH_BINARY); \n\timwrite(\"../opencv-thresh-binary.jpg\", dst);\n\t\n\t// 反二值化\n\tthreshold(src,dst,127,255, THRESH_BINARY_INV); \n\timwrite(\"../opencv-thresh-binary-inv.jpg\", dst);\n\t\n\t// 截断阈值\n\tthreshold(src,dst,127,255, THRESH_TRUNC); \n\timwrite(\"../opencv-thresh-trunc.jpg\", dst);\n\n\t//  零阈值\n\tthreshold(src,dst,127,255, THRESH_TOZERO); \n\timwrite(\"../opencv-thresh-tozero.jpg\", dst);\n\n\t//反转零阈值\n\tthreshold(src,dst,127,255, THRESH_TOZERO_INV); \n\timwrite(\"../opencv-thresh-to-zero-inv.jpg\", dst);\n} \n\n\n```","source":"_posts/阈值分割.md","raw":"---\ntitle: 阈值分割\ntags:\n  - cv\ncategories:\n  - 框架\n  - opencv\ntoc: false\ndate: 2020-03-09 01:26:44\n---\n\n# 什么是图像阈值\n![image.png](https://blog.mviai.com/images/Fn5xqMS4X6jN0--YE7zgY47l2LfF)\n灰度值   0-->255  黑-->白 暗-->亮\n\n# 工作原理\n所有阈值算法都将源图像（src）和阈值（thresh）作为输入，并通过将源像素（x，y）的像素值与阈值进行比较来生成输出图像（dst）。如果src（x，y）> thresh，则为dst（x，y）分配一个值。否则，将为dst（x，y）分配一些其他值。\n\n# 二值化(type = THRESH_BINARY )\n最简单的阈值形式称为二值化。除了源图像（src）和阈值（thresh）之外，它还使用另一个称为最大值（maxValue）的输入参数。在每个像素位置（x，y），它将像素值src（x，y）与thresh进行比较。如果src（x，y）大于thresh，则将目标图像像素dst（x，y）的值设置为maxValue，否则将其设置为零。\n- 二值化（thresh = 0和maxValue = 255）\n- ![image.png](https://blog.mviai.com/images/Fg1I9CWbDTr4TuzBnAj_dZBzrYWi)\n- 二值化（thresh= 127，maxValue= 255）\n- ![image.png](https://blog.mviai.com/images/Fv1pTQtw9FsxHhO9F4v5Ac31Be1w)\n- 将maxValue设置为128的二值化\n- ![image.png](https://blog.mviai.com/images/FiByv3uqNQ-nmg26XScffnMk7p1M)\n- \n\n# 反向二值化（类型= THRESH_BINARY_INV）\n反向二值化与二值化恰好相反。如果相应的源像素大于阈值，则将目标像素设置为零；如果源像素小于阈值，则将目标像素设置为maxValue。\n![image.png](https://blog.mviai.com/images/FkGSgV0-6uydZVQlUclO3ZyrSckp)\n反向二值化（thresh = 127，maxValue = 0）\n\n\n# 截断阈值（类型= THRESH_TRUNC）\n在这种类型的阈值处理中，如果源像素值大于阈值，则将目标像素设置为阈值（  thresh） 。否则，将其设置为源像素值。maxValue被忽略。\n - 高于阈值（127）的所有值均被设置为127，并且小于或等于127的所有值均保持不变。maxValue被忽略。\n - ![image.png](https://blog.mviai.com/images/FoU2pwY1kupkcwNVxz5AFHkw4rWz)\n\n\n# 零阈值（类型= THRESH_TOZERO）\n在这种阈值化中，如果源像素值大于阈值，则将目标像素值设置为对应的源像素值。否则将其设置为零。maxValue被忽略。\n- 零阈值（阈值= 127）\n- ![image.png](https://blog.mviai.com/images/FppxkaM7HQq1li844yKJ7nWQgW8d)\n\n# 反转零阈值（类型= THRESH_TOZERO_INV）\n在这种阈值处理中，如果源像素值大于阈值，则将目标像素值设置为零。否则，将其设置为源像素值。maxValue被忽略。\n将阈值反转为零,低于阈值的数字保留其灰度值，高于阈值的数字为0（边界除外）。边界上的伪影是由于以下事实：边界上的像素值从0过渡到几个像素上的数字值。因此，某些边界像素低于阈值。\n\n![image.png](https://blog.mviai.com/images/FoGfZgexKOvcf4uIuP-7J_hqniG3)\n\n\n```python\n\n# 导入 opencv\nimport cv2 \n\n# 读取图片\nsrc = cv2.imread(\"threshold.png\", cv2.IMREAD_GRAYSCALE); \n\n# 二值化\nth, dst = cv2.threshold(src, 0, 255, cv2.THRESH_BINARY); \ncv2.imwrite(\"opencv-threshold-example.jpg\", dst); \n\n# maxValue设置为128的阈值\nth, dst = cv2.threshold(src, 0, 128, cv2.THRESH_BINARY); \ncv2.imwrite(\"opencv-thresh-binary-maxval.jpg\", dst); \n\n# 设置为127的阈值\nth, dst = cv2.threshold(src,127,255, cv2.THRESH_BINARY); \ncv2.imwrite(\"opencv-thresh-binary.jpg\", dst); \n\n#反二值化\nth, dst = cv2.threshold(src,127,255, cv2.THRESH_BINARY_INV); \ncv2.imwrite(\"opencv-thresh-binary-inv.jpg\", dst); \n\n# 截断阈值\nth, dst = cv2.threshold(src,127,255, cv2.THRESH_TRUNC); \ncv2.imwrite(\"opencv-thresh-trunc.jpg\", dst); \n\n# 零阈值\nth, dst = cv2.threshold(src,127,255, cv2.THRESH_TOZERO); \ncv2.imwrite(\"opencv-thresh-tozero.jpg\", dst); \n\n# 反转零阈值\nth, dst = cv2.threshold(src,127,255, cv2.THRESH_TOZERO_INV); \ncv2.imwrite(\"opencv-thresh-to-zero-inv.jpg\", dst); \n\n```\n\n```C++\n\n\n// 导入相关包\n#include \"opencv2/opencv.hpp\"\n\nusing namespace cv;\nusing namespace std;\n\nint main( int argc, char** argv )\n{\n\n\t// 读取图片\n\tMat src = imread(\"threshold.png\", IMREAD_GRAYSCALE); \n\tMat dst; \n\t\n\t// 二值化\n\tthreshold(src,dst,0, 255, THRESH_BINARY); \n\timwrite(\"../opencv-threshold-example.jpg\", dst);\n\n\t// maxValue设置为128的阈值\n\tthreshold(src, dst, 0, 128, THRESH_BINARY); \n\timwrite(\"../opencv-thresh-binary-maxval.jpg\", dst);\n\t\n\t// 设置为127的阈值\n\tthreshold(src,dst,127,255, THRESH_BINARY); \n\timwrite(\"../opencv-thresh-binary.jpg\", dst);\n\t\n\t// 反二值化\n\tthreshold(src,dst,127,255, THRESH_BINARY_INV); \n\timwrite(\"../opencv-thresh-binary-inv.jpg\", dst);\n\t\n\t// 截断阈值\n\tthreshold(src,dst,127,255, THRESH_TRUNC); \n\timwrite(\"../opencv-thresh-trunc.jpg\", dst);\n\n\t//  零阈值\n\tthreshold(src,dst,127,255, THRESH_TOZERO); \n\timwrite(\"../opencv-thresh-tozero.jpg\", dst);\n\n\t//反转零阈值\n\tthreshold(src,dst,127,255, THRESH_TOZERO_INV); \n\timwrite(\"../opencv-thresh-to-zero-inv.jpg\", dst);\n} \n\n\n```","slug":"阈值分割","published":1,"updated":"2021-07-26T09:58:02.584Z","comments":1,"layout":"post","photos":[],"link":"","_id":"clep90m3f004xigta5bxvbcru","content":"<h1 id=\"什么是图像阈值\"><a href=\"#什么是图像阈值\" class=\"headerlink\" title=\"什么是图像阈值\"></a>什么是图像阈值</h1><p><img src=\"https://blog.mviai.com/images/Fn5xqMS4X6jN0--YE7zgY47l2LfF\" alt=\"image.png\"><br>灰度值   0–&gt;255  黑–&gt;白 暗–&gt;亮</p>\n<h1 id=\"工作原理\"><a href=\"#工作原理\" class=\"headerlink\" title=\"工作原理\"></a>工作原理</h1><p>所有阈值算法都将源图像（src）和阈值（thresh）作为输入，并通过将源像素（x，y）的像素值与阈值进行比较来生成输出图像（dst）。如果src（x，y）&gt; thresh，则为dst（x，y）分配一个值。否则，将为dst（x，y）分配一些其他值。</p>\n<h1 id=\"二值化-type-THRESH-BINARY\"><a href=\"#二值化-type-THRESH-BINARY\" class=\"headerlink\" title=\"二值化(type = THRESH_BINARY )\"></a>二值化(type = THRESH_BINARY )</h1><p>最简单的阈值形式称为二值化。除了源图像（src）和阈值（thresh）之外，它还使用另一个称为最大值（maxValue）的输入参数。在每个像素位置（x，y），它将像素值src（x，y）与thresh进行比较。如果src（x，y）大于thresh，则将目标图像像素dst（x，y）的值设置为maxValue，否则将其设置为零。</p>\n<ul>\n<li>二值化（thresh = 0和maxValue = 255）</li>\n<li><img src=\"https://blog.mviai.com/images/Fg1I9CWbDTr4TuzBnAj_dZBzrYWi\" alt=\"image.png\"></li>\n<li>二值化（thresh= 127，maxValue= 255）</li>\n<li><img src=\"https://blog.mviai.com/images/Fv1pTQtw9FsxHhO9F4v5Ac31Be1w\" alt=\"image.png\"></li>\n<li>将maxValue设置为128的二值化</li>\n<li><img src=\"https://blog.mviai.com/images/FiByv3uqNQ-nmg26XScffnMk7p1M\" alt=\"image.png\"></li>\n<li></li>\n</ul>\n<h1 id=\"反向二值化（类型-THRESH-BINARY-INV）\"><a href=\"#反向二值化（类型-THRESH-BINARY-INV）\" class=\"headerlink\" title=\"反向二值化（类型= THRESH_BINARY_INV）\"></a>反向二值化（类型= THRESH_BINARY_INV）</h1><p>反向二值化与二值化恰好相反。如果相应的源像素大于阈值，则将目标像素设置为零；如果源像素小于阈值，则将目标像素设置为maxValue。<br><img src=\"https://blog.mviai.com/images/FkGSgV0-6uydZVQlUclO3ZyrSckp\" alt=\"image.png\"><br>反向二值化（thresh = 127，maxValue = 0）</p>\n<h1 id=\"截断阈值（类型-THRESH-TRUNC）\"><a href=\"#截断阈值（类型-THRESH-TRUNC）\" class=\"headerlink\" title=\"截断阈值（类型= THRESH_TRUNC）\"></a>截断阈值（类型= THRESH_TRUNC）</h1><p>在这种类型的阈值处理中，如果源像素值大于阈值，则将目标像素设置为阈值（  thresh） 。否则，将其设置为源像素值。maxValue被忽略。</p>\n<ul>\n<li>高于阈值（127）的所有值均被设置为127，并且小于或等于127的所有值均保持不变。maxValue被忽略。</li>\n<li><img src=\"https://blog.mviai.com/images/FoU2pwY1kupkcwNVxz5AFHkw4rWz\" alt=\"image.png\"></li>\n</ul>\n<h1 id=\"零阈值（类型-THRESH-TOZERO）\"><a href=\"#零阈值（类型-THRESH-TOZERO）\" class=\"headerlink\" title=\"零阈值（类型= THRESH_TOZERO）\"></a>零阈值（类型= THRESH_TOZERO）</h1><p>在这种阈值化中，如果源像素值大于阈值，则将目标像素值设置为对应的源像素值。否则将其设置为零。maxValue被忽略。</p>\n<ul>\n<li>零阈值（阈值= 127）</li>\n<li><img src=\"https://blog.mviai.com/images/FppxkaM7HQq1li844yKJ7nWQgW8d\" alt=\"image.png\"></li>\n</ul>\n<h1 id=\"反转零阈值（类型-THRESH-TOZERO-INV）\"><a href=\"#反转零阈值（类型-THRESH-TOZERO-INV）\" class=\"headerlink\" title=\"反转零阈值（类型= THRESH_TOZERO_INV）\"></a>反转零阈值（类型= THRESH_TOZERO_INV）</h1><p>在这种阈值处理中，如果源像素值大于阈值，则将目标像素值设置为零。否则，将其设置为源像素值。maxValue被忽略。<br>将阈值反转为零,低于阈值的数字保留其灰度值，高于阈值的数字为0（边界除外）。边界上的伪影是由于以下事实：边界上的像素值从0过渡到几个像素上的数字值。因此，某些边界像素低于阈值。</p>\n<p><img src=\"https://blog.mviai.com/images/FoGfZgexKOvcf4uIuP-7J_hqniG3\" alt=\"image.png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 导入 opencv</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2 </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 读取图片</span></span><br><span class=\"line\">src = cv2.imread(<span class=\"string\">\"threshold.png\"</span>, cv2.IMREAD_GRAYSCALE); </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 二值化</span></span><br><span class=\"line\">th, dst = cv2.threshold(src, <span class=\"number\">0</span>, <span class=\"number\">255</span>, cv2.THRESH_BINARY); </span><br><span class=\"line\">cv2.imwrite(<span class=\"string\">\"opencv-threshold-example.jpg\"</span>, dst); </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># maxValue设置为128的阈值</span></span><br><span class=\"line\">th, dst = cv2.threshold(src, <span class=\"number\">0</span>, <span class=\"number\">128</span>, cv2.THRESH_BINARY); </span><br><span class=\"line\">cv2.imwrite(<span class=\"string\">\"opencv-thresh-binary-maxval.jpg\"</span>, dst); </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置为127的阈值</span></span><br><span class=\"line\">th, dst = cv2.threshold(src,<span class=\"number\">127</span>,<span class=\"number\">255</span>, cv2.THRESH_BINARY); </span><br><span class=\"line\">cv2.imwrite(<span class=\"string\">\"opencv-thresh-binary.jpg\"</span>, dst); </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#反二值化</span></span><br><span class=\"line\">th, dst = cv2.threshold(src,<span class=\"number\">127</span>,<span class=\"number\">255</span>, cv2.THRESH_BINARY_INV); </span><br><span class=\"line\">cv2.imwrite(<span class=\"string\">\"opencv-thresh-binary-inv.jpg\"</span>, dst); </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 截断阈值</span></span><br><span class=\"line\">th, dst = cv2.threshold(src,<span class=\"number\">127</span>,<span class=\"number\">255</span>, cv2.THRESH_TRUNC); </span><br><span class=\"line\">cv2.imwrite(<span class=\"string\">\"opencv-thresh-trunc.jpg\"</span>, dst); </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 零阈值</span></span><br><span class=\"line\">th, dst = cv2.threshold(src,<span class=\"number\">127</span>,<span class=\"number\">255</span>, cv2.THRESH_TOZERO); </span><br><span class=\"line\">cv2.imwrite(<span class=\"string\">\"opencv-thresh-tozero.jpg\"</span>, dst); </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 反转零阈值</span></span><br><span class=\"line\">th, dst = cv2.threshold(src,<span class=\"number\">127</span>,<span class=\"number\">255</span>, cv2.THRESH_TOZERO_INV); </span><br><span class=\"line\">cv2.imwrite(<span class=\"string\">\"opencv-thresh-to-zero-inv.jpg\"</span>, dst);</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 导入相关包</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"opencv2/opencv.hpp\"</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> cv;</span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">( <span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv )</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 读取图片</span></span><br><span class=\"line\">\tMat src = imread(<span class=\"string\">\"threshold.png\"</span>, IMREAD_GRAYSCALE); </span><br><span class=\"line\">\tMat dst; </span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">// 二值化</span></span><br><span class=\"line\">\tthreshold(src,dst,<span class=\"number\">0</span>, <span class=\"number\">255</span>, THRESH_BINARY); </span><br><span class=\"line\">\timwrite(<span class=\"string\">\"../opencv-threshold-example.jpg\"</span>, dst);</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// maxValue设置为128的阈值</span></span><br><span class=\"line\">\tthreshold(src, dst, <span class=\"number\">0</span>, <span class=\"number\">128</span>, THRESH_BINARY); </span><br><span class=\"line\">\timwrite(<span class=\"string\">\"../opencv-thresh-binary-maxval.jpg\"</span>, dst);</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">// 设置为127的阈值</span></span><br><span class=\"line\">\tthreshold(src,dst,<span class=\"number\">127</span>,<span class=\"number\">255</span>, THRESH_BINARY); </span><br><span class=\"line\">\timwrite(<span class=\"string\">\"../opencv-thresh-binary.jpg\"</span>, dst);</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">// 反二值化</span></span><br><span class=\"line\">\tthreshold(src,dst,<span class=\"number\">127</span>,<span class=\"number\">255</span>, THRESH_BINARY_INV); </span><br><span class=\"line\">\timwrite(<span class=\"string\">\"../opencv-thresh-binary-inv.jpg\"</span>, dst);</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">// 截断阈值</span></span><br><span class=\"line\">\tthreshold(src,dst,<span class=\"number\">127</span>,<span class=\"number\">255</span>, THRESH_TRUNC); </span><br><span class=\"line\">\timwrite(<span class=\"string\">\"../opencv-thresh-trunc.jpg\"</span>, dst);</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">//  零阈值</span></span><br><span class=\"line\">\tthreshold(src,dst,<span class=\"number\">127</span>,<span class=\"number\">255</span>, THRESH_TOZERO); </span><br><span class=\"line\">\timwrite(<span class=\"string\">\"../opencv-thresh-tozero.jpg\"</span>, dst);</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">//反转零阈值</span></span><br><span class=\"line\">\tthreshold(src,dst,<span class=\"number\">127</span>,<span class=\"number\">255</span>, THRESH_TOZERO_INV); </span><br><span class=\"line\">\timwrite(<span class=\"string\">\"../opencv-thresh-to-zero-inv.jpg\"</span>, dst);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>","site":{"data":{}},"excerpt":"","more":"<h1 id=\"什么是图像阈值\"><a href=\"#什么是图像阈值\" class=\"headerlink\" title=\"什么是图像阈值\"></a>什么是图像阈值</h1><p><img src=\"https://blog.mviai.com/images/Fn5xqMS4X6jN0--YE7zgY47l2LfF\" alt=\"image.png\"><br>灰度值   0–&gt;255  黑–&gt;白 暗–&gt;亮</p>\n<h1 id=\"工作原理\"><a href=\"#工作原理\" class=\"headerlink\" title=\"工作原理\"></a>工作原理</h1><p>所有阈值算法都将源图像（src）和阈值（thresh）作为输入，并通过将源像素（x，y）的像素值与阈值进行比较来生成输出图像（dst）。如果src（x，y）&gt; thresh，则为dst（x，y）分配一个值。否则，将为dst（x，y）分配一些其他值。</p>\n<h1 id=\"二值化-type-THRESH-BINARY\"><a href=\"#二值化-type-THRESH-BINARY\" class=\"headerlink\" title=\"二值化(type = THRESH_BINARY )\"></a>二值化(type = THRESH_BINARY )</h1><p>最简单的阈值形式称为二值化。除了源图像（src）和阈值（thresh）之外，它还使用另一个称为最大值（maxValue）的输入参数。在每个像素位置（x，y），它将像素值src（x，y）与thresh进行比较。如果src（x，y）大于thresh，则将目标图像像素dst（x，y）的值设置为maxValue，否则将其设置为零。</p>\n<ul>\n<li>二值化（thresh = 0和maxValue = 255）</li>\n<li><img src=\"https://blog.mviai.com/images/Fg1I9CWbDTr4TuzBnAj_dZBzrYWi\" alt=\"image.png\"></li>\n<li>二值化（thresh= 127，maxValue= 255）</li>\n<li><img src=\"https://blog.mviai.com/images/Fv1pTQtw9FsxHhO9F4v5Ac31Be1w\" alt=\"image.png\"></li>\n<li>将maxValue设置为128的二值化</li>\n<li><img src=\"https://blog.mviai.com/images/FiByv3uqNQ-nmg26XScffnMk7p1M\" alt=\"image.png\"></li>\n<li></li>\n</ul>\n<h1 id=\"反向二值化（类型-THRESH-BINARY-INV）\"><a href=\"#反向二值化（类型-THRESH-BINARY-INV）\" class=\"headerlink\" title=\"反向二值化（类型= THRESH_BINARY_INV）\"></a>反向二值化（类型= THRESH_BINARY_INV）</h1><p>反向二值化与二值化恰好相反。如果相应的源像素大于阈值，则将目标像素设置为零；如果源像素小于阈值，则将目标像素设置为maxValue。<br><img src=\"https://blog.mviai.com/images/FkGSgV0-6uydZVQlUclO3ZyrSckp\" alt=\"image.png\"><br>反向二值化（thresh = 127，maxValue = 0）</p>\n<h1 id=\"截断阈值（类型-THRESH-TRUNC）\"><a href=\"#截断阈值（类型-THRESH-TRUNC）\" class=\"headerlink\" title=\"截断阈值（类型= THRESH_TRUNC）\"></a>截断阈值（类型= THRESH_TRUNC）</h1><p>在这种类型的阈值处理中，如果源像素值大于阈值，则将目标像素设置为阈值（  thresh） 。否则，将其设置为源像素值。maxValue被忽略。</p>\n<ul>\n<li>高于阈值（127）的所有值均被设置为127，并且小于或等于127的所有值均保持不变。maxValue被忽略。</li>\n<li><img src=\"https://blog.mviai.com/images/FoU2pwY1kupkcwNVxz5AFHkw4rWz\" alt=\"image.png\"></li>\n</ul>\n<h1 id=\"零阈值（类型-THRESH-TOZERO）\"><a href=\"#零阈值（类型-THRESH-TOZERO）\" class=\"headerlink\" title=\"零阈值（类型= THRESH_TOZERO）\"></a>零阈值（类型= THRESH_TOZERO）</h1><p>在这种阈值化中，如果源像素值大于阈值，则将目标像素值设置为对应的源像素值。否则将其设置为零。maxValue被忽略。</p>\n<ul>\n<li>零阈值（阈值= 127）</li>\n<li><img src=\"https://blog.mviai.com/images/FppxkaM7HQq1li844yKJ7nWQgW8d\" alt=\"image.png\"></li>\n</ul>\n<h1 id=\"反转零阈值（类型-THRESH-TOZERO-INV）\"><a href=\"#反转零阈值（类型-THRESH-TOZERO-INV）\" class=\"headerlink\" title=\"反转零阈值（类型= THRESH_TOZERO_INV）\"></a>反转零阈值（类型= THRESH_TOZERO_INV）</h1><p>在这种阈值处理中，如果源像素值大于阈值，则将目标像素值设置为零。否则，将其设置为源像素值。maxValue被忽略。<br>将阈值反转为零,低于阈值的数字保留其灰度值，高于阈值的数字为0（边界除外）。边界上的伪影是由于以下事实：边界上的像素值从0过渡到几个像素上的数字值。因此，某些边界像素低于阈值。</p>\n<p><img src=\"https://blog.mviai.com/images/FoGfZgexKOvcf4uIuP-7J_hqniG3\" alt=\"image.png\"></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 导入 opencv</span></span><br><span class=\"line\"><span class=\"keyword\">import</span> cv2 </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 读取图片</span></span><br><span class=\"line\">src = cv2.imread(<span class=\"string\">\"threshold.png\"</span>, cv2.IMREAD_GRAYSCALE); </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 二值化</span></span><br><span class=\"line\">th, dst = cv2.threshold(src, <span class=\"number\">0</span>, <span class=\"number\">255</span>, cv2.THRESH_BINARY); </span><br><span class=\"line\">cv2.imwrite(<span class=\"string\">\"opencv-threshold-example.jpg\"</span>, dst); </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># maxValue设置为128的阈值</span></span><br><span class=\"line\">th, dst = cv2.threshold(src, <span class=\"number\">0</span>, <span class=\"number\">128</span>, cv2.THRESH_BINARY); </span><br><span class=\"line\">cv2.imwrite(<span class=\"string\">\"opencv-thresh-binary-maxval.jpg\"</span>, dst); </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 设置为127的阈值</span></span><br><span class=\"line\">th, dst = cv2.threshold(src,<span class=\"number\">127</span>,<span class=\"number\">255</span>, cv2.THRESH_BINARY); </span><br><span class=\"line\">cv2.imwrite(<span class=\"string\">\"opencv-thresh-binary.jpg\"</span>, dst); </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">#反二值化</span></span><br><span class=\"line\">th, dst = cv2.threshold(src,<span class=\"number\">127</span>,<span class=\"number\">255</span>, cv2.THRESH_BINARY_INV); </span><br><span class=\"line\">cv2.imwrite(<span class=\"string\">\"opencv-thresh-binary-inv.jpg\"</span>, dst); </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 截断阈值</span></span><br><span class=\"line\">th, dst = cv2.threshold(src,<span class=\"number\">127</span>,<span class=\"number\">255</span>, cv2.THRESH_TRUNC); </span><br><span class=\"line\">cv2.imwrite(<span class=\"string\">\"opencv-thresh-trunc.jpg\"</span>, dst); </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 零阈值</span></span><br><span class=\"line\">th, dst = cv2.threshold(src,<span class=\"number\">127</span>,<span class=\"number\">255</span>, cv2.THRESH_TOZERO); </span><br><span class=\"line\">cv2.imwrite(<span class=\"string\">\"opencv-thresh-tozero.jpg\"</span>, dst); </span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># 反转零阈值</span></span><br><span class=\"line\">th, dst = cv2.threshold(src,<span class=\"number\">127</span>,<span class=\"number\">255</span>, cv2.THRESH_TOZERO_INV); </span><br><span class=\"line\">cv2.imwrite(<span class=\"string\">\"opencv-thresh-to-zero-inv.jpg\"</span>, dst);</span><br></pre></td></tr></table></figure>\n<figure class=\"highlight c++\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\">// 导入相关包</span></span><br><span class=\"line\"><span class=\"meta\">#<span class=\"meta-keyword\">include</span> <span class=\"meta-string\">\"opencv2/opencv.hpp\"</span></span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> cv;</span><br><span class=\"line\"><span class=\"keyword\">using</span> <span class=\"keyword\">namespace</span> <span class=\"built_in\">std</span>;</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">int</span> <span class=\"title\">main</span><span class=\"params\">( <span class=\"keyword\">int</span> argc, <span class=\"keyword\">char</span>** argv )</span></span></span><br><span class=\"line\"><span class=\"function\"></span>&#123;</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// 读取图片</span></span><br><span class=\"line\">\tMat src = imread(<span class=\"string\">\"threshold.png\"</span>, IMREAD_GRAYSCALE); </span><br><span class=\"line\">\tMat dst; </span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">// 二值化</span></span><br><span class=\"line\">\tthreshold(src,dst,<span class=\"number\">0</span>, <span class=\"number\">255</span>, THRESH_BINARY); </span><br><span class=\"line\">\timwrite(<span class=\"string\">\"../opencv-threshold-example.jpg\"</span>, dst);</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">// maxValue设置为128的阈值</span></span><br><span class=\"line\">\tthreshold(src, dst, <span class=\"number\">0</span>, <span class=\"number\">128</span>, THRESH_BINARY); </span><br><span class=\"line\">\timwrite(<span class=\"string\">\"../opencv-thresh-binary-maxval.jpg\"</span>, dst);</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">// 设置为127的阈值</span></span><br><span class=\"line\">\tthreshold(src,dst,<span class=\"number\">127</span>,<span class=\"number\">255</span>, THRESH_BINARY); </span><br><span class=\"line\">\timwrite(<span class=\"string\">\"../opencv-thresh-binary.jpg\"</span>, dst);</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">// 反二值化</span></span><br><span class=\"line\">\tthreshold(src,dst,<span class=\"number\">127</span>,<span class=\"number\">255</span>, THRESH_BINARY_INV); </span><br><span class=\"line\">\timwrite(<span class=\"string\">\"../opencv-thresh-binary-inv.jpg\"</span>, dst);</span><br><span class=\"line\">\t</span><br><span class=\"line\">\t<span class=\"comment\">// 截断阈值</span></span><br><span class=\"line\">\tthreshold(src,dst,<span class=\"number\">127</span>,<span class=\"number\">255</span>, THRESH_TRUNC); </span><br><span class=\"line\">\timwrite(<span class=\"string\">\"../opencv-thresh-trunc.jpg\"</span>, dst);</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">//  零阈值</span></span><br><span class=\"line\">\tthreshold(src,dst,<span class=\"number\">127</span>,<span class=\"number\">255</span>, THRESH_TOZERO); </span><br><span class=\"line\">\timwrite(<span class=\"string\">\"../opencv-thresh-tozero.jpg\"</span>, dst);</span><br><span class=\"line\"></span><br><span class=\"line\">\t<span class=\"comment\">//反转零阈值</span></span><br><span class=\"line\">\tthreshold(src,dst,<span class=\"number\">127</span>,<span class=\"number\">255</span>, THRESH_TOZERO_INV); </span><br><span class=\"line\">\timwrite(<span class=\"string\">\"../opencv-thresh-to-zero-inv.jpg\"</span>, dst);</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure>"}],"PostAsset":[],"PostCategory":[{"post_id":"clep90m160009igtaekqftsha","category_id":"clep90m1e000iigtaj9ghkgwx","_id":"clep90m25001uigtama14xgqr"},{"post_id":"clep90m160009igtaekqftsha","category_id":"clep90m20001jigtaa1h4m1g5","_id":"clep90m26001xigtaq8sf2g5o"},{"post_id":"clep90m1k000pigtaq1qbcu2a","category_id":"clep90m1e000iigtaj9ghkgwx","_id":"clep90m2b0025igtadoclvd7g"},{"post_id":"clep90m1k000pigtaq1qbcu2a","category_id":"clep90m20001jigtaa1h4m1g5","_id":"clep90m2d0029igtagwescv2r"},{"post_id":"clep90m17000aigta69m0mseq","category_id":"clep90m1j000nigtafn4plil3","_id":"clep90m2e002cigtazn2sfa5t"},{"post_id":"clep90m17000aigta69m0mseq","category_id":"clep90m270020igtat5u8vg6u","_id":"clep90m2f002gigtaey1ecxj2"},{"post_id":"clep90m1n000uigta605du5ob","category_id":"clep90m150008igtaub81ddvy","_id":"clep90m2h002kigtajnceoq4y"},{"post_id":"clep90m1n000uigta605du5ob","category_id":"clep90m1n000sigtag4kz3d20","_id":"clep90m2j002oigtapm59r4z2"},{"post_id":"clep90m1n000uigta605du5ob","category_id":"clep90m2b0026igtacmdf5qil","_id":"clep90m2l002sigtar3h1xh3y"},{"post_id":"clep90m2d002aigtav88kdgc9","category_id":"clep90m1j000nigtafn4plil3","_id":"clep90m2n002wigtayxfzf5gd"},{"post_id":"clep90m2d002aigtav88kdgc9","category_id":"clep90m270020igtat5u8vg6u","_id":"clep90m2p002yigtamay1n8t7"},{"post_id":"clep90m2f002figtahc8j02a2","category_id":"clep90m1j000nigtafn4plil3","_id":"clep90m2r0033igtaec56p604"},{"post_id":"clep90m2f002figtahc8j02a2","category_id":"clep90m270020igtat5u8vg6u","_id":"clep90m2s0035igta28pndiis"},{"post_id":"clep90m0z0004igtavxljvzfz","category_id":"clep90m150008igtaub81ddvy","_id":"clep90m2t0039igtacyeo604n"},{"post_id":"clep90m0z0004igtavxljvzfz","category_id":"clep90m1n000sigtag4kz3d20","_id":"clep90m2u003cigtajlx9nfdu"},{"post_id":"clep90m0z0004igtavxljvzfz","category_id":"clep90m2e002digtagz16kxel","_id":"clep90m2v003gigtazxepuuj5"},{"post_id":"clep90m1q0010igta9xzsbukb","category_id":"clep90m1j000nigtafn4plil3","_id":"clep90m2w003jigtau4jjmg30"},{"post_id":"clep90m1q0010igta9xzsbukb","category_id":"clep90m2i002nigta9xayotb1","_id":"clep90m2x003nigtaazpz8b8u"},{"post_id":"clep90m19000digtaprt0ukxv","category_id":"clep90m150008igtaub81ddvy","_id":"clep90m2y003qigtauanku5uo"},{"post_id":"clep90m19000digtaprt0ukxv","category_id":"clep90m1q000yigtahlxusmqb","_id":"clep90m2z003tigtahw3fvyoy"},{"post_id":"clep90m19000digtaprt0ukxv","category_id":"clep90m2q0031igtakowaynnn","_id":"clep90m30003xigtaakvaj04k"},{"post_id":"clep90m1t0014igta3r3abjy5","category_id":"clep90m2t0038igtaovf882gd","_id":"clep90m320040igta1uno8pst"},{"post_id":"clep90m2u003digtap6wwkwfq","category_id":"clep90m150008igtaub81ddvy","_id":"clep90m330043igta2dnmvad9"},{"post_id":"clep90m2u003digtap6wwkwfq","category_id":"clep90m1n000sigtag4kz3d20","_id":"clep90m350047igta0ky5q06m"},{"post_id":"clep90m140007igtaefhtnl48","category_id":"clep90m150008igtaub81ddvy","_id":"clep90m36004aigta4p6l32j1"},{"post_id":"clep90m140007igtaefhtnl48","category_id":"clep90m1q000yigtahlxusmqb","_id":"clep90m37004eigtapx0ulozc"},{"post_id":"clep90m140007igtaefhtnl48","category_id":"clep90m2q0031igtakowaynnn","_id":"clep90m39004higtalti8w2l6"},{"post_id":"clep90m3d004rigtaxpczvvrj","category_id":"clep90m1e000iigtaj9ghkgwx","_id":"clep90m3g0051igta894logyk"},{"post_id":"clep90m3d004rigtaxpczvvrj","category_id":"clep90m20001jigtaa1h4m1g5","_id":"clep90m3h0053igtaxzzbdyfb"},{"post_id":"clep90m3f004xigta5bxvbcru","category_id":"clep90m1j000nigtafn4plil3","_id":"clep90m3h0056igtam4lbt17d"},{"post_id":"clep90m3f004xigta5bxvbcru","category_id":"clep90m270020igtat5u8vg6u","_id":"clep90m3i0058igtajqowbz2m"},{"post_id":"clep90m27001yigtafjjiu2s9","category_id":"clep90m2t0038igtaovf882gd","_id":"clep90m3p005qigtag3zl4o61"},{"post_id":"clep90m280022igta03psn4v8","category_id":"clep90m150008igtaub81ddvy","_id":"clep90m3q005uigta4a8vjl6l"},{"post_id":"clep90m280022igta03psn4v8","category_id":"clep90m1n000sigtag4kz3d20","_id":"clep90m3r005xigtapwjn6ro1"},{"post_id":"clep90m280022igta03psn4v8","category_id":"clep90m3m005oigta05clydu6","_id":"clep90m3r005zigta0nhw2jsq"},{"post_id":"clep90m2j002qigtarrhskwb5","category_id":"clep90m2t0038igtaovf882gd","_id":"clep90m3w006cigtabsf0lqs8"},{"post_id":"clep90m2m002tigtabvmrtv1l","category_id":"clep90m1e000iigtaj9ghkgwx","_id":"clep90m3x006iigtaellxbjjb"},{"post_id":"clep90m2m002tigtabvmrtv1l","category_id":"clep90m3v0069igtaiq414pp5","_id":"clep90m3y006jigtamuyq0o7x"},{"post_id":"clep90m1r0011igta8i7ruxxl","category_id":"clep90m1j000nigtafn4plil3","_id":"clep90m3z006qigtacq128whm"},{"post_id":"clep90m1r0011igta8i7ruxxl","category_id":"clep90m2i002nigta9xayotb1","_id":"clep90m40006sigta7txmbw50"},{"post_id":"clep90m1r0011igta8i7ruxxl","category_id":"clep90m3x006higtaxgvv9u8n","_id":"clep90m41006vigtahajkwfkr"},{"post_id":"clep90m1u0016igtagiat4f4t","category_id":"clep90m1j000nigtafn4plil3","_id":"clep90m45007bigta3mmvb58c"},{"post_id":"clep90m1u0016igtagiat4f4t","category_id":"clep90m2i002nigta9xayotb1","_id":"clep90m45007digtaga9wvbh9"},{"post_id":"clep90m1u0016igtagiat4f4t","category_id":"clep90m430074igtaq71f3pvq","_id":"clep90m46007figtazkxr3rgu"},{"post_id":"clep90m2y003rigta05qustf1","category_id":"clep90m150008igtaub81ddvy","_id":"clep90m47007kigtalk6sskaf"},{"post_id":"clep90m2y003rigta05qustf1","category_id":"clep90m1n000sigtag4kz3d20","_id":"clep90m47007migtajhmql9i1"},{"post_id":"clep90m2y003rigta05qustf1","category_id":"clep90m45007aigtac9lboyiu","_id":"clep90m48007pigtatsw4ryx2"},{"post_id":"clep90m1v0018igtas9rtb31x","category_id":"clep90m1j000nigtafn4plil3","_id":"clep90m49007vigtasygb0hil"},{"post_id":"clep90m1v0018igtas9rtb31x","category_id":"clep90m2i002nigta9xayotb1","_id":"clep90m4a007wigtarabzbxgo"},{"post_id":"clep90m1v0018igtas9rtb31x","category_id":"clep90m48007oigtah4t2tyg6","_id":"clep90m4a007yigtarg9cme59"},{"post_id":"clep90m1w001bigtasvyfvjx0","category_id":"clep90m1j000nigtafn4plil3","_id":"clep90m4c0081igtaa3gehdan"},{"post_id":"clep90m1w001bigtasvyfvjx0","category_id":"clep90m2i002nigta9xayotb1","_id":"clep90m4c0082igta9uanwj9r"},{"post_id":"clep90m1w001bigtasvyfvjx0","category_id":"clep90m48007oigtah4t2tyg6","_id":"clep90m4d0084igta76tf34qd"},{"post_id":"clep90m1d000higta0d8fsc9z","category_id":"clep90m1j000nigtafn4plil3","_id":"clep90m4e0087igtak04o3ztq"},{"post_id":"clep90m1d000higta0d8fsc9z","category_id":"clep90m2i002nigta9xayotb1","_id":"clep90m4e0088igtawr1sq3kk"},{"post_id":"clep90m1d000higta0d8fsc9z","category_id":"clep90m4d0083igta2vp33y72","_id":"clep90m4f008aigta7qlqw2nq"},{"post_id":"clep90m1x001digtab4cn33dc","category_id":"clep90m1j000nigtafn4plil3","_id":"clep90m4g008digtau3hlwa5w"},{"post_id":"clep90m1x001digtab4cn33dc","category_id":"clep90m2i002nigta9xayotb1","_id":"clep90m4g008eigta4qete6tt"},{"post_id":"clep90m1x001digtab4cn33dc","category_id":"clep90m48007oigtah4t2tyg6","_id":"clep90m4h008gigtawmxek14q"},{"post_id":"clep90m1z001gigta4u7diq7b","category_id":"clep90m1j000nigtafn4plil3","_id":"clep90m4i008iigtan9pgp285"},{"post_id":"clep90m1z001gigta4u7diq7b","category_id":"clep90m2i002nigta9xayotb1","_id":"clep90m4i008kigta2qinit92"},{"post_id":"clep90m1z001gigta4u7diq7b","category_id":"clep90m48007oigtah4t2tyg6","_id":"clep90m4i008ligtajufz1rmo"},{"post_id":"clep90m3c004qigtay36bc7hm","category_id":"clep90m150008igtaub81ddvy","_id":"clep90m4i008nigtau45ugxmu"},{"post_id":"clep90m3c004qigtay36bc7hm","category_id":"clep90m1n000sigtag4kz3d20","_id":"clep90m4j008oigtavrml6zuw"},{"post_id":"clep90m3c004qigtay36bc7hm","category_id":"clep90m4h008higta7juxddcc","_id":"clep90m4j008qigta7i43myo9"},{"post_id":"clep90m1e000kigtak0uehcto","category_id":"clep90m1j000nigtafn4plil3","_id":"clep90m4j008rigta3zqlzfjf"},{"post_id":"clep90m1e000kigtak0uehcto","category_id":"clep90m2i002nigta9xayotb1","_id":"clep90m4j008tigtarszkbom0"},{"post_id":"clep90m1e000kigtak0uehcto","category_id":"clep90m4d0083igta2vp33y72","_id":"clep90m4k008uigtamgkn076g"},{"post_id":"clep90m20001iigtastcd8ych","category_id":"clep90m1j000nigtafn4plil3","_id":"clep90m4k008wigta6kwkk0yw"},{"post_id":"clep90m20001iigtastcd8ych","category_id":"clep90m2i002nigta9xayotb1","_id":"clep90m4k008xigta9dm93231"},{"post_id":"clep90m20001iigtastcd8ych","category_id":"clep90m48007oigtah4t2tyg6","_id":"clep90m4k008zigtahdzy20q9"},{"post_id":"clep90m21001ligtat5p15sni","category_id":"clep90m1j000nigtafn4plil3","_id":"clep90m4l0090igtabbtwlno1"},{"post_id":"clep90m21001ligtat5p15sni","category_id":"clep90m2i002nigta9xayotb1","_id":"clep90m4l0092igta7qaxjm3s"},{"post_id":"clep90m21001ligtat5p15sni","category_id":"clep90m4j008sigtaot7qmgs9","_id":"clep90m4l0093igtaoc6lfbz1"},{"post_id":"clep90m22001nigtasoggl053","category_id":"clep90m1j000nigtafn4plil3","_id":"clep90m4m0095igtado9o80dv"},{"post_id":"clep90m22001nigtasoggl053","category_id":"clep90m2i002nigta9xayotb1","_id":"clep90m4m0096igtazsagzbum"},{"post_id":"clep90m22001nigtasoggl053","category_id":"clep90m4k008vigtavgx1nfxj","_id":"clep90m4m0098igtaltpbiuqf"},{"post_id":"clep90m23001qigtaws455ryc","category_id":"clep90m1j000nigtafn4plil3","_id":"clep90m4m0099igtag8zy29pp"},{"post_id":"clep90m23001qigtaws455ryc","category_id":"clep90m2i002nigta9xayotb1","_id":"clep90m4n009bigta5usvibez"},{"post_id":"clep90m23001qigtaws455ryc","category_id":"clep90m48007oigtah4t2tyg6","_id":"clep90m4n009cigtar5d4jenk"},{"post_id":"clep90m1g000migtax17ipfwu","category_id":"clep90m1j000nigtafn4plil3","_id":"clep90m4n009digtat9umgdlv"},{"post_id":"clep90m1g000migtax17ipfwu","category_id":"clep90m2i002nigta9xayotb1","_id":"clep90m4o009figtav8ktxq85"},{"post_id":"clep90m1g000migtax17ipfwu","category_id":"clep90m48007oigtah4t2tyg6","_id":"clep90m4o009gigtaet764u5e"},{"post_id":"clep90m24001sigta4d4nsv0w","category_id":"clep90m1j000nigtafn4plil3","_id":"clep90m4p009iigtakrn73nbp"},{"post_id":"clep90m24001sigta4d4nsv0w","category_id":"clep90m2i002nigta9xayotb1","_id":"clep90m4p009jigta15hjeve1"},{"post_id":"clep90m24001sigta4d4nsv0w","category_id":"clep90m48007oigtah4t2tyg6","_id":"clep90m4p009ligta274zw1wj"},{"post_id":"clep90m26001wigtacpznq66k","category_id":"clep90m1j000nigtafn4plil3","_id":"clep90m4p009migtaavyrwvua"},{"post_id":"clep90m26001wigtacpznq66k","category_id":"clep90m2i002nigta9xayotb1","_id":"clep90m4q009oigta3r2pyacx"},{"post_id":"clep90m26001wigtacpznq66k","category_id":"clep90m4m0097igtapw63gtng","_id":"clep90m4q009pigta5vvempx2"},{"post_id":"clep90m2c0028igta97y4ah0u","category_id":"clep90m3q005wigtaojzizpgr","_id":"clep90m4q009rigta6x9qhra3"},{"post_id":"clep90m2c0028igta97y4ah0u","category_id":"clep90m4n009eigtaoe1uh27q","_id":"clep90m4q009sigtab9449ju3"},{"post_id":"clep90m2i002migtaalic8oly","category_id":"clep90m3q005sigta7m2hemoe","_id":"clep90m4r009uigta5td2j90o"},{"post_id":"clep90m2i002migtaalic8oly","category_id":"clep90m4n009aigta3dxbhtgk","_id":"clep90m4r009vigtath8b1717"},{"post_id":"clep90m2o002xigtaqit8u6o9","category_id":"clep90m3q005sigta7m2hemoe","_id":"clep90m4r009xigtaarklkn5d"},{"post_id":"clep90m2o002xigtaqit8u6o9","category_id":"clep90m4n009aigta3dxbhtgk","_id":"clep90m4s009yigtaeaurslvo"},{"post_id":"clep90m2s0036igtaefs1tou6","category_id":"clep90m3q005sigta7m2hemoe","_id":"clep90m4s00a0igtawog6d2bc"},{"post_id":"clep90m2s0036igtaefs1tou6","category_id":"clep90m4r009tigta3ayjozzj","_id":"clep90m4s00a1igtacjf12l1w"},{"post_id":"clep90m2t003bigtacrpg397s","category_id":"clep90m3q005sigta7m2hemoe","_id":"clep90m4t00a3igtany0navce"},{"post_id":"clep90m2t003bigtacrpg397s","category_id":"clep90m4r009tigta3ayjozzj","_id":"clep90m4t00a4igta5mtgsquf"},{"post_id":"clep90m2v003higtatcp123au","category_id":"clep90m3q005sigta7m2hemoe","_id":"clep90m4t00a6igta5zccpn1t"},{"post_id":"clep90m2v003higtatcp123au","category_id":"clep90m4r009tigta3ayjozzj","_id":"clep90m4t00a7igta523fu3us"},{"post_id":"clep90m2w003kigtap5gwoyxl","category_id":"clep90m3q005sigta7m2hemoe","_id":"clep90m4u00a9igtabdwx5sxw"},{"post_id":"clep90m2w003kigtap5gwoyxl","category_id":"clep90m4r009tigta3ayjozzj","_id":"clep90m4u00aaigtavbed8wqe"},{"post_id":"clep90m2x003oigta2nasqjp4","category_id":"clep90m3q005sigta7m2hemoe","_id":"clep90m4v00acigta5vvghlub"},{"post_id":"clep90m2x003oigta2nasqjp4","category_id":"clep90m4r009tigta3ayjozzj","_id":"clep90m4v00adigtam4cdb9gg"},{"post_id":"clep90m30003vigta5umhb0ms","category_id":"clep90m3q005sigta7m2hemoe","_id":"clep90m4v00afigtagmmtrln2"},{"post_id":"clep90m30003vigta5umhb0ms","category_id":"clep90m4r009tigta3ayjozzj","_id":"clep90m4v00agigtar265h4xg"},{"post_id":"clep90m31003yigtan83sa9dx","category_id":"clep90m3q005sigta7m2hemoe","_id":"clep90m4w00aiigtaliome22r"},{"post_id":"clep90m31003yigtan83sa9dx","category_id":"clep90m4r009tigta3ayjozzj","_id":"clep90m4w00ajigtaby7khrj8"},{"post_id":"clep90m320041igtarkho11pp","category_id":"clep90m3q005sigta7m2hemoe","_id":"clep90m4x00aligtaw81y87ab"},{"post_id":"clep90m320041igtarkho11pp","category_id":"clep90m4r009tigta3ayjozzj","_id":"clep90m4x00amigtaiqo5p4q0"},{"post_id":"clep90m330045igtaeusxazq0","category_id":"clep90m3q005sigta7m2hemoe","_id":"clep90m4x00aoigtap6p07x8k"},{"post_id":"clep90m330045igtaeusxazq0","category_id":"clep90m4r009tigta3ayjozzj","_id":"clep90m4x00apigtazgqzygb4"},{"post_id":"clep90m350048igtaf306c3w4","category_id":"clep90m3q005sigta7m2hemoe","_id":"clep90m4y00arigtax4g1iv4n"},{"post_id":"clep90m350048igtaf306c3w4","category_id":"clep90m4r009tigta3ayjozzj","_id":"clep90m4y00asigtaj8yqlil1"},{"post_id":"clep90m36004bigta4lbhnnkt","category_id":"clep90m3q005sigta7m2hemoe","_id":"clep90m4y00auigtan8gkslhg"},{"post_id":"clep90m36004bigta4lbhnnkt","category_id":"clep90m4r009tigta3ayjozzj","_id":"clep90m4z00avigta0m8bqiuc"},{"post_id":"clep90m38004figta9x7jgotb","category_id":"clep90m3q005sigta7m2hemoe","_id":"clep90m4z00axigta2duk0nie"},{"post_id":"clep90m38004figta9x7jgotb","category_id":"clep90m4r009tigta3ayjozzj","_id":"clep90m4z00ayigtabmrixxfl"},{"post_id":"clep90m39004iigtabyd2xu7u","category_id":"clep90m3q005sigta7m2hemoe","_id":"clep90m4z00b0igtaroqy0m5a"},{"post_id":"clep90m39004iigtabyd2xu7u","category_id":"clep90m4r009tigta3ayjozzj","_id":"clep90m5000b1igtaehuwsp50"},{"post_id":"clep90m3a004ligta57gv0gt5","category_id":"clep90m3q005sigta7m2hemoe","_id":"clep90m5100b3igtact5t52ee"},{"post_id":"clep90m3a004ligta57gv0gt5","category_id":"clep90m4r009tigta3ayjozzj","_id":"clep90m5100b4igtazqju1h8t"},{"post_id":"clep90m3b004nigtaizijwihb","category_id":"clep90m3q005sigta7m2hemoe","_id":"clep90m5100b6igtamo2nio2r"},{"post_id":"clep90m3b004nigtaizijwihb","category_id":"clep90m4r009tigta3ayjozzj","_id":"clep90m5100b7igta2478irqi"},{"post_id":"clep90m2a0023igtamesrqd2c","category_id":"clep90m3q005sigta7m2hemoe","_id":"clep90m5200b9igta6jom1igj"},{"post_id":"clep90m2a0023igtamesrqd2c","category_id":"clep90m4n009aigta3dxbhtgk","_id":"clep90m5200bbigta0w7zspt1"},{"post_id":"clep90m2a0023igtamesrqd2c","category_id":"clep90m5100b5igta9j7vqb4f","_id":"clep90m5200bcigtaajb3w36m"},{"post_id":"clep90m2g002iigtad99tyutg","category_id":"clep90m3q005sigta7m2hemoe","_id":"clep90m5300beigtanfiodfud"},{"post_id":"clep90m2g002iigtad99tyutg","category_id":"clep90m4o009higtadu1ctbj0","_id":"clep90m5300bfigta0qx31c84"},{"post_id":"clep90m2g002iigtad99tyutg","category_id":"clep90m5200b8igtazq6a4zud","_id":"clep90m5300bgigtau5ha9con"},{"post_id":"clep90m2p0030igtam0nyt1r5","category_id":"clep90m3q005sigta7m2hemoe","_id":"clep90m5300bhigtatqned8wz"},{"post_id":"clep90m2p0030igtam0nyt1r5","category_id":"clep90m4o009higtadu1ctbj0","_id":"clep90m5300biigta5kulc8we"},{"post_id":"clep90m2p0030igtam0nyt1r5","category_id":"clep90m5200baigtaf0k8itra","_id":"clep90m5400bjigta3gutw32k"},{"post_id":"clep90m3e004vigtav82h0lqb","category_id":"clep90m3q005sigta7m2hemoe","_id":"clep90m5400bkigtauv46333s"},{"post_id":"clep90m3e004vigtav82h0lqb","category_id":"clep90m4o009higtadu1ctbj0","_id":"clep90m5400bligta4jvfz4xd"},{"post_id":"clep90m3e004vigtav82h0lqb","category_id":"clep90m5300bdigtad6g9b4lv","_id":"clep90m5400bmigtapxb5bwa1"}],"PostTag":[{"post_id":"clep90m0u0002igtaquofoseq","tag_id":"clep90m120005igtarkgl4inn","_id":"clep90m18000cigtaych8ac2y"},{"post_id":"clep90m0z0004igtavxljvzfz","tag_id":"clep90m18000bigta91f4sfap","_id":"clep90m1e000jigta3bqqix2r"},{"post_id":"clep90m140007igtaefhtnl48","tag_id":"clep90m1c000gigta4iu3thlq","_id":"clep90m1k000oigtaqz8qekcs"},{"post_id":"clep90m160009igtaekqftsha","tag_id":"clep90m1f000ligta4r9uaodw","_id":"clep90m1n000tigtaxypdrk0l"},{"post_id":"clep90m1k000pigtaq1qbcu2a","tag_id":"clep90m1f000ligta4r9uaodw","_id":"clep90m1o000vigtarckmn771"},{"post_id":"clep90m17000aigta69m0mseq","tag_id":"clep90m1l000qigtadgj044mj","_id":"clep90m1q000zigtadoyoo643"},{"post_id":"clep90m19000digtaprt0ukxv","tag_id":"clep90m1c000gigta4iu3thlq","_id":"clep90m1s0013igtabt39hbe1"},{"post_id":"clep90m1b000figtarwp3x27n","tag_id":"clep90m1s0012igta44g7m8qm","_id":"clep90m1w001aigtav9kx6nls"},{"post_id":"clep90m1d000higta0d8fsc9z","tag_id":"clep90m1v0017igta2tl3z9tr","_id":"clep90m1y001figtamt8y5g7d"},{"post_id":"clep90m1e000kigtak0uehcto","tag_id":"clep90m1v0017igta2tl3z9tr","_id":"clep90m21001kigta3uc8mqx5"},{"post_id":"clep90m1g000migtax17ipfwu","tag_id":"clep90m1z001higta8n83s1i7","_id":"clep90m23001pigtaq4ljc2pg"},{"post_id":"clep90m1m000rigta7baisx83","tag_id":"clep90m1s0012igta44g7m8qm","_id":"clep90m25001vigtaewyh8q5j"},{"post_id":"clep90m1n000uigta605du5ob","tag_id":"clep90m24001rigta5bfrel1u","_id":"clep90m280021igtaw4o8tnlv"},{"post_id":"clep90m1o000wigtackjw33d9","tag_id":"clep90m1s0012igta44g7m8qm","_id":"clep90m2c0027igtasp3289a8"},{"post_id":"clep90m1q0010igta9xzsbukb","tag_id":"clep90m1s0012igta44g7m8qm","_id":"clep90m2e002eigta1sog3bhc"},{"post_id":"clep90m2d002aigtav88kdgc9","tag_id":"clep90m1l000qigtadgj044mj","_id":"clep90m2g002higta55qurr1o"},{"post_id":"clep90m2f002figtahc8j02a2","tag_id":"clep90m1l000qigtadgj044mj","_id":"clep90m2i002ligtaa2a4t999"},{"post_id":"clep90m1r0011igta8i7ruxxl","tag_id":"clep90m2e002bigta1czlbw7k","_id":"clep90m2j002pigtaaiil9600"},{"post_id":"clep90m1t0014igta3r3abjy5","tag_id":"clep90m2h002jigtaf6juu6i7","_id":"clep90m2n002vigta5bx86tnh"},{"post_id":"clep90m1u0016igtagiat4f4t","tag_id":"clep90m2l002rigta63lrvcp4","_id":"clep90m2q0032igtahqomrbth"},{"post_id":"clep90m1v0018igtas9rtb31x","tag_id":"clep90m2p002zigta0fncqtyn","_id":"clep90m2t003aigtaw7hemofu"},{"post_id":"clep90m1w001bigtasvyfvjx0","tag_id":"clep90m2s0037igtazxpt8yxx","_id":"clep90m2w003iigta5dwf66wt"},{"post_id":"clep90m1x001digtab4cn33dc","tag_id":"clep90m2u003eigta9py13a7s","_id":"clep90m2y003pigtagdqulyzg"},{"post_id":"clep90m1z001gigta4u7diq7b","tag_id":"clep90m2x003ligtar651c672","_id":"clep90m30003wigta1puhatl0"},{"post_id":"clep90m20001iigtastcd8ych","tag_id":"clep90m2z003uigtak90xo9q3","_id":"clep90m330044igtaqhcbo81g"},{"post_id":"clep90m21001ligtat5p15sni","tag_id":"clep90m330042igtavk79fdzh","_id":"clep90m37004cigtavenf9d1v"},{"post_id":"clep90m22001nigtasoggl053","tag_id":"clep90m360049igtapilq5m9x","_id":"clep90m3a004jigtaohvufcl9"},{"post_id":"clep90m23001qigtaws455ryc","tag_id":"clep90m39004gigta42ivn7ou","_id":"clep90m3c004oigtaerjy5x6v"},{"post_id":"clep90m24001sigta4d4nsv0w","tag_id":"clep90m3b004migtake08i82r","_id":"clep90m3e004uigtaw52mkysx"},{"post_id":"clep90m3d004rigtaxpczvvrj","tag_id":"clep90m1f000ligta4r9uaodw","_id":"clep90m3f004wigtarpcoq2uw"},{"post_id":"clep90m26001wigtacpznq66k","tag_id":"clep90m3d004sigta8s7c3m6a","_id":"clep90m3g0050igtad3n9vx6d"},{"post_id":"clep90m3f004xigta5bxvbcru","tag_id":"clep90m1l000qigtadgj044mj","_id":"clep90m3g0052igtagp4cac02"},{"post_id":"clep90m280022igta03psn4v8","tag_id":"clep90m3f004yigtaz0ltqtvv","_id":"clep90m3h0057igtarc5eagfe"},{"post_id":"clep90m2a0023igtamesrqd2c","tag_id":"clep90m3h0054igtaa72wwbfg","_id":"clep90m3i005bigtaqcct1dbq"},{"post_id":"clep90m2c0028igta97y4ah0u","tag_id":"clep90m3i005aigtaoqlesgtn","_id":"clep90m3j005eigtaphr3xpr7"},{"post_id":"clep90m2g002iigtad99tyutg","tag_id":"clep90m3j005digtaowk7gfdy","_id":"clep90m3k005higtazo65dbkt"},{"post_id":"clep90m2i002migtaalic8oly","tag_id":"clep90m3k005gigta6bh38nsp","_id":"clep90m3l005kigtamemu5eie"},{"post_id":"clep90m2m002tigtabvmrtv1l","tag_id":"clep90m3l005jigtanpim3pzn","_id":"clep90m3m005nigtajuh2csjv"},{"post_id":"clep90m2p0030igtam0nyt1r5","tag_id":"clep90m3m005migtaxg71a4to","_id":"clep90m3p005rigtaxm77y867"},{"post_id":"clep90m2r0034igtajkb8xgjt","tag_id":"clep90m3o005pigta6k0xrh2u","_id":"clep90m3q005vigtatwlazgod"},{"post_id":"clep90m2s0036igtaefs1tou6","tag_id":"clep90m3q005tigta651kgd14","_id":"clep90m3r0060igtah9rr76ke"},{"post_id":"clep90m2t003bigtacrpg397s","tag_id":"clep90m3q005tigta651kgd14","_id":"clep90m3t0063igtastbyiuka"},{"post_id":"clep90m2u003digtap6wwkwfq","tag_id":"clep90m3s0062igtan7w34hfl","_id":"clep90m3u0067igtak7z6mc1b"},{"post_id":"clep90m2v003higtatcp123au","tag_id":"clep90m3q005tigta651kgd14","_id":"clep90m3v006aigtaxhr4fuqx"},{"post_id":"clep90m2w003kigtap5gwoyxl","tag_id":"clep90m3q005tigta651kgd14","_id":"clep90m3w006digtalaj7rvx1"},{"post_id":"clep90m2x003oigta2nasqjp4","tag_id":"clep90m3q005tigta651kgd14","_id":"clep90m3x006gigtaxlrgab3f"},{"post_id":"clep90m2y003rigta05qustf1","tag_id":"clep90m3s0062igtan7w34hfl","_id":"clep90m3y006ligtaxa5kuoqc"},{"post_id":"clep90m30003vigta5umhb0ms","tag_id":"clep90m3q005tigta651kgd14","_id":"clep90m3z006oigta3pftsxbc"},{"post_id":"clep90m31003yigtan83sa9dx","tag_id":"clep90m3q005tigta651kgd14","_id":"clep90m40006tigta7g4jfrn6"},{"post_id":"clep90m320041igtarkho11pp","tag_id":"clep90m3q005tigta651kgd14","_id":"clep90m41006xigtaflb9y3kg"},{"post_id":"clep90m330045igtaeusxazq0","tag_id":"clep90m3q005tigta651kgd14","_id":"clep90m420070igtapftjr1l9"},{"post_id":"clep90m350048igtaf306c3w4","tag_id":"clep90m3q005tigta651kgd14","_id":"clep90m430073igtajlzd87z8"},{"post_id":"clep90m36004bigta4lbhnnkt","tag_id":"clep90m3q005tigta651kgd14","_id":"clep90m440076igta2a9qxiv5"},{"post_id":"clep90m38004figta9x7jgotb","tag_id":"clep90m3q005tigta651kgd14","_id":"clep90m440079igtaks0et5bj"},{"post_id":"clep90m39004iigtabyd2xu7u","tag_id":"clep90m3q005tigta651kgd14","_id":"clep90m45007eigtat6y2lx67"},{"post_id":"clep90m3a004ligta57gv0gt5","tag_id":"clep90m3q005tigta651kgd14","_id":"clep90m46007iigtaqtxqeomd"},{"post_id":"clep90m3b004nigtaizijwihb","tag_id":"clep90m3q005tigta651kgd14","_id":"clep90m47007nigtabvy72ldb"},{"post_id":"clep90m3c004qigtay36bc7hm","tag_id":"clep90m47007ligta1ss21y4e","_id":"clep90m48007rigtayszm9z5v"},{"post_id":"clep90m3e004vigtav82h0lqb","tag_id":"clep90m3m005migtaxg71a4to","_id":"clep90m49007tigtaji983blk"}],"Tag":[{"name":"kdd99","_id":"clep90m120005igtarkgl4inn"},{"name":"LOL","_id":"clep90m18000bigta91f4sfap"},{"name":"jetson nano","_id":"clep90m1c000gigta4iu3thlq"},{"name":"wordpress","_id":"clep90m1f000ligta4r9uaodw"},{"name":"cv","_id":"clep90m1l000qigtadgj044mj"},{"name":"爬坑","_id":"clep90m1s0012igta44g7m8qm"},{"name":"fastai","_id":"clep90m1v0017igta2tl3z9tr"},{"name":"instaGAN","_id":"clep90m1z001higta8n83s1i7"},{"name":"系统软件","_id":"clep90m24001rigta5bfrel1u"},{"name":"AlexNet","_id":"clep90m2e002bigta1czlbw7k"},{"name":"心理","_id":"clep90m2h002jigtaf6juu6i7"},{"name":"CNN","_id":"clep90m2l002rigta63lrvcp4"},{"name":"BEGAN","_id":"clep90m2p002zigta0fncqtyn"},{"name":"DiscoGAN","_id":"clep90m2s0037igtazxpt8yxx"},{"name":"DCGAN","_id":"clep90m2u003eigta9py13a7s"},{"name":"GAN","_id":"clep90m2x003ligtar651c672"},{"name":"VAEGAN","_id":"clep90m2z003uigtak90xo9q3"},{"name":"Resnet","_id":"clep90m330042igtavk79fdzh"},{"name":"VGG","_id":"clep90m360049igtapilq5m9x"},{"name":"WGAN","_id":"clep90m39004gigta42ivn7ou"},{"name":"pix2pix","_id":"clep90m3b004migtake08i82r"},{"name":"加载数据集","_id":"clep90m3d004sigta8s7c3m6a"},{"name":"思维导图","_id":"clep90m3f004yigtaz0ltqtvv"},{"name":"归一化","_id":"clep90m3h0054igtaa72wwbfg"},{"name":"pyqt5","_id":"clep90m3i005aigtaoqlesgtn"},{"name":"网络","_id":"clep90m3j005digtaowk7gfdy"},{"name":"推导","_id":"clep90m3k005gigta6bh38nsp"},{"name":"hexo","_id":"clep90m3l005jigtanpim3pzn"},{"name":"计算机网络","_id":"clep90m3m005migtaxg71a4to"},{"name":"破解MathType","_id":"clep90m3o005pigta6k0xrh2u"},{"name":"课后解答","_id":"clep90m3q005tigta651kgd14"},{"name":"GItKraken","_id":"clep90m3s0062igtan7w34hfl"},{"name":"github","_id":"clep90m47007ligta1ss21y4e"}]}}