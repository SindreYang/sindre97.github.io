<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[P图(无缝克隆)]]></title>
    <url>%2F2020%2F03%2F09%2FP%E5%9B%BE-%E6%97%A0%E7%BC%9D%E5%85%8B%E9%9A%86%2F</url>
    <content type="text"><![CDATA[无缝克隆是什么两张图片合在一起,一般有以下三种方式 新手方式 Photoshop(遮罩) opencv方式 ![image.png]https://blog.mviai.com/images/FprK2rkiGOSWO25lKuShhVluN77_) 原理OpenCV中的无缝克隆是SIGGRAPH 2003有影响力的论文的实现，该论文名为Patrick Poez，Michel Gangnet和Andrew Blake，名称为“ Poisson Image Editing”。 现在我们知道，如果使用精心创建的遮罩将源图像（飞机）的强度（RGB值）与目标图像（天空）混合，我们将获得如图3所示的结果。本文的中心思想是使用图像梯度而不是图像强度可以产生更真实的结果。无缝克隆后，蒙版区域中结果图像的强度与蒙版区域中源区域的强度不同。相反，结果图像在遮罩区域中的梯度与源区域在遮罩区域中的梯度大约相同。另外，在被遮蔽区域的边界处的结果图像的强度与目的地图像（天空）的强度相同。 作者表明，这是通过求解泊松方程来完成的，因此可以解决论文的标题-泊松图像编辑。该论文的理论和实现细节实际上非常酷. 主要函数1output = cv2.seamlessClone(src, dst, mask, center, flags) 1seamlessClone(Mat src, Mat dst, Mat mask, Point center, Mat output, int flags) src 将被复制到目标图像的源图像。在我们的示例中是飞机。dst 源映像将被克隆到的目标映像。在我们的示例中，它是天空图像。mask 要克隆的对象周围的粗糙蒙版。这应该是源图像的大小。如果您很懒，请将其设置为全白图像！center 源图像中心在目标图像中的位置。flags 当前起作用的两个标志是NORMAL_CLONE和MIXED_CLONE。正常克隆和无缝克隆。output 输出结果图像。 基础版1234567891011121314151617181920212223242526# 基本# 导入相关的包import cv2import numpy as np # 读入图片src = cv2.imread("images/airplane.jpg")dst = cv2.imread("images/sky.jpg")#在飞机周围创建一个粗糙的mask。src_mask = np.zeros(src.shape, src.dtype)#将遮罩定义为封闭的多边形poly = np.array([ [4,80], [30,54], [151,63], [254,37], [298,90], [272,134], [43,122] ], np.int32)#函数cv :: fillPoly填充由多个多边形轮廓所界定的区域。该函数可以填充。复杂区域，例如，带有孔的区域，具有自相交的轮廓（它们的某些部分）等等cv2.fillPoly(src_mask, [poly], (255, 255, 255))# 飞机中心的位置center = (800,100)# 完成克隆output = cv2.seamlessClone(src, dst, src_mask, center, cv2.NORMAL_CLONE)# 保存结果cv2.imwrite("images/opencv-seamless-cloning-example.jpg", output); 12345678910111213141516171819202122232425262728293031323334353637383940414243444546//# 基本////# 导入相关的包#include "opencv2/opencv.hpp"using namespace cv;using namespace std;int main( int argc, char** argv )&#123; // 读入图片 Mat src = imread("../images/airplane.jpg"); Mat dst = imread("../images/sky.jpg"); // 在飞机周围创建一个粗糙的mask。 Mat src_mask = Mat::zeros(src.rows, src.cols, src.depth()); // 将遮罩定义为封闭的多边形 Point poly[1][7]; poly[0][0] = Point(4, 80); poly[0][1] = Point(30, 54); poly[0][2] = Point(151,63); poly[0][3] = Point(254,37); poly[0][4] = Point(298,90); poly[0][5] = Point(272,134); poly[0][6] = Point(43,122); const Point* polygons[1] = &#123; poly[0] &#125;; int num_points[] = &#123; 7 &#125;; // 通过填充多边形来创建蒙版n fillPoly(src_mask, polygons, num_points, 1, Scalar(255,255,255)); // 飞机中心的位置 Point center(800,100); // 将src无缝克隆到dst中，然后将结果放入输出中 Mat output; seamlessClone(src, dst, src_mask, center, output, NORMAL_CLONE); // 保存结果 imwrite("../images/opencv-seamless-cloning-example.jpg", output); &#125; 高级版12345678910111213141516171819202122import cv2import numpy as np#读取图像im = cv2.imread("images/wood-texture.jpg")obj= cv2.imread("images/iloveyouticket.jpg")# 创建全白图像mask = 255 * np.ones(obj.shape, obj.dtype)# dst中src中心的位置width, height, channels = im.shapecenter = (int(height/2), int(width/2))#将src无缝克隆到dst中，然后将结果放入输出中normal_clone = cv2.seamlessClone(obj, im, mask, center, cv2.NORMAL_CLONE)mixed_clone = cv2.seamlessClone(obj, im, mask, center, cv2.MIXED_CLONE)# 写入结果cv2.imwrite("images/opencv-normal-clone-example.jpg", normal_clone)cv2.imwrite("images/opencv-mixed-clone-example.jpg", mixed_clone) 123456789101112131415161718192021222324252627282930313233#include "opencv2/opencv.hpp"using namespace cv;using namespace std;int main( int argc, char** argv )&#123; // 读取图像：src图像将被克隆到dst中 Mat src = imread("images/iloveyouticket.jpg"); Mat dst = imread("images/wood-texture.jpg"); // 创建全白mask Mat src_mask = 255 * Mat::ones(src.rows, src.cols, src.depth()); // dst中src中心的位置 Point center(dst.cols/2,dst.rows/2); // 将src无缝克隆到dst中，然后将结果放入输出中 Mat normal_clone; Mat mixed_clone; seamlessClone(src, dst, src_mask, center, normal_clone, NORMAL_CLONE); seamlessClone(src, dst, src_mask, center, mixed_clone, MIXED_CLONE); // 写入图像 imwrite("images/opencv-normal-clone-example.jpg", normal_clone); imwrite("images/opencv-mixed-clone-example.jpg", mixed_clone); &#125; 大师版123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778import cv2import numpy as npimport matplotlib.pyplot as pltimport matplotlib.image as mpimg# 读取图片A = cv2.imread("images/man.jpg")B = cv2.imread("images/woman.jpg")# 转换成浮点数A = np.float32(A) / 255.0B = np.float32(B) / 255.0## 在A中的人脸周围创建一个粗糙的maskmask = np.zeros(A.shape,A.dtype)polygon = np.array([[164,226], [209,225], [238,188], [252,133], [248,75], [240,29], [192,15], [150,15], [100,70], [106,133], [123,194] ], np.int32)cv2.fillPoly(mask, [polygon], (255, 255, 255))# 将mask转换浮点数mask = np.float32(mask) / 255.0# 浮点数&lt;1.0 就乘以获取男女mask的加权平均值mask = mask * 0.7 # 0.7 for man, 0.3 for woman# 调整大小为 2^（金字塔中的级别）的倍数，因此在本例中为32A = cv2.resize(A,(384,352))# B的mask的大小应与A相同，以便以后进行乘法和加法运算B = cv2.resize(B,(A.shape[1],A.shape[0]))mask = cv2.resize(mask,(A.shape[1],A.shape[0]))# 从原始图像开始（金字塔底）guassianA = A.copy()guassianB = B.copy()guassianMask = mask.copy()cv2.imshow('guass',guassianMask)# 两种图像的拉普拉斯金字塔相结合combinedLaplacianPyramids = []# 金字塔中的级别数，尝试使用不同的值，请注意图像大小maxIterations = 5for i in range(maxIterations): # 计算两个图像的拉普拉斯金字塔 laplacianA = cv2.subtract(guassianA, cv2.pyrUp(cv2.pyrDown(guassianA))) laplacianB = cv2.subtract(guassianB, cv2.pyrUp(cv2.pyrDown(guassianB))) # 结合两个拉普拉斯金字塔，将加权平均与mask金字塔金字塔相结合 combinedLaplacian = guassianMask * laplacianA + (1.0 - guassianMask) * laplacianB # 在合并的拉普拉斯金字塔列表的开头添加CombinedLaplacian combinedLaplacianPyramids.insert(0,combinedLaplacian) # 更新高斯金字塔以进行下一次迭代 guassianA = cv2.pyrDown(guassianA) guassianB = cv2.pyrDown(guassianB) guassianMask = cv2.pyrDown(guassianMask)# 添加拉普拉斯金字塔的最后一个组合（金字塔的最高层）lastCombined = guassianMask * guassianA + (1.0 - guassianMask) * guassianBcombinedLaplacianPyramids.insert(0,lastCombined)# 重建影像blendedImage = combinedLaplacianPyramids[0]for i in range(1,len(combinedLaplacianPyramids)): # upSample并添加到下一个级别 blendedImage = cv2.pyrUp(blendedImage) blendedImage = cv2.add(blendedImage, combinedLaplacianPyramids[i])cv2.imshow('Blended',blendedImage)# 直接融合两个图像进行比较directCombination = mask * A + (1.0 - mask) * Bcv2.imshow('Direct combination',directCombination)cv2.waitKey(0) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152#include "opencv2/opencv.hpp"using namespace cv;using namespace std;void getLaplacianPyramid(Mat&amp; guassianPyramid, Mat&amp; laplacianPyramid)&#123; // 从高斯金字塔计算拉普拉斯金字塔 Mat downSampled; pyrDown(guassianPyramid,downSampled); // 上采样下采样 Mat blurred; pyrUp(downSampled,blurred); subtract(guassianPyramid, blurred, laplacianPyramid);&#125;void combineImages(Mat&amp; A, Mat&amp; B, Mat&amp; mask, Mat&amp; destination)&#123; destination = Mat::zeros(A.rows, A.cols, CV_32FC3); // 目的是求A和B的加权总和，分别具有权重掩码和1-掩码 for(int y = 0; y &lt; A.rows; y++) &#123; for(int x = 0; x &lt; A.cols; x++) &#123; Vec3f a = A.at&lt;Vec3f&gt;(Point(x,y)); Vec3f b = B.at&lt;Vec3f&gt;(Point(x,y)); Vec3f m = mask.at&lt;Vec3f&gt;(Point(x,y)); float b_ = a[0]*m[0]+(1-m[0])*b[0]; float g_ = a[1]*m[1]+(1-m[1])*b[1]; float r_ = a[2]*m[2]+(1-m[2])*b[2]; destination.at&lt;Vec3f&gt;(y,x)[0] = b_; destination.at&lt;Vec3f&gt;(y,x)[1] = g_; destination.at&lt;Vec3f&gt;(y,x)[2] = r_; &#125; &#125;&#125;int main( int argc, char** argv )&#123; // 读取图片 Mat A = imread("images/man.jpg"); Mat B = imread("images/woman.jpg"); // 转换成浮点数 A.convertTo(A, CV_32FC3, 1/255.0); B.convertTo(B, CV_32FC3, 1/255.0); //在A的人脸周围创建一个粗糙的mask。 Mat mask = Mat::zeros(A.rows, A.cols, CV_8UC3); // 创建飞机的边缘点 Point points[11]; points[0] = Point(164,226); points[1] = Point(209,225); points[2] = Point(238,188); points[3] = Point(252,133); points[4] = Point(248,75); points[5] = Point(240,29); points[6] = Point(192,15); points[7] = Point(150,15); points[8] = Point(100,70); points[9] = Point(106,133); points[10] = Point(123,194); const Point* polygon[1] = &#123;points&#125;; //构成点数组 int npt[] = &#123;11&#125;; // 点数组的长度 //填充由点形成的多边形 fillPoly(mask, polygon, npt, 1, Scalar(255, 255, 255)); // 转换成浮点数 mask.convertTo(mask, CV_32FC3, 1/255.0); // 用 浮点数&lt;1.0 乘以获取男女面部的加权平均值 mask = mask * 0.7; // 调整大小为2^（金字塔中的级别）的倍数，因此在本例中为32 resize(A, A, Size(384,352)); //B mask的大小应与A相同，以便以后进行乘法和加法运算 resize(B, B, A.size()); resize(mask, mask, A.size()); //从原始图像开始（金字塔底） Mat guassianA = A.clone(); Mat guassianB = B.clone(); Mat guassianMask = mask.clone(); // 金字塔中的级别数，尝试使用不同的值。注意图像尺寸 int maxIterations = 2; // 两种图像的组合拉普拉斯金字塔 vector&lt;Mat&gt; combinedLaplacianPyramids; for (int i = 0; i &lt; maxIterations; i++)&#123; // 计算A的拉普拉斯金字塔 Mat laplacianA; getLaplacianPyramid(guassianA,laplacianA); // 计算B的拉普拉斯金字塔 Mat laplacianB; getLaplacianPyramid(guassianB,laplacianB); // 结合拉普拉斯金字塔 Mat combinedLaplacian; combineImages(laplacianA, laplacianB, guassianMask, combinedLaplacian); //在合并的拉普拉斯金字塔列表的开头插入combinedLaplacian combinedLaplacianPyramids.insert(combinedLaplacianPyramids.begin(),combinedLaplacian); // 更新高斯金字塔以进行下一次迭代 pyrDown(guassianA,guassianA); pyrDown(guassianB,guassianB); pyrDown(guassianMask,guassianMask); &#125; //合并最后一个guassian（拉普拉斯金字塔的顶层与guassian的金字塔相同） Mat lastCombined; combineImages(guassianA, guassianB, guassianMask, lastCombined); // 在合并的拉普拉斯金字塔列表的开头插入lastCombined combinedLaplacianPyramids.insert(combinedLaplacianPyramids.begin(),lastCombined); // 重建影像 Mat blendedImage = combinedLaplacianPyramids[0]; for (int i = 1; i &lt; combinedLaplacianPyramids.size(); i++)&#123; // upSample并添加到下一个级别 pyrUp(blendedImage,blendedImage); add(blendedImage, combinedLaplacianPyramids[i],blendedImage); &#125; // 将混合图像放回原始位置的天空图像 imshow("blended",blendedImage); // 将混合图像放回原始位置的天空图像 Mat directCombined; combineImages(A, B, mask, directCombined); imshow("directCombined",directCombined); waitKey(0); return 0;&#125;]]></content>
      <categories>
        <category>框架</category>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>cv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[阈值分割]]></title>
    <url>%2F2020%2F03%2F09%2F%E9%98%88%E5%80%BC%E5%88%86%E5%89%B2%2F</url>
    <content type="text"><![CDATA[什么是图像阈值灰度值 0–&gt;255 黑–&gt;白 暗–&gt;亮 工作原理所有阈值算法都将源图像（src）和阈值（thresh）作为输入，并通过将源像素（x，y）的像素值与阈值进行比较来生成输出图像（dst）。如果src（x，y）&gt; thresh，则为dst（x，y）分配一个值。否则，将为dst（x，y）分配一些其他值。 二值化(type = THRESH_BINARY )最简单的阈值形式称为二值化。除了源图像（src）和阈值（thresh）之外，它还使用另一个称为最大值（maxValue）的输入参数。在每个像素位置（x，y），它将像素值src（x，y）与thresh进行比较。如果src（x，y）大于thresh，则将目标图像像素dst（x，y）的值设置为maxValue，否则将其设置为零。 二值化（thresh = 0和maxValue = 255） 二值化（thresh= 127，maxValue= 255） 将maxValue设置为128的二值化 反向二值化（类型= THRESH_BINARY_INV）反向二值化与二值化恰好相反。如果相应的源像素大于阈值，则将目标像素设置为零；如果源像素小于阈值，则将目标像素设置为maxValue。反向二值化（thresh = 127，maxValue = 0） 截断阈值（类型= THRESH_TRUNC）在这种类型的阈值处理中，如果源像素值大于阈值，则将目标像素设置为阈值（ thresh） 。否则，将其设置为源像素值。maxValue被忽略。 高于阈值（127）的所有值均被设置为127，并且小于或等于127的所有值均保持不变。maxValue被忽略。 零阈值（类型= THRESH_TOZERO）在这种阈值化中，如果源像素值大于阈值，则将目标像素值设置为对应的源像素值。否则将其设置为零。maxValue被忽略。 零阈值（阈值= 127） 反转零阈值（类型= THRESH_TOZERO_INV）在这种阈值处理中，如果源像素值大于阈值，则将目标像素值设置为零。否则，将其设置为源像素值。maxValue被忽略。将阈值反转为零,低于阈值的数字保留其灰度值，高于阈值的数字为0（边界除外）。边界上的伪影是由于以下事实：边界上的像素值从0过渡到几个像素上的数字值。因此，某些边界像素低于阈值。 12345678910111213141516171819202122232425262728293031323334# 导入 opencvimport cv2 # 读取图片src = cv2.imread("threshold.png", cv2.IMREAD_GRAYSCALE); # 二值化th, dst = cv2.threshold(src, 0, 255, cv2.THRESH_BINARY); cv2.imwrite("opencv-threshold-example.jpg", dst); # maxValue设置为128的阈值th, dst = cv2.threshold(src, 0, 128, cv2.THRESH_BINARY); cv2.imwrite("opencv-thresh-binary-maxval.jpg", dst); # 设置为127的阈值th, dst = cv2.threshold(src,127,255, cv2.THRESH_BINARY); cv2.imwrite("opencv-thresh-binary.jpg", dst); #反二值化th, dst = cv2.threshold(src,127,255, cv2.THRESH_BINARY_INV); cv2.imwrite("opencv-thresh-binary-inv.jpg", dst); # 截断阈值th, dst = cv2.threshold(src,127,255, cv2.THRESH_TRUNC); cv2.imwrite("opencv-thresh-trunc.jpg", dst); # 零阈值th, dst = cv2.threshold(src,127,255, cv2.THRESH_TOZERO); cv2.imwrite("opencv-thresh-tozero.jpg", dst); # 反转零阈值th, dst = cv2.threshold(src,127,255, cv2.THRESH_TOZERO_INV); cv2.imwrite("opencv-thresh-to-zero-inv.jpg", dst); 12345678910111213141516171819202122232425262728293031323334353637383940414243// 导入相关包#include "opencv2/opencv.hpp"using namespace cv;using namespace std;int main( int argc, char** argv )&#123; // 读取图片 Mat src = imread("threshold.png", IMREAD_GRAYSCALE); Mat dst; // 二值化 threshold(src,dst,0, 255, THRESH_BINARY); imwrite("../opencv-threshold-example.jpg", dst); // maxValue设置为128的阈值 threshold(src, dst, 0, 128, THRESH_BINARY); imwrite("../opencv-thresh-binary-maxval.jpg", dst); // 设置为127的阈值 threshold(src,dst,127,255, THRESH_BINARY); imwrite("../opencv-thresh-binary.jpg", dst); // 反二值化 threshold(src,dst,127,255, THRESH_BINARY_INV); imwrite("../opencv-thresh-binary-inv.jpg", dst); // 截断阈值 threshold(src,dst,127,255, THRESH_TRUNC); imwrite("../opencv-thresh-trunc.jpg", dst); // 零阈值 threshold(src,dst,127,255, THRESH_TOZERO); imwrite("../opencv-thresh-tozero.jpg", dst); //反转零阈值 threshold(src,dst,127,255, THRESH_TOZERO_INV); imwrite("../opencv-thresh-to-zero-inv.jpg", dst);&#125;]]></content>
      <categories>
        <category>框架</category>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>cv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[教程2:斑点检测(Blob检测)]]></title>
    <url>%2F2020%2F03%2F09%2F%E6%95%99%E7%A8%8B2-%E6%96%91%E7%82%B9%E6%A3%80%E6%B5%8B-Blob%E6%A3%80%E6%B5%8B%2F</url>
    <content type="text"><![CDATA[什么是Blob？Blob是图像中一组共享的像素，它们具有某些共同的属性（例如灰度值）。在上图中，深色连接区域是斑点，斑点检测的目的是识别并标记这些区域。 如何检测？顾名思义，SimpleBlobDetector基于以下描述的相当简单的算法。该算法由参数控制（下面以粗体显示），并具有以下步骤。 阈值处理：通过以minThreshold开始的阈值对源图像进行阈值处理，将源图像转换为多个二进制图像 。这些阈值以thresholdStep递增， 直到 maxThreshold。因此，第一个阈值为 minThreshold， 第二个阈值为 minThreshold + thresholdStep，第三个阈 值为 minThreshold + 2 x thresholdStep，依此类推。 分组： 在每个二进制图像中，连接的白色像素被分组在一起。让我们称这些二进制blob。3. 合并 ：计算二进制图像中二进制斑点的中心，并合并比minDistBetweenBlob 更近的斑点 。 中心和半径计算： 计算并返回新合并的Blob的中心和半径。 过滤方法? 按颜色：首先，您需要设置 filterByColor =1。设置 blobColor = 0以选择较暗的blob，将 blobColor = 255设置为较浅的blob。 按大小： 可以通过设置参数filterByArea = 1以及minArea 和maxArea的适当值来基于大小过滤blob 。例如，设置 minArea = 100将滤除所有少于100个像素的斑点。 按形状： 现在形状具有三个不同的参数。 圆度： 这只是测量斑点距圆的距离。例如，正六边形的圆度比正方形大。要按圆度过滤，请设置 filterByCircularity =1。然后为minCircularity 和maxCircularity设置适当的值。 圆度定义为 \ frac {4 \ pi Area} {perimeter * perimeter} 这意味着圆的圆度为1，正方形的圆度为0.785，依此类推。 凸性： 凸度定义为（斑点的面积/凸包的面积）。现在，形状的凸包是完全封闭该形状的最紧密的凸形。由凸滤波器，首先设置filterByConvexity = 1 ，然后设置0≤ minConvexity ≤1 和maxConvexity（≤1） 图为凹形与凸形 惯性比： 不要让它吓到你。数学家经常使用容易混淆的单词来描述非常简单的事物。您只需要知道这可以衡量形状的伸长程度。例如，对于一个圆，该值是1，对于椭圆它是0和1之间，而对于线是0。要通过过滤器惯量比，设置 filterByInertia = 1 ， 并设置0≤ minInertiaRatio ≤1 和 maxInertiaRatio （≤ 1） 适当。 SimpleBlobDetector1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253# 导入相关的包import cv2import numpy as np# 读取图片im = cv2.imread("blob.jpg", cv2.IMREAD_GRAYSCALE)# 设置SimpleBlobDetector参数params = cv2.SimpleBlobDetector_Params()# 更改阈值params.minThreshold = 10params.maxThreshold = 200# 基于大小过滤params.filterByArea = Trueparams.minArea = 1500# 基于圆度过滤params.filterByCircularity = Trueparams.minCircularity = 0.1# 按凸性过滤params.filterByConvexity = Trueparams.minConvexity = 0.87 # 按惯性过滤params.filterByInertia = Trueparams.minInertiaRatio = 0.01# 通过参数创建检测器ver = (cv2.__version__).split('.')if int(ver[0]) &lt; 3 : detector = cv2.SimpleBlobDetector(params)else : detector = cv2.SimpleBlobDetector_create(params)# 检测 blobs.keypoints = detector.detect(im)# 将检测到的斑点绘制为红色圆圈# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS# 确保圆的大小对应blobs的大小im_with_keypoints = cv2.drawKeypoints(im, keypoints, np.array([]), (0,0,255), cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)# 显示 blobscv2.imshow("Keypoints", im_with_keypoints)cv2.waitKey(0) 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869// 导入相关包#include "opencv2/opencv.hpp"using namespace cv;using namespace std;int main( int argc, char** argv )&#123; //读取图片 Mat im = imread( "../blob.jpg", IMREAD_GRAYSCALE ); // 设置SimpleBlobDetector参数 SimpleBlobDetector::Params params; // 设置阈值 params.minThreshold = 10; params.maxThreshold = 200; // 按大小过滤 params.filterByArea = true; params.minArea = 1500; // 按圆度过滤 params.filterByCircularity = true; params.minCircularity = 0.1; // 按凸性过滤 params.filterByConvexity = true; params.minConvexity = 0.87; // 按惯性过滤 params.filterByInertia = true; params.minInertiaRatio = 0.01; // 创建保存特征点变量 vector&lt;KeyPoint&gt; keypoints;#if CV_MAJOR_VERSION &lt; 3 // 如果使用 OpenCV 2 // 设置通过参数创建检测器 SimpleBlobDetector detector(params); // 检测 blobs detector.detect( im, keypoints);#else // 设置通过参数创建检测器 Ptr&lt;SimpleBlobDetector&gt; detector = SimpleBlobDetector::create(params); // 检测 blobs detector-&gt;detect( im, keypoints);#endif //# 将检测到的斑点绘制为红色圆圈 //# cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS //# 确保圆的大小对应blobs的大小 Mat im_with_keypoints; drawKeypoints( im, keypoints, im_with_keypoints, Scalar(0,0,255), DrawMatchesFlags::DRAW_RICH_KEYPOINTS ); // 显示 blobs imshow("keypoints", im_with_keypoints ); waitKey(0);&#125; 注:希望能调好参数,把所有的都识别到]]></content>
      <categories>
        <category>框架</category>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>cv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[教程1:OpenCV代码转换为Web API]]></title>
    <url>%2F2020%2F03%2F08%2F%E6%95%99%E7%A8%8B1-OpenCV%E4%BB%A3%E7%A0%81%E8%BD%AC%E6%8D%A2%E4%B8%BAWeb-API%2F</url>
    <content type="text"><![CDATA[目标: 我们将创建一个Web API，允许用户调用OpenCV代码。 快速建立一个简单的示例。 只需要一个Web浏览器，即可在所有平台上运行。 该项目将是免费的！将注册一个免费帐户，并使用一个开源框架。 将从一个非常基本的示例开始，在该示例中，用户将输入图像url传递到后端。后端读取图像并返回其宽度和高度。 工具: pythonanywhere PythonAnywhere不仅仅是一个托管平台。这是用于编写python代码的功能强大的IDE。它使您可以通过Web浏览器访问带有语法高亮显示的代码编辑器，Unix终端，访问日志文件。当然，您可以轻松地从github转移现有代码，也可以根据需要在vi中转移代码。它还附带安装了OpenCV！ web2py 免费的开源全栈框架，用于快速开发快速，可伸缩，安全和可移植的数据库驱动的基于Web的应用程序。用Python编写和编程 步骤:注册 注册PythonAnywhere并安装web2py(初学者的帐户是免费的,记住您的用户名) 注册并登录后，转到“ Web”选项卡，然后添加一个新的Web应用程序。 选择web2py作为您的python框架 选择web2py的管理员密码。(记住这是管理员密码,不是登录密码) 在web2py上创建Web应用 打开一个新标签，然后转到位于web2py的管理界面(https://你的用户名.pythonanywhere.com/admin/default/index) 登陆后,检查是否有如下文件:(出现sindre目录) 将OpenCV代码添加到web2pyweb2py目录结构: 模型包含应用程序的所有数据和规则 控制器包含用于处理数据的代码 视图则显示基础数据的某些状态 TODO: 输入图像URL–&gt;返回图像的宽度和高度 在控制器 controllers / default.py最后添加以下代码 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152# -*- coding: UTF-8 -*-'''=================================================@path ：learnopencv -&gt; web@IDE ：CLion@Author ：sindre@Date ：2020/3/8 下午7:41=================================================='''__author__ = 'sindre'import cv2import numpy as npimport urllib2import jsondef image_dimensions(): # 伪装成Mozilla，因为一些web服务器可能不喜欢python机器人 hdr = &#123;'User-Agent': 'Mozilla/5.0'&#125; # 设定要求 req = urllib2.Request(urllib2.request.vars.url, headers=hdr) try: # 获取URL的内容 con = urllib2.urlopen( req ) # 读取内容并将其转换为numpy数组 im_array = np.asarray(bytearray(con.read()), dtype=np.uint8) #将numpy数组转换为图像。 im = cv2.imdecode(im_array, cv2.IMREAD_GRAYSCALE) # 获取图像的宽度和高度。 height, width = im.shape #将宽度和高度封装在一个对象中，并返回经过编码的JSON return json.dumps(&#123;"width" : width, "height" : height&#125;) except urllib2.HTTPError as e: return e.fp.read() 保存后就可以测试了(注意,点 save file旁的图标才是保存) 测试随机找个图片地址如:https://home.yx1024.top/images/1.png curl -F url=https://home.yx1024.top/images/1.png http://你的用户名.pythonanywhere.com/你的应用名/default/image_dimensions]]></content>
      <categories>
        <category>框架</category>
        <category>opencv</category>
      </categories>
      <tags>
        <tag>cv</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第二部分:GitKraken破解及教程]]></title>
    <url>%2F2020%2F03%2F02%2F%E7%AC%AC%E4%BA%8C%E9%83%A8%E5%88%86-GitKraken%E7%A0%B4%E8%A7%A3%E5%8F%8A%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[1. 首次打开程序第一次打开GitKraken程序时， GitKraken会提示需要登陆，可以用github.com的账号登陆，或者用邮箱创建账号登陆,选择第一个可以直接与github关联. 2. Authentication（授权）我们一般用到比较多的情况是从服务器上clone一个已有的仓库。在clone服务器上的仓库前，首先需要设置/生成本地的加密解密密钥。 打开 GitKraken 的File =&gt; Preference =&gt; Authentication 3. 修改用户名为了方便项目中代码的管理，需要重新编辑用户名。 点击右上角的图像即可看到所示的下拉菜单，鼠标悬于Profile上，会出现一个Edit按钮。File =&gt; Preference =&gt;Profile 4. 初始化本地仓库如果你需要在自己本地代码的目录下新建一个Git仓库，点击左上角的 File =&gt; Init Repo，点击 浏览 按钮选择需要初始化仓库的目录，然后点击 创建储存库 即会出现如下图所示的界面。 图中的.gitignore 和 License 都是可选的。.gitignore文件是git在提交时会读取的一个文件，现在可以不用管它的作用是什么（如果项目是一个python工程，我们可以选用预设好的python.gitignore）。当然如果有兴趣对此深入了解的话，建议去看一看progit这本书，这本书详细了介绍了Git。 5.克隆服务器上的项目首先，返回主界面，点击File =&gt; Clone Repo，选择 使用URL克隆，如下图： 6. 打开现有的Git仓库点击左上角 File ==&gt; open repo 7. Kraken界面主界面 功能界面 - 最上面的 本地 下拉菜单中显示的是本地的分支。 - 远程 下拉菜单中显示的是远程仓库的列表，点击其中一个远程仓库，就会显示该仓库中拥有的分支数（远程分支）。 可以通过程序上方的 按钮将本地的分支上传到服务器。（非管理员无法删除服务器上的主分支） - 标签 下拉菜单中显示的是本地的标签，需要推送到服务器才能分享标签。 - 子模块 表示当前仓库的子模块 提交记录区域每一行都表示一个提交记录 文件改动区域当文件修改后: 未暂存相当于草稿,暂存后就可以提交了 顶部操作区域 相当于 Undo（回退一个提交记录）； Redo（回到回退前的那个提交记录）； Push（将本地的提交记录同步到服务器上）； Pull（将服务器上的提交记录同步到本地）； Branch（新建一个分支）； 8. 提交代码修改了某个文件后，在程序右侧会出现已修改文件的列表点击文件,就可以查看差异: 如果在未暂存区域(草稿):还可以通过比较,选择性保留及删除点击 暂存 按钮将会暂存这一块修改的内容，保留绿色部分（即保留+2 ~ +4 行的内容，丢弃 -2 ~ -4 行的内容）， 点击 丢弃 将会丢弃掉改动的这一部分，保留红色的部分（保留-2 ~ -4 行的内容，丢弃 +2 ~ +4 行的内容）。 放弃本次文件的改动有些情况下，由于更改代码造成了编译无法通过等错误时，想要放弃这次对文件的修改，将文件还原成上一次提交后的状态，一种简单的恢复文件的方法就是，在未暂存列表中找到这个文件，右键点击，选择丢弃改动就行.(如果要放弃全部更改,点击放弃按钮就行) 修改提交记录的描述信息 查看文件的历史修改及其追责右键点击,选择历史记录或文件追责 历史记录(显示每次提交记录与前次提交记录的差异；) 追责(显示该次提交记录完成的文件内容) 8. 本地分支和标签在提交记录区中查看分支状态 创建本地（Local）分支在GitKraken中央区域的提交记录处右键点击,选择中间的 在此处创建分支; 切换本地（Local）分支左侧有勾的表明该分支是当前所在的分支 直接在本地分支列表中双击 可以切换至该分支 参考:https://www.cnblogs.com/brifuture/p/9052512.html]]></content>
      <categories>
        <category>工具</category>
        <category>日常工具</category>
        <category>GItKraken</category>
      </categories>
      <tags>
        <tag>GItKraken</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一部分:GitKraken破解及教程]]></title>
    <url>%2F2020%2F03%2F01%2F%E7%AC%AC%E4%B8%80%E9%83%A8%E5%88%86-GitKraken%E7%A0%B4%E8%A7%A3%E5%8F%8A%E6%95%99%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[1.GItKraken介绍gitKraken，这款工具操作比较方便，UI也是我喜欢的风格，对没有太多git使用经验的新手比较友好，学习成本相对较低。尤其喜欢的一点就是它的分支和提交非常清晰。优点: 可以在不切换分支的情况下，操作其他的分支 多平台(Windows,liunx,mac) 缺点: 启动慢,占用资源多 收费 2.下载官网下载 3.汉化虽然都能认识,但是第一次接触,汉化亲切些; 下载1git clone https://github.com/k-skye/gitkraken-chinese.git 原理通过修改软件目录下english语言对应的一个json文件内容来完成汉化目的 操作步骤(注意备份英文文件,备份为strings.json.bak,习惯了操作就改回来) 将项目中的 strings.json 替换到 GitKraken 语言目录下的 strings.json.(实际目录可能会不一样,但文件名一定是strings.json) Windows: %程序安装目录%\gitkraken\app-x.x.x\resources\app\src\strings.json (x.x.x 是你的GitKraken版本) Mac: /Applications/GitKraken.app/Contents/Resources/app/src/strings.json Linux: /usr/share/gitkraken/resources/app.asar.unpacked/src (感谢lyydhy 10.31补充 Gitkraken是deepin 通过deb 安装的) 重启GitKraken. 4.破解1.安装完成后(sudo dpkg -i xx.deb),打开软件2.打开网址破解器,查看是否版本对应,否则查看问题回答最多(里面有解决方案)3.我下载的更新分支(github.com/BoGnY/GitCracken)的,它支持6.54.看说明:如下 GNU/Linux不要用snap安装 macOS必须开启后在破解(实测liunx也需要) node.js 版本需要12及其以上(sudo n 选择) yarn必须安装完成上述几条,执行 123yarn install yarn buildnode dist/bin/gitcracken.js --help 如遇到下载问题,首先查看是否默认换到淘宝源,如遇到报错,点击下载链接是否可以远程下载,如无法,打开yarn.lock文件修改地址(可以尝试本地地址 file://xxxxx) 完成后开始破解123yarn run gitcracken patcheryarn run gitcracken patcher --asar ~/Downloads/gitkraken/resources/app.asar(修改为你的安装地址)yarn run gitcracken patcher backup unpack patch 注意:如果报错,用yarn run gitcracken patcher remove 删除,然后到sudo rm gitkraken/resources/app.asar.*(如果破解后启动不了,也用这个方法) 提示:防止更新**更新后还要收费,修改hosts文件** vim etc/hosts 然后在文件最后加入 10.0.0.0 release.gitkraken.com#屏蔽官方地址]]></content>
      <categories>
        <category>工具</category>
        <category>日常工具</category>
      </categories>
      <tags>
        <tag>GItKraken</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jetson nano 配置]]></title>
    <url>%2F2019%2F06%2F10%2FNvidia-Jetson-nano-%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[通过设置（system settings）–&gt;network–&gt;ipv4是查看dhcp分配ip为192.108.1.105；jetson nano已经默认开启了openssh-server服务。可以通过xshell直接连上，用教程一中设置的jetson登录； 可见Ubuntu版本是18.04.2为了方便操作，设置初始化root的密码；设置为jetson,具体操作如下；123456789101112131415jetson@jetson-desktop:~$ sudo passwd[sudo] password for jetson: Enter new UNIX password: Retype new UNIX password: passwd: password updated successfullyjetson@jetson-desktop:~$ suPassword: root@jetson-desktop:/home/jetson# 设置允许超级管理员远程访问# vi /etc/ssh/sshd_config找到并用#注释掉这行：PermitRootLogin prohibit-password新建一行 添加：PermitRootLogin yes 重启服务1# service ssh restart 设置固定ip1234567891011121314151617181920212223/etc/network/interfaces# interfaces(5) file used by ifup(8) and ifdown(8)# Include files from /etc/network/interfaces.d:source-directory /etc/network/interfaces.dauto eth0iface eth0 inet staticaddress 192.168.1.105netmask 255.255.255.0gateway 192.168.1.1/etc/systemd/resolved.conf[Resolve]DNS==8.8.8.8 223.5.5.5#FallbackDNS=8.8.8.8#Domains=#LLMNR=no#MulticastDNS=no#DNSSEC=no#Cache=yes#DNSStubListener=yes 重启再连接；联网正常；12345678root@jetson-desktop:~# ping www.yangxin.comPING www.a.shifen.com (183.232.231.174) 56(84) bytes of data.64 bytes from 183.232.231.174 (183.232.231.174): icmp_seq=1 ttl=57 time=5.70 ms64 bytes from 183.232.231.174 (183.232.231.174): icmp_seq=2 ttl=57 time=5.61 ms^C--- www.a.shifen.com ping statistics ---2 packets transmitted, 2 received, 0% packet loss, time 1002msrtt min/avg/max/mdev = 5.617/5.661/5.706/0.087 ms 2、默认组件Jetson nano的镜像已经自带了JetPack，cuda，cudnn，opencv组件和sample，这些例子安装路径如下所示123456TensorRT /usr/src/tensorrt/samples/CUDA /usr/local/cuda-/samples/cuDNN /usr/src/cudnn_samples_v7/Multimedia API /usr/src/tegra_multimedia_api/VisionWorks /usr/share/visionworks/sources/samples/ /usr/share/visionworks-tracking/sources/samples/ /usr/share/visionworks-sfm/sources/samples/OpenCV /usr/share/OpenCV/samples/ 2.0获取超级 1sudo su 2.1核对CUDA12root@jetson-desktop:/# nvcc -V-bash: nvcc: command not found 加入路径1gedit ~/.bashrc 文件最后加入1234export CUBA_HOME=/usr/local/cuda-10.0export LD_LIBRARY_PATH=/usr/local/cuda-10.0/lib64:$LD_LIBRARY_PATHexport PATH=/usr/local/cuda-10.0/bin:$PATH 执行使生效1source ~/.bashrc 再次执行,显示cuda10.01234567root@jetson-desktop:/# source ~/.bashrcroot@jetson-desktop:/# nvcc -Vnvcc: NVIDIA (R) Cuda compiler driverCopyright (c) 2005-2018 NVIDIA CorporationBuilt on Sun_Sep_30_21:09:22_CDT_2018Cuda compilation tools, release 10.0, V10.0.166root@jetson-desktop:/# 2.2核对opencv 12root@jetson-desktop:/# pkg-config opencv --modversion3.3.1 显示opencv当前版本是3.3.12.3核对cuDNN12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970root@jetson-desktop:/# cd /usr/src/cudnn_samples_v7/mnistCUDNN/root@jetson-desktop:/usr/src/cudnn_samples_v7/mnistCUDNN# make/usr/local/cuda/bin/nvcc -ccbin g++ -I/usr/local/cuda/include -IFreeImage/include -m64 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_53,code=sm_53 -gencode arch=compute_53,code=compute_53 -o fp16_dev.o -c fp16_dev.cug++ -I/usr/local/cuda/include -IFreeImage/include -o fp16_emu.o -c fp16_emu.cppg++ -I/usr/local/cuda/include -IFreeImage/include -o mnistCUDNN.o -c mnistCUDNN.cpp/usr/local/cuda/bin/nvcc -ccbin g++ -m64 -gencode arch=compute_30,code=sm_30 -gencode arch=compute_35,code=sm_35 -gencode arch=compute_50,code=sm_50 -gencode arch=compute_53,code=sm_53 -gencode arch=compute_53,code=compute_53 -o mnistCUDNN fp16_dev.o fp16_emu.o mnistCUDNN.o -I/usr/local/cuda/include -IFreeImage/include -LFreeImage/lib/linux/aarch64 -LFreeImage/lib/linux -lcudart -lcublas -lcudnn -lfreeimage -lstdc++ -lmFreeImage/lib/linux/aarch64/libfreeimage.a(strenc.o): In function `StrIOEncInit&apos;:strenc.c:(.text+0x1294): warning: the use of `tmpnam&apos; is dangerous, better use `mkstemp&apos;执行sampleroot@jetson-desktop:/usr/src/cudnn_samples_v7/mnistCUDNN# chmod a+x mnistCUDNNroot@jetson-desktop:/usr/src/cudnn_samples_v7/mnistCUDNN# ./mnistCUDNN cudnnGetVersion() : 7301 , CUDNN_VERSION from cudnn.h : 7301 (7.3.1)Host compiler version : GCC 7.3.0There are 1 CUDA capable devices on your machine :device 0 : sms 1 Capabilities 5.3, SmClock 921.6 Mhz, MemSize (Mb) 3964, MemClock 12.8 Mhz, Ecc=0, boardGroupID=0Using device 0Testing single precisionLoading image data/one_28x28.pgmPerforming forward propagation ...Testing cudnnGetConvolutionForwardAlgorithm ...Fastest algorithm is Algo 1Testing cudnnFindConvolutionForwardAlgorithm ...^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.341979 time requiring 3464 memory^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.395625 time requiring 0 memory^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 5.210573 time requiring 207360 memory^^^^ CUDNN_STATUS_SUCCESS for Algo 7: 5.213230 time requiring 2057744 memory^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 14.978802 time requiring 57600 memoryResulting weights from Softmax:0.0000000 0.9999399 0.0000000 0.0000000 0.0000561 0.0000000 0.0000012 0.0000017 0.0000010 0.0000000 Loading image data/three_28x28.pgmPerforming forward propagation ...Resulting weights from Softmax:0.0000000 0.0000000 0.0000000 0.9999288 0.0000000 0.0000711 0.0000000 0.0000000 0.0000000 0.0000000 Loading image data/five_28x28.pgmPerforming forward propagation ...Resulting weights from Softmax:0.0000000 0.0000008 0.0000000 0.0000002 0.0000000 0.9999820 0.0000154 0.0000000 0.0000012 0.0000006 Result of classification: 1 3 5Test passed!Testing half precision (math in single precision)Loading image data/one_28x28.pgmPerforming forward propagation ...Testing cudnnGetConvolutionForwardAlgorithm ...Fastest algorithm is Algo 1Testing cudnnFindConvolutionForwardAlgorithm ...^^^^ CUDNN_STATUS_SUCCESS for Algo 0: 0.135000 time requiring 0 memory^^^^ CUDNN_STATUS_SUCCESS for Algo 1: 0.170885 time requiring 3464 memory^^^^ CUDNN_STATUS_SUCCESS for Algo 2: 0.282708 time requiring 28800 memory^^^^ CUDNN_STATUS_SUCCESS for Algo 4: 1.206094 time requiring 207360 memory^^^^ CUDNN_STATUS_SUCCESS for Algo 5: 5.214895 time requiring 203008 memoryResulting weights from Softmax:0.0000001 1.0000000 0.0000001 0.0000000 0.0000563 0.0000001 0.0000012 0.0000017 0.0000010 0.0000001 Loading image data/three_28x28.pgmPerforming forward propagation ...Resulting weights from Softmax:0.0000000 0.0000000 0.0000000 1.0000000 0.0000000 0.0000714 0.0000000 0.0000000 0.0000000 0.0000000 Loading image data/five_28x28.pgmPerforming forward propagation ...Resulting weights from Softmax:0.0000000 0.0000008 0.0000000 0.0000002 0.0000000 1.0000000 0.0000154 0.0000000 0.0000012 0.0000006 Result of classification: 1 3 5Test passed! 测试通过；2.4核对python1234root@jetson-desktop:/# python3Python 3.6.7 (default, Oct 22 2018, 11:32:17)[GCC 8.2.0] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information. 默认已经安装python2.7 和python3.6.7版本3、增加python相关内容3.1安装pip31234567891011121314151617181920root@jetson-desktop:/# apt-get install python3-pip正在读取软件包列表... 完成正在分析软件包的依赖关系树 root@jetson-desktop:/# pip3 -Vpip 9.0.1 from /usr/lib/python3/dist-packages (python 3.6)升级下版本到19.1;root@jetson-desktop:~# python3 -m pip install --upgrade pipCollecting pip Downloading https://files.pythonhosted.org/packages/f9/fb/863012b13912709c13cf5cfdbfb304fa6c727659d6290438e1a88df9d848/pip-19.1-py2.py3-none-any.whl (1.4MB) 100% |████████████████████████████████| 1.4MB 279kB/s Installing collected packages: pip Found existing installation: pip 9.0.1 Not uninstalling pip at /usr/lib/python3/dist-packages, outside environment /usrSuccessfully installed pip-19.1root@jetson-desktop:~# pip3 -Vpip 19.1 from /usr/local/lib/python3.6/dist-packages/pip (python 3.6) 3.2安装python-OpenCV123456789101112131415161718192021222324252627282930313233root@jetson-desktop:/# sudo apt-get install python3-opencv正在读取软件包列表... 完成正在分析软件包的依赖关系树 正在读取状态信息... 完成 下列软件包是自动安装的并且现在不需要了： apt-clone archdetect-deb busybox-static cryptsetup-bin dpkg-repack gir1.2-timezonemap-1.0 gir1.2-xkl-1.0 grub-common kde-window-manager kinit kio kpackagetool5 kwayland-data kwin-common kwin-data kwin-x11 libdebian-installer4 libkdecorations2-5v5 libkdecorations2private5v5 libkf5activities5 libkf5attica5 libkf5completion-data libkf5completion5 libkf5declarative-data libkf5declarative5 libkf5doctools5 libkf5globalaccel-data libkf5globalaccel5 libkf5globalaccelprivate5 libkf5idletime5 libkf5jobwidgets-data libkf5jobwidgets5 libkf5kcmutils-data libkf5kcmutils5 libkf5kiocore5 libkf5kiontlm5 libkf5kiowidgets5 libkf5newstuff-data libkf5newstuff5 libkf5newstuffcore5 libkf5package-data libkf5package5 libkf5plasma5 libkf5quickaddons5 libkf5solid5 libkf5solid5-data libkf5sonnet5-data libkf5sonnetcore5 libkf5sonnetui5 libkf5textwidgets-data libkf5textwidgets5 libkf5waylandclient5 libkf5waylandserver5 libkf5xmlgui-bin libkf5xmlgui-data libkf5xmlgui5 libkscreenlocker5 libkwin4-effect-builtins1 libkwineffects11 libkwinglutils11 libkwinxrenderutils11 libqgsttools-p1 libqt5designer5 libqt5help5 libqt5multimedia5 libqt5multimedia5-plugins libqt5multimediaquick-p5 libqt5multimediawidgets5 libqt5opengl5 libqt5positioning5 libqt5printsupport5 libqt5qml5 libqt5quick5 libqt5quickwidgets5 libqt5sensors5 libqt5sql5 libqt5test5 libqt5webchannel5 libqt5webkit5 libxcb-composite0 libxcb-cursor0 libxcb-damage0 os-prober python3-dbus.mainloop.pyqt5 python3-icu python3-pam python3-pyqt5 python3-pyqt5.qtsvg python3-pyqt5.qtwebkit python3-sip qml-module-org-kde-kquickcontrolsaddons qml-module-qtmultimedia qml-module-qtquick2 rdate使用&apos;sudo apt autoremove&apos;来卸载它(它们)。将会同时安装下列软件： gdal-data libaec0 libarmadillo8 libarpack2 libcharls1 libdap25 libdapclient6v5 libepsilon1 libfreexl1 libfyba0 libgdal20 libgdcm2.8 libgeos-3.6.2 libgeos-c1v5 libgeotiff2 libgif7 libgl2ps1.4 libhdf4-0-alt libhdf5-100 libhdf5-openmpi-100 libjsoncpp1 libkmlbase1 libkmldom1 libkmlengine1 liblept5 libminizip1 libnetcdf-c++4 libnetcdf13 libodbc1 libogdi3.2 libopencv-calib3d3.2 libopencv-contrib3.2 libopencv-core3.2 libopencv-features2d3.2 libopencv-flann3.2 libopencv-highgui3.2 libopencv-imgcodecs3.2 libopencv-imgproc3.2 libopencv-ml3.2 libopencv-objdetect3.2 libopencv-photo3.2 libopencv-shape3.2 libopencv-stitching3.2 libopencv-superres3.2 libopencv-video3.2 libopencv-videoio3.2 libopencv-videostab3.2 libopencv-viz3.2 libpq5 libproj12 libqhull7 libsocket++1 libspatialite7 libsuperlu5 libsz2 libtcl8.6 libtesseract4 libtk8.6 liburiparser1 libvtk6.3 libxerces-c3.2 odbcinst odbcinst1debian2 proj-bin proj-data python3-numpy建议安装： geotiff-bin gdal-bin libgeotiff-epsg libhdf4-doc libhdf4-alt-dev hdf4-tools libmyodbc odbc-postgresql tdsodbc unixodbc-bin ogdi-bin tcl8.6 tk8.6 mpi-default-bin vtk6-doc vtk6-examples gfortran python-numpy-doc python3-nose python3-numpy-dbg下列【新】软件包将被安装： gdal-data libaec0 libarmadillo8 libarpack2 libcharls1 libdap25 libdapclient6v5 libepsilon1 libfreexl1 libfyba0 libgdal20 libgdcm2.8 libgeos-3.6.2 libgeos-c1v5 libgeotiff2 libgif7 libgl2ps1.4 libhdf4-0-alt libhdf5-100 libhdf5-openmpi-100 libjsoncpp1 libkmlbase1 libkmldom1 libkmlengine1 liblept5 libminizip1 libnetcdf-c++4 libnetcdf13 libodbc1 libogdi3.2 libopencv-calib3d3.2 libopencv-contrib3.2 libopencv-core3.2 libopencv-features2d3.2 libopencv-flann3.2 libopencv-highgui3.2 libopencv-imgcodecs3.2 libopencv-imgproc3.2 libopencv-ml3.2 libopencv-objdetect3.2 libopencv-photo3.2 libopencv-shape3.2 libopencv-stitching3.2 libopencv-superres3.2 libopencv-video3.2 libopencv-videoio3.2 libopencv-videostab3.2 libopencv-viz3.2 libpq5 libproj12 libqhull7 libsocket++1 libspatialite7 libsuperlu5 libsz2 libtcl8.6 libtesseract4 libtk8.6 liburiparser1 libvtk6.3 libxerces-c3.2 odbcinst odbcinst1debian2 proj-bin proj-data python3-numpy python3-opencv升级了 0 个软件包，新安装了 67 个软件包，要卸载 0 个软件包，有 315 个软件包未被升级。需要下载 55.8 MB 的归档。解压缩后会消耗 265 MB 的额外空间。您希望继续执行吗？ [Y/n] y 测试下看看12345678root@jetson-desktop:~# python3Python 3.6.7 (default, Oct 22 2018, 11:32:17) [GCC 8.2.0] on linuxType &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; import cv2&gt;&gt;&gt; print(cv2.__version__)3.2.0&gt;&gt;&gt; 默认3.2版本，和系统本身自带的不统一;python2.7版本自带的opencv12345678910111213root@jetson-desktop:~# pythonPython 2.7.15rc1 (default, Nov 12 2018, 14:31:15) [GCC 7.3.0] on linux2Type &quot;help&quot;, &quot;copyright&quot;, &quot;credits&quot; or &quot;license&quot; for more information.&gt;&gt;&gt; import cv2&gt;&gt;&gt; print(cv2.__version__) File &quot;&lt;stdin&gt;&quot;, line 1 print(cv2.__version__) ^IndentationError: unexpected indent&gt;&gt;&gt; print(cv2.__version__)3.3.1&gt;&gt;&gt; python3能安装的OpenCV的版本太低;稍后再解决;4，更新系统 执行命令1apt-get update &amp;&amp; apt-get upgrade -y 12345678910111213141516171819202122232425262728效果片段如下：下载内容较多，可能时间会很长。升级了 305 个软件包，新安装了 0 个软件包，要卸载 0 个软件包，有 10 个软件包未被升级。需要下载 396 MB/396 MB 的归档。解压缩后会消耗 69.5 MB 的额外空间。命中:13 http://ports.ubuntu.com/ubuntu-ports bionic InRelease 获取:1 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 login arm64 1:4.5-1ubuntu2 [301 kB]命中:14 http://ports.ubuntu.com/ubuntu-ports bionic-updates InRelease 命中:15 http://ports.ubuntu.com/ubuntu-ports bionic-backports InRelease 命中:16 http://ports.ubuntu.com/ubuntu-ports bionic-security InRelease 正在读取软件包列表... 完成 20%] 80.2 kB/s 1小时 22分 13秒 获取:2 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libgomp1 arm64 8.3.0-6ubuntu1~18.04 [69.6 kB] 获取:3 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libitm1 arm64 8.3.0-6ubuntu1~18.04 [24.3 kB] 获取:4 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 gcc-8-base arm64 8.3.0-6ubuntu1~18.04 [18.7 kB] 获取:5 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libgcc1 arm64 1:8.3.0-6ubuntu1~18.04 [34.4 kB] 获取:6 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 liblsan0 arm64 8.3.0-6ubuntu1~18.04 [121 kB] 获取:7 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libtsan0 arm64 8.3.0-6ubuntu1~18.04 [269 kB] 获取:8 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libcc1-0 arm64 8.3.0-6ubuntu1~18.04 [46.4 kB] 获取:9 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libatomic1 arm64 8.3.0-6ubuntu1~18.04 [9,164 B] 获取:10 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libstdc++6 arm64 8.3.0-6ubuntu1~18.04 [372 kB] 获取:11 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libnss-systemd arm64 237-3ubuntu10.21 [90.1 kB] 获取:12 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libudev1 arm64 237-3ubuntu10.21 [45.2 kB] 获取:13 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 udev arm64 237-3ubuntu10.21 [1,050 kB] 获取:14 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libnss-myhostname arm64 237-3ubuntu10.21 [30.2 kB] 获取:15 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libpam-systemd arm64 237-3ubuntu10.21 [92.8 kB] 获取:17 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libsystemd0 arm64 237-3ubuntu10.21 [171 kB] 获取:18 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libpam0g arm64 1.1.8-3.6ubuntu2.18.04.1 [51.1 kB] 获取:16 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 systemd arm64 237-3ubuntu10.21 [2,551 kB] 获取:19 http://ports.ubuntu.com/ubuntu-ports bionic-updates/main arm64 libpam-modules-bin arm64 1.1.8-3.6ubuntu2.18.04.1 [32.7 kB] 默认的更新源国内访问实在太慢了。/etc/apt/sources.list文件1gudit /etc/apt/sources.list 里面的链接全部替换成清华的源123456789101112131415161718deb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main multiverse restricted universedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main multiverse restricted universedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main multiverse restricted universedeb http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main multiverse restricted universedeb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic main multiverse restricted universedeb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-security main multiverse restricted universedeb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-updates main multiverse restricted universedeb-src http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports/ bionic-backports main multiverse restricted universe然后重新执行;获取:84 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/main arm64 Packages [1,024 B] 获取:85 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/main Translation-en [448 B] 获取:86 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/universe arm64 Packages [3,468 B] 获取:87 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/universe Translation-en [1,604 B] 获取:88 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/universe arm64 DEP-11 Metadata [7,156 B] 获取:89 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/universe DEP-11 48x48 Icons [29 B] 获取:90 http://mirrors.tuna.tsinghua.edu.cn/ubuntu-ports bionic-backports/universe DEP-11 64x64 Icons [29 B] 已下载 45.5 MB，耗时 16秒 (2,900 kB/s) 速度超快！5，关闭桌面系统先看下内存12345root@jetson-desktop:~# free total used free shared buff/cache availableMem: 4059712 572136 2529292 19044 958284 3304544Swap: 0 0 0root@jetson-desktop:~# 关闭桌面1234root@jetson-desktop:~# sudo systemctl set-default multi-user.targetRemoved /etc/systemd/system/default.target.Created symlink /etc/systemd/system/default.target → /lib/systemd/system/multi-user.target.root@jetson-desktop:~# reboot 再看内存12345root@jetson-desktop:~# free total used free shared buff/cache availableMem: 4059712 321340 3511972 17616 226400 3573020Swap: 0 0 0root@jetson-desktop:~# 参考链接：https://www.jianshu.com/p/1fac6cdedd0d]]></content>
      <categories>
        <category>工具</category>
        <category>嵌入式</category>
        <category>nvidia</category>
      </categories>
      <tags>
        <tag>jetson nano</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Jetson nano 介绍]]></title>
    <url>%2F2019%2F06%2F10%2FNvidia-Jetson-nano-%E4%BB%8B%E7%BB%8D%2F</url>
    <content type="text"><![CDATA[1、官网介绍https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-nano/ 良心价，只要99美元。各模型跑分。 2、相关参数 跟x1对比功耗超低； 3、软件支持相关内容可以到官网下载https://developer.nvidia.com/embedded/downloads 有些资源估计的科学下载才行。国内微雪作为销售商，已经整理了资料更方便下载，百度云盘下载快很多。http://www.waveshare.net/wiki/Jetson_Nano_Developer_Kit 系统是Ubuntu定制版，有5g多。5、开箱图片 做工精良，良心机。 6、配件及软件准备Jetson nano包装只有板子。6.1.电源小米充电器，5V 2A，电源线；要保证2A。有5V 2Adc口电源线亦可，但是需要设置跳线屏蔽usb供电口。 6.2 TF卡要刷系统到TF卡，最小要求16G。sd卡插在如图：6.3 格式化软件https://www.sdcard.org/downloads/formatter/6.4 烧录软件Nvidia官方推荐使用Etcher 支持各种平台。6.5 显示配件键盘鼠标、hdmi接口显示器等；7、烧录系统通过微雪的百度云分享下载完成后，用sdformater格式化sd卡，然后用ether烧录系统镜像。烧录要12分钟，12g的系统镜像。 8、启动系统 设置完初始信息即可进入系统，跟Ubuntu操作体验一样。 9、启动系统查看工作状态，温度1234567891011121314sudo tegrastatsroot@jetson-desktop:~# sudo tegrastatsRAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [1%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/125RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [1%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35.5C thermal@28.5C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/125RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [0%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35.5C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/111RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [2%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35.5C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/104RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [3%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27C PMIC@100C GPU@29C AO@34.5C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/99RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [0%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@28C PMIC@100C GPU@29C AO@35C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/104RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [2%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@24.5C CPU@28C PMIC@100C GPU@28.5C AO@35C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/101RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [0%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35.5C thermal@28.5C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/104RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [1%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@24.5C CPU@27.5C PMIC@100C GPU@28.5C AO@35C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/101RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [1%@102,1%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35.5C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/104RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [4%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@25C CPU@27.5C PMIC@100C GPU@29C AO@35C thermal@28.25C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 125/105RAM 724/3965MB (lfb 81x4MB) IRAM 0/252kB(lfb 252kB) CPU [1%@102,0%@102,0%@102,0%@102] EMC_FREQ 4%@204 GR3D_FREQ 0%@153 APE 25 PLL@24.5C CPU@27C PMIC@100C GPU@28.5C AO@35C thermal@28C POM_5V_IN 877/877 POM_5V_GPU 0/0 POM_5V_CPU 83/104 开箱介绍完成。 参考：https://www.jianshu.com/p/c9a7635f315c]]></content>
      <categories>
        <category>工具</category>
        <category>嵌入式</category>
        <category>nvidia</category>
      </categories>
      <tags>
        <tag>jetson nano</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[RuntimeError output with shape [1,x,x] doesn't match the broadcast shape [3, x, x]]]></title>
    <url>%2F2019%2F05%2F15%2Fpytorch%E7%BB%B4%E5%BA%A6%E6%8A%A5%E9%94%99%2F</url>
    <content type="text"><![CDATA[在用pytorch导入图片数据时出现了上述错误，报错程序：123transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])]) 报错原因：这是因图片里面有是灰度图像，只有一个通道，而上面的transforms.Normalize 却对三个通道都归一化了，这肯定会报错，所以只要像下面修改即可：12345transform = transforms.Compose([ transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))# 第一个是均值，第二个是标准差， ]) 参考：https://blog.csdn.net/qq_31829611/article/details/90200694]]></content>
      <categories>
        <category>框架</category>
        <category>pytorch</category>
      </categories>
      <tags>
        <tag>爬坑</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[在Pytorch中正确设计dateset并加载数据集]]></title>
    <url>%2F2019%2F05%2F07%2F%E5%9C%A8Pytorch%E4%B8%AD%E6%AD%A3%E7%A1%AE%E8%AE%BE%E8%AE%A1dateset%E5%B9%B6%E5%8A%A0%E8%BD%BD%E6%95%B0%E6%8D%AE%E9%9B%86%2F</url>
    <content type="text"><![CDATA[一、前言在构建深度学习任务中，最重要的当然是如何设计我们的神经网络。 但在实际的训练过程中，如何正确编写、使用加载数据集的代码同样是不可缺少的一环，在不同的任务中不同数据格式的任务中，加载数据的代码难免会有差别。为了避免重复编写并且避免一些与算法无关的错误，我们有必要讨论一下如何正确加载数据集。 这里只讨论如何加载图像格式的数据集，对于文字或者其他的数据集不进行讨论。 二、正确加载数据集加载数据集是深度学习训练过程中不可缺少的一环。一般地，在平常的时候，我们第一个想到的是将所有需要的数据聚成一堆一堆然后通过构建list去一一读取我们的数据：假如我们编写了上述的图像加载数据集代码，在训练中我们就可以依靠get_training_data()这个函数来得到batch_size个数据，从而进行训练，乍看下去没什么问题，但是一旦我们的数据量超过1000： 将所有的图像数据直接加载到numpy数据中会占用大量的内存 由于需要对数据进行导入，每次训练的时候在数据读取阶段会占用大量的时间 只使用了单线程去读取，读取效率比较低下 拓展性很差，如果需要对数据进行一些预处理，只能采取一些不是特别优雅的做法 既然问题这么多，到底说回来，我们应该如何正确地加载数据集呢？ 本文将会介绍如何根据Pytorch官方提供的数据加载模板，去编写自己的加载数据集类，从而实现高效稳定地加载我们的数据集。(Pytorch官方教程介绍) 三、Dataset类Dataset类是Pytorch中图像数据集中最为重要的一个类，也是Pytorch中所有数据集加载类中应该继承的父类。其中父类中的两个私有成员函数必须被重载，否则将会触发错误提示：12def getitem(self, index):def len(self): 其中 __len__ 应该返回数据集的大小，而__getitem__应该编写支持数据集索引的函数，例如通过dataset [i]可以得到数据集中的第 i+1个数据。 上面所示的这个类，其实也就是起到了封装我们加载函数的作用(对象处理起来更加方便明朗么)，在继承了这个Dataset类之后，我们需要实现的核心功能便是 __getitem__() 函数， __getitem__() 是Python中类的默认成员函数，我们通过实现这个成员函数实现可以通过索引来返回图像数据的功能。 那么怎么得到图像从而去返回呢？当然不会直接将图像数据加载到内存中，相反我们只需要得到图像的地址就足够了，然后在调用的时候通过不同的读取方式读取即可。 关于读取方式：https://oldpan.me/archives/pytorch-transforms-opencv-scikit-image 定义自己的数据集类那么我们开始定义一个自己的数据集类吧。 首先继承上面的dataset 类。然后在__init__() 方法中得到图像的路径，然后将图像路径组成一个数组，这样在__getitim__() 中就可以直接读取：1234567891011121314151617181920# 假设下面这个类是读取船只的数据类class ShipDataset(Dataset): """ root：图像存放地址根路径 augment：是否需要图像增强 """ def __init__(self, root, augment=None): # 这个list存放所有图像的地址 self.image_files = np.array([x.path for x in os.scandir(root) if x.name.endswith(".jpg") or x.name.endswith(".png") or x.name.endswith(".JPG")] self.augment = augment # 是否需要图像增强 def __getitem__(self, index): # 读取图像数据并返回 # 这里的open_image是读取图像函数，可以用PIL、opencv等库进行读取 return open_image(self.image_files[index]) def __len__(self): # 返回图像的数量 return len(self.image_files) 如果我们需要在读取数据的同时对图像进行增强的话，可以在 __getitem__(self, index)函数中设置图像增强的代码，例如：123456789def __getitem__(self, index): if self.augment: image = open_image(self.image_files[index]) iamge = self.augment(iamge) # 这里对图像进行了增强 return image else: # 如果不进行增强，直接读取图像数据并返回 # 这里的open_image是读取图像函数，可以用PIL、opencv等库进行读取 return open_image(self.image_files[index]) 当然，图像增强的方法可以使用Pytorch内置的图像增强方式，也可以使用自定义或者其他的图像增强库。这个很灵活，当然要记住一点，在Pytorch中得到的图像必须是 tensor，也就是说我们还需要再修改一下__getitem__(self, index)：123456789def __getitem__(self, index): if self.augment: image = open_image(self.image_files[index]) iamge = self.augment(iamge) # 这里对图像进行了增强 return to_tensor(image) # 将读取到的图像变成tensor再传出 else: # 如果不进行增强，直接读取图像数据并返回 # 这里的open_image是读取图像函数，可以用PIL、opencv等库进行读取 return to_tensor(open_image(self.image_files[index])) 这样，一个基本的数据类就设计好了。 DataLoader类之前所说的 Dataset类是读入数据集数据并且对读入的数据进行了索引。但是光有这个功能是不够用的，在实际的加载数据集的过程中，我们的数据量往往都很大，对此我们还需要一下几个功能： 可以分批次读取：batch-size 可以对数据进行随机读取，可以对数据进行洗牌操作(shuffling)，打乱数据集内数据分布的顺序 可以并行加载数据(利用多核处理器加快载入数据的效率) 这时候就需要 Dataloader类了， Dataloader这个类并不需要我们自己设计代码，我们只需要利用 DataLoader类读取我们设计好的ShipDataset即可：1234# 利用之前创建好的ShipDataset类去创建数据对象ship_train_dataset = ShipDataset(data_path, augment=transform)# 利用dataloader读取我们的数据对象，并设定batch-size和工作现场ship_train_loader = DataLoader(ship_train_dataset, batch_size=16, num_workers=4, shuffle=False, **kwargs) 这时候通过 ship_train_loader返回的数据就是按照batch-size来返回特定数量的训练数据的tensor，而且此时利用了多线程，读取数据的速度相比单线程快很多。 我们这样读取:123456for image in train_loader: image = image.to(device) # 将tensor数据移动到device当中 optimizer.zero_grad() output = model(image) # model模型处理(n,c,h,w)格式的数据，n为batch-size ... 读取数据的基本模式就是这样，当然在实际中不可能这么简单，我们除了图像数据可能还有json、csv等文件需要我们去读取配合图像完成任务。但是原理基本都是一样的，具体复杂点的例子可以查看官方的例程介绍，这里就不赘述了。 创建自己的数据集除了设计读取数据集的代码，我们实际的图像数据应该怎么去放置呢？ 一般来说，我们自己制作的数据集一般包含三个部分：train、val和test，我们一般放在三个文件夹中，然后利用代码读取。这样是最舒服最方便的了。 但是因为某些原因，我们得到的数据集却不是这样放好的，比如只有一个文件夹，所有文件都放里头了。或者好几个trian的文件夹需要我们去合并。 当然，如果数据集很小的话(例如小于1000个)，那就无所谓了，直接打开文件夹移动就行，但是如果数据为10W以上级别。直接打开文件夹移动文件那电脑会直接卡死(内存32G，6核处理器依旧卡顿)。那么怎么去整体我们的数据，让代码可以顺利训练数据放去训练？ 这里有两种方式。 1、自己写脚本移动这些文件这里以Linux为例，linux下为.sh脚本文件，window则为bat文件。 将下面的脚本代码保存为 mm.sh(随便起的)，自己修改 path/from/和 path/to/的地址，tail后面为移动文件的数量。1234for file in $(ls path/from/ -p | grep -v / | tail -100)domv $file path/to/done 如果移动过程中遇到下面的问题，试着改编权限再来一次。1mv: cannot stat &apos;03c5d57c0.jpg&apos;: No such file or directory 2、编写代码灵活读取train、val、以及test文件夹中的数据之前所说的读取方式ShipDataset类仅仅支持一个文件夹的读取，但是我们得到的只是一个文件夹里面包含了我们采集的数据，但是这些数据有比较多(比如50G)，也不好进行移动分成三份(训练集、验证集和测试集)，这时我们需要自己设计编写代码去实现这些功能。 至于如何去编写，大家可以阅读fastai的源代码去理解一下基本思路(很好的思路，可以好好借鉴下)，fastai是一个包装了Pytorch的快速深度学习开发库：https://oldpan.me/archives/fastai-1-0-quick-study 本文转自：https://oldpan.me/archives/how-to-load-dataset-in-correctly-pytorch]]></content>
      <categories>
        <category>框架</category>
        <category>pytorch</category>
        <category>数据加载</category>
      </categories>
      <tags>
        <tag>加载数据集</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决向github提交代码不用输入帐号密码]]></title>
    <url>%2F2019%2F05%2F04%2F%E8%A7%A3%E5%86%B3%E5%90%91github%E6%8F%90%E4%BA%A4%E4%BB%A3%E7%A0%81%E4%B8%8D%E7%94%A8%E8%BE%93%E5%85%A5%E5%B8%90%E5%8F%B7%E5%AF%86%E7%A0%81%2F</url>
    <content type="text"><![CDATA[方案一： 在你的用户目录下新建一个文本文件.git-credentials123456Windows：C:/Users/usernameMac OS X： /Users/usernameLinux： /home/username#注意：鼠标右键新建文件重复命名是成功不了的，需要借助Sublime等IDE工具来创建文件。 .git-credentials在文件中输入以下内容：123https:&#123;username&#125;:&#123;password&#125;@github.com#&#123;username&#125;和&#123;password&#125;是你的github的账号和密码 修改git配置执行命令：1git config --global credential.helper store 上述命令会在.gitconfig文件(.gitconfig与.git-credentials在同目录下)末尾添加如下配置:12345[user] name = alice email = alice@aol.com[credential] helper = store 经过上述三步配置之后, 你push代码到github时, 便无需再输入用户名密码了 方案二： 在命令行输入命令:1git config --global credential.helper store 这一步会在用户目录下的.gitconfig文件最后添加：12[credential] helper = store push 代码 push你的代码 (git push), 这时会让你输入用户名和密码, 这一步输入的用户名密码会被记住, 下次再push代码时就不用输入用户名密码!这一步会在用户目录下生成文件.git-credential记录用户名密码的信息。 总结： 方案一与方案二都是创建.git-credential文件并写入用户信息，一个是手动创建，一个命令创建。]]></content>
      <categories>
        <category>工具</category>
        <category>日常工具</category>
        <category>github</category>
      </categories>
      <tags>
        <tag>github</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[KDD CUP99数据集预处理]]></title>
    <url>%2F2019%2F05%2F04%2FKDD-CUP99%E6%95%B0%E6%8D%AE%E9%9B%86%E9%A2%84%E5%A4%84%E7%90%86%2F</url>
    <content type="text"><![CDATA[KDD CUP99数据集预处理 1、数据集下载：http://kdd.ics.uci.edu/databases/kddcup99/kddcup99.html 2、KDDCup99网络入侵检测数据集介绍： https://blog.csdn.net/com_stu_zhang/article/details/6987632 https://www.cnblogs.com/gongyanc/p/6703532.html 3、Weka进阶——基于KDD99数据集的入侵检测分析： https://blog.csdn.net/jbfsdzpp/article/details/44099849 4、符号型特征数值化 采用one-hot方法进行数值化：https://blog.csdn.net/qq_28617019/article/details/79717184 5、KDD CUP99数据集预处理 （1）字符型特征转换为数值型特征（即符号型特征数值化）Python3对KDD CUP99数据集预处理代码实现（仅实现字符型特征转为数值型特征） kdd99数据集预处理 将kdd99符号型数据转化为数值型数据 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104# coding:utf-8import numpy as npimport pandas as pdimport csvimport timeglobal label_list # label_list为全局变量list_big=[] #储存大数据# 定义kdd99数据预处理函数def preHandel_data (): source_file = 'kddcup.data_10_percent_corrected' handled_file = 'kddcup.data_10_percent_corrected.csv' data_file = open (handled_file, 'w', newline='') # python3.x中添加newline=''这一参数使写入的文件没有多余的空行 with open (source_file, 'r') as data_source: csv_reader = csv.reader (data_source) csv_writer = csv.writer (data_file) count = 0 # 记录数据的行数，初始化为0 for row in csv_reader: temp_line = np.array (row) # 将每行数据存入temp_line数组里 list_big.append (int(temp_line [4])) list_big.append (int(temp_line [5])) temp_line [1] = handleProtocol (row) # 将源文件行中3种协议类型转换成数字标识 temp_line [2] = handleService (row) # 将源文件行中70种网络服务类型转换成数字标识 temp_line [3] = handleFlag (row) # 将源文件行中11种网络连接状态转换成数字标识 temp_line [4] = handlenorm (int(row[4])) temp_line [5] = handlenorm (int(row[5])) temp_line [41] = handleLabel (row) # 将源文件行中23种攻击类型转换成数字标识 csv_writer.writerow (temp_line) count += 1 # 输出每行数据中所修改后的状态 #print (count, 'status:', temp_line [1], temp_line [2], temp_line [3], temp_line [41]) data_file.close ()# 将相应的非数字类型转换为数字标识即符号型数据转化为数值型数据def find_index (x, y): return [i for i in range (len (y)) if y [i] == x]# 定义将源文件行中3种协议类型转换成数字标识的函数def handleProtocol (input): protocol_list = ['tcp', 'udp', 'icmp'] if input [1] in protocol_list: return find_index (input [1], protocol_list) [0]# 定义将源文件行中70种网络服务类型转换成数字标识的函数def handleService (input): service_list = ['aol', 'auth', 'bgp', 'courier', 'csnet_ns', 'ctf', 'daytime', 'discard', 'domain', 'domain_u', 'echo', 'eco_i', 'ecr_i', 'efs', 'exec', 'finger', 'ftp', 'ftp_data', 'gopher', 'harvest', 'hostnames', 'http', 'http_2784', 'http_443', 'http_8001', 'imap4', 'IRC', 'iso_tsap', 'klogin', 'kshell', 'ldap', 'link', 'login', 'mtp', 'name', 'netbios_dgm', 'netbios_ns', 'netbios_ssn', 'netstat', 'nnsp', 'nntp', 'ntp_u', 'other', 'pm_dump', 'pop_2', 'pop_3', 'printer', 'private', 'red_i', 'remote_job', 'rje', 'shell', 'smtp', 'sql_net', 'ssh', 'sunrpc', 'supdup', 'systat', 'telnet', 'tftp_u', 'tim_i', 'time', 'urh_i', 'urp_i', 'uucp', 'uucp_path', 'vmnet', 'whois', 'X11', 'Z39_50'] if input [2] in service_list: return find_index (input [2], service_list) [0]# 定义将源文件行中11种网络连接状态转换成数字标识的函数def handleFlag (input): flag_list = ['OTH', 'REJ', 'RSTO', 'RSTOS0', 'RSTR', 'S0', 'S1', 'S2', 'S3', 'SF', 'SH'] if input [3] in flag_list: return find_index (input [3], flag_list) [0]# 定义将源文件行中攻击类型转换成数字标识的函数(训练集中共出现了22个攻击类型，而剩下的17种只在测试集中出现)def handleLabel (input): # label_list=['normal.', 'buffer_overflow.', 'loadmodule.', 'perl.', 'neptune.', 'smurf.', # 'guess_passwd.', 'pod.', 'teardrop.', 'portsweep.', 'ipsweep.', 'land.', 'ftp_write.', # 'back.', 'imap.', 'satan.', 'phf.', 'nmap.', 'multihop.', 'warezmaster.', 'warezclient.', # 'spy.', 'rootkit.'] global label_list # 在函数内部使用全局变量并修改它 if input [41] in label_list: return find_index (input [41], label_list) [0] else: label_list.append (input [41]) return find_index (input [41], label_list) [0]#定义将源文件行中从源主机到目标主机的数据的字节数归一化到（0,255)def handlenorm(input): max_data=max(list_big) min_data=min(list_big) results=255/max_data*(input-min_data) return resultsif __name__ == '__main__': start_time = time.clock () global label_list # 声明一个全局变量的列表并初始化为空 label_list = [] preHandel_data () end_time = time.clock () print ("Running time:", (end_time - start_time)) # 输出程序运行时间 该代码仅对10%的训练集（kddcup.data_10_percent_corrected）进行处理 引用：https://blog.csdn.net/asialee_bird/article/details/80491256 6、KDD CUP99数据集按行转换成图片 将其转换为图片12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061import csvimport numpy as npdata =np.random.random((4,4,3))data=[]def Toimage(): source_file = 'kddcup.data_10_percent_corrected.csv' with open (source_file, 'r') as data_source: csv_reader = csv.reader (data_source) count = 0 记录数据的行数，初始化为0 for row in csv_reader: new_row=[float(x) for x in row] image_data=np.array(new_row) data = np.array (image_data).reshape (6, 7) imageio.imwrite ('image/&#123;&#125;.jpg'.format(count), data) count+=1'''#Toimage()#print(np.array(data))## new_list = [i for i in range(9)]# data=np.array(data).reshape(4,4,3)# print(data)from multiprocessing import Processfrom multiprocessing import Managerimport cv2def Toimage (): source_file = 'kddcup.data_10_percent_corrected.csv' with open (source_file, 'r') as data_source: csv_reader = csv.reader (data_source) count = 0 # 记录数据的行数，初始化为0 for row in csv_reader: new_row = [float (x) for x in row] image_data = np.array (new_row) data = np.array (image_data).reshape (6, 7) cv2.imwrite ('image/&#123;&#125;.jpg'.format (count), data) cv2.waitKey () cv2.destroyAllWindows () count += 1if __name__ == '__main__': # 进程间默认不能共用内存 manager = Manager () dic = manager.dict () # 这是一个特殊的字典 p = Process (target=Toimage, args=(dic)) p.start () p.join () print ('end')]]></content>
      <tags>
        <tag>kdd99</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一些系统软件]]></title>
    <url>%2F2019%2F03%2F27%2F%E4%B8%80%E4%BA%9B%E7%B3%BB%E7%BB%9F%E7%9A%84%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[下载链接在最后 系统类：系统激活：（针对2015长期维护版 win10）在联网的前提下打开命令行：‘’’slmgr /ipk WNMTR-4C88C-JK8YV-HQ7T2-76DF9slmgr /skms zh.us.toslmgr /ato直接运行这个命令就行了 ‘’’ office2016 破解版(三合一：直接下载 Microsoft Office 2016 X64 20170323后安装（请勿开启微软自带和其他杀毒软件） 内存测试： MemTest_ProMemTest验证RAM的可靠性。正确运行的计算机应该能够以100％的准确度将数据存储在内存中。### 硬盘测试（固态）：获取详细信息（如通电次数，硬盘健康状态）CrystalDiskInfo 测试速度： CrystalDiskMark 任务栏透明美化（win最底下）：StartIsBack v2.8.2_P（破解版） 雷克沙固态检测（专用）Lexar_SSD_Dash uefi启动管理器（破解版）：EasyUEFI 如果是mbr 启动 用Easybcd——-# 软件类：### 冰点文库： 可以下载百度文库等各大文库文章。（采用截图方式生成pdf文件）### 蓝色鼠标： 解压后将文件打开AutoSetup.inf右键安装 Git （github）：Git-2.20.1-64-bit vpn （谷歌浏览器 火狐浏览器）：商店可以直接下，速度只适合浏览网页 SetupVPN VS 精简版（快速安装）Visual Studio 2017 Enterprise 会在最后报错 点击忽略,完成后打开软件帮助选项激活（激活码百度输入Visual Studio 2017 激活码） windows获取Linux命令插件： MinGW * 将文件夹路径添加进环境变量（path）# win10 小坑：### 优化清理软件：Dism++ (几kb，但是什么都能做） 有些电脑显卡驱动老是安装失败，只能用官方驱动显卡驱动卸载神器（ddu）* 卸载完后，就可以安装最新驱动。性能最大化### 微软商店连不上网打开设置–&gt;选择网络和internet–&gt;代理–&gt;所有开启的全部关闭 换硬盘卡死 进不去系统强制关机重启（重复几次） –》选择启动–》安全启动–》只要进去就可以重启！（来源于驱动问题） 否则进pe引导系统或者重装 远程控制Teamvier可以实现远程辅助，比qq好用 强大 下载地址（百度云） 下载地址：链接：https://pan.yangxin.com/s/10Xbd6X8JbimC8dnxdKANVw 提取码：vdrv]]></content>
      <categories>
        <category>工具</category>
        <category>日常工具</category>
        <category>系统软件</category>
      </categories>
      <tags>
        <tag>系统软件</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回顾-instaGAN]]></title>
    <url>%2F2019%2F02%2F21%2Finstagan-pytorch1.1%E5%AE%9E%E7%8E%B0%2F</url>
    <content type="text"><![CDATA[1.InstaGAN简介：InstaGAN这种 GAN 结合了实例信息（如目标分割掩码），提高了多实例转换的能力。在保持实例置换不变性的同时，该 GAN 对图像和相应的实例属性集进行转换。为此，研究人员引入了一个语境保留损失函数，鼓励网络学习目标实例之外的恒等函数。此外，他们还提出了一种序列 mini-batch 推理/训练技术，这种技术借助有限的 GPU 内存处理多个实例，增强了该网络在多实例任务中的泛化能力。 是Cycle GAN的改进版本。虽然Cycle GAN替换不能改变形状，但它可以改变形状。但老实说，这种印象是准确度和分辨率仍然很低 2. instaGANGAN网络结构:如图: 首先看图（左边） 这是全局图，可以看到依然是cycleGAN模式，最大特点就是原图与mask进行合并（cat）输入和输出*（右边） 大体上我们可以把G看做，d看做 看到原图与mask合并后，还加了一个add模块 ，即为了获得属性，我们对所有集合元素的不变性求和，然后将其与等方差的恒等映射连接起来。 中间f，表示用通过f函数提取特征。3.instaGAN损失函数其实就是把加一个约束，保证masks之外的信息保持不变（下式中的L_{ctx}项）。整个loss如下： 对比下cycleGAN的损失函数 然后在分开看下instaGAN的loss： 解释下： LSGAN损失函数时最基本的GAN网络损失函数 cycle-consistency loss cyclegan网络的损失函数，为保证图像翻译过程中映射关系一一对应 identity mapping loss 也是内容损失函数保证图像翻译前后内容不变 context preserving loss ，也是保证在实例翻译时图像的背景内容不发生变化。 4 创新点1、提出了一个多属性图像翻译的网络结构，且属性之间的顺序是任意的2、提出了context preserving loss来鼓励网络去学习一个目标示例的之外的一个恒等映射3、提出一种sequential mini-batch的方法顺序生成mini-batchs的属性，而不是在整个数据集上做一次。 * sequential mini-batch其实就是渐进迭代的方法把mask分开，一个个生成就好了。但是这里要注意，通常小的mask放到后面效果会更好。因为迭代进行的话，每次生成的图片都会被改变，后面如果是大mask，很容易把前面生成的小mask跟淹没掉。 所以，使用这种办法，一定程度上破坏了object mask之间的时序不变性，如果GPU显存足够，就不要用这种方法了。]]></content>
      <categories>
        <category>框架</category>
        <category>pytorch</category>
        <category>GAN</category>
      </categories>
      <tags>
        <tag>instaGAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pytorch expected backend CPU and dtype Double but got backend CPU and dtype Float]]></title>
    <url>%2F2019%2F01%2F25%2Fpytorch%E6%90%AD%E5%BB%BA%E7%BD%91%E7%BB%9C%E6%B5%8B%E8%AF%95%E6%97%B6%E6%8A%A5%E9%94%99RuntimeError-expected-backend-CPU-and-dtype-Double-but-got-backend-CPU-and-dtype-Float%2F</url>
    <content type="text"><![CDATA[用pytorch搭建网络测试时，代码报错如下：RuntimeError: expected backend CPU and dtype Double but got backend CPU and dtype Float 报错在transform.ToTensor ()： 如图： 报类型错误，默认x类型为float64，加上那句运行正确。 尝试过其他方法： 1：如A fix would be to call .double() on your model (or .float() on the input)https://github.com/pytorch/pytorch/issues/2138 2： from_numpy().float() 3:astype(‘float’) 4:您的输入和目标张量是DoubleTensors，但您的模型参数是FloatTensors。您必须转换输入或参数。 要将输入转换为float（推荐）： inputs, labels = datainputs = inputs.float()labels = labels.float()inputs, labels = Variable(inputs), Variable(labels)要将模型转换为double： model = ColorizerNet()model.double()我建议使用浮动而不是双打。它是PyTorch中的默认张量类型。在GPU上，浮点计算比双重计算快得多。https://discuss.pytorch.org/t/problems-with-weight-array-of-floattensor-type-in-loss-function/381]]></content>
      <tags>
        <tag>爬坑</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[pytorch expected backend CPU and dtype Double but got backend CPU and dtype Float]]></title>
    <url>%2F2019%2F01%2F25%2Fpytorch%20RuntimeError-expected-backend-CPU-and-dtype-Double-but-got-backend-CPU-and-dtype-Float%2F</url>
    <content type="text"><![CDATA[用pytorch搭建网络测试时，代码报错如下：RuntimeError: expected backend CPU and dtype Double but got backend CPU and dtype Float 报错在transform.ToTensor ()： 如图： 报类型错误，默认x类型为float64，加上那句运行正确。 尝试过其他方法： 1：如A fix would be to call .double() on your model (or .float() on the input)https://github.com/pytorch/pytorch/issues/2138 2： from_numpy().float() 3:astype(‘float’) 4:您的输入和目标张量是DoubleTensors，但您的模型参数是FloatTensors。您必须转换输入或参数。 要将输入转换为float（推荐）： inputs, labels = datainputs = inputs.float()labels = labels.float()inputs, labels = Variable(inputs), Variable(labels)要将模型转换为double： model = ColorizerNet()model.double()我建议使用浮动而不是双打。它是PyTorch中的默认张量类型。在GPU上，浮点计算比双重计算快得多。https://discuss.pytorch.org/t/problems-with-weight-array-of-floattensor-type-in-loss-function/381]]></content>
      <tags>
        <tag>爬坑</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[将数据归一化到任意区间范围的方法]]></title>
    <url>%2F2019%2F01%2F15%2F%E5%B0%86%E6%95%B0%E6%8D%AE%E5%BD%92%E4%B8%80%E5%8C%96%E5%88%B0%E4%BB%BB%E6%84%8F%E5%8C%BA%E9%97%B4%E8%8C%83%E5%9B%B4%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[一般常见的数据归一化，是归一化到0~1，或者-1~1的区间，但在一些特殊场合下，我们需要根据实际情况归一化到其他任意区间，方法是： 将数据归一化到[a,b]区间范围的方法： （1）首先找到样本数据Y的最小值Min及最大值Max（2）计算系数为：k=（b-a)/(Max-Min)（3）得到归一化到[a,b]区间的数据：newY=a+k(Y-Min)]]></content>
      <categories>
        <category>学习</category>
        <category>算法</category>
        <category>数据处理</category>
      </categories>
      <tags>
        <tag>归一化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LOL-换肤快捷工具]]></title>
    <url>%2F2019%2F01%2F02%2FLOL-%E6%8D%A2%E8%82%A4%E5%BF%AB%E6%8D%B7%E5%B7%A5%E5%85%B7%2F</url>
    <content type="text"><![CDATA[第一步:打开链接: 百度云:https://pan.yangxin.com/s/13YsHOdSH82qGBO4XRh2TFA 选择Setup_sindre.exe 下载 如需改进(新手别点):源码文件:https://pan.yangxin.com/s/15er7GhOfnFoOse7YmK4vzQ 第二步:下载安装(纯净,无二次添加): 第三步:就可以用了 lolsk 使用:打开如图: 登入游戏:(默认每个英雄都有皮肤) 切忌不能关掉,不然进去就失效,窗口缩小即可 切忌不能关掉,不然进去就失效,窗口缩小即可 切忌不能关掉,不然进去就失效,窗口缩小即可 切忌不能关掉,不然进去就失效,窗口缩小即可 如果要自定义皮肤:选好 按右下角蓝色按钮激活]]></content>
      <categories>
        <category>工具</category>
        <category>日常工具</category>
        <category>LOL</category>
      </categories>
      <tags>
        <tag>LOL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回顾-DiscoGAN]]></title>
    <url>%2F2018%2F12%2F28%2F%E5%9B%9E%E9%A1%BE-DiscoGAN%2F</url>
    <content type="text"></content>
      <categories>
        <category>框架</category>
        <category>pytorch</category>
        <category>GAN</category>
      </categories>
      <tags>
        <tag>DiscoGAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回顾-WGAN]]></title>
    <url>%2F2018%2F12%2F27%2F%E5%9B%9E%E9%A1%BE-WGAN%2F</url>
    <content type="text"><![CDATA[1.WGAN 简介:2.WGAN 网络结构:3.WGAN 创新点:4.Pytorch 实现:]]></content>
      <categories>
        <category>框架</category>
        <category>pytorch</category>
        <category>GAN</category>
      </categories>
      <tags>
        <tag>WGAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回顾-BEGAN]]></title>
    <url>%2F2018%2F12%2F26%2F%E5%9B%9E%E9%A1%BE-BEGAN%2F</url>
    <content type="text"></content>
      <categories>
        <category>框架</category>
        <category>pytorch</category>
        <category>GAN</category>
      </categories>
      <tags>
        <tag>BEGAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回顾-pix2pix]]></title>
    <url>%2F2018%2F12%2F25%2F%E5%9B%9E%E9%A1%BE-pix2pix%2F</url>
    <content type="text"><![CDATA[1.Pix2Pix 简介: 1.这是基于CGAN的pix2pix模型! 2.Pix2Pix与一般GAN不同的地方在于，其实现的目标是图像翻译，A-》B，比如，一张场景可以转换为RGB全彩图，也可以转化成素描，也可以转化为灰度图。 顾名思义，Pix2Pix指的是像素对像素的翻译，图像大小保持不变。G网络的输入是A图像，通过G网络生成的图像叫做FakeB，而真实的图像就是RealB。 论文: https://arxiv.org/abs/1611.07004 项目：https://github.com/phillipi/pix2pix 2.Pix2Pix 网络架构: 生成网络: 生成器G使用U-net实现: 从图中可以看出u-net采用跳跃式链接的全卷积结构(有点像resnet的跨层链接) U-net来源于VAE的encoder-decoder:如图;注:U-Net通过卷积和反卷积实现的U形形状的网络结构；输入和输出都是3个维度 判别网络: 判别器D使用马尔科夫性的判别器(PatchGAN)(论文) 简单来说:PatchGAN可以理解为一种风格/纹理损失网络 注:根据kernelsize是1的进行将为，最终实现1个chanel的图像 损失函数: 原始GAN(G不需要x): CGAN(G需要x): 给GAN加个L1或L2,而Pix2pix使用的是L1架构，可以减少模糊程度: 最终G损失: 注:最终的loss是针对一个chanel的图像的每个像素求MSE(均方差loss，fake的label为0，real的label为1)或BCE(二进制交叉熵)。 训练方法: 训练大致过程如上图所示。图片 x 作为此cGAN的条件，需要输入到G和D中。G的输入是{x,z}（其中，x 是需要转换的图片，z 是随机噪声），输出是生成的图片G(x,z)。D则需要分辨出{x,G(x,z)}和{x,y}。 3.Pix2Pix 创新点: 1.一般的方法都是训练CNN去缩小输入跟输出的欧氏距离,论文在GAN的基础上提出一个通用的方法：pix2pix 来解决这一类问题。通过pix2pix来完成成对的图像转换 2.输入为图像而不是随机向量 3.成对输入为图像而不是随机向量 4.Patch判别器来降低计算量提升效果 5.L1损失函数的加入来保证输入和输出之间的一致性。 4. Pytorch实现:]]></content>
      <categories>
        <category>框架</category>
        <category>pytorch</category>
        <category>GAN</category>
      </categories>
      <tags>
        <tag>pix2pix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[The size of tensor a (5) must match the size of tensor b (3) at non-singleton dimension 3]]></title>
    <url>%2F2018%2F12%2F25%2FThe-size-of-tensor-a-(5)-must-match-the-size-of-tensor-b-(3)-at-non-singleton-dimension-3%2F</url>
    <content type="text"><![CDATA[打印所有操作的张量形状，然后您将更好地了解Tensor形状如何随每个操作而变化。之后，可以找出要更改的行以使尺寸匹配。 主要在你的输入尺寸 输出尺寸 模型结构方面考虑 用.size（）排错]]></content>
      <tags>
        <tag>爬坑</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回顾-VAEGAN]]></title>
    <url>%2F2018%2F12%2F24%2F%E5%9B%9E%E9%A1%BE-VAEGAN%2F</url>
    <content type="text"><![CDATA[1.VAEGAN 简介:关于如何解决VAE解码器产生图片模糊问题?作者将VAE作为生成器 与 判别器结合为新GAN,即VAEGAN通过GANs去提升了VAE的图片生成质量. 2.VAEGAN 网络结构:还是先来看图:官方图:网络图:可以看出什么呢? 1.输入一张真实图片(x)-编码器-&gt;正态分布(z)-解码器-&gt;生成图片(~x) 左边就是VAE,VAE希望生成图片与真实图片loss越小越好,但是loss小不见得图片就清晰. 2.为了解决这个问题,就将生成图片(~x) 给判别器,让判别器判断生成图片属于真实,还是属于生成,这样就可以让生成图片与真实图片难以区分,从而提升图片质量 3. VAEGAN创新点: 1.将元素方面的错误替换为特征方面的错误 2.将VAEs和GANs合并为一个无监督生成模型，同时学习编码、生成和比较数据集样本。 3.通过学习相似度度量训练的生成模型比接受过元素误差模拟训练的模型产生更好的图像样本 4.证明了无监督训练可以产生更具有解纠缠因子的潜在图像表示法。 5.在学习的潜空间中应用简单的算法可以生成反映这些属性变化的图像(使用编码器来计算潜在向量)。 4.VAEGAN实现: pytorch1.0 network.py12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576'''跟着图走'''import torch.nn as nn#我们首先建立G (由一个编码器,一个解码器构成)class G(nn.Module): def __init__(self,args): super(G,self).__init__() ngf = args.ngf #ngf 设置为128 卷积一般扩大两倍 参数为4,2,1 self.encoder= nn.Sequential( # 输入一个真实图像3*64*64 nn.Conv2d (3, ngf, 4, 2, 1, bias=False), nn.BatchNorm2d (ngf), nn.LeakyReLU (True), # (ngf) x 32x 32 nn.Conv2d (ngf, ngf * 2, 4, 2, 1, bias=False), nn.BatchNorm2d (ngf * 2), nn.LeakyReLU (True), # (ngf*2) x 16 x 16 nn.Conv2d (ngf * 2, ngf, 4, 2, 1, bias=False), nn.BatchNorm2d (ngf), nn.LeakyReLU (True)) #还原尺寸 self.decoder = nn.Sequential ( nn.ConvTranspose2d(ngf,ngf*2,4,2,1), nn.BatchNorm2d(ngf*2), nn.ReLU(), nn.ConvTranspose2d (ngf*2,ngf,4,2,1), nn.BatchNorm2d (ngf), nn.ReLU (), nn.ConvTranspose2d (ngf, 3, 4, 2, 1), nn.Tanh ()) #3*64*64 #前向传播 def forward(self,x): out=self.encoder(x) out_x=self.decoder(out) #print(out_x.size()) return out_x#建立Dclass D(nn.Module): def __init__(self,args): super(D,self).__init__() ndf = args.ndf # ndf 128 self.D_layer= nn.Sequential( # 输入 1 x 64 x 64, nn.Conv2d (3, ndf, 4, 2, 1, bias=False), nn.BatchNorm2d (ndf), nn.LeakyReLU (True), #输出 (ndf)*32*32 nn.Conv2d(ndf,ndf*2,4,2,1, bias=False), nn.BatchNorm2d (ndf*2), nn.LeakyReLU (True), # 输出 (ndf*2)*16*16 nn.Conv2d (ndf*2, ndf*4, 4, 2, 1, bias=False), nn.BatchNorm2d (ndf*4), nn.LeakyReLU (True), # 输出 (ndf*4)*8*8 nn.Conv2d (ndf*4, ndf*8, 4, 2, 1, bias=False), nn.BatchNorm2d (ndf*8), nn.LeakyReLU (True), # 输出 (ndf*8)*4*4 nn.Conv2d (ndf * 8, 1, 4, 1, 0, bias=False), # 输出 1*1*1 nn.Sigmoid())#告诉D概率 #前向传播 def forward(self,x): out=self.D_layer(x) return out train.py123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397import torchimport torch.nn as nnimport torchvision.datasets as datasetsimport torchvision.transforms as transformsfrom torch.autograd import Variableimport torch.backends.cudnn as cudnn# 工具包import argparse# 载入网络from network import G, D#############参数设置#################命令行设置########parser = argparse.ArgumentParser (description='GANs') # 导入命令行模块# 对关于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明#关于训练参数parser.add_argument ('--batch_size', type=int, default=64, help='训练batch-size大小 (default: 64)')parser.add_argument ('--imageSize', type=int, default=64, help='图片尺寸')parser.add_argument ('--max_epoch', type=int, default=20, help='最大迭代数 (default: 12)')#关于网络参数parser.add_argument ('--lr_g', type=float, default=2e-4, help='生成器学习率 (default: 2e-4)')parser.add_argument ('--lr_d', type=float, default=2e-4, help='判别器学习率 (default: 2e-4)')parser.add_argument ('--ngf', type=int, default=64, help='生成器feature map数')parser.add_argument ('--ndf', type=int, default=64, help='判别器feature map数')parser.add_argument ('--d_every', type=int, default=1, help='每几个batch训练一次判别器')parser.add_argument ('--g_every', type=int, default=4, help='每几个batch训练一次生成器')parser.add_argument ('--nz', type=int, default=3, help='噪声维度')#关于优化器参数parser.add_argument ('--beta1', type=int, default=0.5, help='Adam优化器的beta1参数')#路径parser.add_argument ('--dataset', default='data/', help='数据集路径')parser.add_argument ('--save_data', default='save/', help='保存路径')#可视化parser.add_argument ('--vis', action='store_true', help='使用visdom可视化')parser.add_argument ('--plot_every', type=int, default=1, help='每间隔_batch，visdom画图一次')# 其他parser.add_argument ('--cuda', action='store_true', help='开启cuda训练')parser.add_argument ('--plt', action='store_true', help='开启画图')parser.add_argument ('--test', action='store_true', help='开启测试生成')parser.add_argument ('--save_every', type=int, default=5, help='几个epoch保存一次模型 (default: 2)')parser.add_argument ('--seed', type=int, default=1, help='随机种子 (default: 1)')args = parser.parse_args () # 相当于激活命令#训练过程def train(): ###############判断gpu############# device = torch.device ('cuda') if args.cuda else torch.device ('cpu') ####### 为CPU设置种子用于生成随机数，以使得结果是确定的########## torch.manual_seed (args.seed) if args.cuda: torch.cuda.manual_seed (args.seed) cudnn.benchmark = True #################可视化############### if args.vis: vis = Visualizer ('GANs') ##########数据转换##################### data_transforms = transforms.Compose ([transforms.Scale (args.imageSize), # 通过调整比例调整大小,会报警 transforms.CenterCrop (args.imageSize), # 在中心裁剪给指定大小方形PIL图像 transforms.ToTensor (),# 转换成pytorch 变量tensor transforms.Normalize ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) ###############数据载入################ # train_dataset = datasets.ImageFolder (root=args.dataset, # 数据路径目录 # transform=data_transforms) # 把数据转换成上面约束样子 train_dataset = datasets.CIFAR10(root=args.dataset, train=True, transform=data_transforms, download=False) # test_dataset = datasets.ImageFolder (root=args.dataset, # transform=data_transforms) ##############数据装载############### train_loader = torch.utils.data.DataLoader (dataset=train_dataset, # 装载数据 batch_size=args.batch_size, # 设置批大小 shuffle=True) # 是否随机打乱 # test_loader = torch.utils.data.DataLoader (dataset=test_dataset, # batch_size=args.batch_size, # shuffle=True) #############模型载入################# netG ,netD= G (args),D (args) netG.to (device) netD.to (device) print (netD, netG) ###############损失函数################## criterion = torch.nn.BCELoss ().to (device) optimizerD = torch.optim.Adam (netD.parameters (), lr=args.lr_d,betas=(0.5, 0.999)) # Adam优化器 optimizerG = torch.optim.Adam (netG.parameters (), lr=args.lr_g,betas=(0.5, 0.999)) # Adam优化器 ###############画图参数保存################## G_losses = [] D_losses = [] img_list = [] #############训练过程##################### import tqdm # Tqdm是一个快速，可扩展的Python进度条，可以在Python # 长循环中添加一个进度提示信息，用户只需要封装任意的迭代器 # tqdm (iterator)。 for epoch in range (args.max_epoch): for i, (images, labels) in tqdm.tqdm(enumerate (train_loader)): # 枚举出来 #数据处理 images = images.to (device) # 装箱 images = Variable (images) noises=Variable(torch.randn(images.size(0), args.nz, 1, 1).to(device)) #遍历每张图片,并且根据指定的训练机制训练 if i % args.d_every==0:#满足此条件训练D #D前向传播 optimizerD.zero_grad () #D网络输出 output_r = netD (images).view(-1) #定义真张量 #返回第一个参数为大小 第二参数为值 的张量 true_label = torch.full ((images.size(0),), 1, device=device) #判别真的损失 d_real_loss = criterion(output_r, true_label) #反向传播 d_real_loss.backward() #G网络输出 fake = netG (images) # 根据真生成图 #把假图给d output_f = netD (fake).view(-1) #d假的损失 #print(fake.size(),output_f.size(),output_r.size()) # 返回第一个参数为大小 第二参数为值 的张量 fake_label = torch.full ((images.size (0),), 0, device=device) d_fake_loss= criterion(output_f,fake_label) #D假反向传播 d_fake_loss.backward () # 总损失 D_loss=d_fake_loss+d_real_loss #D更新参数 optimizerD.step () # 度量 D_x = output_r.mean ().item () D_G_z1 = output_f.mean ().item () if i % args.g_every==0:#满足此条件训练G #G前向传播 optimizerG.zero_grad () #G网络输出 fake = netG (images) # 根据噪声生成假图 #把假图给G output_f = netD (fake).view(-1) #G的损失 true_label = torch.full ((images.size (0),), 1, device=device) G_loss = criterion(output_f,true_label) #G反向传播 G_loss.backward () #度量 D_G_z2 = output_f.mean ().item () #D更新参数 optimizerG.step () ########################################### ##########可视化(可选)##################### if args.vis and i % args.plot_every == args.plot_every - 1: fake = netG (noises) vis.images (fake.detach ().cpu ().numpy () [:64] * 0.5 + 0.5, win='fixfake') vis.images (images.data.cpu ().numpy () [:64] * 0.5 + 0.5, win='real') vis.plot ('errord', D_loss.item ()) vis.plot ('errorg', G_loss.item ()) ####################################### ############打印记录################### if i % 1== 0: print ('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f' % (epoch, args.max_epoch, i, len (train_loader), D_loss.item (), G_loss.item (), D_x, D_G_z1, D_G_z2)) ########添加画图参数######## G_losses.append (G_loss.item ()) D_losses.append (D_loss.item ()) with torch.no_grad (): noises = torch.randn (args.batch_size, args.nz, 1, 1).to (device) fake = netG (images).detach ().cpu () import torchvision.utils as vutils img_list.append (vutils.make_grid (fake, padding=2, normalize=True)) ####################################### ############保存模型################### if (epoch + 1) % args.save_every == 0: import torchvision as tv # 保存模型、图片 tv.utils.save_image (fake.data [:64], '%s/%s.png' % (args.save_data, epoch), normalize=True,range=(-1, 1)) torch.save (netD.state_dict (), 'checkpoints/netd_%s.pth' % epoch) torch.save (netG.state_dict (), 'checkpoints/netg_%s.pth' % epoch) print('完成%s的模型保存'%epoch) ####################################### ############画图################### if args.plt: import matplotlib.pyplot as plt import numpy as np import torchvision.utils as vutils plt.figure (figsize=(10, 5)) plt.title ("GAN") plt.plot (G_losses, label="G") plt.plot (D_losses, label="D") plt.xlabel ("迭代次数",fontproperties='SimHei') plt.ylabel ("损失",fontproperties='SimHei') plt.legend () plt.show () # 从数据集加载 real_batch = next (iter (train_dataset)) # 画出真图 plt.figure (figsize=(15, 10)) plt.subplot (1, 2, 1) plt.axis ("off") plt.title ("真图",fontproperties='SimHei') plt.imshow (np.transpose ( vutils.make_grid (real_batch [0].to (device) [:64], padding=5, normalize=True).cpu (), (1, 2, 0))) # 画出假图 plt.subplot (1, 2, 2) plt.axis ("off") plt.title ("假图",fontproperties='SimHei') plt.imshow (np.transpose (img_list [-1], (1, 2, 0))) plt.show () @torch.no_grad()#禁用梯度计算def test(): #判断Gpu device = torch.device ('cuda') if args.cuda else torch.device ('cpu') #初始化网络 netg, netd = netG (args).eval (), netD (args).eval () #定义噪声 noises = torch.randn (args.batch_size, args.nz, 1, 1).to (device) #载入网络 netd.load_state_dict (torch.load ('checkpoints/netd_%s.pth'%args.max_epoch)) netg.load_state_dict (torch.load ('checkpoints/netg_%s.pth'%args.max_epoch)) #设备化 netd.to (device) netg.to (device) # 生成图片，并计算图片在判别器的分数 fake_img = netg (noises) scores = netd (fake_img).detach () # 挑选最好的某几张 indexs = scores.topk (5) [1] result = [] for i in indexs: result.append (fake_img.data [i]) # 保存图片 import torchvision as tv tv.utils.save_image (torch.stack (result), 5, normalize=True, range=(-1, 1)) ###################可视化类##################################import visdomimport timeimport torchvision as tvimport numpy as npclass Visualizer (): """ 封装了visdom的基本操作，但是你仍然可以通过`self.vis.function` 调用原生的visdom接口 """ def __init__ (self, env='default', **kwargs): import visdom self.vis = visdom.Visdom (env=env, use_incoming_socket=False, **kwargs) # 画的第几个数，相当于横座标 # 保存（’loss',23） 即loss的第23个点 self.index = &#123;&#125; self.log_text = '' def reinit (self, env='default', **kwargs): """ 修改visdom的配置 """ self.vis = visdom.Visdom (env=env, use_incoming_socket=False, **kwargs) return self def plot_many (self, d): """ 一次plot多个 @params d: dict (name,value) i.e. ('loss',0.11) """ for k, v in d.items (): self.plot (k, v) def img_many (self, d): for k, v in d.items (): self.img (k, v) def plot (self, name, y): """ self.plot('loss',1.00) """ x = self.index.get (name, 0) self.vis.line (Y=np.array ([y]), X=np.array ([x]), win=(name), opts=dict (title=name), update=None if x == 0 else 'append' ) self.index [name] = x + 1 def img (self, name, img_): """ self.img('input_img',t.Tensor(64,64)) """ if len (img_.size ()) &lt; 3: img_ = img_.cpu ().unsqueeze (0) self.vis.image (img_.cpu (), win=(name), opts=dict (title=name) ) def img_grid_many (self, d): for k, v in d.items (): self.img_grid (k, v) def img_grid (self, name, input_3d): """ 一个batch的图片转成一个网格图，i.e. input（36，64，64） 会变成 6*6 的网格图，每个格子大小64*64 """ self.img (name, tv.utils.make_grid ( input_3d.cpu () [0].unsqueeze (1).clamp (max=1, min=0))) def log (self, info, win='log_text'): """ self.log(&#123;'loss':1,'lr':0.0001&#125;) """ self.log_text += ('[&#123;time&#125;] &#123;info&#125; &lt;br&gt;'.format ( time=time.strftime ('%m%d_%H%M%S'), info=info)) self.vis.text (self.log_text, win=win) def __getattr__ (self, name): return getattr (self.vis, name) if __name__ == '__main__': if args.test: test() else: train() **输出:]]></content>
      <categories>
        <category>框架</category>
        <category>pytorch</category>
        <category>GAN</category>
      </categories>
      <tags>
        <tag>VAEGAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回顾-DCGAN]]></title>
    <url>%2F2018%2F12%2F24%2F%E5%9B%9E%E9%A1%BE-DCGAN%2F</url>
    <content type="text"><![CDATA[1. DCGAN 简介:如何把CNN与GAN结合？DCGAN是这方面最好的尝试之一，DCGAN的原理和GAN是一样的，这里就不在赘述。它只是把经典GAN中的G和D换成了两个卷积神经网络（CNN）。但是，并不是直接替换就可以了， DCGAN 对卷积神经网络的结构做了一些改变，以提高样本的质量和收敛的速度。用了哪些方法!我们简单了解下,原文地址:点我 2. 网络结构： 首先看图：网络改进点:简单解释下:GAN 的第一层采用均匀噪声分布Z作为输入,因为它只是一个矩阵乘法操作所以可以称为全连接,但结果被重组为一个4维的张量,并作为卷积叠加（convolution stack）的开始。对于判别网络,最后卷积层是平滑的然后送入单个sigmoid输出。 1.使用步幅卷积替代确定性空间池化函数(比如最大池化)，允许网络学习自身的空间下采样的方法应用在生成网络当中，在判别网络中允许它学习自己的空间上采样。 2.在卷积层的中间地带直接分别连接到生成网络的输入和判别网络的输出系统也可以很好的工作。 其次一个趋势是在最顶层的卷积后面去除全连接层特点。发现全局平均池化虽然增加了模型的稳定性但却影响了收敛速度。 3.最后是批量规范化:通过将输入的每个单元标准化为0均值与单位方差来稳定学习。有助于处理初始化不良导致的训练问题另外还有助于梯度流向更深的网络。 不要批量规范化（batchnorm）将应用到生成网络的输出层和判别网络输入层可以避免直接对所有的层采取批量归一化,导致采样的振荡和模型的不稳定问题 4.使用有界激活可以让模型更快学习达到饱和并覆盖训练分布的颜色空间。在判别器中,发现LeakyReLU激活函数能够很好地工作,特别是对于更高分辨率的模型。 总结: 训练细节上的改进: 1.训练图像除了缩放到tanh激活函数的[-1,1]范围之外,没有经过其他的预处理。 2.所有的模型都是通过小批量随机梯度下降法进行训练的(小批量的大小是 128) 3.所有权重的初始化为均值为 0 和方差为 0.02的正态分布。 4.在LeakyReLU, 所有模型的leak的斜率设置为0.2。 5.DCGAN是使用Adam优化程序调整超参数。建议使用的学习率是0.001，太高的话使用0.0002代替。 6.优化器参数beta1，在建议的0.9训练动荡且不稳定，但降低到0.5是有利于模型的稳定。 3. pytorch 实现: network.py1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071'''跟着图走'''import torch.nn as nn#我们首先建立Gclass G(nn.Module): def __init__(self,args): super(G,self).__init__() ngf = args.ngf #ndf 设置为128 卷积一般扩大两倍 参数为4,2,1 self.G_layer= nn.Sequential( # 输入的相当于nz*1*1 nn.ConvTranspose2d (args.nz, ngf * 8, 4, 1, 0, bias=False), nn.BatchNorm2d (ngf * 8), nn.ReLU (True), # (ngf*8) x 4 x 4 nn.ConvTranspose2d (ngf * 8, ngf * 4, 4, 2, 1, bias=False), nn.BatchNorm2d (ngf * 4), nn.ReLU (True), # (ngf*4) x 8 x 8 nn.ConvTranspose2d (ngf * 4, ngf * 2, 4, 2, 1, bias=False), nn.BatchNorm2d (ngf * 2), nn.ReLU (True), # (ngf*2) x 16 x 16 nn.ConvTranspose2d (ngf * 2, ngf, 4, 2, 1, bias=False), nn.BatchNorm2d (ngf), nn.ReLU (True), # (ngf) x 32 x 32 nn.ConvTranspose2d (ngf, 3, 4, 2, 1, bias=False), nn.Tanh ()) # 3 x 64 x 64 #前向传播 def forward(self,x): out=self.G_layer(x) return out#建立Dclass D(nn.Module): def __init__(self,args): super(D,self).__init__() ndf = args.ndf # ndf 128 self.D_layer= nn.Sequential( # 输入 3 x 64 x 64, nn.Conv2d(3,ndf,4,2,1), nn.BatchNorm2d (ndf), nn.LeakyReLU (True), #输出 (ndf)*32*32 nn.Conv2d(ndf,ndf*2,4,2,1), nn.BatchNorm2d (ndf*2), nn.LeakyReLU (True), # 输出 (ndf*2)*16*16 nn.Conv2d (ndf*2, ndf*4, 4, 2, 1), nn.BatchNorm2d (ndf*4), nn.LeakyReLU (True), # 输出 (ndf*4)*8*8 nn.Conv2d (ndf*4, ndf*8, 4, 2, 1), nn.BatchNorm2d (ndf*8), nn.LeakyReLU (True), # 输出 (ndf*8)*4*4 nn.Conv2d (ndf * 8, 1, 4, 1, 0), # 输出 1*0*0 nn.Sigmoid())#告诉D概率 #前向传播 def forward(self,x): out=self.D_layer(x) return out train.py 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380381382383384385386387388389390391392393394395396397398import torchimport torch.nn as nnimport torchvision.datasets as datasetsimport torchvision.transforms as transformsfrom torch.autograd import Variableimport torch.backends.cudnn as cudnn# 工具包import argparse# 载入网络from network import G, D#############参数设置#################命令行设置########parser = argparse.ArgumentParser (description='GANs') # 导入命令行模块# 对关于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明#关于训练参数parser.add_argument ('--batch_size', type=int, default=64, help='训练batch-size大小 (default: 64)')parser.add_argument ('--imageSize', type=int, default=64, help='图片尺寸')parser.add_argument ('--max_epoch', type=int, default=20, help='最大迭代数 (default: 12)')#关于网络参数parser.add_argument ('--lr_g', type=float, default=2e-4, help='生成器学习率 (default: 2e-4)')parser.add_argument ('--lr_d', type=float, default=2e-4, help='判别器学习率 (default: 2e-4)')parser.add_argument ('--ngf', type=int, default=128, help='生成器feature map数')parser.add_argument ('--ndf', type=int, default=128, help='判别器feature map数')parser.add_argument ('--d_every', type=int, default=1, help='每几个batch训练一次判别器')parser.add_argument ('--g_every', type=int, default=4, help='每几个batch训练一次生成器')parser.add_argument ('--nz', type=int, default=100, help='噪声维度')#关于优化器参数parser.add_argument ('--beta1', type=int, default=0.5, help='Adam优化器的beta1参数')#路径parser.add_argument ('--dataset', default='data/', help='数据集路径')parser.add_argument ('--save_data', default='save/', help='保存路径')#可视化parser.add_argument ('--vis', action='store_true', help='使用visdom可视化')parser.add_argument ('--plot_every', type=int, default=1, help='每间隔_batch，visdom画图一次')# 其他parser.add_argument ('--cuda', action='store_true', help='开启cuda训练')parser.add_argument ('--plt', action='store_true', help='开启画图')parser.add_argument ('--test', action='store_true', help='开启测试生成')parser.add_argument ('--save_every', type=int, default=5, help='几个epoch保存一次模型 (default: 2)')parser.add_argument ('--seed', type=int, default=1, help='随机种子 (default: 1)')args = parser.parse_args () # 相当于激活命令#训练过程def train(): ###############判断gpu############# device = torch.device ('cuda') if args.cuda else torch.device ('cpu') ####### 为CPU设置种子用于生成随机数，以使得结果是确定的########## torch.manual_seed (args.seed) if args.cuda: torch.cuda.manual_seed (args.seed) cudnn.benchmark = True #################可视化############### if args.vis: vis = Visualizer ('GANs') ##########数据转换##################### data_transforms = transforms.Compose ([transforms.Scale (args.imageSize), # 通过调整比例调整大小,会报警 transforms.CenterCrop (args.imageSize), # 在中心裁剪给指定大小方形PIL图像 transforms.ToTensor (),# 转换成pytorch 变量tensor transforms.Normalize ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) ###############数据载入################ # train_dataset = datasets.ImageFolder (root=args.dataset, # 数据路径目录 # transform=data_transforms) # 把数据转换成上面约束样子 train_dataset = datasets.CIFAR10(root=args.dataset, train=True, transform=data_transforms, download=False) # test_dataset = datasets.ImageFolder (root=args.dataset, # transform=data_transforms) ##############数据装载############### train_loader = torch.utils.data.DataLoader (dataset=train_dataset, # 装载数据 batch_size=args.batch_size, # 设置批大小 shuffle=True) # 是否随机打乱 # test_loader = torch.utils.data.DataLoader (dataset=test_dataset, # batch_size=args.batch_size, # shuffle=True) #############模型载入################# netG ,netD= G (args),D (args) netG.to (device) netD.to (device) print (netD, netG) ###############损失函数################## criterion = torch.nn.BCELoss ().to (device) optimizerD = torch.optim.Adam (netD.parameters (), lr=args.lr_d,betas=(0.5, 0.999)) # Adam优化器 optimizerG = torch.optim.Adam (netG.parameters (), lr=args.lr_g,betas=(0.5, 0.999)) # Adam优化器 ###############画图参数保存################## G_losses = [] D_losses = [] img_list = [] #############训练过程##################### import tqdm # Tqdm是一个快速，可扩展的Python进度条，可以在Python # 长循环中添加一个进度提示信息，用户只需要封装任意的迭代器 # tqdm (iterator)。 for epoch in range (args.max_epoch): for i, (images, labels) in tqdm.tqdm(enumerate (train_loader)): # 枚举出来 #数据处理 images = images.to (device) # 装箱 images = Variable (images) noises=Variable(torch.randn(images.size(0), args.nz, 1, 1).to(device)) #遍历每张图片,并且根据指定的训练机制训练 if i % args.d_every==0:#满足此条件训练D #D前向传播 optimizerD.zero_grad () #D网络输出 output_r = netD (images).view(-1) #定义真张量 #返回第一个参数为大小 第二参数为值 的张量 true_label = torch.full ((images.size(0),), 1, device=device) #判别真的损失 d_real_loss = criterion(output_r, true_label) #反向传播 d_real_loss.backward() #G网络输出 noises.data.copy_ (torch.randn (images.size(0), args.nz, 1, 1)) fake = netG (noises).detach () # 根据噪声生成假图 #把假图给d output_f = netD (fake).view(-1) #d假的损失 #print(fake.size(),output_f.size(),output_r.size()) # 返回第一个参数为大小 第二参数为值 的张量 fake_label = torch.full ((images.size (0),), 0, device=device) d_fake_loss= criterion(output_f,fake_label) #D假反向传播 d_fake_loss.backward () # 总损失 D_loss=d_fake_loss+d_real_loss #D更新参数 optimizerD.step () # 度量 D_x = output_r.mean ().item () D_G_z1 = output_f.mean ().item () if i % args.g_every==0:#满足此条件训练G #G前向传播 optimizerG.zero_grad () #G网络输出 fake = netG (noises) # 根据噪声生成假图 #把假图给G output_f = netD (fake).view(-1) #G的损失 true_label = torch.full ((images.size (0),), 1, device=device) G_loss = criterion(output_f,true_label) #G反向传播 G_loss.backward () #度量 D_G_z2 = output_f.mean ().item () #D更新参数 optimizerG.step () ########################################### ##########可视化(可选)##################### if args.vis and i % args.plot_every == args.plot_every - 1: fake = netG (noises) vis.images (fake.detach ().cpu ().numpy () [:64] * 0.5 + 0.5, win='fixfake') vis.images (images.data.cpu ().numpy () [:64] * 0.5 + 0.5, win='real') vis.plot ('errord', D_loss.item ()) vis.plot ('errorg', G_loss.item ()) ####################################### ############打印记录################### if i % 1== 0: print ('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f' % (epoch, args.max_epoch, i, len (train_loader), D_loss.item (), G_loss.item (), D_x, D_G_z1, D_G_z2)) ########添加画图参数######## G_losses.append (G_loss.item ()) D_losses.append (D_loss.item ()) with torch.no_grad (): noises = torch.randn (args.batch_size, args.nz, 1, 1).to (device) fake = netG (noises).detach ().cpu () import torchvision.utils as vutils img_list.append (vutils.make_grid (fake, padding=2, normalize=True)) ####################################### ############保存模型################### if (epoch + 1) % args.save_every == 0: import torchvision as tv # 保存模型、图片 tv.utils.save_image (fake.data [:64], '%s/%s.png' % (args.save_data, epoch), normalize=True,range=(-1, 1)) torch.save (netD.state_dict (), 'checkpoints/netd_%s.pth' % epoch) torch.save (netG.state_dict (), 'checkpoints/netg_%s.pth' % epoch) print('完成%s的模型保存'%epoch) ####################################### ############画图################### if args.plt: import matplotlib.pyplot as plt import numpy as np import torchvision.utils as vutils plt.figure (figsize=(10, 5)) plt.title ("GAN") plt.plot (G_losses, label="G") plt.plot (D_losses, label="D") plt.xlabel ("迭代次数",fontproperties='SimHei') plt.ylabel ("损失",fontproperties='SimHei') plt.legend () plt.show () # 从数据集加载 real_batch = next (iter (train_dataset)) # 画出真图 plt.figure (figsize=(15, 10)) plt.subplot (1, 2, 1) plt.axis ("off") plt.title ("真图",fontproperties='SimHei') plt.imshow (np.transpose ( vutils.make_grid (real_batch [0].to (device) [:64], padding=5, normalize=True).cpu (), (1, 2, 0))) # 画出假图 plt.subplot (1, 2, 2) plt.axis ("off") plt.title ("假图",fontproperties='SimHei') plt.imshow (np.transpose (img_list [-1], (1, 2, 0))) plt.show () @torch.no_grad()#禁用梯度计算def test(): #判断Gpu device = torch.device ('cuda') if args.cuda else torch.device ('cpu') #初始化网络 netg, netd = netG (args).eval (), netD (args).eval () #定义噪声 noises = torch.randn (args.batch_size, args.nz, 1, 1).to (device) #载入网络 netd.load_state_dict (torch.load ('checkpoints/netd_%s.pth'%args.max_epoch)) netg.load_state_dict (torch.load ('checkpoints/netg_%s.pth'%args.max_epoch)) #设备化 netd.to (device) netg.to (device) # 生成图片，并计算图片在判别器的分数 fake_img = netg (noises) scores = netd (fake_img).detach () # 挑选最好的某几张 indexs = scores.topk (5) [1] result = [] for i in indexs: result.append (fake_img.data [i]) # 保存图片 import torchvision as tv tv.utils.save_image (torch.stack (result), 5, normalize=True, range=(-1, 1)) ###################可视化类##################################import visdomimport timeimport torchvision as tvimport numpy as npclass Visualizer (): """ 封装了visdom的基本操作，但是你仍然可以通过`self.vis.function` 调用原生的visdom接口 """ def __init__ (self, env='default', **kwargs): import visdom self.vis = visdom.Visdom (env=env, use_incoming_socket=False, **kwargs) # 画的第几个数，相当于横座标 # 保存（’loss',23） 即loss的第23个点 self.index = &#123;&#125; self.log_text = '' def reinit (self, env='default', **kwargs): """ 修改visdom的配置 """ self.vis = visdom.Visdom (env=env, use_incoming_socket=False, **kwargs) return self def plot_many (self, d): """ 一次plot多个 @params d: dict (name,value) i.e. ('loss',0.11) """ for k, v in d.items (): self.plot (k, v) def img_many (self, d): for k, v in d.items (): self.img (k, v) def plot (self, name, y): """ self.plot('loss',1.00) """ x = self.index.get (name, 0) self.vis.line (Y=np.array ([y]), X=np.array ([x]), win=(name), opts=dict (title=name), update=None if x == 0 else 'append' ) self.index [name] = x + 1 def img (self, name, img_): """ self.img('input_img',t.Tensor(64,64)) """ if len (img_.size ()) &lt; 3: img_ = img_.cpu ().unsqueeze (0) self.vis.image (img_.cpu (), win=(name), opts=dict (title=name) ) def img_grid_many (self, d): for k, v in d.items (): self.img_grid (k, v) def img_grid (self, name, input_3d): """ 一个batch的图片转成一个网格图，i.e. input（36，64，64） 会变成 6*6 的网格图，每个格子大小64*64 """ self.img (name, tv.utils.make_grid ( input_3d.cpu () [0].unsqueeze (1).clamp (max=1, min=0))) def log (self, info, win='log_text'): """ self.log(&#123;'loss':1,'lr':0.0001&#125;) """ self.log_text += ('[&#123;time&#125;] &#123;info&#125; &lt;br&gt;'.format ( time=time.strftime ('%m%d_%H%M%S'), info=info)) self.vis.text (self.log_text, win=win) def __getattr__ (self, name): return getattr (self.vis, name) if __name__ == '__main__': if args.test: test() else: train() 注 :数据集用的cifar-10-batches-py 结果: 迭代一次 迭代二次]]></content>
      <categories>
        <category>框架</category>
        <category>pytorch</category>
        <category>GAN</category>
      </categories>
      <tags>
        <tag>DCGAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[破解MathType-方法]]></title>
    <url>%2F2018%2F12%2F24%2F%E7%A0%B4%E8%A7%A3MathType-%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[流程：1.首先打开运行，快捷键 win+R2.输入regedit。3.打开注册表4.在HKEY_CURRENT_USER项右键 点击查找5.输入Install Options6.删除键值对 快捷方式：新建记事本：输入12345@echo onreg delete &quot;HKEY_CURRENT_USER\Software\Install Options\Options7.2&quot; /fpause 注意： reg delete后面 路径每个电脑不同 保存 新建文档.txt(没有txt，请打开后缀） 重命名 为刷新mathtype.bat 每次到期 运行下就可以了]]></content>
      <tags>
        <tag>破解MathType</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回顾-GAN]]></title>
    <url>%2F2018%2F12%2F21%2F%E5%9B%9E%E9%A1%BE-GAN%2F</url>
    <content type="text"><![CDATA[1.GAN 简介：GAN是2014年放出的一篇开山之作.LSTM作者认为GAN是其他模型的变种,因为他在92年提出PM（PredictabilityMinimization）模型,所以他一直认为GAN是goodfellow在自己PM模型上的改进!哈哈!! GAN的主要灵感来源于博弈论中零和博弈的思想,即一个网络与另一个网络对抗!从而互相提升自己,我以前曾想有没有互助网络!答案是肯定的,遇到在说! 2. GAN网络结构:如图: 从这图告诉我什么呢? 首先看到是两个大字 G D ,G表示生成网络,D表示判别网络! 然后我们看这类似电路的网络图,我们从左往右看! (主干线) 在变量空间构造Noise(噪声)→送给→G(生成网络)→生出→假东西 （看G上面） 一堆真东西 真东西（上面），假东西（G生出来的）交给D（判别网络）给出两个的有多像真东西几率 （当然给出真东西（上面）几率为100%（因为本来就是真的），假东西（G生出来的）几率为0~100%） 如果很差，就告诉D（生成网络）你不行啊！！，然后D借鉴上次失败重新生成假东西，去骗G！ 就这样持续了。。。。。。世纪，最终达到平衡，这时候G肯定很强大了 然后我们说下平衡核心： 然后我们从右到左说下: 首先想解释E E就是期望(期望就是概率求和)还有有就是log,这是逻辑回归那取对数似然出来的 最右边,G(z):其中z表示噪声.G(z)就表示生成的假东西,D(G(z))就表示D是否要告诉G(‘你不行’)的概率 下角的 z-Pz表示一个噪声到噪声数据集 然后是D(x)表示看模板(真东西)是不是真东西概率 下角的 x-Pdata 表示x到真实数据集(表示要慢慢来,慢慢学,不然容易崩溃哟) 最后 min max ,你肯定有点不解,不是应该maxG吗? 简单理解下,当G最失败(最小)时候,就是让D看假东西得出概率最大. (最垃圾时候,D都说你行,那就别说G强大时候了) 即在局部最大中试图找出全局最大 3.GAN的创新点: 相比较传统的模型，他存在两个不同的网络，而不是单一的网络，并且训练方式采用的是对抗训练方式 GAN中G的梯度更新信息自于判别模型D的一个反传梯度。，而不是来自数据样本 4.GAN的优缺点:优点:● 训练时不需要对隐变量做推断,而且G参数来源于D ● GAN是一种生成式模型，相比较其他生成模型（玻尔兹曼机和GSNs）只用到了反向传播,而不需要复杂的马尔科夫链 ● 相比其他所有模型, GAN可以产生更加清晰，真实的样本 ● GAN采用的是一种无监督的学习方式训练，可以被广泛用在无监督学习和半监督学习领域 ● 相比于变分自编码器, GANs没有引入任何决定性偏置( deterministic bias),变分方法引入决定性偏置,因为他们优化对数似然的下界,而不是似然度本身,这看起来导致了VAEs生成的实例比GANs更模糊 ● 相比VAE, GANs没有变分下界,如果鉴别器训练良好,那么生成器可以完美的学习到训练样本的分布.换句话说,GANs是渐进一致的,但是VAE是有偏差的 ● GAN应用到一些场景上，比如图片风格迁移，超分辨率，图像补全，去噪，避免了损失函数设计的困难，不管三七二十一，只要有一个的基准，直接上判别器，剩下的就交给对抗训练了。 缺点:● 很不好训练,一是DG的同仇敌忾问题(同步) ● G参数来源于D,所以很难解释G的模型分布 ● 训练GAN需要达到纳什均衡,有时候可以用梯度下降法做到,有时候做不到.我们还没有找到很好的达到纳什均衡的方法,所以训练GAN相比VAE或者PixelRNN是不稳定的,但我认为在实践中它还是比训练玻尔兹曼机稳定的多 ● GAN不适合处理离散形式的数据，比如文本 ● GAN存在训练不稳定、梯度消失、模式崩溃的问题（就是自我欺骗,最后谁也不行!解决在WGAN） 5.GAN的训练建议:注:来自https://github.com/soumith/ganhacks#authors 1.标准化输入 在-1和1之间标准化图像 Tanh作为发电机输出的最后一层 2：修改的损失函数在GAN论文中，优化G的损失函数是min (log 1-D)，但实际上人们实际使用max log D 因为第一个损失在早期就已经消失了 Goodfellow et。al（2014） 在实践中，运作良好： 训练生成器时调换标签：real = fake，fake = real 3：使用球形 不要从统一分布中取样 来自高斯分布的样本 进行插值时，通过大圆进行插值，而不是从A点到B点的直线 Tom White的采样生成网络参考代码https://github.com/dribnet/plat 4：BatchNorm 构建真实和假的不同小批次，即每个小批量只需要包含所有真实图像或所有生成的图像。 当batchnorm不是一个选项时，使用实例标准化（对于每个样本，减去平均值并除以标准偏差）。 5：避免稀疏梯度：ReLU，MaxPool 如果你的梯度稀疏，GANs的稳定性就会受到影响 LeakyReLU =优良（G和D都有） 对于Downsampling，使用：Average Pooling，Conv2d+ stride 对于Upsampling，请使用：PixelShuffle,ConvTranspose2d + stride PixelShuffle 6：使用平滑和复杂的标签 标签平滑，即如果你有两个目标标签：Real = 1和Fake = 0，那么对于每个传入的样本，如果它是真的，那么用0.7到1.2之间的随机数替换标签，如果它是假的样本，将其替换为0.0和0.3 使标签对于鉴别器来说是有噪声的：在训练鉴别器时偶尔会调换标签 7：DCGAN /混合模型 尽可能使用DCGAN。有用！ 如果您无法使用DCGAN并且没有模型稳定，请使用混合型号：KL + GAN或VAE + GAN 8：使用RL的稳定性技巧 重复性经验 保留过去几代的重复缓冲区并偶尔展示它们 保持G和D过去的检查点，并偶尔交换它们几次迭代 所有稳定性技巧都适用于深层确定性策略梯度( policy gradient) 见Pfau＆Vinyals（2016） 9：使用Adam Optimizer optim.Adam规则！ 使用SGD作为鉴别器，使用Adam作为生成器 10：尽早跟踪故障 D损失为0：故障模式 检查渐变的规范：如果他们超过100件事情搞砸了 当事情正在发挥作用时，D损失的方差很小，并且随着时间的推移而下降，而且存在巨大的差异和尖峰 如果生成器的损失稳定下降，那就是用垃圾愚弄D（马丁说） 11：不要通过统计平衡损失（除非你有充分的理由） 不要试图找到一个（G的数量/ D的数量）计划来解开训练这很难，我们都尝试过。 如果您确实尝试过，请采用原则性方法，而不是直觉 例如1234while lossD &gt; A: train Dwhile lossG &gt; B: train G 12：如果你有标签，请使用它们 如果您有可用的标签，则训练鉴别器以对样品进行分类：辅助GAN 13：向输入添加噪声，随时间衰减 在D的输入上添加一些人为噪声（Arjovsky et.al.Huszar，2016） http://www.inference.vc/instance-noise-a-trick-for-stabilising-gan-training/ https://openreview.net/forum?id=Hk4_qw5xe 在生成器的每一层都加入高斯噪声（Zhao et al。EBGAN） 改进的GAN：OpenAI代码也有它（注释掉） 14：[notsure]（有时）更多的训练鉴别器 特别是当你有噪音时 很难找到D迭代次数与G次迭代的时间表 15：[notsure]批量鉴别 结果喜忧参半 16：条件GAN中的离散变量 使用嵌入层 添加为图像的附加通道 保持低维度嵌入和上采样以匹配图像通道大小 17：在train和test阶段使用G中的Dropouts 以随机的形式提供噪音（50％）。 在训练和测试时间应用于我们的发电机的几个层 https://arxiv.org/pdf/1611.07004v1.pdf 18.其他小技巧 输入规范化到（-1，1）之间，最后一层的激活函数使用tanh 使用wassertein GAN的损失函数 学习率不要设置太大，初始1e-4可以参考，另外可以随着训练进行不断缩小学习率 给D的网络层增加高斯噪声，相当于是一种正则 6.GANs的发展:更多,可以浏览:https://github.com/hindupuravinash 7. pytorch实现: 目录结构: 注:从上到下依次是模型保存文件夹-&gt;数据集文件夹-&gt;生成文件夹 设计网络常用计算: 反卷积: 卷积: network.py文件:1234567891011121314151617181920212223242526272829303132333435363738394041424344'''为了简单明了,所以今天还是创最最简单的GAN首先 有两个网络 分别是G D'''import torch.nn as nn#我们首先建立Gclass G(nn.Module): def __init__(self,args): super(G,self).__init__() ngf = args.ngf # 生成器feature map数(该层卷积核的个数，有多少个卷积核，经过卷积就会产生多少个feature map) self.G_layer= nn.Sequential( #输入是一个nz维度的噪声，我们可以认为它是一个1 * 1 * nz的feature map nn.ConvTranspose2d(args.nz, 3,5,1,0),# 反conv2d nn.BatchNorm2d (3), nn.LeakyReLU(True),) # 输出大小为3*5*5 #前向传播 def forward(self,x): out=self.G_layer(x) return out#建立Dclass D(nn.Module): def __init__(self,args): super(D,self).__init__() ndf = args.ndf # 生成器feature map数(该层卷积核的个数，有多少个卷积核，经过卷积就会产生多少个feature map) self.D_layer= nn.Sequential( # 输入 3 x 5 x 5, nn.Conv2d(3,ndf, 3), nn.BatchNorm2d (ndf), nn.LeakyReLU (True), #输出 (ndf)*1*1 nn.Conv2d (ndf,1,1), # 输出 1*0*0 nn.Sigmoid())#告诉D概率 #前向传播 def forward(self,x): out=self.D_layer(x) return out train.py文件:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106107108109110111112113114115116117118119120121122123124125126127128129130131132133134135136137138139140141142143144145146147148149150151152153154155156157158159160161162163164165166167168169170171172173174175176177178179180181182183184185186187188189190191192193194195196197198199200201202203204205206207208209210211212213214215216217218219220221222223224225226227228229230231232233234235236237238239240241242243244245246247248249250251252253254255256257258259260261262263264265266267268269270271272273274275276277278279280281282283284285286287288289290291292293294295296297298299300301302303304305306307308309310311312313314315316317318319320321322323324325326327328329330331332333334335336337338339340341342343344345346347348349350351352353354355356357358359360361362363364365366367368369370371372373374375376377378379380import torchimport torch.nn as nnimport torchvision.datasets as datasetsimport torchvision.transforms as transformsfrom torch.autograd import Variableimport torch.backends.cudnn as cudnn# 工具包import argparse# 载入网络from network import G, D#############参数设置#################命令行设置########parser = argparse.ArgumentParser (description='GAN') # 导入命令行模块# 对关于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明#关于训练参数parser.add_argument ('--batch_size', type=int, default=12, help='训练batch-size大小 (default: 64)')parser.add_argument ('--imageSize', type=int, default=5, help='图片尺寸')parser.add_argument ('--max_epoch', type=int, default=5, help='最大迭代数 (default: 5)')#关于网络参数parser.add_argument ('--lr_g', type=float, default=2e-4, help='生成器学习率 (default: 2e-4)')parser.add_argument ('--lr_d', type=float, default=2e-4, help='判别器学习率 (default: 2e-4)')parser.add_argument ('--ngf', type=int, default=32, help='生成器feature map数')parser.add_argument ('--ndf', type=int, default=32, help='判别器feature map数')parser.add_argument ('--d_every', type=int, default=1, help='每几个batch训练一次判别器')parser.add_argument ('--g_every', type=int, default=2, help='每几个batch训练一次生成器')parser.add_argument ('--nz', type=int, default=5, help='噪声维度')#关于优化器参数parser.add_argument ('--beta1', type=int, default=0.5, help='Adam优化器的beta1参数')#路径parser.add_argument ('--dataset', default='data/', help='数据集路径')parser.add_argument ('--save_data', default='save/', help='保存路径')#可视化parser.add_argument ('--vis', action='store_true', help='是否使用visdom可视化')parser.add_argument ('--plot_every', type=int, default=1, help='每间隔_batch，visdom画图一次')# 其他parser.add_argument ('--cuda', action='store_true', help='开启cuda训练')parser.add_argument ('--plt', action='store_true', help='开启画图')parser.add_argument ('--test', action='store_true', help='开启测试生成')parser.add_argument ('--save_every', type=int, default=3, help='几个epoch保存一次模型 (default: 3)')parser.add_argument ('--seed', type=int, default=1, help='随机种子 (default: 1)')args = parser.parse_args () # 相当于激活命令#训练过程def train(): ###############判断gpu############# device = torch.device ('cuda') if args.cuda else torch.device ('cpu') ####### 为CPU设置种子用于生成随机数，以使得结果是确定的########## torch.manual_seed (args.seed) if args.cuda: torch.cuda.manual_seed (args.seed) cudnn.benchmark = True #################可视化############### if args.vis: vis = Visualizer ('GANs') ##########数据转换##################### data_transforms = transforms.Compose ([transforms.Scale (args.imageSize), # 通过调整比例调整大小,会报警 transforms.CenterCrop (args.imageSize), # 在中心裁剪给指定大小方形PIL图像 transforms.ToTensor (),# 转换成pytorch 变量tensor transforms.Normalize ((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]) ###############数据载入################ train_dataset = datasets.ImageFolder (root=args.dataset, # 数据路径目录 transform=data_transforms) # 把数据转换成上面约束样子 # test_dataset = datasets.ImageFolder (root=args.dataset, # transform=data_transforms) ##############数据装载############### train_loader = torch.utils.data.DataLoader (dataset=train_dataset, # 装载数据 batch_size=args.batch_size, # 设置批大小 shuffle=True) # 是否随机打乱 # test_loader = torch.utils.data.DataLoader (dataset=test_dataset, # batch_size=args.batch_size, # shuffle=True) #############模型载入################# netG ,netD= G (args),D (args) netG.to (device) netD.to (device) print (netD, netG) ###############损失函数################## optimizerD = torch.optim.Adam (netD.parameters (), lr=args.lr_d,betas=(0.5, 0.999)) # Adam优化器 optimizerG = torch.optim.Adam (netG.parameters (), lr=args.lr_g,betas=(0.5, 0.999)) # Adam优化器 ###############画图参数保存################## G_losses = [] D_losses = [] img_list = [] #############训练过程##################### import tqdm # Tqdm是一个快速，可扩展的Python进度条，可以在Python # 长循环中添加一个进度提示信息，用户只需要封装任意的迭代器 # tqdm (iterator)。 for epoch in range (args.max_epoch): for i, (images, labels) in tqdm.tqdm(enumerate (train_loader)): # 枚举出来 #数据处理 images = images.to (device) # 装箱 images = Variable (images) noises=Variable(torch.randn(args.batch_size, args.nz, 1, 1).to(device)) #遍历每张图片,并且根据指定的训练机制训练 if i % args.d_every==0:#满足此条件训练D #D前向传播 optimizerD.zero_grad () #D网络输出 output_r = netD (images) #G网络输出 noises.data.copy_ (torch.randn (args.batch_size, args.nz, 1, 1)) fake = netG (noises).detach () # 根据噪声生成假图 #把假图给d output_f = netD (fake) #D的损失 #print(fake.size(),output_f.size(),output_r.size()) D_loss = - torch.mean (torch.log (output_r) + torch.log (1. - output_f)) #D反向传播 D_loss.backward () #度量 D_x = output_r.mean ().item () D_G_z1 = output_f.mean ().item () #D更新参数 optimizerD.step () if i % args.g_every==0:#满足此条件训练G #G前向传播 optimizerG.zero_grad () #G网络输出 fake = netG (noises) # 根据噪声生成假图 #把假图给G output_f = netD (fake) #G的损失 G_loss = torch.mean (torch.log (1. - output_f)) #G反向传播 G_loss.backward () #度量 D_G_z2 = output_f.mean ().item () #D更新参数 optimizerG.step () ########################################### ##########可视化(可选)##################### if args.vis and i % args.plot_every == args.plot_every - 1: fake = netG (noises) vis.images (fake.detach ().cpu ().numpy () [:64] * 0.5 + 0.5, win='fixfake') vis.images (images.data.cpu ().numpy () [:64] * 0.5 + 0.5, win='real') vis.plot ('errord', D_loss.item ()) vis.plot ('errorg', G_loss.item ()) ####################################### ############打印记录################### if i % 1== 0: print ('[%d/%d][%d/%d]\tLoss_D: %.4f\tLoss_G: %.4f\tD(x): %.4f\tD(G(z)): %.4f / %.4f' % (epoch, args.max_epoch, i, len (train_loader), D_loss.item (), G_loss.item (), D_x, D_G_z1, D_G_z2)) ########添加画图参数######## G_losses.append (G_loss.item ()) D_losses.append (D_loss.item ()) with torch.no_grad (): noises = torch.randn (args.batch_size, args.nz, 1, 1).to (device) fake = netG (noises).detach ().cpu () import torchvision.utils as vutils img_list.append (vutils.make_grid (fake, padding=2, normalize=True)) ####################################### ############保存模型################### if (epoch + 1) % args.save_every == 0: import torchvision as tv # 保存模型、图片 tv.utils.save_image (fake.data [:64], '%s/%s.png' % (args.save_data, epoch), normalize=True,range=(-1, 1)) torch.save (netD.state_dict (), 'checkpoints/netd_%s.pth' % epoch) torch.save (netG.state_dict (), 'checkpoints/netg_%s.pth' % epoch) print('完成%s的模型保存'%epoch) ####################################### ############画图################### if args.plt: import matplotlib.pyplot as plt import numpy as np import torchvision.utils as vutils plt.figure (figsize=(10, 5)) plt.title ("GAN") plt.plot (G_losses, label="G") plt.plot (D_losses, label="D") plt.xlabel ("迭代次数") plt.ylabel ("损失") plt.legend () plt.show () # 从数据集加载 real_batch = next (iter (train_dataset)) # 画出真图 plt.figure (figsize=(15, 10)) plt.subplot (1, 2, 1) plt.axis ("off") plt.title ("真图") plt.imshow (np.transpose ( vutils.make_grid (real_batch [0].to (device) [:64], padding=5, normalize=True).cpu (), (1, 2, 0))) # 画出假图 plt.subplot (1, 2, 2) plt.axis ("off") plt.title ("假图") plt.imshow (np.transpose (img_list [-1], (1, 2, 0))) plt.show () @torch.no_grad()#禁用梯度计算def test(): #判断Gpu device = torch.device ('cuda') if args.cuda else torch.device ('cpu') #初始化网络 netg, netd = netG (args).eval (), netD (args).eval () #定义噪声 noises = torch.randn (args.batch_size, args.nz, 1, 1).to (device) #载入网络 netd.load_state_dict (torch.load ('checkpoints/netd_%s.pth'%args.max_epoch)) netg.load_state_dict (torch.load ('checkpoints/netg_%s.pth'%args.max_epoch)) #设备化 netd.to (device) netg.to (device) # 生成图片，并计算图片在判别器的分数 fake_img = netg (noises) scores = netd (fake_img).detach () # 挑选最好的某几张 indexs = scores.topk (5) [1] result = [] for i in indexs: result.append (fake_img.data [i]) # 保存图片 import torchvision as tv tv.utils.save_image (torch.stack (result), 5, normalize=True, range=(-1, 1)) ###################可视化类##################################import visdomimport timeimport torchvision as tvimport numpy as npclass Visualizer (): """ 封装了visdom的基本操作，但是你仍然可以通过`self.vis.function` 调用原生的visdom接口 """ def __init__ (self, env='default', **kwargs): import visdom self.vis = visdom.Visdom (env=env, use_incoming_socket=False, **kwargs) # 画的第几个数，相当于横座标 # 保存（’loss',23） 即loss的第23个点 self.index = &#123;&#125; self.log_text = '' def reinit (self, env='default', **kwargs): """ 修改visdom的配置 """ self.vis = visdom.Visdom (env=env, use_incoming_socket=False, **kwargs) return self def plot_many (self, d): """ 一次plot多个 @params d: dict (name,value) i.e. ('loss',0.11) """ for k, v in d.items (): self.plot (k, v) def img_many (self, d): for k, v in d.items (): self.img (k, v) def plot (self, name, y): """ self.plot('loss',1.00) """ x = self.index.get (name, 0) self.vis.line (Y=np.array ([y]), X=np.array ([x]), win=(name), opts=dict (title=name), update=None if x == 0 else 'append' ) self.index [name] = x + 1 def img (self, name, img_): """ self.img('input_img',t.Tensor(64,64)) """ if len (img_.size ()) &lt; 3: img_ = img_.cpu ().unsqueeze (0) self.vis.image (img_.cpu (), win=(name), opts=dict (title=name) ) def img_grid_many (self, d): for k, v in d.items (): self.img_grid (k, v) def img_grid (self, name, input_3d): """ 一个batch的图片转成一个网格图，i.e. input（36，64，64） 会变成 6*6 的网格图，每个格子大小64*64 """ self.img (name, tv.utils.make_grid ( input_3d.cpu () [0].unsqueeze (1).clamp (max=1, min=0))) def log (self, info, win='log_text'): """ self.log(&#123;'loss':1,'lr':0.0001&#125;) """ self.log_text += ('[&#123;time&#125;] &#123;info&#125; &lt;br&gt;'.format ( time=time.strftime ('%m%d_%H%M%S'), info=info)) self.vis.text (self.log_text, win=win) def __getattr__ (self, name): return getattr (self.vis, name) if __name__ == '__main__': if args.test: test() else: train() 输入： 训练: 1python train.py --cuda --plt 测试: 1python train.py --cuda --test --cuda表示用GPU --plt表示启动画图功能 --vis 表示使用visdom可视化 具体可看参数列表: 输出： 注：为什么结果这样，为了迎合网络，简单我把图片改的不成样 具体可以看参数设置]]></content>
      <categories>
        <category>框架</category>
        <category>pytorch</category>
        <category>GAN</category>
      </categories>
      <tags>
        <tag>GAN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回顾-Resnet]]></title>
    <url>%2F2018%2F12%2F20%2F%E5%9B%9E%E9%A1%BE-Resnet%2F</url>
    <content type="text"><![CDATA[1.Resnet 简介:MSRA（微软亚洲研究院）何凯明团队的深度残差网络（Deep Residual Network）在2015年的ImageNet上取得冠军，该网络简称为ResNet（由算法Residual命名）， 层数达到了152层，top-5错误率降到了3.57，而2014年冠军GoogLeNet的错误率是6.7。ResNet取得了5项第一，并又一次刷新了CNN模型在ImageNet上的历史! 2. Resnet 网络结构: 1.昨天我们看了vgg,深刻的感觉到了加深网络所带来的好处,即: 1.从我写的cnn一层→→Alexnet 的八层→→vgg16的十六层,可以看出层数越深,获取的特征越丰富,拟合能力越强 2.当然肯定想说,想通过VGG堆叠那样无限制加深网络,来加强拟合能力! 当然你会遇到以下问题 1.对于原来的网络，如果简单地增加深度，会导致梯度弥散或梯度爆炸(注:就是前向传的过去,反向传不回来(想成小时候传话游戏,传着传着就变味了)). 遇到这个问题,其实可以正则化初始化和加入正则化层（Batch Normalization）或中间层添加辅助损失（auxiliary loss）作为额外的监督。,这样训练几十层应该没问题! 2.上面加深,没啥问题,但是在更深的网络有更高的训练误差和测试误差,即退化问题?(你肯定想问,我不是刚说越深越强吗?现在怎么又不行了?(回答这个,最简单就是名字,退化嘛,就像无限逼近定理一样,理想很丰满,现实很骨感)) 退化问题,推断能是因为深层的网络并不是那么好训练(也就是求解器很难去利用多层网络拟合同等函数(再简单一点,课程太多,学的有点崩溃)) 3.如何解决所谓的退化问题? 1. 首先我们看作者怎么玩的?如图: 注 : 图太大,就保存在桌面缩小慢慢对比 1.1:我们继续看图说故事! 1.我们首先看vgg19和34层网络(图左和图中),作者跟大家一样想法,加深到34层,并且通过无数爬坑失败经验!进行改进了,如下: 图中与图左差别: 1.把每个maxpool(池化层)都改成了stride=2的卷积层做下采样(下采样就是缩小图片图片) 2.去掉了最后那个耗费资源的全连接,用global average pool层替换 然后就遇到了退化问题……..然后尝试了………………次 终于在一次尝试中使用改进Highway Network带参数gate控制shortcut(就是图右的弯曲黑线,我叫它脑筋急转弯),以前我觉得是学LSTM(学这个最深感触,就是感觉在学电路分析)中也有一个forget gate来控制着流入下一阶段的信息量. ———所以知识都是互通的! 1,怎么改进呢? 上面是Highway Network(公路网络),不是还有更快的高速公路吗,就改成高速公路(刚才说的图右的弯曲黑线),什么是高速公路(官方叫恒等式变化),即简单,直接 下面我们来看看这所谓高速路是不是水泥构造:如图: 从这个图,我们能看出什么呢? 假设直下来表示很努力很努力的同学,弯弯曲曲的代表喜欢耍的同学!x代表刚入学,大家都一样,最下面(F(x)+x)代表清华北大哈! 现在,我要喜欢耍的同学考入清华北大! 怎么做呢? 清华北大=F(x)+x,我是x!我是不是只要学习我没有的F(x)呢, F(x)怎么来呢? F(x)=清华北大-x,这就是残差,所以我们不用想怎么考清华北大,而是想考清华北大同学有啥优点!,学习其优点,就可以无限接近清华北大! 注: 后面三层残差,这个函数变成清华北大=F(x)+wx,多了个w,W是卷积操作，用来调整x的channel维度的。意思喊你不要一下啥都学,适合自己才是最好的! 3.Resnet创新点: 1.shortcut连接的方式使用恒等映射，如果residual block的输入输出维度不一致，对增加的维度用0来填充(使用0填充时，可以保证模型的复杂度最低，这对于更深的网络是更加有利的)； 2.shortcut连接的方式维度一致时使用恒等映射,不一致时使用线性投影以保证维度一致 3.ResNets并不能更好的表征某一方面的特征，但是ResNets允许逐层深入地表征更多的模型。(可看经典的残差网络变体) 4.残差网络使得前馈式/反向传播算法非常顺利进行，在极大程度上，残差网络使得优化较深层模型更为简单 5.“shortcut”快捷连接添加既不产生额外的参数，也不会增加计算的复杂度。 6.快捷连接简单的执行身份映射，并将它们的输出添加到叠加层的输出。通过反向传播的SGD，整个网络仍然可以被训练成终端到端的形式。 更多信息,可以看原文( 标题1处的链接 ) 4.PyTorch实现: 为了简化,采用resnet32网络!如图: 网络架构:Resnet.py文件: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104105106import torch'''今天在vgg基础上再优雅点'''#遵从原来步骤class Resnet(torch.nn.Module): #初始化 def __init__(self): super(Resnet, self).__init__() # self.Sumlayers=self.make_layers()#这里我们交由make_layers函数创建相似的模块 # #假设我们上面已经创好五个模块(文章第一幅图block1-&gt;block5) #现在最顶端的不同层,看文章34层那个最上面橘色简化图的7*7 self.top=torch.nn.Sequential( torch.nn.Conv2d(3,64,7,2,3), torch.nn.BatchNorm2d(64), torch.nn.ReLU (inplace=True), torch.nn.MaxPool2d(3,2,1))#最顶部构建完成 #中间重复太多,交给make_layers函数创建相似的模块 #第三个参数来表示有多少个捷径(高速公路) #先来一打紫色的(文中图) self.layer1 = self.make_layer (64,64,3) # 再来一打绿色的(文中图) self.layer2 = self.make_layer (64, 128, 4,stride=2)#图中第一个有/2 # 再来一打橘色的(文中图) self.layer3 = self.make_layer ( 128,256, 6,stride=2)#图中第一个有/2 # 再来一打银色的(文中图) self.layer4= self.make_layer (256, 512, 3, stride=2) # 图中第一个有/2 #中间重复的构造完了 #开始最后的了 self.avgPool =torch.nn.AvgPool2d(7)#全局平均化 self.fc = torch.nn.Linear (512, 2)#最后分成猫狗两类 self.last=torch.nn.Softmax (dim=1) #前向传播 def forward (self, x): x = self.top (x) x = self.layer1 (x) x = self.layer2 (x) x = self.layer3 (x) x = self.layer4 (x) x = self.avgPool(x) res = x.view (x.size (0), -1) # 展平多维的卷积图成 一维 out = self.fc(res) out = self.last(out) return out #构建刚才的构建模块函数make_layers def make_layer(self,in_c,out_c,n_block,stride=1): #创建一个列表,用来放后面层 ,后面我们直接往里面添加就可以了 Sumlayers=[] #构建捷径(高速公路) shortcut=torch.nn.Sequential( torch.nn.Conv2d(in_c,out_c,1,stride),#1*1卷积 torch.nn.BatchNorm2d(out_c), ) #构建完成残差 Sumlayers.append(ResBlock(in_c,out_c,stride,shortcut)) #构建右边的公路 for i in range(1,n_block): Sumlayers.append (ResBlock (out_c, out_c))#注意输入,输出应该一样 return torch.nn.Sequential (*Sumlayers) #然后把构建好模型传出 #构建残差块 因为参数是变动的,所以引入变量,最后一个变量表示快捷通道个数,默认没有class ResBlock(torch.nn.Module): def __init__(self,in_c,out_c,stride=1,shortcut=None): super(ResBlock, self).__init__() #左边的公路 self.left=torch.nn.Sequential( torch.nn.Conv2d (in_c,out_c,3,stride,1), torch.nn.BatchNorm2d (out_c), torch.nn.ReLU (inplace=True), torch.nn.Conv2d (out_c,out_c,3,1,1),#注意 这里输入输出应该一样 torch.nn.BatchNorm2d (out_c) ) #右边的高速公路 self.right=shortcut #最后 self.last_y=torch.nn.ReLU() #前向 def forward(self, x): y_l=self.left(x) y_r = x if self.right is None else self.right (x) #如果有高数路为空,就直接保存在res中,否则执行高速路保存在res sum_x=y_l+y_r #两个总和 out=self.last_y(sum_x) return out 网络架构:Train.py文件: 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102import torchimport torch.nn as nnimport torchvision.datasets as datasetsimport torchvision.transforms as transformsfrom torch.autograd import Variable# 工具包import argparse# 载入网络from Resnet import Resnet#############参数设置#################命令行设置########parser = argparse.ArgumentParser (description='CNN') # 导入命令行模块# 对于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明parser.add_argument ('--batch-size', type=int, default=2, metavar='N', help='训练batch-size大小 (default: 2)')parser.add_argument ('--epochs', type=int, default=10, metavar='N', help='训练epochs大小 (default: 10)')parser.add_argument ('--lr', type=float, default=0.001, metavar='LR', help='学习率 (default: 0.001)')parser.add_argument ('--no-cuda', action='store_true', default=False, help='不开启cuda训练')parser.add_argument ('--seed', type=int, default=1, metavar='S', help='随机种子 (default: 1)')parser.add_argument ('--log-interval', type=int, default=1, metavar='N', help='记录等待n批次 (default: 1)')args = parser.parse_args () # 相当于激活命令args.cuda = not args.no_cuda and torch.cuda.is_available () # 判断gputorch.manual_seed (args.seed)if args.cuda: torch.cuda.manual_seed (args.seed) # 为CPU设置种子用于生成随机数，以使得结果是确定的##########数据转换#####################data_transforms = transforms.Compose ([transforms.Scale (224), # 通过调整比例调整大小,会报警 transforms.CenterCrop (224), # 在中心裁剪给指定大小方形PIL图像 transforms.ToTensor ()]) # 转换成pytorch 变量tensor###############数据载入################train_dataset = datasets.ImageFolder (root="./data/train/", # 保存目录 transform=data_transforms) # 把数据转换成上面约束样子test_dataset = datasets.ImageFolder (root='./data/test/', transform=data_transforms)##########数据如下##### # root/dog/xxx.png# # root/dog/xxy.png# # root/dog/xxz.png# ## # root/cat/123.png# # root/cat/nsdf3.png# # root/cat/asd932_.png####################################数据装载###############train_loader = torch.utils.data.DataLoader (dataset=train_dataset, # 装载数据 batch_size=args.batch_size, # 设置批大小 shuffle=True) # 是否随机打乱test_loader = torch.utils.data.DataLoader (dataset=test_dataset, batch_size=args.batch_size, shuffle=True)#############模型载入#################Resnet=Resnet ()if not args.no_cuda: print ('正在使用gpu') Resnet.cuda ()print (Resnet)###############损失函数##################criterion = nn.CrossEntropyLoss () # 内置标准损失optimizer = torch.optim.Adam (Resnet.parameters (), lr=args.lr) # Adam优化器#############训练过程#####################total_loss = 0 #内存循环使用for epoch in range (args.epochs): for i, (images, labels) in enumerate (train_loader): # 枚举出来 if not args.no_cuda: # 数据处理是否用gpu images = images.cuda () labels = labels.cuda () images = Variable (images) # 装箱 labels = Variable (labels) ##前向传播 optimizer.zero_grad () outputs = Resnet (images) # 损失 loss = criterion (outputs, labels) # 反向传播 loss.backward () optimizer.step ()#更新参数 total_loss += loss#内存循环使用 防止cuda超出内存 ##打印记录 if (i + 1) % args.log_interval == 0: print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f' % (epoch + 1, args.epochs, i + 1, len (train_dataset) // args.batch_size, loss.item ())) # 保存模型 torch.save (Resnet.state_dict (), 'Resnet.pkl') 结果: 注意残差的前向传播 ,一不小心都不知道自己哪里错了!!]]></content>
      <categories>
        <category>框架</category>
        <category>pytorch</category>
        <category>Resnet</category>
      </categories>
      <tags>
        <tag>Resnet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回顾-VGG]]></title>
    <url>%2F2018%2F12%2F19%2F%E5%9B%9E%E9%A1%BE-VGG%2F</url>
    <content type="text"><![CDATA[1. VGGNet 简介:1.VGG是由Simonyan 和Zisserman在文献《Very Deep Convolutional Networks for Large Scale Image Recognition》中提出卷积神经网络模型，其名称来源于作者所在的牛津大学视觉几何组(Visual Geometry Group)的缩写。 2.该模型参加2014年的 ImageNet图像分类与定位挑战赛，取得了优异成绩：在分类任务上排名第二，在定位任务上排名第一。 2. VGGNet 网络结构:根据VGG中根据卷积核大小和卷积层数目的不同,分为A,A-LRN,B,C,D,E共6个网络结构配置! D,E就是常用配置,也就是常说的VGG16和VGG19 如图: 1.为什么叫vgg16? 如图绿色(D配置),即VGG16配置, 1.用conv3表示3*3卷积,conv3-xx中的xx表示通道数(也就是有多少个这样的卷积核) 2.一共数下来 有13个conv3,3个FC(最下面那里),5个池化层(每个模块中间) 3.13(卷积)+3(全连接)=16,不加池化层,是因为池化层不涉及权重.所以d配置叫VGG16,其他以此类推! 官方图: 如图: 这个图又看出什么? 1.每个卷积层(上面的conv3-xx)里面是表示conv+relu(图中黑色方块注释) 2.看到红色方块(池化层)没,是不是经过它,似乎方块都变小1/2了! 即池化层采用的参数均为2*2,步幅stride=2，max的池化方式，这样就能够使得每一个池化层的宽和高是前一层的1/2。 输入图片大小变化图: 这个图又看出什么? 1.图片从224*244大小→112*112→56*56→28*28→ 14*14→7*7大小(图最左边Size),大小一直减半 2.卷积通道数(卷积核数量)从64–&gt;128–&gt;256–&gt;512,然后固定在512! 都是2倍数(因为计算机以2进制计算)—————-2是个好东西 计算量图: 注:memory=内存计算(红色),params=参数量计算(蓝色) 3.VGG优缺点: 优点: 1.VGGNet的结构非常简洁，整个网络都使用了同样大小的卷积核尺寸（3x3）和最大池化尺寸（2x2） 2.几个小滤波器（3x3）卷积层的组合比一个大滤波器（5x5或7x7）卷积层好 3.通过不断加深网络结构可以提升性能.具有很高的拟合能力(怎么加深?(这个网络告诉我们就像汉堡一样一层层堆叠上去)) 缺点: 1.训练时间过长(3个全连接啊(听说:发现这些全连接层即使被去除，对于性能也没有什么影响，这样就显著降低了参数数量))，调参难度大 2.需要的存储容量大，不利于部署。(单片机就那几MB可怜的空间) 4.PyTorch实现: 网络架构:VGG.py文件:1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162import torch'''今天这个有点难得堆一个个写,重复性太高,而且不利于观看,不优雅重复性事我们交给你喊函数完成'''#遵从原来步骤class VGG(torch.nn.Module): #初始化 def __init__(self): super(VGG, self).__init__() self.Sumlayers=self.make_layers()#这里我们交由make_layers函数创建相似的模块 #假设我们上面已经创好五个模块(文章第一幅图block1-&gt;block5) #现在创建最后的Fc self.fc=torch.nn.Sequential( torch.nn.Linear (7*7*512, 4096), # 第一个全连接 torch.nn.ReLU(), torch.nn.Linear (4096, 4096), # 第二个全连接 torch.nn.ReLU(), torch.nn.Linear (4096, 2), # 第三个全连接 # 原版1000类 最后分成2类 因为只有猫狗两个类 torch.nn.ReLU(), torch.nn.Softmax (dim=1), # 最后一个 softmax 不填dim=1会报警 1.0以前好像可以直接写Softmax () ) #前向传播 def forward (self, x): conv = self.Sumlayers (x) res = conv.view (conv.size (0), -1) # 展平多维的卷积图成 一维 out = self.fc(res) return out #构建刚才的构建模块函数make_layers def make_layers(self): #创建一个列表,用来快速构造模块,你也可以测试vgg19等等 vgg16=[64, 64, 'Maxpool', 128, 128, 'Maxpool', 256, 256, 256, 'Maxpool', 512, 512, 512, 'Maxpool', 512, 512, 512, 'Maxpool'] #创建一个列表,用来放后面层 ,后面我们直接往里面添加就可以了 Sumlayers=[] #创建一个变量，来控制 卷积参数输入大小（in_channels）和输出大小（out_channels） in_c = 3 #第一次输入大小 #遍历列表 for x in vgg16: #获取到每个配置,我这只有vgg16这一行 if x =='Maxpool':#如果遇到Maxpool ,我们就创建maxpool层 Sumlayers+=[torch.nn.MaxPool2d(kernel_size=2, stride=2)]#参数看上文 else: #否则我们创建conv(卷积模块) Sumlayers+= [torch.nn.Conv2d (in_channels=in_c,out_channels=x , kernel_size=3, padding=1), #x是列表中的参数 torch.nn.BatchNorm2d (x),#标准化一下 torch.nn.ReLU ()] in_c=x #输出大小成为下个输入大小 return torch.nn.Sequential (*Sumlayers) #然后把构建好模型传出 网络架构:train.py文件:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102import torchimport torch.nn as nnimport torchvision.datasets as datasetsimport torchvision.transforms as transformsfrom torch.autograd import Variable# 工具包import argparse# 载入网络from VGG import VGG#############参数设置#################命令行设置########parser = argparse.ArgumentParser (description='CNN') # 导入命令行模块# 对于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明parser.add_argument ('--batch-size', type=int, default=2, metavar='N', help='训练batch-size大小 (default: 2)')parser.add_argument ('--epochs', type=int, default=10, metavar='N', help='训练epochs大小 (default: 10)')parser.add_argument ('--lr', type=float, default=0.001, metavar='LR', help='学习率 (default: 0.001)')parser.add_argument ('--no-cuda', action='store_true', default=False, help='不开启cuda训练')parser.add_argument ('--seed', type=int, default=1, metavar='S', help='随机种子 (default: 1)')parser.add_argument ('--log-interval', type=int, default=1, metavar='N', help='记录等待n批次 (default: 1)')args = parser.parse_args () # 相当于激活命令args.cuda = not args.no_cuda and torch.cuda.is_available () # 判断gputorch.manual_seed (args.seed)if args.cuda: torch.cuda.manual_seed (args.seed) # 为CPU设置种子用于生成随机数，以使得结果是确定的##########数据转换#####################data_transforms = transforms.Compose ([transforms.Scale (224), # 通过调整比例调整大小,会报警 transforms.CenterCrop (224), # 在中心裁剪给指定大小方形PIL图像 transforms.ToTensor ()]) # 转换成pytorch 变量tensor###############数据载入################train_dataset = datasets.ImageFolder (root="./data/train/", # 保存目录 transform=data_transforms) # 把数据转换成上面约束样子test_dataset = datasets.ImageFolder (root='./data/test/', transform=data_transforms)##########数据如下##### # root/dog/xxx.png# # root/dog/xxy.png# # root/dog/xxz.png# ## # root/cat/123.png# # root/cat/nsdf3.png# # root/cat/asd932_.png####################################数据装载###############train_loader = torch.utils.data.DataLoader (dataset=train_dataset, # 装载数据 batch_size=args.batch_size, # 设置批大小 shuffle=True) # 是否随机打乱test_loader = torch.utils.data.DataLoader (dataset=test_dataset, batch_size=args.batch_size, shuffle=True)#############模型载入#################VGG=VGG ()if not args.no_cuda: print ('正在使用gpu') VGG.cuda ()print (VGG)###############损失函数##################criterion = nn.CrossEntropyLoss () # 内置标准损失optimizer = torch.optim.Adam (VGG.parameters (), lr=args.lr) # Adam优化器#############训练过程#####################total_loss = 0 #内存循环使用for epoch in range (args.epochs): for i, (images, labels) in enumerate (train_loader): # 枚举出来 if not args.no_cuda: # 数据处理是否用gpu images = images.cuda () labels = labels.cuda () images = Variable (images) # 装箱 labels = Variable (labels) ##前向传播 optimizer.zero_grad () outputs = VGG (images) # 损失 loss = criterion (outputs, labels) # 反向传播 loss.backward () optimizer.step ()#更新参数 total_loss += loss#内存循环使用 防止cuda超出内存 ##打印记录 if (i + 1) % args.log_interval == 0: print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f' % (epoch + 1, args.epochs, i + 1, len (train_dataset) // args.batch_size, loss.item ())) # 保存模型 torch.save (VGG.state_dict (), 'VGG.pkl') 结果如图: 注:如果提示内存不够,可以在命令行用下面命令训练:1python train.py --no-cuda --batch-size=2 因为我自带内存8g,显卡内存2g,所以我不用gpu跑]]></content>
      <categories>
        <category>框架</category>
        <category>pytorch</category>
        <category>VGG</category>
      </categories>
      <tags>
        <tag>VGG</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回顾-AlexNet]]></title>
    <url>%2F2018%2F12%2F18%2F%E5%9B%9E%E9%A1%BE-AlexNet%2F</url>
    <content type="text"><![CDATA[1. AlexNet 简介:AlexNet由Alex Krizhevsky于2012年提出，夺得2012年ILSVRC比赛的冠军，top5预测的错误率为16.4%，远超第一名。 2. AlexNet 网络结构:AlexNet采用8层的神经网络，5个卷积层和3个全连接层(3个卷积层后面加了最大池化层)，包含6亿3000万个链接，6000万个 参数和65万个神经元。 如图: 官方图: 3. AlexNet 改进点: 1.使用ReLU作为CNN的激活函数，验证了其效果在较深的网络中超过了Sigmoid.解决了Sigmoid在网络较深时的梯度弥散问题。 2.使用最大池化可以避免平均池化的模糊效果。同时重叠效果可以提升特征的丰富性。 3.提出LRN（Local Response Normalization，即局部响应归一化）层，对局部神经元的活动创建竞争机制，使得其中响应比较大的值变得相对更大，并抑制其他反馈较小的神经元，增强了模型的泛化能力。 4.数据增强，随机的从256*256的图片中截取224*224大小的区域（以及水平翻转的镜像），相当于增加了（256-224)*(2^2)=2048 倍的数据量，如果没有数据增强，模型会陷入过拟合中，使用数据增强可以增大模型的泛化能力。 5.使用CUDA加速神经网络的训练，利用了GPU强大的计算能力。 6.训练时使用Dropout随机忽略一部分神经元，以避免模型过拟合，一般在全连接层使用，在预测的时候是不使用Dropout的，即Dropout为1. 4.PyTorch实现: 网络架构:AlexNet.py文件:12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576import torch#跟着第一幅图走class AlexNet(torch.nn.Module): def __init__(self): super(AlexNet, self).__init__() # 输入图片大小 227*227*3 #第一层 self.conv1 = torch.nn.Sequential( #卷积 torch.nn.Conv2d(in_channels=3, out_channels=96, kernel_size=11, stride=4, padding=0), # (227-11)/4+1=55, 输出图片大小:55*55*96 torch.nn.ReLU(),#激活层 torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0) # (55-3)/2+1=27, 输出图片大小: 27*27*96 ) # 从上面获得图片大小27*27*96 self.conv2 = torch.nn.Sequential( torch.nn.Conv2d(in_channels=96, out_channels=256, kernel_size=5, stride=1, padding=2), # （27-5 + 2*2）/ 1 + 1 = 27, 输出图片大小:27*27*256 torch.nn.ReLU(), torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0) # (27 - 3 )/2 + 1 = 13, 输出图片大小:13*13*256 ) # 从上面获得图片大小13*13*256 self.conv3 = torch.nn.Sequential( torch.nn.Conv2d(in_channels=256, out_channels=384, kernel_size=3, stride=1, padding=1), # (13 - 3 +1*2)/1 + 1 = 13 , 输出图片大小:13*13*384 torch.nn.ReLU() ) # 从上面获得图片大小13*13*384 self.conv4 = torch.nn.Sequential( torch.nn.Conv2d(in_channels=384, out_channels=384, kernel_size=3, stride=1, padding=1), # (13 - 3 + 1*2)/1 +1 = 13, 输出图片大小:13*13*384 torch.nn.ReLU() ) # 从上面获得图片大小13*13*384 self.conv5 = torch.nn.Sequential( torch.nn.Conv2d(in_channels=384, out_channels=256, kernel_size=3, stride=1, padding=1), # (13 - 3 + 1*2) +1 = 13, 13*13*256 torch.nn.ReLU(), torch.nn.MaxPool2d(kernel_size=3, stride=2, padding=0) # (13 - 3 )/2 +1 =6, 6*6*256 ) # 从上面获得图片大小 6*6*256 = 9216 共9216输出特征 self.lostlayer = torch.nn.Sequential( #第六层 torch.nn.Linear(9216, 4096),#全连接 torch.nn.ReLU(),#激活层 torch.nn.Dropout(0.5),#以0.5&amp;几率随机忽略一部分神经元 #第七层 torch.nn.Linear(4096, 4096), torch.nn.ReLU(), torch.nn.Dropout(0.5), #第八层 torch.nn.Linear(4096, 2) # 最后输出2 ,因为只分猫狗两类 ) #前向传播 def forward(self, x): conv1_out = self.conv1(x) conv2_out = self.conv2(conv1_out) conv3_out = self.conv3(conv2_out) conv4_out = self.conv4(conv3_out) conv5_out = self.conv5(conv4_out) res = conv5_out.view(conv5_out.size(0), -1)#展平多维的卷积图成 一维(batch_size, 4096) out = self.lostlayer(res) return out 训练架构:train.py文件 猫狗10张图:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102import torchimport torch.nn as nnimport torchvision.datasets as datasetsimport torchvision.transforms as transformsfrom torch.autograd import Variable# 工具包import argparse# 载入网络from AlexNet import AlexNet#############参数设置#################命令行设置########parser = argparse.ArgumentParser (description='CNN') # 导入命令行模块# 对于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明parser.add_argument ('--batch-size', type=int, default=32, metavar='N', help='训练batch-size大小 (default: 32)')parser.add_argument ('--epochs', type=int, default=10, metavar='N', help='训练epochs大小 (default: 10)')parser.add_argument ('--lr', type=float, default=0.001, metavar='LR', help='学习率 (default: 0.001)')parser.add_argument ('--no-cuda', action='store_true', default=False, help='不开启cuda训练')parser.add_argument ('--seed', type=int, default=1, metavar='S', help='随机种子 (default: 1)')parser.add_argument ('--log-interval', type=int, default=1, metavar='N', help='记录等待n批次 (default: 1)')args = parser.parse_args () # 相当于激活命令args.cuda = not args.no_cuda and torch.cuda.is_available () # 判断gputorch.manual_seed (args.seed)if args.cuda: torch.cuda.manual_seed (args.seed) # 为CPU设置种子用于生成随机数，以使得结果是确定的##########数据转换#####################data_transforms = transforms.Compose([transforms.Scale(227),#通过调整比例调整大小,会报警 transforms.CenterCrop(227),#在中心裁剪给指定大小方形PIL图像 transforms.ToTensor ()])#转换成pytorch 变量tensor###############数据载入################train_dataset = datasets.ImageFolder(root="./data/train/", # 保存目录 transform=data_transforms) # 把数据转换成上面约束样子test_dataset = datasets.ImageFolder (root='./data/test/', transform=data_transforms)##########数据如下##### # root/dog/xxx.png# # root/dog/xxy.png# # root/dog/xxz.png# ## # root/cat/123.png# # root/cat/nsdf3.png# # root/cat/asd932_.png####################################数据装载###############train_loader = torch.utils.data.DataLoader (dataset=train_dataset, # 装载数据 batch_size=args.batch_size, # 设置批大小 shuffle=True) # 是否随机打乱test_loader = torch.utils.data.DataLoader (dataset=test_dataset, batch_size=args.batch_size, shuffle=True)#############模型载入#################AlexNet = AlexNet ()if not args.no_cuda: print ('正在使用gpu') AlexNet.cuda ()print (AlexNet)###############损失函数##################criterion = nn.CrossEntropyLoss () # 内置标准损失optimizer = torch.optim.Adam (AlexNet.parameters (), lr=args.lr) # Adam优化器#############训练过程#####################for epoch in range (args.epochs): for i, (images, labels) in enumerate (train_loader): # 枚举出来 if not args.no_cuda: # 数据处理是否用gpu images = images.cuda () labels = labels.cuda () images = Variable (images) # 装箱 labels = Variable (labels) ##前向传播 optimizer.zero_grad () outputs = AlexNet(images) # 损失 loss = criterion (outputs, labels) # 反向传播 loss.backward () optimizer.step () ##打印记录 if (i + 1) % args.log_interval == 0: print ('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f' % (epoch + 1, args.epochs, i + 1, len (train_dataset) // args.batch_size, loss.item ())) # 保存模型 torch.save (AlexNet.state_dict (), 'AlexNet.pkl') 效果如图:]]></content>
      <categories>
        <category>框架</category>
        <category>pytorch</category>
        <category>AlexNet</category>
      </categories>
      <tags>
        <tag>AlexNet</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[回顾-CNN]]></title>
    <url>%2F2018%2F12%2F17%2F%E5%9B%9E%E9%A1%BE-CNN%2F</url>
    <content type="text"><![CDATA[卷积神经网络通常包含以下几种层：1.卷积层（Convolutional layer）:卷积神经网路中每层卷积层由若干卷积单元组成，每个卷积单元的参数都是通过反向传播算法优化得到的。卷积运算的目的是提取输入的不同特征，第一层卷积层可能只能提取一些低级的特征如边缘、线条和角等层级，更多层的网络能从低级特征中迭代提取更复杂的特征。2.线性整流层（Rectified Linear Units layer, ReLU layer）:这一层神经的激活函数（Activation function）使用线性整流（Rectified Linear Units, ReLU）。就像容器 不管你水怎样流 放进去都是容器形状(这叫容器整流) 3.池化层（Pooling layer）:通常在卷积层之后会得到维度很大的特征，将特征切成几个区域，取其最大值或平均值，得到新的、维度较小的特征。4.全连接层（ Fully-Connected layer）:把所有局部特征结合变成全局特征，用来计算最后每一类的得分。 卷积层:1.局部感知:相当于看一副很大很大的图,你必须从图中一区域(感受野)开始挨个浏览(扫描),你就能知道这幅图到底是啥!有啥好处,一下看很大的图–身心疲惫,而且还不一定能看懂慢慢看,又优雅,又高尚,还能快速抓到要点(就像你看到有德玛西亚,你就可以知道跟lol有关)2.权值共享(参数共享)比说,刚花了一万的力气创造了猪八戒和孙悟空,猪八戒找的到吃的,孙悟空能打小怪兽,后面我遇到小怪兽就不用创造悟空了,直接拿过来打小怪兽就可以了!如果遇到肚子饿了,孙悟空就没用了,就可以用猪八戒找吃的! 所以参数共享能节省不必要的重复消耗,加快计算 池化层:池化（pool）即下采样（downsamples），目的是为了减少特征图。池化操作对每个深度切片独立，规模一般为 2＊2，相对于卷积层进行卷积运算，池化层进行的运算一般有以下几种： 最大池化（Max Pooling）。取4个点的最大值。这是最常用的池化方法。 均值池化（Mean Pooling）。取4个点的均值。 注: 池化操作将保存深度大小不变。 如果池化层的输入单元大小不是二的整数倍， 一般采取边缘补零（zero-padding）的方式补成2的倍数，然后再池化。 全连接层:全连接层 可相互转换 卷积层 常见卷积网络架构:输入 -&gt; [[卷积层(CONV) -&gt; 激活层(RELU)] N -&gt; 池化层(POOL)] M-&gt; [全连接(fc) -&gt; 激活层(RELU)]* K -&gt; 全连接(fc) PyTorch:网络架构:CNN.py文件:123456789101112131415161718import torch.nn as nnclass CNN(nn.Module): def __init__(self): super(CNN, self).__init__() # 输入MNIST 图片大小是(1,28,28) self.layer=nn.Sequential(nn.Conv2d(1,8,kernel_size=5,padding=2),#第一个参数,输入是1,表示输入图片通道为1 ,8表示输出,5卷积核大小,2补边大小 nn.BatchNorm2d(8),#归一化 nn.ReLU(),#激活层 nn.MaxPool2d(2),#池化层 到这 (8,28,28)图片就被池化成(8,14,14)了 ) self.fc=nn.Linear(14*14*8,10) #全连接层 第一个输入的特征数,第二个 输出的特征 (0-9) 共10特征 #前向传播 def forward(self, x): out=self.layer(x) out=out.view(out.size(0),-1)#展平多维的卷积图成 (batch_size, 32 * 7 * 7) out=self.fc(out) return out 训练架构:train.py文件1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162636465666768697071727374757677787980818283848586878889909192939495#pytorchimport torchimport torch.nn as nnimport torchvision.datasets as datasetsimport torchvision.transforms as transformsfrom torch.autograd import Variable#工具包import argparse#载入网络from CNN import CNN#############参数设置#################命令行设置########parser = argparse.ArgumentParser(description='CNN') #导入命令行模块#对于函数add_argumen()第一个是选项，第二个是数据类型，第三个默认值，第四个是help命令时的说明parser.add_argument('--batch-size', type=int, default=64, metavar='N', help='训练batch-size大小 (default: 64)')parser.add_argument('--epochs', type=int, default=10, metavar='N', help='训练epochs大小 (default: 10)')parser.add_argument('--lr', type=float, default=0.001, metavar='LR', help='学习率 (default: 0.001)')parser.add_argument('--no-cuda', action='store_true', default=False, help='不开启cuda训练')parser.add_argument('--seed', type=int, default=1, metavar='S', help='随机种子 (default: 1)')parser.add_argument('--log-interval', type=int, default=50, metavar='N', help='记录等待n批次 (default: 50)')args = parser.parse_args()#相当于激活命令args.cuda = not args.no_cuda and torch.cuda.is_available()#判断gputorch.manual_seed(args.seed)if args.cuda: torch.cuda.manual_seed(args.seed)#为CPU设置种子用于生成随机数，以使得结果是确定的 ###############数据载入################train_dataset=datasets.MNIST(root="./data/",#保存目录 train=True, #选择训练集 transform=transforms.ToTensor(), #把数据转换成pytorch张量 Tensor download=True) #是否下载数据集test_dataset=datasets.MNIST(root='./data/', train=False,#关闭 表示选择测试集 transform=transforms.ToTensor(), download=True)##############数据装载###############train_loader=torch.utils.data.DataLoader(dataset=train_dataset,#装载数据 batch_size=args.batch_size,#设置批大小 shuffle=True)#是否随机打乱test_loader=torch.utils.data.DataLoader(dataset=test_dataset, batch_size=args.batch_size, shuffle=True)#############模型载入#################cnn=CNN()if not args.no_cuda: print('正在使用gpu') cnn.cuda()print(cnn)###############损失函数##################criterion=nn.CrossEntropyLoss()#内置标准损失optimizer=torch.optim.Adam(cnn.parameters(),lr=args.lr)#Adam优化器#############训练过程#####################for epoch in range (args.epochs): for i, (images,labels) in enumerate(train_loader):#枚举出来 if not args.no_cuda:#数据处理是否用gpu images=images.cuda() labels=labels.cuda() images=Variable(images)#装箱 labels=Variable(labels) ##前向传播 optimizer.zero_grad() outputs=cnn(images) #损失 loss=criterion(outputs,labels) #反向传播 loss.backward() optimizer.step () ##打印记录 if (i+1)% args.log_interval==0: print('Epoch [%d/%d], Iter [%d/%d] Loss: %.4f' %(epoch+1, args.epochs, i+1, len(train_dataset)//args.batch_size, loss.item())) #保存模型 torch.save(cnn.state_dict(), 'cnn.pkl') 注: 数据集下载不下来,修改pytorch里面MNIST.py文件 效果如图:]]></content>
      <categories>
        <category>框架</category>
        <category>pytorch</category>
        <category>CNN</category>
      </categories>
      <tags>
        <tag>CNN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fastai-入门视觉]]></title>
    <url>%2F2018%2F12%2F15%2Ffastai-%E5%85%A5%E9%97%A8%E8%A7%86%E8%A7%89%2F</url>
    <content type="text"><![CDATA[来自官方文档!! 视觉库概览:1.visionfastai库的模块包含定义数据集和训练计算机视觉任务模型的所有必要功能。它包含四个不同的子模块来实现该目标： 2.vision.image包含Image对象的基本定义以及在后台使用的所有函数，以将转换应用于此类对象。 3.vision.transform 包含我们可用于数据扩充的所有变换。 4.vision.data包含定义ImageClassificationDataset以及实用功能，以轻松构建DataBunch计算机视觉问题。 5.vision.learner 允许您使用预训练的CNN骨干构建和微调模型，或从头开始训练随机​​初始化的模型。 12345678910111213141516171819202122232425262728293031323334353637383940414243#首先，从fastai库导入您需要的所有内容。from fastai.vision import* #导入计算机视觉库from fastai import * #导入常用库## 首先，创建一个包含MNIST子集的数据文件夹# ，data/mnist_sample使用这个小帮助程序，为您下载它：path=untar_data(URLs.MNIST_SAMPLE)#print(path)#由于下载文件家包含标准文件夹train和valid文件夹，并且每个文件夹包含一个文件夹# ，因此您可以DataBunch在一行中创建：data=ImageDataBunch.from_folder(path)# 复习：# from_folder：从imagenet风格数据集创建# path与train，valid，test子文件夹# （或提供valid_pct）# “ Imagenet风格 ”数据集看起来像这样（请注意，测试文件夹是可选的）：# path\# train\# clas1\# clas2\# ...# valid\# clas1\# clas2\# ...# test\#加载一个预训练模型（从vision.models）准备进行微调：learn=create_cnn(data,models.resnet18,metrics=accuracy)#完成所有工作 开始训练learn.fit(1) ok 就这么暴力,完了!!!让我想起了sklearn! 下面来回头看下:1234567891011#############################################回 顾##########################################首先来看最重要数据长什么样#print(data)#可以通过获取相应的属性来访问该训练集和验证集ds = data.train_ds# print(ds)# 1234567891011121314# 我们顺便看看vision.image，它定义了Image类。# 我们的数据集将在索引时返回Image对象。from fastai.vision import Imageimport matplotlib.pyplot as pltimg,label=ds[0]#print(img)#换种方式显示图片img.show(figsize=(2, 1), title='Little ')#同时 你还可以改变它#如旋转img.rotate(35) 12345678910111213141516171819202122232425#下面来看看数据增强方式# vision.transform让我们进行数据扩充。# 最简单的方法是从一组标准变换中进行选择，# 其中默认值是为图片设计的#print(help(get_transforms))#创建你想要的列表tfms=[rotate(degrees=(-20,20)),symmetric_warp(magnitude=(-0.3,0.3))]print(tfms)#可以使用apply tfms方法将这些变换应用于图像fig,axes=plt.subplots(1,4,figsize=(8,2))print(fig,axes)for ax in axes: ds[0][0].apply_tfms(tfms).show(ax=ax)# 您可以使用转换后的训练和验证数据加载器在单个步骤中# 创建一个数据库，并传入一个元组（train_TFMS，valid_TFMS）data=ImageDataBunch.from_folder(path,ds_tfms=(tfms,[]))print(data) 1234567891011121314151617181920212223242526##############################################3#下面来看训练过程# 现在你已准备好训练一个模型。要创建模型，# 只需将您的DataBunch和模型创建函数# （例如vision.models或torchvision.models提供的函数）# 传递给create_cnn，并调用fit：learn=create_cnn(data,models.resnet18,metrics=accuracy,callback_fns = ShowGraph)learn.fit(100)#接下来我们看一下最不正确的图像，以及分类矩阵。interp=ClassificationInterpretation.from_learner(learn)interp.plot_top_losses(9,figsize=(6,6))interp.plot_confusion_matrix()# 要简单地预测新图像的结果（类型为image，# 例如用open image打开），# 只需使用learn.predict。它返回类，它的索引# 和每个类的概率。img=learn.data.train_ds[0][0]print(learn.predict(img)) ** 要显示图像记得添加(我是在最后直接显示:1plt.show()]]></content>
      <categories>
        <category>框架</category>
        <category>pytorch</category>
        <category>fastai</category>
      </categories>
      <tags>
        <tag>fastai</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[fastai-安装]]></title>
    <url>%2F2018%2F12%2F15%2Ffastai-%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[来自官方文档!!!! 前提:注意:Python:需要python3.6及其以上 fastai需要pytorch1.0以上 pytorch1.0可直接安装: 平台 GPU cpu Linux 直接安装 直接安装 Mac 源码安装 直接安装 Windows 直接安装 直接安装 具体更新,请看官方:https://pytorch.org/***# cpu安装:conda 安装：12conda install -c pytorch pytorch-cpu torchvisionconda install -c fastai fastai pip 安装： 12pip install http://download.pytorch.org/whl/cpu/torch-1.0.0-cp36-cp36m-linux_x86_64.whlpip install fastai*# Gpu安装: 注意对应cuda版本,以下以9.2为例conda 安装：12conda install -c pytorch pytorch-nightly cuda92conda install -c fastai fastai pip 安装： 123pip install torch_nightly -f https://download.pytorch.org/whl/nightly/cu90/torch_nightly.htmlpip install --index-url https://test.pypi.org/simple/ --extra-index-url https://pypi.orgpip install fastai***下图给liunx用户安装cuda提醒: CUDA工具包 NVIDIA（Linux x86_64）显卡驱动 CUDA 10.0 &gt; = 410.00 CUDA 9.0 &gt; = 384.81 CUDA 8.0 &gt; = 367.48]]></content>
      <categories>
        <category>框架</category>
        <category>pytorch</category>
        <category>fastai</category>
      </categories>
      <tags>
        <tag>fastai</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[小玩具-VIP视频解析界面]]></title>
    <url>%2F2018%2F12%2F14%2F%E5%B0%8F%E7%8E%A9%E5%85%B7-VIP%E8%A7%86%E9%A2%91%E8%A7%A3%E6%9E%90%E7%95%8C%E9%9D%A2%2F</url>
    <content type="text"><![CDATA[需要下列工具: QT-designer(用于快速构造界面) QT-pyuic(用于把刚才界面转换成py文件,方便设计) main.py空文件(用于储存页面逻辑) url.txt(用于储存解析网址) 背景图一张(可选) 第一步:直接打开QT-designer拖动组件设计出如下界面: 第二步:用Qt-pyuic (python文件里面的Scripts) 将设计好的转换成.py文件 如在生成.ui文件下 运行命令 1pyuic5 -o 文件名.py 文件名.ui 注: 如果找不到pyuic5 看是否将Scripts加入了环境变量 然后可以看到生成对应的.py文件 我是生成ui.py,如图:123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566from PyQt5 import QtCore, QtGui, QtWidgetsimport sysclass Ui_widget(object): def setupUi(self, widget): widget.setObjectName("widget") widget.setEnabled(True) widget.resize(416, 667) widget.setFixedSize(widget.width(), widget.height()) self.label = QtWidgets.QLabel(widget) self.label.setGeometry(QtCore.QRect(30, 10, 191, 17)) self.label.setObjectName("label") self.lineEdit = QtWidgets.QLineEdit(widget) self.lineEdit.setGeometry(QtCore.QRect(0, 35, 301, 21)) self.lineEdit.setObjectName("lineEdit") self.label_2 = QtWidgets.QLabel(widget) self.label_2.setGeometry(QtCore.QRect(0, 60, 391, 21)) self.label_2.setObjectName("label_2") self.pushButton_run = QtWidgets.QPushButton(widget) self.pushButton_run.setGeometry(QtCore.QRect(310, 30, 89, 31)) self.pushButton_run.setObjectName("pushButton_run") self.label_3 = QtWidgets.QLabel(widget) self.label_3.setGeometry(QtCore.QRect(90, 170, 211, 20)) self.label_3.setObjectName("label_3") self.gridLayoutWidget = QtWidgets.QWidget(widget) self.gridLayoutWidget.setGeometry(QtCore.QRect(10, 200, 401, 451)) self.gridLayoutWidget.setObjectName("gridLayoutWidget") self.gridLayout = QtWidgets.QGridLayout(self.gridLayoutWidget) names=['优酷','土豆','爱奇艺','芒果','乐视','腾讯','搜狐','PPTV','360视','暴风影音','M1905','咪咕视频', '音悦台','哔哩哔哩','华数TV','网易公开课','新浪视频','范特西','M3U8','私有云','韩国DAUM' ,'品善网','开眼视频' ,'优米网','好看视频','美拍','2MM','凤凰视频','Naver','糖豆网','秒拍','快手','17173','梨视频','中国蓝','第一视频' ,'爱拍视频','汽车之家','ECHOMV','东方头条','今日头条','阳光宽频','西瓜视频','酷6视频','CCTV央视','27盘','91广场舞', '爆米花','火猫直播','酷狗MV','酷狗MV','QQ音乐MV','酷狗直播','酷狗LIVE','天天看看','激动网','斗鱼视频','斗鱼直播', '虎牙视频','虎牙直播','熊猫星颜','熊猫直播','战旗视频','战旗直播','龙珠视频','龙珠直播','来疯直播','触手视频','触手直播','花椒直播','花椒视频' ,'全民直播','全民视频','CC直播','CC视频','印客直播','YY神曲','YY回放','YY小','一直播','NOW直播' ] posittions=[(i,j)for i in range(19) for j in range(5)] for posittions,name in zip(posittions,names): label=QtWidgets.QLabel(name) label.setStyleSheet("font:10pt;color:rgb(0,0, 255);font-weight:40px;") self.gridLayout.addWidget(label,*posittions) self.gridLayout.setContentsMargins(0, 1, 2, 0) self.gridLayout.setObjectName("gridLayout") self.pushButton_switch = QtWidgets.QPushButton(widget) self.pushButton_switch.setGeometry(QtCore.QRect(100, 110, 171, 31)) self.pushButton_switch.setObjectName("pushButton_switch") self.retranslateUi(widget) QtCore.QMetaObject.connectSlotsByName(widget) def retranslateUi(self, widget): _translate = QtCore.QCoreApplication.translate widget.setWindowTitle(_translate("widget", "VIP会员-新")) self.label.setText(_translate("widget", "视频网页最上面网址(链接):")) self.label_2.setText(_translate("widget", "复制VIP视频的地址到↑↑↑上栏中点击立即播放就行了")) self.pushButton_run.setText(_translate("widget", "开始播放")) self.pushButton_run.setStyleSheet("color:rgb(255,0,0)") self.label_3.setText(_translate("widget", "↓↓现支持以下免费播放↓↓")) self.pushButton_switch.setText(_translate("widget", "如果不能播放用力点我")) self.pushButton_switch.setStyleSheet("background: rgb(0,191,255);color:rgb(128,0,0)") self.pushButton_run.setStyleSheet ("background: rgb(0,191,255);color:rgb(128,0,0)") 如果想看看界面,可以创建test.py,输入123456789101112#继承窗口class MainWindow(QMainWindow): def __init__(self): super(MainWindow, self).__init__() self.ui = Ui_widget() self.ui.setupUi(self) if __name__ =='__main__': app = QApplication (sys.argv) win1 = MainWindow ()# 创建实例 win1.show () app.exec_ () 第三步: 有了界面,还需要个播放窗口! 为了简单,直接使用了浏览器当窗口! 代码如下: 123456789101112131415161718192021222324class ScreenWindow (QMainWindow): def __init__ (self,url): super (ScreenWindow, self).__init__ () self.setWindowTitle('vip视频影院') self.setGeometry(5,30,1355,730) self.browser=QWebEngineView() self.browser.settings().setAttribute(QWebEngineSettings.PluginsEnabled, True) # 支持视频播放 self.browser.settings().setAttribute(QWebEngineSettings.JavascriptEnabled, True) self.browser.settings().setAttribute(QWebEngineSettings.FullScreenSupportEnabled, True) # self.browser.page().fullScreenRequested.connect(self._fullScreenRequested) self.browser.load (QUrl (url)) self.setCentralWidget(self.browser) # # def _fullScreenRequested(request): # request.accept() # w.showFullScreen() def screendisplay(self): if not self.isVisible (): self.show () 注:中间那三行,为了加载flash插件,不然播放不了视频 最后一行,为了让用户点击触发显示函数 传入参数url 是为了让用户切换解析接口 url来自下面↓ 最后一步: 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556 class MainWindow(QMainWindow): def __init__(self): super(MainWindow, self).__init__() self.ui = Ui_widget() self.ui.setupUi(self) url=self.switch() #print(url) self.setIcon() self.ui.pushButton_run.clicked.connect (self.TwoT) self.ui.pushButton_switch.clicked.connect (self.TwoT) def TwoT(self): url = self.switch () self.win2 = ScreenWindow (url) self.win2.screendisplay() def setIcon (self): palette1 = QPalette () # palette1.setColor(self.backgroundRole(), QColor(192,253,123)) # 设置背景颜色.scaled(self.width(), self.height() palette1.setBrush (self.backgroundRole (), QBrush (QPixmap ('d.png'))) # 设置背景图片 self.setPalette (palette1) self.setAutoFillBackground(True) # 不设置也可以 self.setWindowIcon (QIcon ('d.png')) def addurl(self): url = self.ui.lineEdit.text () return url def switch(self): countmax = len (open ('url', 'r').readlines ()) count=random.randint(0,countmax-1) if count &gt;= countmax-1: count = random.randint(0,countmax-1) else: count += 1 with open ('url', 'r') as f: vurl = f.readlines () vurl = vurl [count].replace ('\n', '') qurl = vurl + self.addurl() #print(qurl) return qurlif __name__ =='__main__': #argvs = sys.argv # 支援flash #argvs.append('--ppapi-flash-path=./pepflashplayer.dll') app = QApplication (sys.argv) win1 = MainWindow () win1.show () app.exec_ () **注: 初始化函数__init__中 :继承窗口界面,两个触发函数 TWoT:触发函数触发事件(运行切换函数,生成播放窗口) setIcon:设置界面背景 addurl:读取用户输入url switch:随机取url文件里的解析口和用户输入url组成新的url URL文件: 1234567891011121314 https://jx.lache.me/cc/?url=Https://al.lache.me/vip/?url=https://2wk.com/vip.php?url=http://api.bbbbbb.me/jx/?url=https://www.myxin.top/jx/api/?url=http://www.syhbyl.tw/jx/api/?url=https://vip.hackmg.com/jx/index.php?url=http://jx.wslmf.com/?url=http://api.52xmw.com/?url=http://yun.baiyug.cn/vip/index.php?url=https://jx.lache.me/cc/?url=Https://al.lache.me/vip/?url=https://jx.lache.me/cc/?url=Https://al.lache.me/vip/?url= 最后创建窗口,启动! 注:无法观看,请下载flashplay (虽然已被淘汰) over ***想要一键运行: 创建run.bat文件 输入:1python main.py 保存 就可以点击运行 github: 项目地址点我]]></content>
      <categories>
        <category>界面</category>
        <category>pyqt</category>
      </categories>
      <tags>
        <tag>pyqt5</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[漂亮又简洁的hexo编辑器hexoEditor]]></title>
    <url>%2F2018%2F11%2F05%2F%E6%BC%82%E4%BA%AE%E5%8F%88%E7%AE%80%E6%B4%81%E7%9A%84hexo%E7%BC%96%E8%BE%91%E5%99%A8hexoEditor%2F</url>
    <content type="text"><![CDATA[地址： 项目地址 ：点我 功能 HexoEditor 预览内容与 Hexo 生成页面内容高度相似 支持 Hexo 原生 Tag/Filter/Renderer 支持使用 Hexo 配置文件 _config.yml 快速生成 新Post 到项目资源路径下 快速修改文件名(在Hexo编辑模式中) 快速部署 快速执行Hexo命令 hexo d,hexo g,hexo s,hexo clean 图片自动转换为Markdown格式 支持拖拽图片 支持剪贴板粘贴 图床支持(一键上传) 支持 SM.MS 支持 QiNiu 支持 Tencent 快速启动（常用目录，常用地址） 滚动条启用/取消同步滚动 HexoEditor (继承 Moeditor 原有功能) GitHub 风格 Markdown 显示 TeX math 表达式 UML 设计图 编辑框代码高亮显示 只读/只写/预览多模式切换 用户自定义 字体，行高，字体大小 用户自定义主题（文件名：main.csss） 高亮代码块皮肤切换(由 highlight.js 提供支持) 自动重载文件 本地化 专注模式 截图 动态截图 计划要做的 添加目录 添加标题头设置(100%) 添加基本语法快捷键 添加历史文件树木….. 快速部署 多标签编辑显示 快捷键 按键 方法 说明 Tab tabAdd 添加缩进 Shift - Tab tabSubtract 减少缩进 Ctrl - B toggleBlod 切换粗体 Ctrl - I toggleItalic 切换斜体 Ctrl - D toggleDelete 删除当前行 Ctrl - ` toggleComment 切换注解 Ctrl - L toggleUnOrderedList 切换无序列表 Ctrl - Alt - L toggleOrderedList 切换有序列表 Ctrl - ] toggleHeader 降级标题 Ctrl - [ toggleUnHeader 升级标题 Ctrl - = toggleBlockquote 增加引用 Ctrl - - toggleUnBlockquote 减少引用 Ctrl - U drawLink 添加超级链接 Ctrl - Alt - U drawImageLink 添加图片 Ctrl - T drawTable(row col) 添加表格(行 列) Ctrl - V pasteOriginContent 源内容粘贴 Shift - Ctrl - V pasteContent 智能粘贴 Alt - F formatTables 格式化表格 Ctrl - N 新建md文档 Ctrl - H 新建Hexo文档 Ctrl - O 打开md文件 Ctrl - S 保存文档 Shift - Ctrl - S 另存为 Alt - Ctrl - S 打开设置 Ctrl - W 切换写作模式 Ctrl - P 切换预览模式 Ctrl - R 切换阅读模式 提示: 在 Mac OS下, 请使用 Cmd 来代替 Ctrl . 安装12345678910111213141516//如果使用 Windows:npm config set prefix "C:/Program Files/nodejs/npm_global"npm config set cache "C:/Program Files/nodejs/npm_cache" //如果使用 Linux\Mac:npm config set prefix "~/nodejs/npm_global"npm config set cache "~/nodejs/npm_cache" //在中国，中国，中国，你应该设置淘宝镜像来加速下载。npm config set registry "https://registry.npm.taobao.org/"npm config set electron_mirror "https://npm.taobao.org/mirrors/electron/"git clone https://github.com/zhuzhuyule/HexoEditor.gitcd HexoEditornpm installnpm start 这里是 详细安装方式 国内，如果想要提高下载速度，请使用 cnpm 来代替 npm，命令如下 。 调试模式这里有三种方法打开 Chrome开发者工具. 启动命令行添加参数 --debug : 1npm start -- --debug 使用快捷键：Linux / Windows： Ctrl + Shift + IOS X / macOS ： Command + Option + I 在 config 设置 debug: true。 配置文件在缓存中，路径：123windows: %USERPROFILE%\.config\configstore\HexoEditor.jsonlinux : ~/.config/configstore/HexoEditor.jsonmac : ~/.config/configstore/HexoEditor.json( 待确认) 本地化HexoEditor将自动识别系统语言并使用对应语言包。 你也可以通过设置手动设置语言包。 目前支持：简体中文，英语，法语，德语，西班牙语，俄语 和 不完整的葡萄牙语。 帮助 如果你可以帮助翻译，请修改 app/moe-l10n.js. 许可证HexoEditor 使用许可证为 GPL v3 许可. 一些Node模块使用其他的免费许可证书。 Raleway 字体许可证书为 OFL(Open Font License)。 提示 请修改插件 codemirror，文件路径 : ./node_modules/codemirror/lib/codemirror.js (line: 3104) ./node_modules/codemirror/src/display/selection.js (line: 56) 12//var rightSide = Math.max(display.sizerWidth, displayWidth(cm) - display.sizer.offsetLeft) - padding.right;var rightSide = display.lineDiv.offsetWidth - padding.right; 兼容性 :triangular_flag_on_post: NexT theme]]></content>
      <categories>
        <category>网站</category>
        <category>hexo</category>
      </categories>
      <tags>
        <tag>hexo</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第十五节：正则表达式]]></title>
    <url>%2F2018%2F05%2F30%2F%E7%AC%AC%E5%8D%81%E4%BA%94%E8%8A%82%EF%BC%9A%E6%AD%A3%E5%88%99%E8%A1%A8%E8%BE%BE%E5%BC%8F%2F</url>
    <content type="text"><![CDATA[1.1正则表达式的大致匹配过程是：1.依次拿出表达式和文本中的字符比较， 2.如果每一个字符都能匹配，则匹配成功；一旦有匹配不成功的字符则匹配失败。 3.如果表达式中有量词或边界，这个过程会稍微有一些不同。 1.2. 数量词的贪婪模式与非贪婪模式正则表达式通常用于在文本中查找匹配的字符串。 贪婪模式，总是尝试匹配尽可能多的字符； 非贪婪模式则相反，总是尝试匹配尽可能少的字符。 Python里数量词默认是贪婪的。 例如：正则表达式”ab“如果用于查找”abbbc”，将找到”abbb”。 而如果使用非贪婪的数量词”ab?”，将找到”a”。 正则表达式 代表的匹配字符 [0-9] 0123456789任意之一 [a-z] 小写字母任意之一 [A-Z] 大写字母任意之一 \d 等同于[0-9] \D 等同于[^0-9]匹配非数字 \w 等同于[a-z0-9A-Z_]匹配大小写字母、数字和下划线 \W 等同于[^a-z0-9A-Z_]等同于上一条取非 下面列举一些正则表达式里的元字符及其作用 元字符 说明 . 代表任意字符 | 逻辑或操作符 [ ] 匹配内部的任一字符或子表达式 [^] 对字符集和取非 - 定义一个区间 \ 对下一字符取非（通常是普通变特殊，特殊变普通） * 匹配前面的字符或者子表达式0次或多次 *? 惰性匹配上一个 + 匹配前一个字符或子表达式一次或多次 +? 惰性匹配上一个 ? 匹配前一个字符或子表达式0次或1次重复 {n} 匹配前一个字符或子表达式 {m,n} 匹配前一个字符或子表达式至少m次至多n次 {n,} 匹配前一个字符或者子表达式至少n次 {n,}? 前一个的惰性匹配 ^ 匹配字符串的开头 \A 匹配字符串开头 $ 匹配字符串结束 [\b] 退格字符 \c 匹配一个控制字符 \d 匹配任意数字 \D 匹配数字以外的字符 \t 匹配制表符 \w 匹配任意数字字母下划线 \W 不匹配数字字母下划线 1.3. 反斜杠的问题与大多数编程语言相同，正则表达式里使用”\“作为转义字符，这就可能造成反斜杠困扰。 假如你需要匹配文本中的字符”\“，那么使用编程语言表示的正则表达式里将需要4个反斜杠”\\\“： Python里的原生字符串很好地解决了这个问题，这个例子中的正则表达式可以使用r”\\”表示。 同样，匹配一个数字的”\\d”可以写成r”\d”。 有了原生字符串，妈妈再也不用担心我的反斜杠问题 2.1. recompile(pattern[,flags] ) 根据包含正则表达式的字符串创建模式对象。 match()决定 RE 是否在字符串刚开始的位置匹配 search()扫描字符串，找到这个 RE 匹配的位置 findall()找到 RE 匹配的所有子串，并把它们作为一个列表返回 finditer()找到 RE 匹配的所有子串，并把它们作为一个迭代器返回 split()将字符串在 RE 匹配的地方分片并生成一个列表， sub()找到 RE 匹配的所有子串，并将其用一个不同的字符串替换 subn()与 sub() 相同，但返回新的字符串和替换次数 res = re.match(pattern, string, flags=0) #字符串的开头是否能匹配正则表达式。返回_sre.SRE_Match对象，如果 #不能匹配返回None。 # 如果匹配的话，res.string可以获得原始的字符串，并不是匹配的字符串 re.sub(pattern, repl, string, count=0, flags=0) #找到 RE 匹配的所有子串，并将其用repl替换。可选参数 #count 是模式匹配後替换的最大次数；count 必须是非负整数。缺省值 #是 0 表示替换所有的匹配。如果无匹配，字符串将会无改变地返回。如 #果有匹配,则返回替换后的字符串 # pattern=&apos;he$&apos; 尾部匹配 # pattern=&apos;^he&apos; 头部匹配，等价于match re.findall(pattern,string) # 从 string中找到所有 匹配 pattern的子串，作为列表返回 #如果没有匹配的话，返回空数组，可用来当做if的判断条件 #空数组为False # pattern=&apos;he$&apos; 尾部匹配 # pattern=&apos;^he&apos; 头部匹配，等价于match re.search(pattern, string) #顾名思义，查找，如果找到返回一个match对象，找不到，返回None。 # pattern=&apos;he$&apos; 尾部匹配 # pattern=&apos;^he&apos; 头部匹配，等价于match]]></content>
      <categories>
        <category>学习</category>
        <category>教学</category>
      </categories>
      <tags>
        <tag>课后解答</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第十四节：推导表达式，迭代器，生成器，模块，包]]></title>
    <url>%2F2018%2F05%2F28%2F%E7%AC%AC%E5%8D%81%E5%9B%9B%E8%8A%82%EF%BC%9A%E6%8E%A8%E5%AF%BC%E8%A1%A8%E8%BE%BE%E5%BC%8F%EF%BC%8C%E8%BF%AD%E4%BB%A3%E5%99%A8%EF%BC%8C%E7%94%9F%E6%88%90%E5%99%A8%EF%BC%8C%E6%A8%A1%E5%9D%97%EF%BC%8C%E5%8C%85%2F</url>
    <content type="text"><![CDATA[[danger] 一：推导表达式：一、列表推导式和生成器表达式1 #列表推导式2 l = [i for i in range(10)] 3 print(l) 4 l1 = [‘选项%s’%i for i in range(10)] 5 print(l1) 1.把列表解析的[]换成()得到的就是生成器表达式 2.列表解析与生成器表达式都是一种便利的编程方式，只不过生成器表达式更节省内存 3.Python不但使用迭代器协议，让for循环变得更加通用。大部分内置函数，也是使用迭代器协议访问对象的。例如， sum函数是Python的内置函数，该函数使用迭代器协议访问对象，而生成器实现了迭代器协议，所以，我们可以直接这样计算一系列值的和： 1 sum(x ** 2 for x in range(4)) 二、列表推导式下面是一个以列表推导式为例的推导式详细格式，同样适用于其他推导式。 1 variable = [out_exp_res for out_exp in input_list if out_exp == 2] 2 out_exp_res: 列表生成元素表达式，可以是有返回值的函数。 3 for out_exp in input_list： 迭代input_list将out_exp传入out_exp_res表达式中。 4 if out_exp == 2： 根据条件过滤哪些值可以。 56 #变量（加工后的变量） for 变量 in 可迭代数据类型 条件判断 例一：30以内所有能被3整除的数1 multiples = [i for i in range(30) if i % 3 is 0] 2 print(multiples) 3 # Output: [0, 3, 6, 9, 12, 15, 18, 21, 24, 27] 例二：30以内所有能被3整除的数的平方1 def squared(x): 2 return x*x 3 multiples = [squared(i) for i in range(30) if i % 3 is 0] 4 print(multiples) 例三:找到嵌套列表中名字含有两个‘e’的所有名字1 names = [[‘Tom’, ‘Billy’, ‘Jefferson’, ‘Andrew’, ‘Wesley’, ‘Steven’, ‘Joe’], 2 [‘Alice’, ‘Jill’, ‘Ana’, ‘Wendy’, ‘Jennifer’, ‘Sherry’, ‘Eva’]] 34 print([name for lst in names for name in lst if name.count(‘e’) &gt;= 2]) # 注意遍历顺序，这是实现的关键 列表推导**+**条件判断： l2 = [iforiinrange(1, 11) ifi % 2 == 0] 列表推导**+**三目运算： l3 = [i if i % 2 == 0 else 0 for i in range(1, 11)] 三、字典推导式例一：将一个字典的key和value对调1 mcase = {‘a’: 10, ‘b’: 34} 2 #mcase的值 : key3 mcase_frequency = {mcase[k]: k for k in mcase} 4 print(mcase_frequency) 例二：合并大小写对应的value值，将k统一成小写1 mcase = {‘a’: 10, ‘b’: 34, ‘A’: 7, ‘Z’: 3} 2 #key.lower() : mcase.get(小写的当前key,0) + mcase.get(大写的当前key,0)3 #如果没有找到的话，get返回0.和0相加还是原来数4 mcase_frequency = {k.lower(): mcase.get(k.lower(), 0) + mcase.get(k.upper(), 0) for k in mcase.keys()} 5 print(mcase_frequency) 四、集合推导式例：计算列表中每个值的平方，自带去重功能二：迭代器和生成器：迭代器迭代是Python最强大的功能之一，是访问集合元素的一种方式。 迭代器是一个可以记住遍历的位置的对象。 迭代器对象从集合的第一个元素开始访问，直到所有的元素被访问完结束。迭代器只能往前不会后退。 迭代器有两个基本的方法： _iter__方法：返回迭代器自身。可以通过python内建函数iter()调用。 __next__方法：当next方法被调用的时候，迭代器会返回它的下一个值，如果next方法被调用，但迭代器没有只可以返回，就会引发一个StopIteration异常。该方法可以通过 python 内建函数next()调用。 字符串，列表或元组对象都可用于创建迭代器： 生成器简单的说，生成是包含yield关键字的函数。本质上来说，关键字yield是一个语法糖，内部实现支持了迭代器协议，同时yield内部是一个状态机，维护着挂起和继续的状态。 跟普通函数不同的是，生成器是一个返回迭代器的函数，只能用于迭代操作，更简单点理解生成器就是一个迭代器。 在调用生成器运行的过程中，每次遇到 yield 时函数会暂停并保存当前所有的运行信息，返回 yield 的值, 并在下一次执行 next() 方法时从当前位置继续运行。 调用一个生成器函数，返回的是一个迭代器对象。 三，模块：Python 模块(Module)，是一个 Python 文件，以 .py 结尾，包含了 Python 对象定义和Python语句。 模块让你能够有逻辑地组织你的 Python 代码段。 把相关的代码分配到一个模块里能让你的代码更好用，更易懂。 模块能定义函数，类和变量，模块里也能包含可执行的代码。 import 语句模块的引入模块定义好后，我们可以使用 import 语句来引入模块，语法如下： from…import 语句Python 的 from 语句让你从模块中导入一个指定的部分到当前命名空间中。语法如下： from…import* 语句把一个模块的所有内容全都导入到当前的命名空间也是可行的，只需使用如下声明： 搜索路径当你导入一个模块，Python 解析器对模块位置的搜索顺序是： 1、当前目录 2、如果不在当前目录，Python 则搜索在 shell 变量 PYTHONPATH 下的每个目录。 3、如果都找不到，Python会察看默认路径。UNIX下，默认路径一般为/usr/local/lib/python/。 模块搜索路径存储在 system 模块的 sys.path 变量中。变量里包含当前目录，PYTHONPATH和由安装过程决定的默认目录 四，包及包的管理包概念： 把很多模块放到一个文件夹里面，就可以形成一个包 包管理： 当把很多模块放在文件中时，为了方便引用包中的模块，引入了包管理 在包管理中，加入此模块，则包名可以直接通过属性访问的方式，访问此模块内的对象，此模块不加上可能不会报错，但是规范是要加上，文件内容可以为空 相对路径导入**:** 在包管理中，可以通过 . (一个点) 和 .. (两个点)分别来导入同层和上一层的模块 引入作用: 在包中，如果包中模块要导入同一包中的其他模块，就必须使用此方法导入 使用方法： from .module(..module) import obj (as new_name) 引入之后的影响: 当一个模块中出现此导入方式，则该模块不能被直接运行，只能被导入 我的理解是 from . import XXX默认的就是在当前程序所在文件夹里__init__.py程序中导入XXX，如果当前程序所在文件夹里没有__init__.py文件的话，就不能这样写，而应该写成from .A import XXX，A是指当前文件夹下你想导入的函数(或者其他的)的python程序名，如果你想导入的函数不在当前文件夹，那么就有可能用到 from .. import XXX(即上一个文件夹中的__init__.py)，或者from ..A import XXX(即上一个文件夹中的文件A https://www.zhihu.com/question/28688151/answer/66982373 [/danger]]]></content>
      <categories>
        <category>学习</category>
        <category>教学</category>
      </categories>
      <tags>
        <tag>课后解答</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第十三节：异常]]></title>
    <url>%2F2018%2F05%2F28%2F%E7%AC%AC%E5%8D%81%E4%B8%89%E8%8A%82%EF%BC%9A%E5%BC%82%E5%B8%B8%2F</url>
    <content type="text"><![CDATA[[success] 一：异常及其异常处理： 什么是异常？ ——异常：不正常的情况 异常即是一个事件，该事件会在程序执行过程中发生，影响了程序的正常执行。一般情况下，在Python无法正常处理程序时就会发生一个异常。 异常是Python对象，表示一个错误。 当Python脚本发生异常时我们需要捕获处理它，否则程序会终止执行。 异常出现的原因： 不正常的情况，在程序中，会有两种体现： 代码错误或语法错误；程序都运行不起来！ 程序运行过程中，在某些特定条件下，不合适的数据引起程序出现错误导致程序崩溃 例如：要求用户输入一个数字，但是用户误操作输入了字符串，在进行类型转换时就会出现错误导致程序崩溃！ 为什么要处理异常？ 当程序在运行过程中，由于用户的误操作或者不合适的数据引发的程序错误，让代码自己处理并保证程序的正常执行。而不至于因为错误导致程序崩溃！ 这样提高代码的健壮性！ 怎么处理异常？ l 捕获处理异常 l 断言处理异常【测试异常信息】 捕获处理异常语法： 捕捉异常可以使用 try/except 语句。 try/except语句用来检测try语句块中的错误，从而让except语句捕获异常信息并处理。 如果你不想在异常发生时结束你的程序，只需在try里捕获它。 语法： 以下为简单的try….except…else的语法： 1 try: 2 3 &lt;语句> #运行别的代码 4 5 except &lt;名字&gt;： 6 7 &lt;语句> #如果在try部份引发了’name’异常 8 9 except &lt;名字&gt;，&lt;数据&gt;: 1011 &lt;语句> #如果引发了’name’异常，获得附加的数据1213 else: 1415 &lt;语句> #如果没有异常发生1617 finally： 1819 &lt;语句> #无论try语句是否发生异常，都要执行的语句 处理异常： 1. 基本异常处理 try-except直接处理异常【可以处理任何异常—不能定位具体是什么异常】 try-except [异常信息] 【可以处理指定的异常】 2. 常见的异常 所有异常的超类：BaseException 标准异常的超类：Exception(BaseException) 程序执行过程中经常看到的异常： …… 3. 处理多个异常 try-except (E1, E2, E3, …,En) as e 一个except处理指定的多个异常 try-except E1-except E2-except E3… 每个except处理指定的异常 通常情况下，我们要查看异常信息，就需要打印异常信息—打印e变量的值 问题： 1） 系统提供的异常信息，晦涩难懂！ 2） 系统提供的异常信息，毕竟有限！ 4. 自定义异常 通过创建一个新的异常类，程序可以命名它们自己的异常。异常应该是典型的继承自Exception类，通过直接或间接的方式。 以下为与RuntimeError相关的实例,实例中创建了一个类，基类为RuntimeError，用于在异常触发时输出更多的信息。 在try语句块中，用户自定义的异常后执行except块语句，变量 e 是用于创建Networkerror类的实例。 1 class Networkerror(RuntimeError): 23 def __init__(self, arg): 45 self.args = arg 在你定义以上类后，你可以触发该异常，如下所示： ‘’’ 6 try: 7 8 raise Networkerror(“Bad hostname”) 910 except Networkerror,e: 1112 print e.args‘’’ 异常的参数一个异常可以带上参数，可作为输出的异常信息参数。 5. 主动抛出异常 我们可以使用raise语句自己触发异常 raise语法格式如下： raise [Exception [, args [, traceback]]] 语句中Exception是异常的类型（例如，NameError）参数是一个异常参数值。该参数是可选的，如果不提供，异常的参数是”None”。 最后一个参数是可选的（在实践中很少使用），如果存在，是跟踪异常对象。 实例一个异常可以是一个字符串，类或对象。 Python的内核提供的异常，大多数都是实例化的类，这是一个类的实例的参数。 定义一个异常非常简单，如下所示： def functionName( level ): if level &lt; 1:raise “Invalid level!”, level 5The code below to this would not be executedif we raise the exception 注意：为了能够捕获异常，”except”语句必须有用相同的异常来抛出类对象或者字符串。 例如我们捕获以上异常，”except”语句如下所示： 7 try: 8 Business Logic here… 9 except “Invalid level!”: 10 Exception handling here… 11 else: 12 Rest of the code here… 在开发的过程中，主动出现一种错误，将错误抛出给程序告诉程序出错了。 6.异常处理理解 自定义异常，就是为了专门抛出错误的，抛出错误，就是严重警告这里出现了什么问题 首先-代码执行过程中，出现了异常【系统标准异常】【信息不是很明白】 捕获系统异常，创建一个自定义异常 抛出自定义异常【自定义异常】【信息明确的错误】 自定义异常的目的：转换异常信息，将不明确的异常信息转换成更加精确的异常信息 转换异常信息：异常的传递~传递更加明确的异常，给后面的代码进行处理！ 7.Python标准异常异常名称 描述 BaseException 所有异常的基类 SystemExit 解释器请求退出 KeyboardInterrupt 用户中断执行(通常是输入^C) Exception 常规错误的基类 StopIteration 迭代器没有更多的值 GeneratorExit 生成器(generator)发生异常来通知退出 StandardError 所有的内建标准异常的基类 ArithmeticError 所有数值计算错误的基类 FloatingPointError 浮点计算错误 OverflowError 数值运算超出最大限制 ZeroDivisionError 除(或取模)零 (所有数据类型) AssertionError 断言语句失败 AttributeError 对象没有这个属性 EOFError 没有内建输入,到达EOF 标记 EnvironmentError 操作系统错误的基类 IOError 输入/输出操作失败 OSError 操作系统错误 WindowsError 系统调用失败 ImportError 导入模块/对象失败 LookupError 无效数据查询的基类 IndexError 序列中没有此索引(index) KeyError 映射中没有这个键 MemoryError 内存溢出错误(对于Python 解释器不是致命的) NameError 未声明/初始化对象 (没有属性) UnboundLocalError 访问未初始化的本地变量 ReferenceError 弱引用(Weak reference)试图访问已经垃圾回收了的对象 RuntimeError 一般的运行时错误 NotImplementedError 尚未实现的方法 SyntaxError Python 语法错误 IndentationError 缩进错误 TabError Tab 和空格混用 SystemError 一般的解释器系统错误 TypeError 对类型无效的操作 ValueError 传入无效的参数 UnicodeError Unicode 相关的错误 UnicodeDecodeError Unicode 解码时的错误 UnicodeEncodeError Unicode 编码时错误 UnicodeTranslateError Unicode 转换时错误 Warning 警告的基类 DeprecationWarning 关于被弃用的特征的警告 FutureWarning 关于构造将来语义会有改变的警告 OverflowWarning 旧的关于自动提升为长整型(long)的警告 PendingDeprecationWarning 关于特性将会被废弃的警告 RuntimeWarning 可疑的运行时行为(runtime behavior)的警告 SyntaxWarning 可疑的语法的警告 UserWarning 用户代码生成的警告 二：python断言使用assert断言是学习python一个非常好的习惯，python assert 断言句语格式及用法很简单。在没完善一个程序之前，我们不知道程序在哪里会出错，与其让它在运行最崩溃，不如在出现错误条件时就崩溃，这时候就需要assert断言的帮助。本文主要是讲assert断言的基础知识。 python assert断言的作用python assert断言是声明其布尔值必须为真的判定，如果发生异常就说明表达示为假。可以理解assert断言语句为raise-if-not，用来测试表示式，其返回值为假，就会触发异常。 assert断言语句的语法格式assert python 怎么用？ expression assert 表达式 下面做一些assert用法的语句供参考：assert 1==1assert 2+2==2*2assert len([‘my boy’,12])&lt;10assert range(4)==[0,1,2,3] 如何为assert断言语句添加异常参数assert的异常参数，其实就是在断言表达式后添加字符串信息，用来解释断言并更好的知道是哪里出了问题。格式如下： assert expression [, arguments]assert 表达式 [, 参数]]]></content>
      <categories>
        <category>学习</category>
        <category>教学</category>
      </categories>
      <tags>
        <tag>课后解答</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第十二节：文件IO，私有属性和方法]]></title>
    <url>%2F2018%2F05%2F23%2F%E7%AC%AC%E5%8D%81%E4%BA%8C%E8%8A%82%EF%BC%9A%E6%96%87%E4%BB%B6IO%EF%BC%8C%E7%A7%81%E6%9C%89%E5%B1%9E%E6%80%A7%E5%92%8C%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[一；文件io基本操作：文件的存储方式 计算机中，文件是以二进制的方式保存的 文本文件就是可以使用文本编辑器查看，二进制文件无法使用文本编辑器查看，是提供给其他软件使用的，例如图片，音视频等 操作文件的套路1、打开文件open open函数负责打开文件， 并返回文件对象 打开文件的方式有很多种，常用的如下： r 只读，默认模式，如果文件不存在，抛出异常 w 只写，如果文件存在，则覆盖，不存在，则创建 a 追加，如果文件存在，指针会放在文件的结尾，不存在，创建新文件并写入 rb 以二进制读取内容 wb 以二进制写入内容 开发中更多的时候会以只读，只写的方式来操作文件 2、读写文件read，write read方法一次性读入并返回文件的所有内容，执行后，文件指针会移动到文件的末尾 readline方法可以一次读取一行内容 方法执行后，会把文件指针移动到下一行，准备再次读取，读取大文件时，使用此方法在while循环中，依次读取，节约内存 3、关闭文件close close，如果忘记关闭文件，会造成系统资源消耗，且会影响到后续对文件的访问 文件指针 文件指针标记从哪个位置开始读取数据 第一次打开文件时，通常文件指针会指向文件的开始位置，当执行read后，文件指针移动到末尾 在同一个python文件中，如果执行了read，那么再次使用此方法时，时无法获得内容的，可以使用seek方法改变指针位置 文件/目录的常用管理操作在python中，使用代码实现文件目录操作，需要导入os模块 文件操作 os.rename(源文件名，目标文件名) os.remove（文件名） 目录操作 os.listdir 目录列表，类似ls os.mkdir 创建目录，和linux一致 os.rmdir 删除目录 os.chdir 修改工作目录 os.getcwd 获取当前工作目录current work directory os.path.isdir（文件路径） 判断是否是目录 os.path.isfile 判断是否是文件 python 文件操作seek() 和 telll()file.seek()方法格式： seek(offset,whence=0) 移动文件读取指针到制定位置 offset:开始的偏移量，也就是代表需要移动偏移的字节数。 whence： 给offset参数一个定义，表示要从哪个位置开始偏移；0代表从文件开头算起，1代表开始从当前位置开始算起，2代表从文件末尾开始算起。当有换行时，会被换行截断。 seek（）无返回值，故值为None tell() : 文科文件的当前位置，即tell是获取文件指针位置。 readline(n):读入若干行，n代表读入的最长字节数。 readlines() :读入所有行的内容 read读入所有行的内容 上下文管理器普通版： def A1(): f=open(“out.txt”,”w”) f.write(“123”) f.close() 威胁：如果调用异常，资源卡住，无法释放 升级版： def A1(): f=open(“out.txt”,”w”) try： f.write(“123”) except IOError： print（“error”） finally： f.close() 优雅版： def A1（）： with open（“out.txt”，“w”） as f： f.write（“123”） 优雅的With as语句Python提供了With语句语法，来构建对资源创建与释放的语法糖。给Database添加两个魔法方法： ‘’’python class Database(object): def __enter__(self): self.connect() return self def __exit__(self, exc_type, exc_val, exc_tb): self.close()‘’’然后修改handle_query函数如下： def handle_query(): with Database() as db: print ‘handle —‘, db.query()‘’’在Database类实例的时候，使用with语句。一切正常work。比起装饰器的版本，虽然多写了一些字符，但是代码可读性变强了 io模块StringIO顾名思义就是在内存中读写str。 要把str写入StringIO，我们需要先创建一个StringIO，然后，像文件一样写入即可： from io import StringIO f = StringIO() print(f.write(&apos;hello py1 &apos;)) # 10 print(f.write(&apos;hello py2 &apos;)) # 10 print(f.write(&apos;hello py3 &apos;)) # 10 print(f.getvalue()) # hello py1 hello py2 hello py3 要读取StringIO，可以用一个str初始化StringIO，然后，像读文件一样读取： from io import StringIO f = StringIO(&apos;Hello!\nHi!\nGoodbye!&apos;) print(f.read()) StringIO操作的只能是str，如果要操作二进制数据，就需要使用BytesIO from io import BytesIO f = BytesIO() print(f.write(&apos;中文&apos;.encode(&apos;utf-8&apos;))) # 请注意，写入的不是str，而是经过UTF-8编码的bytes print(f.getvalue()) # b&apos;\xe4\xb8\xad\xe6\x96\x87&apos; BytesIO和StringIO类似，也可以用一个bytes初始化BytesIO，然后，像读文件一样读取： from io import StringIO f = BytesIO(b&apos;\xe4\xb8\xad\xe6\x96\x87&apos;) f.read() b&apos;\xe4\xb8\xad\xe6\x96\x87&apos; StringIO和BytesIO是在内存中操作str和bytes的方法，使得和读写文件具有一致的接口。 os模块os.getcwd() 获取当前工作目录，即当前python脚本工作的目录路径 os.chdir(`“dirname”) 改变当前脚本工作目录；相当于shell下cd` os.curdir 返回当前目录: (`‘.’)` os.pardir 获取当前目录的父目录字符串名：(`‘..’)` os.makedirs(`‘dirname1/dirname2’) 可生成多层递归目录` os.removedirs(`‘dirname1’) 若目录为空，则删除，并递归到上一级目录，如若也为空，则删除，依此类推` os.mkdir(`‘dirname’) 生成单级目录；相当于shell中mkdir dirname` os.rmdir(`‘dirname’) 删除单级空目录，若目录不为空则无法删除，报错；相当于shell中rmdir dirname` os.listdir(`‘dirname’) 列出指定目录下的所有文件和子目录，包括隐藏文件，并以列表方式打印` os.remove() 删除一个文件 os.rename(`“oldname”,“newname”) 重命名文件/目录` os.stat(`‘path/filename’) 获取文件/目录信息` os.sep 输出操作系统特定的路径分隔符，win下为`“\“,Linux下为”/“` os.linesep 输出当前平台使用的行终止符，win下为`“\t\n”,Linux下为“\n”` os.pathsep 输出用于分割文件路径的字符串 os.name 输出字符串指示当前使用平台。win`-&gt;‘nt’; Linux-&gt;‘posix’` os.system(`“bash command”) 运行shell命令，直接显示` os.environ 获取系统环境变量 os.path.abspath(path) 返回path规范化的绝对路径 os.path.split(path) 将path分割成目录和文件名二元组返回 os.path.dirname(path) 返回path的目录。其实就是os.path.split(path)的第一个元素 os.path.basename(path) 返回path最后的文件名。如何path以／或\结尾，那么就会返回空值。即os.path.split(path)的第二个元素 os.path.exists(path) 如果path存在，返回`True；如果path不存在，返回False` os.path.isabs(path) 如果path是绝对路径，返回`True` os.path.isfile(path) 如果path是一个存在的文件，返回`True。否则返回False` os.path.isdir(path) 如果path是一个存在的目录，则返回`True。否则返回False` os.path.join(path1[, path2[, ...]]) 将多个路径组合后返回，第一个绝对路径之前的参数将被忽略 os.path.getatime(path) 返回path所指向的文件或者目录的最后存取时间 os.path.getmtime(path) 返回path所指向的文件或者目录的最后修改时间 4.sys模块 sys.argv 命令行参数`List，第一个元素是程序本身路径` sys.exit(n) 退出程序，正常退出时exit(`0)` sys.version 获取Python解释程序的版本信息 sys.maxint 最大的`Int值` sys.path 返回模块的搜索路径，初始化时使用PYTHONPATH环境变量的值 sys.platform 返回操作系统平台名称 sys.stdout.write(`‘please:’)` val `=sys.stdin.readline()[:-1]` shutil模块：https://docs.python.org/3/library/shutil.html?highlight=shutil#module-shutil 私有属性和方法如果有一个对象，当需要对其进行修改属性时，有2种方法： （1）对象名.属性名=数据—-&gt;直接修改 （2）对象名.方法名()—–&gt;间接修改 为了更好的保障属性安全，不能随意修改，一般处理方式为： （1）将属性定义为私有属性 （2）添加一个可以调用的方法，供调用，也就是间接调用属性 私有方法是不能直接调用的]]></content>
      <categories>
        <category>学习</category>
        <category>教学</category>
      </categories>
      <tags>
        <tag>课后解答</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第十一节：描述符，装饰器，定制属性访问，__new__方法]]></title>
    <url>%2F2018%2F05%2F21%2F%E7%AC%AC%E5%8D%81%E4%B8%80%E8%8A%82%EF%BC%9A%E6%8F%8F%E8%BF%B0%E7%AC%A6%EF%BC%8C%E8%A3%85%E9%A5%B0%E5%99%A8%EF%BC%8C%E5%AE%9A%E5%88%B6%E5%B1%9E%E6%80%A7%E8%AE%BF%E9%97%AE%EF%BC%8C__new__%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[[warning] __new__方法：__new__ 方法是什么？ __new__方法接受的参数虽然也是和__init__一样，但__init__是在类实例创建之后调用，而 __new__方法正是创建这个类实例的方法。 __new__ 的作用 依照Python官方文档的说法，__new__方法主要是当你继承一些不可变的class时(比如int, str, tuple)， 提供给你一个自定义这些类的实例化过程的途径。还有就是实现自定义的metaclass。 定制属性访问:object.`getattr`（self，name） 当默认的属性访问失败，并调用AttributeError（或者__getattribute__()引发AttributeError，因为_名字是不是一个实例的属性或分类的属性self;或__get__()的名称_属性提升AttributeError）。此方法应该返回（计算）的属性值或引发AttributeError异常。 请注意，如果通过正常机制找到属性，__getattr__()则不会调用该属性。（这是__getattr__()和之间的故意不对称__setattr__()）。这是出于效率原因而完成的，否则__getattr__()将无法访问实例的其他属性。请注意，至少在实例变量中，您可以通过在实例属性字典中不插入任何值（而是将它们插入另一个对象中）来伪造完全控制。请参阅__getattribute__()下面的方法，以实际获得对属性访问的完全控制。 object.`getattribute`（self，name） 无条件地调用以实现类的实例的属性访问。如果这个类还定义了__getattr__()，那么除非__getattribute__()明确地调用它或引发一个，否则后者将不会被调用AttributeError。此方法应返回（计算）的属性值或引发AttributeError异常。为了避免此方法中的无限递归，它的实现应始终调用具有相同名称的基类方法来访问它所需的任何属性，例如。object.__getattribute__(self,name) 注意 当通过语言语法或内置函数隐式调用查找特殊方法时，此方法仍可能被忽略。请参阅特殊方法查找。 object.`setattr`（self，name，value） 在试图进行属性分配时调用。这被称为而不是正常机制（即将值存储在实例字典中）。name是属性名称，value是要分配给它的值。 如果__setattr__()想分配给实例属性，它应该调用具有相同名称的基类方法，例如。object.__setattr__(self,name,value) object.`delattr`（self，name） 像__setattr__()但删除属性而不是赋值。这应该只在对对象有意义时才能实现。delobj.name object.`dir`（self） dir()在对象上调用时调用。必须返回一个序列。dir()将返回的序列转换为列表并对其进行排序。 描述符：一句话概括：描述符就是可重用的属性在这里我要告诉你：从根本上讲，描述符就是可以重复使用的属性。也就是说，描述符可以让你编写这样的代码： 1 2 3 4 f = Foo() b = f.bar f.bar = c del f.bar 而在解释器执行上述代码时，当发现你试图访问属性（b = f.bar）、对属性赋值（f.bar = c）或者删除一个实例变量的属性（del f.bar）时，就会去调用自定义的方法。 装饰器:01 什么是装饰器？装饰器可以让一个Python函数拥有原本没有的功能，也就是你可以通过装饰器，让一个平淡无奇的函数变的强大，变的漂亮。 举几个现实中的例子 1、你一个男的程序员，穿上女装，戴上假发，你就有了女人的外表（穿女装、戴假发的过程就是新的特效，你拥有了女人的外表，你原来的小jj还在，没有消失） 2、你新买的毛坯房，装修，买家具后变好看了（装修、家具就是新的特效） 3、孙悟空被放进炼丹炉装饰了一下，出来后，学会了火眼金睛，以前的本领都还在 02 为什么Python要引入装饰器？因为引入装饰器会便于开发，便于代码复用，可以把烂泥扶上墙， 装饰器可以让你一秒变女人且可以保住小JJ，当你某天后悔想重新变回男人，只要脱掉女装和假发即可（如果你变女人的时候，给小JJ做了手术（直接修改函数体的内容），想再变回男人可就痛苦了哦） 03 装饰器有利于解决哪些问题？例子1： 扩展功能 比如你写了一段代码，当你执行 孙悟空() 就打印出它目前的技能 # python3支持用中文做函数名， # 这里为了方便你理解，就用中文，实际情况为了兼容性，你可别用中文哦 def 孙悟空(): print(&apos;吃桃子&apos;) 孙悟空() # 输出: # 吃桃子 现在你希望 孙悟空这个函数 打印出 ’有火眼金睛了’，该怎么做呢？ 是的，你可以直接在函数里加一段 print(‘有火眼金睛了’) 但是这样会破坏原来的代码，如果你的代码量很多很多的话，修改起来则是灾难， 不过别担心，你还可以用装饰器来装饰他，让他在原本基础上，扩展出新的功能 代码如下 def 炼丹炉(func): # func就是‘孙悟空’这个函数 def 变身(*args, **kwargs): #*args, **kwargs就是‘孙悟空’的参数列表，这里的‘孙悟空’函数没有传参数，我们写上也不影响，建议都写上 print(&apos;有火眼金睛了&apos;) # 加特效，增加新功能，比如孙悟空的进了炼丹炉后，有了火眼金睛技能 return func(*args, **kwargs) #保留原来的功能，原来孙悟空的技能，如吃桃子 return 变身 # 炼丹成功，更强大的，有了火眼金睛技能的孙悟空出世 @炼丹炉 def 孙悟空(): print(&apos;吃桃子&apos;) 孙悟空() # 输出: # 有火眼金睛了 # 吃桃子 例子2：扩展权限认证 比如你的代码，默认打开就播放动画片，代码如下 def play(): print(&apos;开始播放动画片 《喜洋洋和灰太狼》&apos;) play() # 输出 # 开始播放动画片 《喜洋洋和灰太狼》 但是突然某天，你突然希望只允许1岁到10才可以看这个动画片，不希望程序员大叔看这个动画片怎么办？ 是的，你可以修改这个代码，加上年龄限制，但如果我们用装饰器的话，就更简单了，就可以不用破坏原来的代码，而且方便扩展到其他函数上 userAge = 40 def canYou(func): def decorator(*args, **kwargs): if userAge &gt; 1 and userAge &lt; 10: return func(*args, **kwargs) print(&apos;你的年龄不符合要求，不能看&apos;) return decorator @canYou def play(): print(&apos;开始播放动画片 《喜洋洋和灰太狼》&apos;) play() # 输出 # 你的年龄不符合要求，不能看 # 你可以修改上面的 userAge 为9 试试 你看，是不是很简单，实际情况中，很多时候，你需要对一段代码加上权限认证，加上各种功能；但是又不想，或者不方便破坏原有代码，则可以用装饰器去扩展它 04 装饰器背后的实现原理是什么？原理 代码逆推后如下 def 炼丹炉(func): def 变身(*args, **kwargs): print(&apos;有火眼金睛了&apos;) return func(*args, **kwargs) return 变身 def 孙悟空(): print(&apos;吃桃子&apos;) 新_孙悟空 = 炼丹炉(孙悟空) #放入原料，原来的弱小的孙悟空，生成炼丹方案给 新_孙悟空 ，这里也可以把炼丹方案给 原来的‘孙悟空’，为了方便理解，给了新的孙悟空 新_孙悟空() # 执行炼丹程序，新的孙悟空出世 然后这段代码，写起来有点麻烦，Python官方出了一个快捷代码，也就是语法糖，用了语法糖就变成了下面这样 def 炼丹炉(func): def 变身(*args, **kwargs): print(&apos;有火眼金睛了&apos;) return func(*args, **kwargs) return 变身 @炼丹炉 # 把下面的 ‘孙悟空’ 塞进炼丹炉，并把新的孙悟空复制给下面的函数 def 孙悟空(): print(&apos;吃桃子&apos;) 孙悟空() # 执行炼丹程序，新的孙悟空出世 可以一次性在一个函数上用多个装饰器吗？ 当然可以，下面我们给孙悟空，弄个金箍棒，让他学会72变，学会飞 def 炼丹炉(func): def 变身(*args, **kwargs): print(&apos;有火眼金睛了&apos;) return func(*args, **kwargs) return 变身 def 龙宫走一趟(func): def 你好(*args, **kwargs): print(&apos;有金箍棒了&apos;) return func(*args, **kwargs) return 你好 def 拜师学艺(func): def 师傅(*args, **kwargs): print(&apos;学会飞、72变了&apos;) return func(*args, **kwargs) return 师傅 @拜师学艺 @龙宫走一趟 @炼丹炉 def 孙悟空(): print(&apos;吃桃子&apos;) 孙悟空() # 输出 # 学会飞、72变了 # 有金箍棒了 # 有火眼金睛了 # 吃桃子 上面代码的等效于 拜师学艺(龙宫走一趟(炼丹炉(孙悟空))) 代码的执行顺序是 先从内到外 先执行 炼丹炉，然后是龙宫走一趟，最后是拜师学艺，[/warning] 链接：https://www.zhihu.com/question/26930016/answer/360300235]]></content>
      <categories>
        <category>学习</category>
        <category>教学</category>
      </categories>
      <tags>
        <tag>课后解答</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第十节:多继承与魔法方法]]></title>
    <url>%2F2018%2F05%2F18%2F%E7%AC%AC%E5%8D%81%E8%8A%82%EF%BC%9A%E5%A4%9A%E7%BB%A7%E6%89%BF%E4%B8%8E%E9%AD%94%E6%B3%95%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[一：多继承：class A(): def __init__(self): print(“A”) class B(A): def __init__(self): super().__init__() print(“B”) class C(A): def __init__(self): super().__init__() print(“C”) class D(B, C): def __init__(self): super().__init__() print(“D”) D() python 支持多继承，但对与经典类和新式类来说，多继承查找的顺序是不一样的。 经典类的搜索方式是按照“从左至右，深度优先”的方式去查找属性。 新式类的搜索方式是采用“广度优先”的方式去查找属性。 二：魔法方法：1、何为魔法方法： Python中，一定要区分开函数和方法的含义； 1.函数：类外部定义的，跟类没有直接关系的；形式： def func(argv): 2.方法：class内部定义的函数（对象的方法也可以认为是属性）；分为两种： ① python自动产生的（魔法方法）：一般形式为 __func__()，python会在对应的时机自动调用该函数； ② 人为自定义的方法：一般和普通函数没有区别，只是定义在了class中而已 3.方法与函数的区别： 方法可认为是函数的特殊情况； ① 方法定义在class内部 ② 方法的第一个参数应为 cls(类方法) 或者 self(实例方法) 2、魔法方法汇总： ①.以上所有的魔法方法，君采用__xx__形式（__为双 “_”，双下划线） ②.以上魔法方法为Python解释器自动调用，当然也可以手动调用 ③.魔法方法Python解释器自动给出默认的，因此除非需要改变其内部功能，其它时刻刻使用默认魔法方法 ④.魔法方法是针对class而言的，脱离了”类“谈magic_method是没有意义的 ⑤.argv为可变的参数列表，类似C语言的va(variable argument),注意与指针的区别，python中暂时忘掉指针，因为python的内存机制都是解释器自动完成的]]></content>
      <categories>
        <category>学习</category>
        <category>教学</category>
      </categories>
      <tags>
        <tag>课后解答</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第九节：类]]></title>
    <url>%2F2018%2F05%2F12%2F%E7%AC%AC%E4%B9%9D%E8%8A%82%EF%BC%9A%E7%B1%BB%2F</url>
    <content type="text"><![CDATA[类定义：用来描述具体相同的属性和方法的对象的集合。定义了该集合中每个对象所共有的属性和方法。对象是类的示例 类 Class: 用来描述具体相同的属性和方法的对象的集合。定义了该集合中每个对象所共有的属性和方法。对象是类的示例。 类变量：类变量在整个实例化的对象中是公用的。类变量定义在类中且在函数体之外。类变量通常不作为实例变量使用。 数据成员：类变量或者实例变量用于处理类及其实例对象的相关数据。 方法重写：如果从父类继承的方法不能满足子类的需求，可以对其 进行改写，这个过程叫方法的覆盖（override），也称为方法的重写。 实例变量：定义在方法中的变量，只作用于当前实例的类。 继承：即一个派生类（derived class）继承基类（base class）的字段和方法。继承也允许把一个派生类的对象作为一个基类对象对待。例如，有这样一个设计：一个Dog类型的对象派生自Animal类，这是模拟”是一个（is-a）”关系（例图，Dog是一个Animal）。 实例化：创建一个类的实例，类的具体对象。就是将创建的类赋值给另一个变量。理解为赋值即可，a = class()，这个过程，就叫做实例化 方法：类中定义的函数。 对象：通过类定义的数据结构实例。对象包括两个数据成员（类变量和实例变量）和方法。 类有这样一些的优点1 ) 、类对象是多态的：也就是多种形态，这意味着我们可以对不同的类对象使用同样的操作方法，而不需要额外写代码。 2 ) 、类的封装：封装之后，可以直接调用类的对象，来操作内部的一些类方法，不需要让使用者看到代码工作的细节。 3 ) 、类的继承：类可以从其它类或者元类中继承它们的方法，直接使用。 属性:1：实例属性： 在__init__(self,…)中初始化 内部调用时都需要加上self. 外部调用时用实例化对象.属性名 2:类属性： 在__init__()外初始化 在内部用类名.类属性名调用 外部既可以用类名.类属性名又可以用实例化对象.类属性名来调用 3：私有属性： 1）：单下划线开头：只是告诉别人这是私有属性，外部依然可以访问更改 2）：双下划线__开头：外部不可通过实例化对象.属性名来访问或者更改 实际将其转化为了**类名__属性名**，只是在内部将变量名修改了，我们仍让可以通过.类名_属性名访问 类属性的修改字典为可变类型，而数字是不可变类型，因此无法通过这种方式修改。所以在实际开发中应该避免通过实例对象去修改类属 性。 类的继承：继承类的构造方法： 1.经典类的写法： 父类名称.__init__(self,参数1，参数2，…) 2. 新式类的写法：super(子类，self).__init__(参数1，参数2，….) class`Person(object):` def`init(self, name, age):` self`.name=name` self`.age=age` self`.weight=‘weight’` def`talk(self):` print`(&quot;person is talking....&quot;)` class`Chinese(Person):` def`init(self, name, age, language): # 先继承，在重构` Person.__init__(`self, name, age)#继承父类的构造方法，` 也可以写成：super(Chinese,self).__init__(name,age) self`.language=language # 定义类的本身属性` def`talk(self): # 子类 重构方法` print`(&#39;%s is speaking chinese&#39;%self.name)` 方法： # --coding:utf-8-- # 普通方法,类方法,静态方法的区别 __metaclass__ = type class Tst: name = ‘tst’ data = ‘this is data’ # 普通方法 def normalMethod(self, name): print self.data, name # 类方法,可以访问类属性 @classmethod def classMethod(cls, name): print cls.data, name # 静态方法,不可以访问类属性 @staticmethod def staticMethod(name): print name 三种方法都可以通过实例来调用，但是静态方法和类方法无法访问实例属性，所以更改了tst.data仅对普通方法起了作用 普通方法不能通过类名调用，但是静态方法和类方法是可以的 普通方法,可以通过self访问实例属性 类方法,可以通过cls访问类属性 静态方法,不可以访问,通过传值的方式]]></content>
      <categories>
        <category>学习</category>
        <category>教学</category>
      </categories>
      <tags>
        <tag>课后解答</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[模型评估与选择]]></title>
    <url>%2F2018%2F05%2F09%2F%E6%A8%A1%E5%9E%8B%E8%AF%84%E4%BC%B0%E4%B8%8E%E9%80%89%E6%8B%A9%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>学习</category>
        <category>算法</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[最小二乘推导]]></title>
    <url>%2F2018%2F05%2F09%2F%E6%9C%80%E5%B0%8F%E4%BA%8C%E4%B9%98%E6%8E%A8%E5%AF%BC%2F</url>
    <content type="text"><![CDATA[]]></content>
      <categories>
        <category>学习</category>
        <category>算法</category>
      </categories>
      <tags>
        <tag>推导</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第八节：函数作用域和匿名函数]]></title>
    <url>%2F2018%2F05%2F08%2F%E7%AC%AC%E5%85%AB%E8%8A%82%EF%BC%9A%E5%87%BD%E6%95%B0%E4%BD%9C%E7%94%A8%E5%9F%9F%E5%92%8C%E5%8C%BF%E5%90%8D%E5%87%BD%E6%95%B0%2F</url>
    <content type="text"><![CDATA[[info] python 使用 lambda 来创建匿名函数。 lambda只是一个表达式，函数体比def简单很多。 lambda的主体是一个表达式，而不是一个代码块。仅仅能在lambda表达式中封装有限的逻辑进去。 lambda函数拥有自己的命名空间，且不能访问自有参数列表之外或全局命名空间里的参数。 虽然lambda函数看起来只能写一行，却不等同于C或C++的内联函数，后者的目的是调用小函数时不占用栈内存从而增加运行效率。 形式： 函数名=lambda 参数：表达式 等价于 def 函数名（参数）： 语句块 return 返回值 lambda作用域说明关于变量在Lambda中的作用域主要可以做出以下几点的总结： 对局部变量可见 对全局变量可见 对当前层传入的参数可见 对上层函数传入的参数可见 对上层Lambda传入的参数可见 局部变量和全局变量：详见：点我 闭包：在函数中可以（嵌套）定义另一个函数时，如果内部的函数引用了外部的函数的变量，则可能产生闭包。闭包可以用来在一个函数与一组“私有”变量之间创建关联关系。在给定函数被多次调用的过程中，这些私有变量能够保持其持久性。 条件： 1)必须有一个内嵌函数(函数里定义的函数）——这对应函数之间的嵌套 2)内嵌函数必须引用一个定义在闭合范围内(外部函数里)的变量——内部函数引用外部变量 3)外部函数必须返回内嵌函数——必须返回那个内部函数 陷阱： 返回函数千万不要引用任何一个循环变量,或者在之后会发生改变的变量. bug代码如下： 希望一次返回3个函数，分别计算1x1,2x2,3x3: def count(): fs = [] for i in range(1, 4): def f(): return i*i fs.append(f) return fs f1, f2, f3 = count() print f1(), f2(), f3() 改进： #coding:utf-8 __author__ = ‘chad’ 希望一次返回3个函数，分别计算1x1,2x2,3x3: def count(): fs = [] for i in range(1, 4): def f(j): def g(): return j*j return g fs.append(f(i)) return fs f1, f2, f3 = count() print f1(), f2(), f3() 递归（自己调用自己）：来源于：数学归纳法 直接调用： def func(): print`(&#39;from func&#39;)` func() func() 间接调用： #间接调用自己 def foo(): print`(&#39;from foo&#39;)` bar() def bar(): print`(&#39;from bar&#39;)` foo() foo() 典型递归：树结构，阶乘，斐波那契数列，汉诺塔 [/info]]]></content>
      <categories>
        <category>学习</category>
        <category>教学</category>
      </categories>
      <tags>
        <tag>课后解答</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第七节：函数基础和函数参数]]></title>
    <url>%2F2018%2F05%2F08%2F%E7%AC%AC%E4%B8%83%E8%8A%82%EF%BC%9A%E5%87%BD%E6%95%B0%E5%9F%BA%E7%A1%80%E5%92%8C%E5%87%BD%E6%95%B0%E5%8F%82%E6%95%B0%2F</url>
    <content type="text"><![CDATA[[danger] 函数定义（一段代码表示）：函数是一段具有特定功能的，可重复使用的语句组 函数其实就是“功能” 有什么用呢？ 以后方便使用，模块化，代码简洁，可重复调用 书写格式：def (函数名）（参数（0个或者多个））： 函数体 return （返回值） 注：函数不调用，它是不会去执行 当函数调用时 分了四种参数：必选参数（在函数体参数项没有赋值），可选参数（默认参数）（在函数体参数项赋了值），可变参数（函数体参数项a表示），关键字参数（函数体参数项**b） \args是可变参数，args接收的是一个tuple（元组–一种特殊的列表）； **kw是关键字参数，kw接收的是一个dict（字典）。 注意，参数定义的顺序必须是：必选参数、默认参数、可变参数和关键字参数。(星星越多，约往后） 如：def fun(a, b, c=0, *args, **kw): 返回值return 可以直接使用return 表示返回保留字。 return可以传递0个返回值，也可以返回多个返回值 局部变量与全局变量区别：简单来说就是 函数体外定义的就是全局变量 函数体内定义的就是局部变量 区别： 1.局部变量在函数体运行完了就释放了 2.基本数据类型，无论重不重名，局部变量与全局变量不同 3.如果硬要在函数内部去声明全局变量，可以通过global声明 Python内置函数：如果记不住，记住方法，善用help（）—-查看帮助 比如看数学运算类的方法 import math dir(math) help(math) 查看所有内置函数：可以在idle里面使用命令dir(__builtins__)查看python的所有你内置函数 数学类: 集合类： io操作类： 函数操作类： 详情链接：点我 [/danger]]]></content>
      <categories>
        <category>学习</category>
        <category>教学</category>
      </categories>
      <tags>
        <tag>课后解答</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第六节：控制流程]]></title>
    <url>%2F2018%2F05%2F08%2F%E7%AC%AC%E5%85%AD%E8%8A%82%EF%BC%9A%E6%8E%A7%E5%88%B6%E6%B5%81%E7%A8%8B%2F</url>
    <content type="text"><![CDATA[1.break和continue的区别和作用break和continue都是用来控制循环结构的，主要是停止循环。 1.break 有时候我们想在某种条件出现的时候终止循环而不是等到循环条件为false才终止。 这是我们可以使用break来完成。break用于完全结束一个循环，跳出循环体执行循环后面的语句。 2.continue continue和break有点类似，区别在于continue只是终止本次循环，接着还执行后面的循环，break则完全终止循环。 可以理解为continue是跳过当次循环中剩下的语句，执行下一次循环。]]></content>
      <categories>
        <category>学习</category>
        <category>教学</category>
      </categories>
      <tags>
        <tag>课后解答</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第四节：格式化输出，字符串]]></title>
    <url>%2F2018%2F05%2F08%2F%E7%AC%AC%E5%9B%9B%E8%8A%82%EF%BC%9A%E6%A0%BC%E5%BC%8F%E5%8C%96%E8%BE%93%E5%87%BA%EF%BC%8C%E5%AD%97%E7%AC%A6%E4%B8%B2%2F</url>
    <content type="text"><![CDATA[一:格式化输出1、整数的输出%o —— oct 八进制%d —— dec 十进制%x —— hex 十六进制1234561 print("%o" % 20)2 243 print("%d" % 20)4 205 print("%x" % 20)6 14 2、浮点数输出（1）格式化输出**1. %f ——保留小数点后面六位有效数字 %.3f，保留3位小数位 %e ——保留小数点后面六位有效数字，指数形式输出 %.3e，保留3位小数位，使用科学计数法 %g ——在保证六位有效数字的前提下，使用小数方式，否则使用科学计数法 %.3g，保留3位有效数字，使用小数或科学计数法`**12345678910111213141 print("%f" % 1.11) # 默认保留6位小数2 1.1100003 print("%.1f" % 1.11) # 取1位小数4 1.15 print("%e" % 1.11) # 默认6位小数，用科学计数法6 1.110000e+007 print("%.3e" % 1.11) # 取3位小数，用科学计数法8 1.110e+009 print("%g" % 1111.1111) # 默认6位有效数字10 1111.1111 print("%.7g" % 1111.1111) # 取7位有效数字12 1111.11113 print("%.2g" % 1111.1111) # 取2位有效数字，自动转换为科学计数法14 1.1e+03 （2）内置round()**round(number[, ndigits])参数：number - 这是一个数字表达式。ndigits - 表示从小数点到最后四舍五入的位数。默认值为0。返回值该方法返回x的小数点舍入为n位数后的值。 round()函数只有一个参数，不指定位数的时候，返回一个整数，而且是最靠近的整数，类似于四舍五入，当指定取舍的小数点位数的时候，一般情况也是使用四舍五入的规则，但是碰到.5的情况时，如果要取舍的位数前的小数是奇数，则直接舍弃，如果是偶数则向上取舍。 注：“.5”这个是一个“坑”，且python2和python3出来的接口有时候是不一样的，尽量避免使用round()函数吧**1234567891011121314151 round(1.1125) # 四舍五入，不指定位数，取整2 13 round(1.1135,3) # 取3位小数，由于3为奇数，则向下“舍”4 1.1135 round(1.1125,3) # 取3位小数，由于2为偶数，则向上“入”6 1.1137 round(1.5) # 无法理解，查阅一些资料是说python会对数据进行截断，没有深究8 29 round(2.5) # 无法理解10 211 round(1.675,2) # 无法理解12 1.6813 round(2.675,2) # 无法理解14 2.6715 3、字符串输出%s%10s——右对齐，占位符10位%-10s——左对齐，占位符10位%.2s——截取2位字符串%10.2s——10位占位符，截取两位字符串1234567891011121 print("%s" % "hello world") # 字符串输出2 hello world3 print("%20s" % "hello world") # 右对齐，取20位，不够则补位4 hello world5 print("%-20s" % "hello world") # 左对齐，取20位，不够则补位6 hello world7 print("%.2s" % "hello world") # 取2位8 he9 print("%10.2s" % "hello world") # 右对齐，取2位10 he11 print("%-10.2s" % "hello world") # 左对齐，取2位12 he 4、 其他 字符串格式代码如下 （2）常用转义字符如下 二、format用法 相对基本格式化输出采用‘%’的方法，format()功能更强大，该函数把字符串当成一个模板，通过传入的参数进行格式化，并且使用大括号‘{}’作为特殊字符代替‘%’ 使用方法由两种：b.format(a)和format(a,b)。 1、基本用法 （1）不带编号，即“{}” （2）带数字编号，可调换顺序，即“{1}”、“{2}” （3）带关键字，即“{a}”、“{tom}”123456789101 print("&#123;&#125; &#123;&#125;".format("hello","world")) # 不带字段2 hello world3 print("&#123;0&#125; &#123;1&#125;".format("hello","world")) # 带数字编号4 hello world5 print("&#123;0&#125; &#123;1&#125; &#123;0&#125;".format("hello","world")) # 打乱顺序6 hello world hello7 print("&#123;1&#125; &#123;1&#125; &#123;0&#125;".format("hello","world"))8 world world hello9 print("&#123;a&#125; &#123;tom&#125; &#123;a&#125;".format(tom="hello",a="world")) # 带关键字10 world hello world 2、进阶用法 （1）（默认）左对齐、 右对齐、^ 中间对齐、= （只用于数字）在小数点后进行补齐 （2）取位数“{:4s}”、”{:.2f}”等123456789101 print("&#123;&#125; and &#123;&#125;".format("hello","world")) # 默认左对齐2 hello and world3 print("&#123;:10s&#125; and &#123;:10s&#125;".format("hello","world")) # 取10位左对齐，取10位右对齐4 hello and world5 print("&#123;:^10s&#125; and &#123;:^10s&#125;".format("hello","world")) # 取10位中间对齐6 hello and world7 print("&#123;&#125; is &#123;:.2f&#125;".format(1.123,1.123)) # 取2位小数8 1.123 is 1.129 print("&#123;0&#125; is &#123;0:10.2f&#125;".format(1.123)) # 取2位小数，右对齐，取10位10 1.123 is 1.12 3、多个格式化“b” - 二进制。将数字以2为基数进行输出。“c” - 字符。在打印之前将整数转换成对应的Unicode字符串。“d” - 十进制整数。将数字以10为基数进行输出。“o” - 八进制。将数字以8为基数进行输出。“x” - 十六进制。将数字以16为基数进行输出，9以上的位数用小写字母。“e” - 幂符号。用科学计数法打印数字。用”e”表示幂。“g” - 一般格式。将数值以fixed-point格式输出。当数值特别大的时候，用幂形式打印。“n” - 数字。当值为整数时和”d”相同，值为浮点数时和”g”相同。不同的是它会根据区域设置插入数字分隔符。“%” - 百分数。将数值乘以100然后以fixed-point(“f”)格式打印，值后面会有一个百分号。1234567891011121314151617181920211 print("&#123;0:b&#125;".format(3))2 113 print("&#123;:c&#125;".format(58))4 :5 print("&#123;:d&#125;".format(20))6 207 print("&#123;:o&#125;".format(20))8 249 print("&#123;:x&#125;".format(20))10 1411 print("&#123;:e&#125;".format(20))12 2.000000e+0113 print("&#123;:g&#125;".format(20.1))14 20.115 print("&#123;:f&#125;".format(20))16 20.00000017 print("&#123;:n&#125;".format(20))18 2019 print("&#123;:%&#125;".format(20))20 2000.000000%21 转载地址；http://www.cnblogs.com/fat39/p/7245035.html]]></content>
      <categories>
        <category>学习</category>
        <category>教学</category>
      </categories>
      <tags>
        <tag>课后解答</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第五节：散列类型，运算符]]></title>
    <url>%2F2018%2F05%2F08%2F%E7%AC%AC%E4%BA%94%E8%8A%82%EF%BC%9A%E6%95%A3%E5%88%97%E7%B1%BB%E5%9E%8B%EF%BC%8C%E8%BF%90%E7%AE%97%E7%AC%A6%2F</url>
    <content type="text"><![CDATA[[info] 一：集合（无序）集合用大括号{}表示，元素间用逗号分割 建立集合类型用{}或set（） 建立空集合类型，必须使用set（） 集合操作： （返回新集合） A|B 并 A-B 差 A&amp;B 交 A^B 补 直接在集合中更新： A|=B A-=B A&amp;=B A^=B 操作方法： 新建：set1 = set() or set1 = {1,2,3} value类型：string、tuple、frozenset、数字等不可变类型； 增：set1.add(5) 增加多个：set.update([5,6,7,8]) 删：set1.remove(1) 查：无法通过下标索引 改：不可变类型无法修改元素 与操作：set1 &amp; set2 或操作：set1 | set2 与非操作：set1 ^ set2 减：set1 - set2 判断是否是子集or超集：set1.issubset(set2) or set1.issubset(set2) 转变成list or tuple: list(set1) or tuple(set1) 二 字典（键（索引）–值（数据））新建：dict = {} or dict = {key:value,…..} key类型：string、tuple、frozenset、数字；value类型；任何类型 增：dict[key] = value 批量增（or批量改同key对应的value值）：dict.update(dict2) 删：del(dict[key]) 查：dict[key] or dict.get(key,default= value) 改：dict[key] = value 判断是否在字典的键中：dict.has_key(key) 列表形式返回字典的键or值：dict.keys() or dict.values() 列表形式返回字典的(key,value)元祖：dict.items() 三 运算符 [/info]]]></content>
      <categories>
        <category>学习</category>
        <category>教学</category>
      </categories>
      <tags>
        <tag>课后解答</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第三节：序列类型的方法]]></title>
    <url>%2F2018%2F05%2F08%2F%E7%AC%AC%E4%B8%89%E8%8A%82%EF%BC%9A%E5%BA%8F%E5%88%97%E7%B1%BB%E5%9E%8B%E7%9A%84%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[1.创建列表。只要把逗号分隔的不同的数据项使用方括号括起来即可 List = [‘wade’,’james’,’bosh’,’haslem’] 与字符串的索引一样，列表索引从0开始。列表可以进行截取、组合等 2.添加新的元素 ? List`.append(&#39;allen&#39;)#方式一：向list结尾添加 参数object` &gt;&gt;&gt; a`=[1,2,3,4]` &gt;&gt;&gt; a.append(`5)` &gt;&gt;&gt; print`(a)` [`1,` `2,3,` `4,5]` List`.insert(4,&#39;lewis&#39;)#方式二：插入一个元素 参数一：index位置 参数二：object` &gt;&gt;&gt; a`=[1,2,4]` &gt;&gt;&gt; a.insert(`2,3)` &gt;&gt;&gt; print`(a)` [`1,` `2,3,` `4]` List`.extend(tableList)#方式三：扩展列表，参数：iterable参数` &gt;&gt;&gt; a`=[1,2,3]` &gt;&gt;&gt; b`=[4,5,6]` &gt;&gt;&gt; a.extend(b) &gt;&gt;&gt; print`(a)` [`1,` `2,3,` `4,5,` `6]` 3.遍历列表 ? 1 2 for i in List`:` print i, 4.访问列表中的值 使用下标索引来访问列表中的值，同样你也可以使用方括号的形式截取字符，如下所示： ? 1 2 3 &gt;&gt;&gt; List = [`1,` `2,3,` `4,5,` `6,7]` &gt;&gt;&gt; print`(List[3])` 4 5.从list删除元素 ? 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 List`.remove()#删除方式一：参数object 如有重复元素，只会删除最靠前的` &gt;&gt;&gt; a`=[1,2,3]` &gt;&gt;&gt; a.remove(`2)` &gt;&gt;&gt; print`(a)` [`1,` `3]` List`.pop()#删除方式二：pop 可选参数index删除指定位置的元素 默认为最后一个元素` &gt;&gt;&gt; a`=[1,` `2,3,` `4,5,` `6]` &gt;&gt;&gt; a.pop() 6 &gt;&gt;&gt; print`(a)` [`1,` `2,3,` `4,5]` del List #删除方式三：可以删除整个列表或指定元素或者列表切片，list删除后无法访问。 &gt;&gt;&gt; a`=[1,` `2,3,` `4,5,` `6]` &gt;&gt;&gt; del a[`5]` &gt;&gt;&gt; print`(a)` [`1,` `2,3,` `4,5]` &gt;&gt;&gt; del a &gt;&gt;&gt; print`(a)` Traceback (most recent call last): File &quot;&lt;pyshell#93&gt;&quot;`, line1,in` print`(a)` 6.排序和反转代码 ? 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 List`.reverse()` &gt;&gt;&gt; a`=[1,` `2,3,` `4,5,` `6]` &gt;&gt;&gt; a.reverse() &gt;&gt;&gt; print`(a)` [`6,` `5,4,` `3,2,` `1]` List`.sort()#sort有三个默认参数 cmp=None,key=None,reverse=False 因此可以制定排序参数` &gt;&gt;&gt; a`=[2,4,6,7,3,1,5]` &gt;&gt;&gt; a.sort() &gt;&gt;&gt; print`(a)` [`1,` `2,3,` `4,5,` `6,7]` #python3X中，不能将数字和字符一起排序，会出现此报错 &gt;&gt;&gt; a`=[2,4,6,7,3,1,5,‘a’]` &gt;&gt;&gt; a.sort() Traceback (most recent call last): File &quot;&lt;pyshell#104&gt;&quot;`, line1,in` a.sort() TypeError: unorderable types: str`() &lt;int()` 7.Python列表截取 Python的列表截取与字符串操作类型相同，如下所示： L = [‘spam’, ‘Spam’, ‘SPAM!’] 操作： ? 1 2 3 4 Python 表达式 结果 描述 L[`2]‘SPAM!’读取列表中第三个元素` L[`-2]‘Spam’读取列表中倒数第二个元素` L[`1:] [‘Spam’,` `&#39;SPAM!&#39;] 从第二个元素开始截取列表` 8.Python列表操作的函数和方法 列表操作包含以下函数: 1、cmp(list1, list2)：比较两个列表的元素 (python3已丢弃) 2、len(list)：列表元素个数 3、max(list)：返回列表元素最大值 4、min(list)：返回列表元素最小值 5、list(seq)：将元组转换为列表 列表操作常用操作包含以下方法: 1、list.append(obj)：在列表末尾添加新的对象 2、list.count(obj)：统计某个元素在列表中出现的次数 3、list.extend(seq)：在列表末尾一次性追加另一个序列中的多个值（用新列表扩展原来的列表） 4、list.index(obj)：从列表中找出某个值第一个匹配项的索引位置 5、list.insert(index, obj)：将对象插入列表 6、list.pop(obj=list[-1])：移除列表中的一个元素（默认最后一个元素），并且返回该元素的值 7、list.remove(obj)：移除列表中某个值的第一个匹配项 8、list.reverse()：反向列表中元素 9、list.sort([func])：对原列表进行排序 注意：与字符串的方法不同，所有对列表操作的方法均会改变原有列表的值，而不是创建一个新的列表！！！修改列表元素的方法修改元素的方法用索引以及切片的方法，如： ▷ 索引： list_name[0] = ‘修改后的值’ ▷ 切片： l**ist_name[0:3] = [a,b,c] 注意：后面需要修改的值的总数可以不与切片的长度相对应，比如说[0:3]这个切片长度为3，后面可以传一个有2个或者4个元素的列表，此时，只是将切片所对应的值剔除，然后将后面列表依次插入 后面也可以赋值一个字符串，此时，只是将切片所对应的值剔除，然后将后面字符串拆开然后依次插入 list_name[0:3] = ‘fuyong’** name_list = [‘赵’,’钱’,’孙’,’李’,’周’,]name_list[2]= ‘sun’print(name_list) #结果为：[‘赵’, ‘钱’, ‘sun’, ‘李’, ‘周’] name_list[2]= name_list[2].title()print(name_list)# 结果为：[‘赵’, ‘钱’, ‘Sun’, ‘李’, ‘周’] name_list[0:2] = [‘zhao’,’qian’]print(name_list) #结果为：[‘zhao’, ‘qian’, ‘Sun’, ‘李’, ‘周’] name_list[0:2] = [‘zhao’,’qian’,’zheng’]print(name_list) #结果为：[‘zhao’, ‘qian’, ‘zheng’, ‘Sun’, ‘李’, ‘周’] name_list[0:2] = [‘zhao’]print(name_list) #结果为：[‘zhao’, ‘zheng’, ‘Sun’, ‘李’, ‘周’] name_list[0:3] = ‘fuyong’print(name_list) #结果为：[‘f’, ‘u’, ‘y’, ‘o’, ‘n’, ‘g’, ‘李’, ‘周’] 五、查询列表元素的方法查询元素的方法用索引以及切片的方法，如： ▷ 索引： list_name[0] ▷ 切片： l**ist_name[0:3] list_name[0:3:2] ** 1 name_list = [‘赵’,’钱’,’孙’,’李’,’周’,] 2 print(name_list[0]) # 赵 3 print(name_list[2]) # 孙 4 5 print(name_list[0:2]) # [‘赵’, ‘钱’] 6 print(name_list[1:]) # [‘钱’, ‘孙’, ‘李’, ‘周’] 7 8 print(name_list[0:4:2]) # [‘赵’, ‘孙’] 9 print(name_list[:4:2]) # [‘赵’, ‘孙’] 1011 print(name_list[4:0:-1]) #[‘周’, ‘李’, ‘孙’, ‘钱’] 12 print(name_list[-2:0:-1]) #[‘李’, ‘孙’, ‘钱’] 另外，如果需要查询列表中所有的元素，可以用for循环来实现，如： 1 name_list = [‘赵’,’钱’,’孙’,’李’,’周’,] 2 for name in name_list: 3 print(name) ‘’’输出结果如下： 赵 钱 孙 李 周 ‘’’ 六、列表的其他方法▷ len(list)方法： 此方法可以用来计算列表的长度，如下： 1 name_list = [‘赵’,’钱’,’孙’,’李’,’周’,] 2 print(len(name_list)) 3 #输出结果为5 ▷count()方法:此方法用来计算列表中一个元素出现的次数，如下： 1 name_list = [‘赵’,’钱’,’孙’,’李’,’周’,’赵’] 2 print(name_list.count(‘赵’)) 3 # 输出结果为2 ▷sort()方法： 次方法是对列表进行排序（列表里的元素要为数字类型），默认是正序，可以指定倒序（reverse = True） 1 num_list = [1,3,6,2,5,0,8] 2 num_list.sort() #默认为正序排列 3 print(num_list) 4 #输出结果为：[0, 1, 2, 3, 5, 6, 8] 56 num_list.sort(reverse=True) #指定reverse为True 则为倒序 7 print(num_list) 8 #输出结果为[8, 6, 5, 3, 2, 1, 0] ▷reverse(): 此方法是将列表里所有元素进行翻转，注意，不是排序，是将所有元素倒过来 ，如： 1 name_list = [‘赵’,’钱’,’孙’,’李’,’周’] 2 name_list.reverse() 3 print(name_list) 4 #结果为：[‘周’, ‘李’, ‘孙’, ‘钱’, ‘赵’] ▷join()方法： 此方法用法与字符串的join方法一样，就是将列表里的元素用指定字符连接起来，字符可以是空格，可以是空字符，可以是下划线以及任意字符，如下： 1 name_list = [‘赵’,’钱’,’孙’,’李’,’周’] 2 print(‘‘.join(name_list)) # 结果：赵钱孙李*周3 print(‘ ‘.join(name_list)) # 结果：赵 钱 孙 李 周4 print(‘’.join(name_list)) # 结果：赵钱孙李周5 print(‘‘.join(name_list)) # 结果：赵钱孙李__周 注：可以利用这种方法将一个列表转为字符串格式 七、列表的嵌套上面说过，列表里可以放一切元素，所以，当然也可以嵌套列表： 如果需要对列表里的列表进行增删改查，只需先索引到里面的列表，然后再进行操作即可，如下： name_list = [‘赵’,’钱’,’孙’,[‘付’,’傅’,’符’],’李’,’周’,’赵’] print(name_list[3][1]) # 傅print(name_list[3][0:2]) #[‘付’, ‘傅’] name_list[3][1]= ‘fu’print(name_list)# 结果为：[‘赵’, ‘钱’, ‘孙’, [‘付’, ‘fu’, ‘符’], ‘李’, ‘周’, ‘赵’] name_list[3].pop(1)print(name_list) #结果为[‘赵’, ‘钱’, ‘孙’, [‘付’, ‘符’], ‘李’, ‘周’, ‘赵’] name_list[3].remove(‘符’)print(name_list) #结果为：[‘赵’, ‘钱’, ‘孙’, [‘付’], ‘李’, ‘周’, ‘赵’] 强调：与字符串的方法不同，所有对列表操作的方法均会改变原有列表的值，而不是创建一个新的列表！！！]]></content>
      <categories>
        <category>学习</category>
        <category>教学</category>
      </categories>
      <tags>
        <tag>课后解答</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第二节：数值类型和序列类型]]></title>
    <url>%2F2018%2F05%2F08%2F%E7%AC%AC%E4%BA%8C%E8%8A%82%EF%BC%9A%E6%95%B0%E5%80%BC%E7%B1%BB%E5%9E%8B%E5%92%8C%E5%BA%8F%E5%88%97%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[[success] 一：注意事项：###Python严格缩进，严格大小写##############数值类型解释：一：整数类型（跟数学一样，可正，可负，没有取值限制）有四种表示方式： 1.十进制：110,520,991 2.二进制：以0b或0B开头：0b110,0B110 3.八进制：以0o或 0O开头：0o110,0O725 4.十六进制:以0x或0X开头：0x1A，0X78 注：第一个都是以小键盘数字0。 二：浮点型（数学中的实数）带有小数点及小数的数字 浮点数间运算尾数存在不确定性 》》》0.2+0.1 0.30000000006 》》》0.2+0.1 0.3 都是一样的，Python就这样 浮点数可以采用科学计数法 2.5e-2就是0.025 2.1E5就是210000.0 三，复数型（数学中概念一致）形如A +Bx就是复数 A 是实部，B是虚部 有什么用呢？？ Y=52+12X Y.real就可以直接获取实部 Y.imag就可以直接获取虚部 二：数值运算操作 &gt;&gt;&gt;10/3 3.3333333333335 10//3 (双斜线表整除） 3 10%3(%取余运算符） 1 》》》10**2（10的平方） 》》》25**0.5（10的开方） 三种存在老大，老小的关系——————————》》 整数————》浮点数————》复数 大包小 如10+1.0=11.0（整数+浮点数=浮点数） 四，字符串：字符串由单引号（‘ ’）或双引号(“ “)表示 如‘A’ ， “收到” 字符串是有序序列，从0开始 “收到”的第0个字符是“收” 三引号’ ‘ ‘ 可表示多行字符串，也可以来注释 如’ ‘ ‘ abc sss ‘ ‘ ‘ 三引号可以同时包含 双单引号 单可以包双，双可以包单 字符串序号： 0 1 2 3 4 5 6 口口口口口口口 -7 -6 -5-4-3-2-1 索引：返回单个字符， 字符串【字符序号】 如s[0] 切片：返回字符子串，字符串【开始序号：结束序号】 缺开头序号表示到开头，缺结尾序号表到结尾 跳跃式切片：字符串【开始序号：结尾序号：步长大小】 字符串的特殊字符“ \” 为了防止冲突表示本意 如 “等等（\“）” 输出 等等（”） 特定组合表示特定功能 如 \b(回退） \n(换行） \r(回车） [/success]]]></content>
      <categories>
        <category>学习</category>
        <category>教学</category>
      </categories>
      <tags>
        <tag>课后解答</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[第一节：开班典礼]]></title>
    <url>%2F2018%2F05%2F08%2F%E7%AC%AC%E4%B8%80%E8%8A%82%EF%BC%9A%E5%BC%80%E7%8F%AD%E5%85%B8%E7%A4%BC%2F</url>
    <content type="text"><![CDATA[[success] 一：下载网速过慢解决方案：将下载源换成国内清华源：https://mirrors.tuna.tsinghua.edu.cn/help/ubuntu/ 二：Linux常用命令： cd 路径 （进入一个路径，比如 /usr/local/lib） cd .. （返回上一个文件夹） ls （显示当前文件夹下的所有文件，Linux独有哦，dir 也有相同功能） sudo 命令 （获取超级管理权限，需要输入密码） 常用新建、删除、拷贝命令： mkdir 目录名 （新建一个文件夹，文件夹在Linux系统中叫做“目录”） touch 文件名 （新建一个空文件） rmdir 目录名 （删除一个空文件夹，文件夹里有内容则不可用） rm -rf 非空目录名 （删除一个包含文件的文件夹） rm 文件名 文件名 （删除多个文件） cp 文件名 目标路径（拷贝一个文件到目标路径，如cp hserver /opt/hqueue） cp -i （拷贝，同名文件存在时，输出 [yes/no] 询问是否执行） cp -f （强制复制文件，如有同名不询问） 常用解压、安装程序、文件更新命令：deb格式双击即可安装tar -zxvf .tar.gz ( 解压 tar.gz格式的文件 ) source .install （安装install格式的安装包） sh 路径/×.sh （安装sh格式的文件，如 sudo sh /home/hp/Downloads/.sh） sudo apt-get upgrade（更新已安装的包） sudo apt-get update （更新源） chmod +x .sh 这个命令是为sh文件增加可执行权限； chmod +R 777 . 对当前目录下的所有子目录和子文件进行 777权限的变更；通在安装软件时复制相关文件。 三：疑难解答：一：Linux与Ubuntu，CentOS等的区别： 其实Ubuntu等是Linux的发行版，就像小米系统，华为系统也是属于安卓系统。 二,使用Linux的好处： 可以增加就业机会，因为Linux是开源免费的。 可以改掉使用电脑坏习惯，让自己真正接触计算机。 开源软件越来约丰富，如ROS，Hadoop等 对配置要求很低，反正我08年笔记本电脑完美运行（新手最好拿使用双系统或者用台不常用的笔记本 [/success]）]]></content>
      <categories>
        <category>学习</category>
        <category>教学</category>
      </categories>
      <tags>
        <tag>课后解答</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[构建简单社交推荐系统——绪论]]></title>
    <url>%2F2018%2F04%2F17%2F%E6%9E%84%E5%BB%BA%E7%AE%80%E5%8D%95%E7%A4%BE%E4%BA%A4%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F%E2%80%94%E2%80%94%E7%BB%AA%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[1.兴趣来源推荐系统的研究和应用从90年代开始兴起，到现在己经有近30年的历史。GroupLens最初研究推荐Usenet上的新闻给可能感兴趣的用户。用户只需要提供对一些新闻的评分或者网站上行为数据,系统就会结合其他用户的评分和行为给出个性化推荐。在这个系统中用户可以在对其他用户或者新闻一无所知的情况下获得推荐。随后推荐系统在机器学习信息检索等领域迅速掀起热潮,众多领域开始引入推荐系统。 最有影响力的推荐应用当属亚马逊购物推荐系统，系统根据用户购买，浏览和评价历史和当前的查看的产品，推荐用户可能购买的其他产品。 在当今网络社交高涨的年代，人人都不易出门交友，导致大部分人朋友圈狭隘。假设有个好友推荐系统，能让用户匹配到性格相似，话语投机的网友，或许可以让冷漠的网络成为一方心灵疏导的乐土。 2.面临难题。1.数据收集社会加速发展，人的观念也在加速变化，无法花费大量成本收集到最新数据。 2.数据稀疏用户之间评分，评价非常少。 3.冷启动问题新用户无历史数据无法推荐。 4.如何制定评分标准一个好的评分标准直接关系到推荐系统的性能。 5.如何计算推荐效果一个好的推荐系统应该具有健壮性，让大多数人信赖。 3.协同过滤推荐算法协同过滤是从当前过去的行为和其他用户对当前用户评分来构建模型。 因为写过简单的电影推荐，所以继续采用K-最近邻（KNN）算法构建推荐系统。 KNN是用k个最近邻的训练数据集来寻找位置对象分类的算法（多数表决法）。 一般分为三个步骤：定义相似度，选择近邻，预测。 4.用户关系网络图用户-标签 ，用户-评分等等之间联系组成一个网络图，每个用户都是一张图，用户-用户间又是一张图，为了简化复杂的网络图， 将一个评价赋予权重，然后将每个用户的评价构成向量C=(V,D)，评价与评价间做余弦定理，计算余弦值，大于阈值，则说明评价对用户无关， 小于阈值，则说明有关。如此迭代，最后将整个网络看成整体，将用户看成一个向量，计算用户与用户间相似性。 待续。。。。。]]></content>
      <categories>
        <category>感悟</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[基于神经网络的入侵检测提取异常行为特征—绪论]]></title>
    <url>%2F2018%2F04%2F17%2F%E5%9F%BA%E4%BA%8E%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E7%9A%84%E5%85%A5%E4%BE%B5%E6%A3%80%E6%B5%8B%E6%8F%90%E5%8F%96%E5%BC%82%E5%B8%B8%E8%A1%8C%E4%B8%BA%E7%89%B9%E5%BE%81%E2%80%94%E7%BB%AA%E8%AE%BA%2F</url>
    <content type="text"><![CDATA[1.兴趣来源在学习计算机网络安全中的异常检测时，看到利用神经网路使用自适应学习技术来提取异常行为特征。 目前有两种主要的入侵检测，一是误用检测，二是异常检测。误用检测根据预定模式，最适用于对已知模式的可靠检测，但漏报率较高；异常检测基于一个假定（用户行为是可预测的，遵循一致性模式的，且随这用户事件的增加，自适应用户行为的变化），简而言之，就是可以检测未知攻击行为，但误报率高。 最早提出使用神经网络来构造系统/用户行为模式的是Fox，他使用Kohonen的自主学习算法（Self Organizing Map，SOM）来发现数据中隐藏的结构。 2.选用Snort原因1.Snort是免费开源软件。 2.Sonrt是用C语言编写。 3.Sonrt轻量级网络入侵检测软件。 4.Snort简单，高效，灵活。 5.Snort支持多操作平台。 6.支持多种数据库。 3.Snort体系结构Snort体系结构上由数据包捕获和解码，检测引擎，日志和报警三个子系统组成。 4.神经网络检测构思模型 待续。。。]]></content>
      <categories>
        <category>感悟</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[如何使用思维导图！]]></title>
    <url>%2F2018%2F04%2F11%2F%E5%A6%82%E4%BD%95%E4%BD%BF%E7%94%A8%E6%80%9D%E7%BB%B4%E5%AF%BC%E5%9B%BE%2F</url>
    <content type="text"><![CDATA[当你看到密密麻麻思维导图是不是很恶心！（密集恐惧症）如图: 所以希望大家下载思维导图文件（不是图片）！下载用相应软件打开：如图： 然后点分类图右边的小圈圈，进行展开：如图： 然后想看哪方面，再点相应分类的小圈圈，再次进行展开 ：如图： 所以大家别在盯着图片看 ，只能看概括 ，自己点点，记忆更深刻，当然如果你能直接看图就能理解，那就很666 软件有免费版，支持mac Windows Linux 手机。官网直接下载，无需激活直接就可以用。链接点我 [/success]]]></content>
      <categories>
        <category>工具</category>
        <category>日常工具</category>
        <category>思维导图</category>
      </categories>
      <tags>
        <tag>思维导图</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[计算机网络体系结构]]></title>
    <url>%2F2018%2F04%2F09%2F%E8%AE%A1%E7%AE%97%E6%9C%BA%E7%BD%91%E7%BB%9C%E4%BD%93%E7%B3%BB%E7%BB%93%E6%9E%84%2F</url>
    <content type="text"><![CDATA[1.计算机发展 2.计算机网络组成 3.网络功能 4.网络性能指标 5.网络分类 6.网络接口，协议，服务 疑难解答：1.协议与服务有什么区别与联系？协议是控制两个对等实体进行通信的规则集合，在协议控制下，两个对等实体间使得本层能向下，向上一层提供服务 区别：协议的实现保证了能够向上一层提供服务。本层服务用户只能看见服务而无法看见下面协议 协议是水平的，服务是垂直的 2.计算机网络与分布式系统别区二者区别主要是软件不同 3.速率提高体现在单位时间发送到链路上的比特数增多，并不是跑的快了！4.理解传输时延，发送时延，传播时延传输时延就是发送时延。 传播时延是指电磁波在信道传播一定距离花费的时间 传播时延=信道长度/电磁波在信道上的传播速率 如何下载使用思维导图（点我） 思维导图下载：链接：https://pan.yangxin.com/s/1TJXj8CgDO-JUbpgcTY6AWg [reply]密码：rdxd[/reply] 待续。。。。。。。]]></content>
      <categories>
        <category>学习</category>
        <category>计算机网络</category>
        <category>网络体系</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WordPress页面，分页函数调用，主题函数调用，模板函数调用]]></title>
    <url>%2F2018%2F04%2F09%2FWordPress%E9%A1%B5%E9%9D%A2%EF%BC%8C%E5%88%86%E9%A1%B5%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%EF%BC%8C%E4%B8%BB%E9%A2%98%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%EF%BC%8C%E6%A8%A1%E6%9D%BF%E5%87%BD%E6%95%B0%E8%B0%83%E7%94%A8%2F</url>
    <content type="text"><![CDATA[WordPress页面，分页函数调用，主题函数调用，模板函数调用 1描述 2与WP_Query的互动 3用法 4方法和属性 4.1属性 4.2方法 5参数 5.1作者 5.2分类目录 5.3标签 5.4自定义分类法 5.5搜索 5.6文章＆页面 5.7文章类型 5.8文章状态 5.9分页 5.10排序 5.11置顶文章 5.12时间 5.13自定义字段 5.14权限 5.15缓存 5.16返回字段 官网法典]]></content>
      <categories>
        <category>网站</category>
        <category>wordpress</category>
      </categories>
      <tags>
        <tag>wordpress</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[php中添加html中的css，js，图片，视频等外部文件方法]]></title>
    <url>%2F2018%2F04%2F08%2Fphp%E4%B8%AD%E6%B7%BB%E5%8A%A0html%E4%B8%AD%E7%9A%84css%EF%BC%8Cjs%EF%BC%8C%E5%9B%BE%E7%89%87%EF%BC%8C%E8%A7%86%E9%A2%91%E7%AD%89%E5%A4%96%E9%83%A8%E6%96%87%E4%BB%B6%E6%96%B9%E6%B3%95%2F</url>
    <content type="text"><![CDATA[php中添加html中的css，js，图片，视频等外部文件方法方法一：1、将 xx.html 修改为 page-xx.php 上传到你当前使用的主题目录中； 2、在WordPress后台创建别名为 xx 的页面后发布，大功告成。 注意：创建的页面别名一定要与page-后面一样。或者在步骤1中将xx改为你的页面ID。 方法二：1、将 xx.html 修改为page-template-xx.php 然后再该文件头部添加： &lt;?php /* Template Name: xx 页面模板 */ ?&gt; 然后上传到你当前使用的主题目录中； 2、在WordPress后台创建别名为 xx 的页面并选择页面模板为第一步中创建的 xx页面模板，然后发布，大功告成。 如果你添加的页面是首页，可以在 设置 &gt; 阅读 > 首页显示 中设置将此页面设置为首页。 关于CSS、JS、图片等外部文件如果你的页面有引用CSS、JS以及图片，例如：sample.css、sample.js、sample.jpg，可以将这些文件一并复制到主题目录下，然后引用地址改为： &lt;link href=&quot;&lt;?php echo get_theme_file_uri( &apos;sample.css&apos; ); ?&gt;&quot; rel=&quot;stylesheet&quot; type=&quot;text/css&quot; /&gt; &lt;script src=&quot;&lt;?php echo get_theme_file_uri( &apos;sample.js&apos; ); ?&gt;&quot; type=&quot;text/javascript&quot;&gt;&lt;/script&gt; &lt;img src=&quot;&lt;?php echo get_theme_file_uri( &apos;sample.jpg&apos; ); ?&gt;&quot; /&gt; 如果有视频等，同上面方法。 如果你想了解更多：2017.11.04 新增： 上面介绍了将WordPress转换为Page（页面）的方法，下面介绍转换为首页、分类、标签、文章等页面的方法： front-page.php：这个文件是首页，如果没有则使用上面方法二中在后台设置为首页的页面； home.php：文档归档页面，通常1中都没有使用这个显示首页； index.php：1、2都没有使用这个显示首页； single.php：文章模板文件； 404.php：404页面文件； page.php：页面模板文件，支持 page-$id （即页面 ID）或 page-$slug （即页面别名）； category.php：分类归档模板文件，支持 category-$id 或category-$slug ； tag.php：标签归档模板文件，支持 category-$id 或category-$slug ； author.php：作者归档模板文件，支持 category-$id 或 category-$slug； date.php：日期归档模板文件； archive.php：如果主题没有7-10之中的任一文件，那么都会用此模板文件显示对应内容，当此模板文件也不存在时，则使用index.php显示，支持 archive-$id 或archive-$slug。 header.php、footer.php、sidebar.php等文件一般都是“页面部分”模板文件，即：页眉、页脚、边栏。 如果你能看懂英文，详细可参考官方文档： WordPress模板文件等级介绍（官方） WordPress获取主题目录里的文件和目录 @马向阳]]></content>
      <categories>
        <category>网站</category>
        <category>wordpress</category>
      </categories>
      <tags>
        <tag>wordpress</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[物理层]]></title>
    <url>%2F2018%2F04%2F05%2F%E7%89%A9%E7%90%86%E5%B1%82%2F</url>
    <content type="text"><![CDATA[物理层基本概念 数据 信号 码元 数据通信组成 信源 信宿 信道 基带传输 宽带传输 通信交互方式 单工通信 半双工通信 全双工通信 传输性能指标 码元速率 信息速率（比特率,带宽） 两大定理 奈奎斯特定理 得出任何信道码元传输速率都是有上限，超出则会出现码间串扰问题 采样定理 得出 带宽越高，速率越高 给出了码元传输率限制，并没有对信息速率限制 香农定理 得出带宽或信道中信噪比越大，信息传输率越高 得出只要有确定带宽和信噪比确定，信息传输率上限确定 只要信息传输率低于信道极限传输率，就一定有方法实现无差错传输 实际信道传输率比香农的传输率低 编码与调制 编码 数字数据转数字信号 非归零编码 曼切斯特编码 差分曼切斯特编码 4B/5B,8B/10B编码 模拟数据转数字信号 采用抽样定理 抽样 量化 编码 调制 数字数据调制为模拟信号 ASK（只改变振幅来表示0,1） FSK（只改变频率来表示1,0） PSK(只改变相位来表示1，0） QAM（正交振幅调制）频率相同条件下，将ASK,PSK（就是冷门的方法）结合 模拟数据装模拟信号 FDM（频分复用技术） 交换技术 电路交换 重要优点 延迟小，数据直达 缺点 复杂，利用率低，建立时间太长 报文交换 分组交换 网络层提供服务 数据报（无连接） 就是想发就发，哪里线路好，往哪里走 虚电路（面向连接） 先修路，然后开车送货 传输介质与设备 传输介质 双绞线 屏蔽双绞线STP 非屏蔽双绞线UTP 同轴电缆 50欧姆（基带同轴电缆） 75欧姆（宽带同轴电缆） 光纤 光源：发光二极管 光的折射（多模光纤 光源：激光二极管 光的直射（单模光纤） 无线传输 无线电波 微波，红外线，激光 接口特性 机械特性 电气特性 功能特性 规程特性 设备 中继器（转发器） 个数不能超过四个 5-4-3规则 不整形的中继器 放大器 集线器（多端口中继器）HUB 逻辑上还是个总线型网络，只能在半双工工作 疑难解答：1.集线器连接的网络是星形，但逻辑上仍然是个总线网 2传输媒介是物理层吗？ 传输媒介不是物理层，可以说是0层，但不能说他属于物理层 3.同步？异步？同步通信？异步通信？ 同步：指某个函数的执行方式 ，函数调用者等待函数执行完后进行下一步 异步：就是不同步 同步通信：通信双方时钟调整到同一个频率，通信双方不停发送接受比特流。分为全网同步（北京时间）， 准同步（四川时间，结点之间允许有误差） 异步通信：发送字符时，发送端字符间可以有时间间隔（所以出现帧格式有开始位，停止位）， 接收端时刻准备接收（有点像c/s模型）]]></content>
      <categories>
        <category>学习</category>
        <category>计算机网络</category>
        <category>物理层</category>
      </categories>
      <tags>
        <tag>计算机网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[数据链路层]]></title>
    <url>%2F2018%2F04%2F05%2F%E6%95%B0%E6%8D%AE%E9%93%BE%E8%B7%AF%E5%B1%82%2F</url>
    <content type="text"><![CDATA[[success] 今天过生，把最难得数据链路层整理下：计算机网络学不好，说真的，确实是数据链路层没搞懂，以前忽视了，现在整理下：数据链路层组帧方法 字符计数法 用个计数字段来表明帧内字符数 字符填充首尾定界法 用开始（DLE STX)和结束（DLE ETX)来控制首尾定界 他的透明传输表现 如果数据部分出现DLE ，发方则在数据部分在加个DLE， 以区别首尾定界，收方收到两个DLE,DLE则删除一个 常用组帧方法 比特填充法 首尾用01111110来标志一帧的开始与结束 他的透明传输表现 如果数据部分出现五个连续1，发方则在五个1后面插入一个0；接收方相反 违规编码法 在物理层编码时，曼切斯特编码用了高低电平表示0,1. 违规编码则是用高高，低低电平表示起始，因为在物理层完成定界，所以不需要要任何技术就能实现透明传输 差错控制 ARQ（自动重传请求） FEC（前向纠错） 检错编码 奇偶校检码 垂直奇偶校检 水平奇偶校检 水平垂直奇偶校检 CRC（循环冗余码） 纠错编码 海明码 M个信息位插入R个校检位组成m+r位码字 ，必须满足关系2^r&gt;=m+r+1; 流控与可靠传输 滑动窗口流控 发送窗口=1，接受窗口=1 停等流控 发方每发送一个帧，必须收到应答才发送下一个帧 发送窗口&gt;1，接受窗口=1 回退N流控 1&lt;=发送窗口&lt;=2^n-1 发送窗口&gt;1，接受窗口&gt;1 选择重传流控 接收窗口+发送窗口&lt;=2^n，接收窗口必须小于序列号范围的一半，接收窗口&lt;=2^(n-1)，否则无意义。 介质访问控制（MAC） 信道划分介质访问控制 频分多路复用（FDM) 将多路基带信号调制到不同频率载波，在进行叠加形成一个符合信号 时分多路复用(TDM) 将一条物理信道按时间分成若干时间片，理论刘分配给多个信号使用 升级版：统计(异步)时分多路复用（STDM) 区别：将固定分配时隙改进成按需动态分配时隙 波分多路复用（WDM） 就是光的频分多路复用：光纤中传输不同波长（频率）的光，通过频率不同分解合成 码分多路复用（cdm) 原理:靠不同编码来区分各路原始信号（共享频率，共享时间） 复用方式 码分多址（cdma） 优点：利用率高，保密强，语音通信好，成本低 应用：无线通信，特别是移动通信 随机访问介质访问控制 ALOHA协议 纯ALOHA 当网络任一站点需要发送数据，不检测就发，如果没收到确认，就等一段时间在发 升级版：时隙ALOHA 区别：把网络时间同步，将时间分成等段的时隙，规定只能在时隙开始时才能发送 csma协议 1-坚持协议（100%发送） 侦听-空闲就发 侦听-忙则等待，并继续侦听到空闲为止 冲突-随机等待一段时间-重新侦听 0-坚持（非坚持）协议 侦听-空闲就发 侦听-忙则放弃侦听，等待随机一段时间 p-坚持协议 侦听-空闲就以p的概率发 以1-p的概率推迟到下个时隙 侦听-忙则等待下个时隙侦听 冲突-随机等待一段时间-重新侦听 CDMA/CD协议 工作流程 先听后发，边听边发，冲突停发，随机重发 检测冲突 以太网端到端往返时间2t叫做争用期（冲突窗口或碰撞期） 最小帧长=总线传播时延（t)*数据传输率（C）*2 冲突后处理 二进制退避法 随着冲突重传次数增大而增大 使用范围 用于总线型网络或半双工网络 CDMA/ca协议 应用：局域网和无线局域网 区别：将cd（碰撞检测）改成ca（碰撞避免） 轮询访问介质访问控制 令牌传递协议 持令发，没持不准发 局域网LAN 以太网(ieee802.3) 逻辑：总线 物理：星形 以太网MAC地址 使用6字节（48比特）地址 高速以太网 100dase-t以太网 吉比特以太网 10吉比特以太网 无线局域网（ieee802.11） 有基础设施 最小单位：基本服务集(BSS) bss中基站也叫接入点（ap） 无基础设施（ad hoc） 令牌环网（IEEE802.5） 逻辑：环形 物理：星形 fddi（IEEE802.8） 逻辑：环形 物理：双环 广域网 面向字节 ppp协议（点到点） 组成 链路控制协议（lcp） 网络控制协议（ncp） 将ip数据报封装在链路的方法 透明传输方法 ppp在异步线路（默认） 使用字节填充法 ppp在sonet/sdh同步线路 使用比特填充法（HDLC一样） 面向比特 hdlc协议 分类 非平衡配置 平衡配置 站的类型 主站 从站 复合站 操作方式 正常响应方式 主站向从站传输数据，从站要得到主站许可，才可以做事（响应） 异步平衡方式 每个复合站都可以向另一个站传输数据 异步响应方式 从站没接受主站许可就可以传输 帧结构 信息帧（i）第一位为0 监控帧（S) 第一二位为1,0 无编号帧（u）第一二位为1,1 设备 网桥 网段概念 通过网桥连接起来的以太网，每个以太网就叫网段 工作层次 链路层的mac子层 路径选择算法 透明网桥 转发表建立方式 自学习算法：从某端口进来，一定能从相反端口出去 工作方式 源端口与目的端口一样，丢弃 源端口与目的端口不同，转发 目的端口未知，扩散 源路由网桥 工作方式 1.广播发送一个发现帧去探索。 2.每个目的站应答，然后发送应答帧 3.应答帧原路径返回，途径网桥把自己标志记录在应答帧中 4.源站确定最佳路由（路线/转发表），以后凡是从这个源发往该目的都要携带理由信息。 局域网交换机（多端口网桥） 交换模式 直通交换 存储转发交换 最大优点 用户独占带宽 加入vlan 可以隔离冲突域，广播域 原理 检测源目的mac地址，查找表，若没有在表中，则加入表，然后再转发 功能 为网络层提供服务 无确认无连接 以太网 有确认无连接 无线网 有确认面向连接 通信要求（可靠性，实时性）较高的场合 链路管理 组帧 帧定界 确定帧的边界（界限） 帧同步 接收方能从比特流中分出帧的起止 透明传输 防止出现数据部分出现与帧定界一样的组合 流控 控制收发的速率，以及缓存空间（窗口）大小 差错控制 位错 ARQ（自动重传请求） CRC（循环冗余校检） 帧错 定时器 编号机制 如何下载使用思维导图（点我） 思维导图下载 链接：https://pan.yangxin.com/s/1J1fkVM3qZEmjMmIydz9lmw [/success] [reply]密码：sml6 [/reply]]]></content>
      <categories>
        <category>学习</category>
        <category>计算机网络</category>
        <category>数据链路层</category>
      </categories>
      <tags>
        <tag>网络</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[解决wordpress下载插件 安装失败 无法创建目录问题]]></title>
    <url>%2F2018%2F04%2F05%2F%E8%A7%A3%E5%86%B3wordpress%E4%B8%8B%E8%BD%BD%E6%8F%92%E4%BB%B6%20%E5%AE%89%E8%A3%85%E5%A4%B1%E8%B4%A5%20%E6%97%A0%E6%B3%95%E5%88%9B%E5%BB%BA%E7%9B%AE%E5%BD%95%E9%97%AE%E9%A2%98%2F</url>
    <content type="text"><![CDATA[[warning] 本文只针对liunxmac可以简单直接更改文件权限，windows 直接获取管理员权限 用户名组名为 www-data(大家可能不太一样）而此时wordpress用户组为root，这样就不能创建目录了，具体原因大家可以查阅linux相关知识。 我们在default目录下 输入ls -l wordpress (wordpress目录具体地址) 就可以看到用户组了，下面是未修改的用户和用户组，都是root 如果不知道自己用户组是www-data还是www ，网上教程都是www，于是自己直接在外面创建文件，然后赋予权限 ，最后ls -l 展示下 发现如图 自己全是www-data 说明自己是www-data用户组 然后修改wordpress目录下整体权限（我是直接把wordprss解压到www下的） 然后大功告成 [/warning]]]></content>
      <categories>
        <category>网站</category>
        <category>wordpress</category>
      </categories>
      <tags>
        <tag>wordpress</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[为什么我要写博客！]]></title>
    <url>%2F2018%2F04%2F05%2F%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E8%A6%81%E5%86%99%E5%8D%9A%E5%AE%A2%EF%BC%81%2F</url>
    <content type="text"><![CDATA[一 不想写博客的原因： 想写，但不知道写什么 没有深厚底蕴，害怕没有意义 害怕浪费宝贵时间 生活繁忙，没有时间整理写作 觉得自己能记住 有度粮，Google等可以查阅 偷懒，不想整理思绪 二 想写博客的原因； 怕自己日后会用到 网络信息繁杂，只有自己实践过的才是真理 提高自己思维整理能力 为自己人生留下些许痕迹 能让他人获得些许帮助 养成良好习惯 汇中式再次学习 记录学习历程 三 为何自建网站写博客: 自己做的比较了解和维护 没有庸俗繁杂广告 可以逼迫自己再次学习相关知识 比较好看，简洁 价格低廉，平均每年约为30元 四 总结；对于一个技术人员来讲 ，写博客是对自己能力，思维，技能，知识的提升和挑战，写博客虽然非常花费时间，但是当网络信息拥堵的年代，这时间花费性价比最高，是最值得的。博客不需要太复杂，简简单单就好。给自己一份勇气，大胆去想，勇敢去写 五 博客结构:框架 pytorch tensorflow 编程 C++ python 界面 PyQT QT 网站 hexo wordpress html 学习 教学 计算机网络 算法 工具 日常工具 嵌入式 感悟]]></content>
      <categories>
        <category>感悟</category>
      </categories>
      <tags>
        <tag>心理</tag>
      </tags>
  </entry>
</search>
